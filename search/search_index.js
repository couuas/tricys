var __index = {"config":{"lang":["en","zh"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"TRICYS: \u6c1a\u71c3\u6599\u5faa\u73af\u96c6\u6210\u4eff\u771f\u5e73\u53f0","text":"<p>\u6b22\u8fce\u4f7f\u7528 TRICYS (TRitium Integrated CYcle Simulation) \u6c1a\u71c3\u6599\u5faa\u73af\u96c6\u6210\u4eff\u771f\u5e73\u53f0\u3002TRICYS \u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u6a21\u5757\u5316\u3001\u591a\u5c3a\u5ea6\u7684\u805a\u53d8\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u4eff\u771f\u5668\uff0c\u65e8\u5728\u63d0\u4f9b\u57fa\u4e8e\u7269\u7406\u7684\u52a8\u6001\u95ed\u73af\u5206\u6790\uff0c\u5e76\u4e25\u683c\u9075\u5b88\u5168\u5382\u8303\u56f4\u7684\u8d28\u91cf\u5b88\u6052\u539f\u5219\u3002</p> <p>\u6211\u4eec\u7684\u76ee\u6807\u662f\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u4e14\u5f3a\u5927\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u63a2\u7d22\u5404\u79cd\u6c1a\u7ba1\u7406\u7b56\u7565\u3001\u4f18\u5316\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5e76\u6df1\u5165\u7406\u89e3\u805a\u53d8\u53cd\u5e94\u5806\u73af\u5883\u4e2d\u6c1a\u7684\u6d41\u52a8\u4e0e\u5e93\u5b58\u52a8\u6001\u3002</p> <p>\u6211\u4eec\u6b22\u8fce\u793e\u533a\u8d21\u732e\uff01\u65e0\u8bba\u60a8\u662f\u805a\u53d8\u79d1\u5b66\u5bb6\u3001\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u8fd8\u662f\u5bf9\u5f00\u6e90\u9879\u76ee\u5145\u6ee1\u70ed\u60c5\u7684\u7231\u597d\u8005\uff0c\u90fd\u6709\u591a\u79cd\u65b9\u5f0f\u53c2\u4e0e TRICYS \u7684\u53d1\u5c55\u3002</p> <p>\u5feb\u901f\u5f00\u59cb \u62a5\u544a\u95ee\u9898 \u6c1a\u71c3\u6599\u5faa\u73af0\u7ef4\u7cfb\u7edf\u793a\u4f8b\u6a21\u578b</p>"},{"location":"index.html#tricys_1","title":"\ud83d\udcda TRICYS \u80fd\u505a\u4ec0\u4e48\uff1f","text":"<ul> <li>\u53c2\u6570\u626b\u63cf\u4e0e\u5e76\u53d1\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u591a\u4e2a\u53c2\u6570\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u652f\u6301\u5e76\u53d1\u8fd0\u884c\u548c\u5927\u89c4\u6a21\u6279\u91cf\u4eff\u771f\u3002</li> <li>\u5b50\u6a21\u5757\u534f\u540c\u4eff\u771f\uff1a\u652f\u6301\u4e0e\u5916\u90e8\u5de5\u5177\uff08\u5982 Aspen Plus\uff09\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u5b8c\u6210\u5b50\u6a21\u5757\u7cfb\u7edf\u96c6\u6210\u3002</li> <li>\u81ea\u52a8\u5316\u62a5\u544a\u751f\u6210\uff1a\u81ea\u52a8\u751f\u6210\u6807\u51c6\u5316\u7684 Markdown \u5206\u6790\u62a5\u544a\uff0c\u5305\u542b\u56fe\u8868\u3001\u7edf\u8ba1\u6570\u636e\u548c\u53ef\u89c6\u5316\u7ed3\u679c\u3002</li> <li>\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a\u652f\u6301\u7cfb\u7edf\u53c2\u6570\u7684\u81ea\u5b9a\u4e49\u654f\u611f\u6027\u5206\u6790\uff0c\u5e76\u96c6\u6210SALib\uff08Sensitivity Analysis Library in Python\uff09\u5e93\u91cf\u5316\u53c2\u6570\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002</li> </ul>"},{"location":"index.html#tricys_2","title":"\ud83d\udd2c \u4e3a\u4ec0\u4e48\u9009\u62e9 TRICYS\uff1f","text":"<ul> <li>\u51c6\u786e\u6027\u4e0e\u7075\u6d3b\u6027\uff1a\u7ed3\u5408\u8be6\u7ec6\u7684\u7269\u7406\u6a21\u578b\u548c\u9ad8\u5ea6\u53ef\u914d\u7f6e\u7684\u7cfb\u7edf\u67b6\u6784\u3002</li> <li>\u6a21\u5757\u5316\u8bbe\u8ba1\uff1a\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u3002</li> <li>\u5de5\u4e1a\u5e94\u7528\uff1a\u9002\u7528\u4e8e\u805a\u53d8\u5806\u8bbe\u8ba1\u4f18\u5316\u3001\u8fd0\u884c\u7b56\u7565\u8bc4\u4f30\u548c\u5b89\u5168\u5206\u6790\u3002</li> <li>\u793e\u533a\u9a71\u52a8\uff1a\u53d7\u76ca\u4e8e\u534f\u4f5c\u5f00\u53d1\u548c\u900f\u660e\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002</li> <li>\u6559\u80b2\u5de5\u5177\uff1a\u4e3a\u5b66\u751f\u548c\u65b0\u7814\u7a76\u4eba\u5458\u7406\u89e3\u805a\u53d8\u71c3\u6599\u5faa\u73af\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u6781\u597d\u7684\u8d44\u6e90\u3002</li> </ul>"},{"location":"changelog.html","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<p>TRICYS \u9075\u5faa\u8bed\u4e49\u5316\u7248\u672c\u89c4\u8303\uff08Semantic Versioning\uff09\uff1a</p> <ul> <li>\u4e3b\u7248\u672c\u53f7\uff08Major\uff09\uff1a\u8fdb\u884c\u4e0d\u517c\u5bb9\u7684 API \u53d8\u66f4\u65f6\u9012\u589e</li> <li>\u6b21\u7248\u672c\u53f7\uff08Minor\uff09\uff1a\u4ee5\u5411\u540e\u517c\u5bb9\u7684\u65b9\u5f0f\u6dfb\u52a0\u65b0\u529f\u80fd\u65f6\u9012\u589e</li> <li>\u4fee\u8ba2\u53f7\uff08Patch\uff09\uff1a\u8fdb\u884c\u5411\u540e\u517c\u5bb9\u7684\u95ee\u9898\u4fee\u6b63\u65f6\u9012\u589e</li> </ul>"},{"location":"changelog.html#100-2025-11-15","title":"1.0.0 ( 2025-11-15 )","text":"<p>TRICYS 1.0.0 \u662f\u9879\u76ee\u7684\u9996\u4e2a\u6b63\u5f0f\u7a33\u5b9a\u7248\u672c\uff0c\u6807\u5fd7\u7740\u6838\u5fc3\u529f\u80fd\u7684\u5b8c\u5584\u548c\u751f\u4ea7\u73af\u5883\u5c31\u7eea\u3002</p> <ul> <li>\u53c2\u6570\u626b\u63cf\u4e0e\u5e76\u53d1\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u591a\u4e2a\u53c2\u6570\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u652f\u6301\u5e76\u53d1\u8fd0\u884c\u548c\u5927\u89c4\u6a21\u6279\u91cf\u4eff\u771f\u3002</li> <li>\u5b50\u6a21\u5757\u534f\u540c\u4eff\u771f\uff1a\u652f\u6301\u4e0e\u5916\u90e8\u5de5\u5177\uff08\u5982 Aspen Plus\uff09\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u5b8c\u6210\u5b50\u6a21\u5757\u7cfb\u7edf\u96c6\u6210\u3002</li> <li>\u81ea\u52a8\u5316\u62a5\u544a\u751f\u6210\uff1a\u81ea\u52a8\u751f\u6210\u6807\u51c6\u5316\u7684 Markdown \u5206\u6790\u62a5\u544a\uff0c\u5305\u542b\u56fe\u8868\u3001\u7edf\u8ba1\u6570\u636e\u548c\u53ef\u89c6\u679c\u3002</li> <li>\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a\u652f\u6301\u7cfb\u7edf\u53c2\u6570\u7684\u81ea\u5b9a\u4e49\u654f\u611f\u6027\u5206\u6790\uff0c\u5e76\u96c6\u6210SALib\uff08SensitivitAnalysis Library in Python\uff09\u5e93\u91cf\u5316\u53c2\u6570\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002</li> </ul>"},{"location":"license.html","title":"\u5f00\u6e90\u8bb8\u53ef","text":"<pre><code>                                                              Apache License\n                                                        Version 2.0, January 2004\n                                                     http://www.apache.org/licenses/\n\n                                TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n                                1. Definitions.\n\n                                   \"License\" shall mean the terms and conditions for use, reproduction,\n                                   and distribution as defined by Sections 1 through 9 of this document.\n\n                                   \"Licensor\" shall mean the copyright owner or entity authorized by\n                                   the copyright owner that is granting the License.\n\n                                   \"Legal Entity\" shall mean the union of the acting entity and all\n                                   other entities that control, are controlled by, or are under common\n                                   control with that entity. For the purposes of this definition,\n                                   \"control\" means (i) the power, direct or indirect, to cause the\n                                   direction or management of such entity, whether by contract or\n                                   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n                                   outstanding shares, or (iii) beneficial ownership of such entity.\n\n                                   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n                                   exercising permissions granted by this License.\n\n                                   \"Source\" form shall mean the preferred form for making modifications,\n                                   including but not limited to software source code, documentation\n                                   source, and configuration files.\n\n                                   \"Object\" form shall mean any form resulting from mechanical\n                                   transformation or translation of a Source form, including but\n                                   not limited to compiled object code, generated documentation,\n                                   and conversions to other media types.\n\n                                   \"Work\" shall mean the work of authorship, whether in Source or\n                                   Object form, made available under the License, as indicated by a\n                                   copyright notice that is included in or attached to the work\n                                   (an example is provided in the Appendix below).\n\n                                   \"Derivative Works\" shall mean any work, whether in Source or Object\n                                   form, that is based on (or derived from) the Work and for which the\n                                   editorial revisions, annotations, elaborations, or other modifications\n                                   represent, as a whole, an original work of authorship. For the purposes\n                                   of this License, Derivative Works shall not include works that remain\n                                   separable from, or merely link (or bind by name) to the interfaces of,\n                                   the Work and Derivative Works thereof.\n\n                                   \"Contribution\" shall mean any work of authorship, including\n                                   the original version of the Work and any modifications or additions\n                                   to that Work or Derivative Works thereof, that is intentionally\n                                   submitted to Licensor for inclusion in the Work by the copyright owner\n                                   or by an individual or Legal Entity authorized to submit on behalf of\n                                   the copyright owner. For the purposes of this definition, \"submitted\"\n                                   means any form of electronic, verbal, or written communication sent\n                                   to the Licensor or its representatives, including but not limited to\n                                   communication on electronic mailing lists, source code control systems,\n                                   and issue tracking systems that are managed by, or on behalf of, the\n                                   Licensor for the purpose of discussing and improving the Work, but\n                                   excluding communication that is conspicuously marked or otherwise\n                                   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n                                   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n                                   on behalf of whom a Contribution has been received by Licensor and\n                                   subsequently incorporated within the Work.\n\n                                2. Grant of Copyright License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   copyright license to reproduce, prepare Derivative Works of,\n                                   publicly display, publicly perform, sublicense, and distribute the\n                                   Work and such Derivative Works in Source or Object form.\n\n                                3. Grant of Patent License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   (except as stated in this section) patent license to make, have made,\n                                   use, offer to sell, sell, import, and otherwise transfer the Work,\n                                   where such license applies only to those patent claims licensable\n                                   by such Contributor that are necessarily infringed by their\n                                   Contribution(s) alone or by combination of their Contribution(s)\n                                   with the Work to which such Contribution(s) was submitted. If You\n                                   institute patent litigation against any entity (including a\n                                   cross-claim or counterclaim in a lawsuit) alleging that the Work\n                                   or a Contribution incorporated within the Work constitutes direct\n                                   or contributory patent infringement, then any patent licenses\n                                   granted to You under this License for that Work shall terminate\n                                   as of the date such litigation is filed.\n\n                                4. Redistribution. You may reproduce and distribute copies of the\n                                   Work or Derivative Works thereof in any medium, with or without\n                                   modifications, and in Source or Object form, provided that You\n                                   meet the following conditions:\n\n                                   (a) You must give any other recipients of the Work or\n                                       Derivative Works a copy of this License; and\n\n                                   (b) You must cause any modified files to carry prominent notices\n                                       stating that You changed the files; and\n\n                                   (c) You must retain, in the Source form of any Derivative Works\n                                       that You distribute, all copyright, patent, trademark, and\n                                       attribution notices from the Source form of the Work,\n                                       excluding those notices that do not pertain to any part of\n                                       the Derivative Works; and\n\n                                   (d) If the Work includes a \"NOTICE\" text file as part of its\n                                       distribution, then any Derivative Works that You distribute must\n                                       include a readable copy of the attribution notices contained\n                                       within such NOTICE file, excluding those notices that do not\n                                       pertain to any part of the Derivative Works, in at least one\n                                       of the following places: within a NOTICE text file distributed\n                                       as part of the Derivative Works; within the Source form or\n                                       documentation, if provided along with the Derivative Works; or,\n                                       within a display generated by the Derivative Works, if and\n                                       wherever such third-party notices normally appear. The contents\n                                       of the NOTICE file are for informational purposes only and\n                                       do not modify the License. You may add Your own attribution\n                                       notices within Derivative Works that You distribute, alongside\n                                       or as an addendum to the NOTICE text from the Work, provided\n                                       that such additional attribution notices cannot be construed\n                                       as modifying the License.\n\n                                   You may add Your own copyright statement to Your modifications and\n                                   may provide additional or different license terms and conditions\n                                   for use, reproduction, or distribution of Your modifications, or\n                                   for any such Derivative Works as a whole, provided Your use,\n                                   reproduction, and distribution of the Work otherwise complies with\n                                   the conditions stated in this License.\n\n                                5. Submission of Contributions. Unless You explicitly state otherwise,\n                                   any Contribution intentionally submitted for inclusion in the Work\n                                   by You to the Licensor shall be under the terms and conditions of\n                                   this License, without any additional terms or conditions.\n                                   Notwithstanding the above, nothing herein shall supersede or modify\n                                   the terms of any separate license agreement you may have executed\n                                   with Licensor regarding such Contributions.\n\n                                6. Trademarks. This License does not grant permission to use the trade\n                                   names, trademarks, service marks, or product names of the Licensor,\n                                   except as required for reasonable and customary use in describing the\n                                   origin of the Work and reproducing the content of the NOTICE file.\n\n                                7. Disclaimer of Warranty. Unless required by applicable law or\n                                   agreed to in writing, Licensor provides the Work (and each\n                                   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n                                   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n                                   implied, including, without limitation, any warranties or conditions\n                                   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n                                   PARTICULAR PURPOSE. You are solely responsible for determining the\n                                   appropriateness of using or redistributing the Work and assume any\n                                   risks associated with Your exercise of permissions under this License.\n\n                                8. Limitation of Liability. In no event and under no legal theory,\n                                   whether in tort (including negligence), contract, or otherwise,\n                                   unless required by applicable law (such as deliberate and grossly\n                                   negligent acts) or agreed to in writing, shall any Contributor be\n                                   liable to You for damages, including any direct, indirect, special,\n                                   incidental, or consequential damages of any character arising as a\n                                   result of this License or out of the use or inability to use the\n                                   Work (including but not limited to damages for loss of goodwill,\n                                   work stoppage, computer failure or malfunction, or any and all\n                                   other commercial damages or losses), even if such Contributor\n                                   has been advised of the possibility of such damages.\n\n                                9. Accepting Warranty or Additional Liability. While redistributing\n                                   the Work or Derivative Works thereof, You may choose to offer,\n                                   and charge a fee for, acceptance of support, warranty, indemnity,\n                                   or other liability obligations and/or rights consistent with this\n                                   License. However, in accepting such obligations, You may act only\n                                   on Your own behalf and on Your sole responsibility, not on behalf\n                                   of any other Contributor, and only if You agree to indemnify,\n                                   defend, and hold each Contributor harmless for any liability\n                                   incurred by, or claims asserted against, such Contributor by reason\n                                   of your accepting any such warranty or additional liability.\n\n                                END OF TERMS AND CONDITIONS\n\n                                APPENDIX: How to apply the Apache License to your work.\n\n                                   To apply the Apache License to your work, attach the following\n                                   boilerplate notice, with the fields enclosed by brackets \"[]\"\n                                   replaced with your own identifying information. (Don't include\n                                   the brackets!)  The text should be enclosed in the appropriate\n                                   comment syntax for the file format. We also recommend that a\n                                   file or class name and description of purpose be included on the\n                                   same \"printed page\" as the copyright notice for easier\n                                   identification within third-party archives.\n\n                                Copyright [yyyy] [name of copyright owner]\n\n                                Licensed under the Apache License, Version 2.0 (the \"License\");\n                                you may not use this file except in compliance with the License.\n                                You may obtain a copy of the License at\n\n                                    http://www.apache.org/licenses/LICENSE-2.0\n\n                                Unless required by applicable law or agreed to in writing, software\n                                distributed under the License is distributed on an \"AS IS\" BASIS,\n                                WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n                                See the License for the specific language governing permissions and\n                                limitations under the License.\n</code></pre>"},{"location":"api/tricys_analysis.html","title":"API \u53c2\u8003 - \u5206\u6790\u6a21\u5757 (Analysis)","text":"<p>\u5206\u6790\u6a21\u5757 (Analysis)</p> <p>\u5206\u6790\u6a21\u5757 (Analysis) \u63d0\u4f9b\u4e86\u7528\u4e8e\u5904\u7406\u3001\u53ef\u89c6\u5316\u548c\u62a5\u544a TRICYS \u4eff\u771f\u7ed3\u679c\u7684\u5de5\u5177\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Metric (\u6307\u6807)Plot (\u7ed8\u56fe)Report (\u62a5\u544a)SALib (\u654f\u611f\u6027) <p>Utility functions for plotting simulation results.</p> <p>This module provides functions to generate plots from the simulation output CSV files, such as visualizing startup tritium inventory or time-series data.</p>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.calculate_doubling_time","title":"<code>calculate_doubling_time(series, time_series)</code>","text":"<p>Calculates the time it takes for the inventory to double its initial value.</p> <p>This function finds the first time point, after the inventory's minimum (turning point), where the inventory level reaches or exceeds twice its initial value.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>series</code> <code>Series</code> <p>The inventory time series data.</p> \u5fc5\u9700 <code>time_series</code> <code>Series</code> <p>The corresponding time data.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>float</code> <p>The doubling time, or NaN if the inventory never doubles.</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>ValueError</code> <p>If time_series is None.</p> Note <p>Only considers the portion of the series after the turning point (minimum). Returns NaN if the inventory never reaches twice the initial value in the post-turning-point region.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/metric.py</code> <pre><code>def calculate_doubling_time(series: pd.Series, time_series: pd.Series) -&gt; float:\n    \"\"\"Calculates the time it takes for the inventory to double its initial value.\n\n    This function finds the first time point, after the inventory's minimum\n    (turning point), where the inventory level reaches or exceeds twice its\n    initial value.\n\n    Args:\n        series: The inventory time series data.\n        time_series: The corresponding time data.\n\n    Returns:\n        The doubling time, or NaN if the inventory never doubles.\n\n    Raises:\n        ValueError: If time_series is None.\n\n    Note:\n        Only considers the portion of the series after the turning point (minimum).\n        Returns NaN if the inventory never reaches twice the initial value in the\n        post-turning-point region.\n    \"\"\"\n    if time_series is None:\n        raise ValueError(\"time_series must be provided for calculate_doubling_time\")\n    initial_inventory = series.iloc[0]\n    doubled_inventory = 2 * initial_inventory\n\n    # Find the first index where the inventory is &gt;= doubled_inventory\n    # We should only consider the part of the series after the turning point\n    min_index = series.idxmin()\n    after_turning_point_series = series.loc[min_index:]\n\n    doubling_indices = after_turning_point_series[\n        after_turning_point_series &gt;= doubled_inventory\n    ].index\n\n    if not doubling_indices.empty:\n        doubling_index = doubling_indices[0]\n        return time_series.loc[doubling_index]\n    else:\n        # If it never doubles, return NaN\n        return np.nan\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.calculate_startup_inventory","title":"<code>calculate_startup_inventory(series, time_series=None)</code>","text":"<p>Calculates the startup inventory.</p> <p>The startup inventory is calculated as the difference between the initial inventory and the minimum inventory (the turning point).</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>series</code> <code>Series</code> <p>The inventory time series data.</p> \u5fc5\u9700 <code>time_series</code> <code>Optional[Series]</code> <p>The corresponding time data (unused).</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>float</code> <p>The calculated startup inventory.</p> Note <p>The time_series parameter is provided for interface consistency but is not used in the calculation. The startup inventory represents the amount of inventory consumed before reaching the minimum point.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/metric.py</code> <pre><code>def calculate_startup_inventory(\n    series: pd.Series, time_series: Optional[pd.Series] = None\n) -&gt; float:\n    \"\"\"Calculates the startup inventory.\n\n    The startup inventory is calculated as the difference between the initial\n    inventory and the minimum inventory (the turning point).\n\n    Args:\n        series: The inventory time series data.\n        time_series: The corresponding time data (unused).\n\n    Returns:\n        The calculated startup inventory.\n\n    Note:\n        The time_series parameter is provided for interface consistency but is not\n        used in the calculation. The startup inventory represents the amount of\n        inventory consumed before reaching the minimum point.\n    \"\"\"\n    initial_inventory = series.iloc[0]\n    minimum_inventory = series.min()\n    return initial_inventory - minimum_inventory\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.extract_metrics","title":"<code>extract_metrics(results_df, metrics_definition, analysis_case)</code>","text":"<p>Extracts summary metrics from detailed simulation results.</p> <p>This function processes a DataFrame from a parameter sweep, calculates various metrics for each run based on a definitions dictionary, and pivots the results into a summary DataFrame where each row corresponds to a unique parameter combination.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>results_df</code> <code>DataFrame</code> <p>DataFrame from the combined sweep results.</p> \u5fc5\u9700 <code>metrics_definition</code> <code>Dict[str, Any]</code> <p>Dictionary defining how to calculate each metric (e.g., source column, method).</p> \u5fc5\u9700 <code>analysis_case</code> <code>Dict[str, Any]</code> <p>The analysis case configuration, used to identify dependent variables.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>DataFrame</code> <p>A pivoted DataFrame with parameters as the index and metric names as columns.</p> Note <p>Parses column names in format \"variable&amp;param1=value1&amp;param2=value2\" to extract parameter values. Skips metrics with \"bisection_search\" method. Returns empty DataFrame if no valid metrics are found or if pivoting fails.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/metric.py</code> <pre><code>def extract_metrics(\n    results_df: pd.DataFrame,\n    metrics_definition: Dict[str, Any],\n    analysis_case: Dict[str, Any],\n) -&gt; pd.DataFrame:\n    \"\"\"Extracts summary metrics from detailed simulation results.\n\n    This function processes a DataFrame from a parameter sweep, calculates\n    various metrics for each run based on a definitions dictionary, and\n    pivots the results into a summary DataFrame where each row corresponds\n    to a unique parameter combination.\n\n    Args:\n        results_df: DataFrame from the combined sweep results.\n        metrics_definition: Dictionary defining how to calculate each metric\n            (e.g., source column, method).\n        analysis_case: The analysis case configuration, used to identify\n            dependent variables.\n\n    Returns:\n        A pivoted DataFrame with parameters as the index and metric names as columns.\n\n    Note:\n        Parses column names in format \"variable&amp;param1=value1&amp;param2=value2\" to extract\n        parameter values. Skips metrics with \"bisection_search\" method. Returns empty\n        DataFrame if no valid metrics are found or if pivoting fails.\n    \"\"\"\n\n    analysis_results = []\n\n    source_to_metric = {}\n    dependent_vars = analysis_case.get(\"dependent_variables\", [])\n\n    for metric_name in dependent_vars:\n        definition = metrics_definition.get(metric_name)\n\n        # If the metric is not in the definition or is calculated via optimization, skip it.\n        if not definition or definition.get(\"method\") == \"bisection_search\":\n            continue\n\n        source = definition[\"source_column\"]\n        if source not in source_to_metric:\n            source_to_metric[source] = []\n        source_to_metric[source].append(\n            {\n                \"metric_name\": metric_name,\n                \"method\": definition[\"method\"],\n            }\n        )\n\n    for col_name in results_df.columns:\n        if col_name.lower() == \"time\":\n            continue\n\n        source_var = None\n        for var in source_to_metric.keys():\n            if col_name.startswith(var):\n                source_var = var\n                break\n\n        if not source_var:\n            continue\n\n        param_str = col_name[len(source_var) :].lstrip(\"&amp;\")\n\n        try:\n            params = dict(item.split(\"=\") for item in param_str.split(\"&amp;\"))\n        except ValueError:\n            print(\n                f\"Warning: Could not parse parameters from column '{col_name}'. Skipping.\"\n            )\n            continue\n\n        for k, v in params.items():\n            try:\n                params[k] = float(v)\n            except ValueError:\n                params[k] = v\n\n        for metric_info in source_to_metric[source_var]:\n            method_name = metric_info[\"method\"]\n            metric_name = metric_info[\"metric_name\"]\n\n            if method_name == \"final_value\":\n                calculation_func = get_final_value\n            elif method_name == \"calculate_startup_inventory\":\n                calculation_func = calculate_startup_inventory\n            elif method_name == \"time_of_turning_point\":\n                calculation_func = time_of_turning_point\n            elif method_name == \"calculate_doubling_time\":\n                calculation_func = calculate_doubling_time\n            else:\n                print(\n                    f\"Warning: Calculation method '{method_name}' not implemented. Skipping.\"\n                )\n                continue\n\n            metric_value = calculation_func(results_df[col_name], results_df[\"time\"])\n\n            result_row = params.copy()\n            result_row[\"metric_name\"] = metric_name\n            result_row[\"metric_value\"] = metric_value\n            analysis_results.append(result_row)\n\n    if not analysis_results:\n        return pd.DataFrame()\n\n    summary_df = pd.DataFrame(analysis_results)\n\n    # Dynamically identify all parameter columns from the dataframe\n    param_cols = [\n        col for col in summary_df.columns if col not in [\"metric_name\", \"metric_value\"]\n    ]\n\n    if not param_cols:\n        return pd.DataFrame()\n\n    try:\n        pivot_df = summary_df.pivot_table(\n            index=param_cols, columns=\"metric_name\", values=\"metric_value\"\n        ).reset_index()\n        return pivot_df\n    except Exception as e:\n        print(f\"Error during pivoting: {e}\")\n        return pd.DataFrame()\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.get_final_value","title":"<code>get_final_value(series, time_series=None)</code>","text":"<p>Gets the final value of a time series.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>series</code> <code>Series</code> <p>The time series data.</p> \u5fc5\u9700 <code>time_series</code> <code>Optional[Series]</code> <p>The corresponding time data (unused).</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>float</code> <p>The last value in the series.</p> Note <p>The time_series parameter is kept for interface consistency but is not used in the calculation. Only the series data is required.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/metric.py</code> <pre><code>def get_final_value(\n    series: pd.Series, time_series: Optional[pd.Series] = None\n) -&gt; float:\n    \"\"\"Gets the final value of a time series.\n\n    Args:\n        series: The time series data.\n        time_series: The corresponding time data (unused).\n\n    Returns:\n        The last value in the series.\n\n    Note:\n        The time_series parameter is kept for interface consistency but is not used\n        in the calculation. Only the series data is required.\n    \"\"\"\n    return series.iloc[-1]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.time_of_turning_point","title":"<code>time_of_turning_point(series, time_series)</code>","text":"<p>Finds the time of the turning point (minimum value) in a series.</p> <p>This function identifies the time corresponding to the minimum value in the series, which often represents the self-sufficiency time in tritium inventory simulations. To handle noisy data, it first smooths the series to find the general trend's minimum. If the smoothed minimum is not at the boundaries, it returns the time of the absolute minimum from the original data.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>series</code> <code>Series</code> <p>The time series data to analyze.</p> \u5fc5\u9700 <code>time_series</code> <code>Series</code> <p>The corresponding time data.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>float</code> <p>The time of the turning point, or NaN if the trend is monotonic.</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>ValueError</code> <p>If time_series is None.</p> Note <p>Uses a rolling window (0.1% of data length) for smoothing to identify the general trend. If the smoothed minimum is within the last 30% of the series, the trend is considered monotonic and NaN is returned. Otherwise, returns the time of the absolute minimum in the original data.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/metric.py</code> <pre><code>def time_of_turning_point(series: pd.Series, time_series: pd.Series) -&gt; float:\n    \"\"\"Finds the time of the turning point (minimum value) in a series.\n\n    This function identifies the time corresponding to the minimum value in the\n    series, which often represents the self-sufficiency time in tritium inventory\n    simulations. To handle noisy data, it first smooths the series to find the\n    general trend's minimum. If the smoothed minimum is not at the boundaries,\n    it returns the time of the absolute minimum from the original data.\n\n    Args:\n        series: The time series data to analyze.\n        time_series: The corresponding time data.\n\n    Returns:\n        The time of the turning point, or NaN if the trend is monotonic.\n\n    Raises:\n        ValueError: If time_series is None.\n\n    Note:\n        Uses a rolling window (0.1% of data length) for smoothing to identify the\n        general trend. If the smoothed minimum is within the last 30% of the series,\n        the trend is considered monotonic and NaN is returned. Otherwise, returns\n        the time of the absolute minimum in the original data.\n    \"\"\"\n\n    print(\n        f\"Calculating time_of_turning_point for series with length {len(series)} and {len(time_series)} \"\n    )\n    if time_series is None:\n        raise ValueError(\"time_series must be provided for time_of_turning_point\")\n\n    # Define a window size for the rolling average, e.g., 5% of the data length\n    # with a minimum size of 1. This helps in smoothing out local fluctuations.\n    window_size = max(1, int(len(series) * 0.001))\n    smoothed_series = series.rolling(\n        window=window_size, center=True, min_periods=1\n    ).mean()\n\n    # Find the index label of the minimum value in the smoothed series.\n    smooth_min_index = smoothed_series.idxmin()\n    min_index = series.idxmin()\n\n    # Check if the minimum of the smoothed data is within the first or last 5%\n    # of the series. If so, the trend is considered monotonic.\n    smooth_min_pos = series.index.get_loc(smooth_min_index)\n    five_percent_threshold = int(len(series) * 0.3)\n\n    if smooth_min_pos &gt;= len(series) - five_percent_threshold:\n        return np.nan\n    else:\n        # A clear turning point is identified in the overall trend.\n        # Now, find the precise turning point in the original, noisy data.\n        min_index = series.idxmin()\n        return time_series.loc[min_index]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.generate_analysis_plots","title":"<code>generate_analysis_plots(summary_df, analysis_case, save_dir, unit_map=None, glossary_path=None)</code>","text":"<p>Generates and saves plots based on the sensitivity analysis summary.</p> <p>This function first generates dedicated plots for all 'Required_***' metrics, then handles plotting for all other standard metrics.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>summary_df</code> <code>DataFrame</code> <p>DataFrame containing the summarized analysis results.</p> \u5fc5\u9700 <code>analysis_case</code> <code>dict</code> <p>Configuration for the analysis cases.</p> \u5fc5\u9700 <code>save_dir</code> <code>str</code> <p>Directory to save the plot images.</p> \u5fc5\u9700 <code>unit_map</code> <code>dict</code> <p>Optional dictionary for unit conversion and labeling. Defaults to None.</p> <code>None</code> <code>glossary_path</code> <code>str</code> <p>Optional path to the glossary CSV file for professional labels.</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>list[str]</code> <p>A list of paths to the saved plot images.</p> Note <p>Handles Required_*** metrics separately with multi-subplot layouts. Standard metrics can be combined or plotted individually based on case configuration. Returns empty list if summary_df is empty. Loads glossary if path provided.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/plot.py</code> <pre><code>def generate_analysis_plots(\n    summary_df: pd.DataFrame,\n    analysis_case: dict,\n    save_dir: str,\n    unit_map: dict = None,\n    glossary_path: str = None,\n) -&gt; list[str]:\n    \"\"\"Generates and saves plots based on the sensitivity analysis summary.\n\n    This function first generates dedicated plots for all 'Required_***' metrics,\n    then handles plotting for all other standard metrics.\n\n    Args:\n        summary_df: DataFrame containing the summarized analysis results.\n        analysis_case: Configuration for the analysis cases.\n        save_dir: Directory to save the plot images.\n        unit_map: Optional dictionary for unit conversion and labeling. Defaults to None.\n        glossary_path: Optional path to the glossary CSV file for professional labels.\n\n    Returns:\n        A list of paths to the saved plot images.\n\n    Note:\n        Handles Required_*** metrics separately with multi-subplot layouts. Standard\n        metrics can be combined or plotted individually based on case configuration.\n        Returns empty list if summary_df is empty. Loads glossary if path provided.\n    \"\"\"\n    if glossary_path:\n        load_glossary(glossary_path)\n\n    if summary_df.empty:\n        return []\n\n    analysis_cases = [analysis_case]  # Keep as a list for consistency\n    sns.set_theme(style=\"whitegrid\")\n    line_colors = sns.color_palette(\"viridis\", 10)\n\n    plot_paths = []\n\n    # If unit_map is not provided, initialize as empty dict\n    if unit_map is None:\n        unit_map = {}\n\n    # --- 1. Handle ALL 'Required_***' plots first and separately ---\n    all_required_vars_from_config = {\n        var\n        for case in analysis_cases\n        for var in case.get(\"dependent_variables\", [])\n        if var.startswith(\"Required_\")\n    }\n\n    for req_var in all_required_vars_from_config:\n        # Find all actual columns in the dataframe for this base name\n        matching_cols = sorted(\n            [\n                c\n                for c in summary_df.columns\n                if c == req_var or c.startswith(req_var + \"(\")\n            ]\n        )\n\n        if not matching_cols:\n            continue\n\n        case_for_plot = analysis_cases[0]\n\n        if len(matching_cols) &gt; 1:\n            # Multi-value case -&gt; generate a multi-subplot figure\n            multi_plot_paths = _generate_multi_required_plot(\n                summary_df,\n                case_for_plot,\n                matching_cols,\n                req_var,\n                save_dir,\n                unit_map=unit_map,\n            )\n            plot_paths.extend(multi_plot_paths)\n        elif len(matching_cols) == 1:\n            # Single-value case -&gt; generate a single, individual plot\n            plot_config = {\n                \"case_name\": case_for_plot[\"name\"],\n                \"x_var\": case_for_plot[\"independent_variable\"],\n                \"y_var\": matching_cols[0],\n                \"plot_type\": \"line\",\n                \"hue_vars\": sorted(\n                    list(case_for_plot.get(\"default_simulation_values\", {}).keys())\n                ),\n            }\n            single_plot_path = _generate_individual_plots(\n                summary_df, [plot_config], save_dir, line_colors, unit_map=unit_map\n            )\n            plot_paths.extend(single_plot_path)\n\n    # --- 2. Handle all other (non-Required) plots ---\n\n    # Collect plot configurations for remaining standard variables\n    valid_plots_for_combine = []\n    for case in analysis_cases:\n        case_name = case[\"name\"]\n        x_var = case[\"independent_variable\"]\n\n        # Filter out the Required_*** vars that we just plotted\n        y_vars = [\n            v\n            for v in case.get(\"dependent_variables\", [])\n            if not v.startswith(\"Required_\")\n        ]\n\n        if x_var not in summary_df.columns:\n            print(\n                f\"Warning: Independent variable '{x_var}' not found in summary data for case '{case_name}'. Skipping.\"\n            )\n            continue\n\n        case_sim_params = case.get(\"default_simulation_values\", {})\n        hue_vars = sorted(list(case_sim_params.keys()))\n\n        for y_var in y_vars:\n            if y_var not in summary_df.columns:\n                print(\n                    f\"Warning: Dependent variable '{y_var}' not found in summary data for case '{case_name}'. Skipping.\"\n                )\n                continue\n\n            # We assume standard metrics have a 1-to-1 name match in the dataframe\n            valid_plots_for_combine.append(\n                {\n                    \"case_name\": case_name,\n                    \"x_var\": x_var,\n                    \"y_var\": y_var,\n                    \"plot_type\": \"line\",\n                    \"hue_vars\": hue_vars,\n                }\n            )\n\n    if valid_plots_for_combine:\n        combine_plots = any(case.get(\"combine_plots\", False) for case in analysis_cases)\n        generated_paths = []\n        if combine_plots:\n            generated_paths = _generate_combined_plots(\n                summary_df,\n                valid_plots_for_combine,\n                save_dir,\n                line_colors,\n                unit_map=unit_map,\n            )\n        else:\n            # If not combining, plot them individually anyway\n            generated_paths = _generate_individual_plots(\n                summary_df,\n                valid_plots_for_combine,\n                save_dir,\n                line_colors,\n                unit_map=unit_map,\n            )\n        plot_paths.extend(generated_paths)\n\n    return plot_paths\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.load_glossary","title":"<code>load_glossary(glossary_path)</code>","text":"<p>Loads glossary data from a CSV file.</p> <p>The CSV file should contain columns for the model parameter, the English term, and the Chinese translation. This data is used to format plot labels.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>glossary_path</code> <code>str</code> <p>The path to the glossary CSV file.</p> \u5fc5\u9700 Note <p>Expected CSV columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\", and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Prints warning if file not found or columns missing. Clears existing glossary maps on error.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/plot.py</code> <pre><code>def load_glossary(glossary_path: str) -&gt; None:\n    \"\"\"Loads glossary data from a CSV file.\n\n    The CSV file should contain columns for the model parameter, the English\n    term, and the Chinese translation. This data is used to format plot labels.\n\n    Args:\n        glossary_path: The path to the glossary CSV file.\n\n    Note:\n        Expected CSV columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\",\n        and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Prints warning if file not found or\n        columns missing. Clears existing glossary maps on error.\n    \"\"\"\n    global _english_glossary_map, _chinese_glossary_map\n\n    if not glossary_path or not os.path.exists(glossary_path):\n        print(\n            f\"Warning: Glossary file not found at {glossary_path}. No labels will be loaded.\"\n        )\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n        return\n\n    try:\n        df = pd.read_csv(glossary_path)\n        if (\n            \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\" in df.columns\n            and \"\u82f1\u6587\u672f\u8bed (English Term)\" in df.columns\n            and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\" in df.columns\n        ):\n            df.dropna(subset=[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"], inplace=True)\n            _english_glossary_map = pd.Series(\n                df[\"\u82f1\u6587\u672f\u8bed (English Term)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            _chinese_glossary_map = pd.Series(\n                df[\"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            print(f\"Successfully loaded glossary from {glossary_path}.\")\n        else:\n            print(\"Warning: Glossary CSV does not contain expected columns.\")\n            _english_glossary_map = {}\n            _chinese_glossary_map = {}\n    except Exception as e:\n        print(f\"Warning: Failed to load or parse glossary file. Error: {e}\")\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.plot_sweep_time_series","title":"<code>plot_sweep_time_series(csv_path, save_dir, y_var_name, independent_var_name, independent_var_alias=None, default_params=None, glossary_path=None)</code>","text":"<p>Generates a single figure with two subplots: an overall time-series view and a zoomed-in view.</p> <p>The time axis is in days. The overall view hides data points for a curve if they exceed twice its initial value.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>csv_path</code> <code>str</code> <p>Path to the scan result CSV file.</p> \u5fc5\u9700 <code>save_dir</code> <code>str</code> <p>Directory to save the image.</p> \u5fc5\u9700 <code>y_var_name</code> <code>Union[str, List[str]]</code> <p>Name(s) of the Y-axis variable(s).</p> \u5fc5\u9700 <code>independent_var_name</code> <code>str</code> <p>Full name of the scan parameter.</p> \u5fc5\u9700 <code>independent_var_alias</code> <code>str</code> <p>Alias for the scan parameter for cleaner plot titles.</p> <code>None</code> <code>default_params</code> <code>Dict[str, Any]</code> <p>A dictionary of default parameters. If provided, only curves matching these parameters will be plotted.</p> <code>None</code> <code>glossary_path</code> <code>str</code> <p>Path to the glossary file for professional labels.</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[str]</code> <p>A list of paths to the saved plot images, or an empty list on failure.</p> Note <p>Converts time from hours to days. Generates bilingual plots (English and Chinese). Overall view masks data exceeding 2x initial value. Zoomed view shows region from t=0 to 2 days past minimum, with red rectangle indicator on overall view. Data is converted from grams to kilograms for display.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/plot.py</code> <pre><code>def plot_sweep_time_series(\n    csv_path: str,\n    save_dir: str,\n    y_var_name: Union[str, List[str]],\n    independent_var_name: str,\n    independent_var_alias: str = None,\n    default_params: Dict[str, Any] = None,\n    glossary_path: str = None,\n) -&gt; List[str]:\n    \"\"\"Generates a single figure with two subplots: an overall time-series view and a zoomed-in view.\n\n    The time axis is in days. The overall view hides data points for a curve if\n    they exceed twice its initial value.\n\n    Args:\n        csv_path: Path to the scan result CSV file.\n        save_dir: Directory to save the image.\n        y_var_name: Name(s) of the Y-axis variable(s).\n        independent_var_name: Full name of the scan parameter.\n        independent_var_alias: Alias for the scan parameter for cleaner plot titles.\n        default_params: A dictionary of default parameters. If provided, only curves\n            matching these parameters will be plotted.\n        glossary_path: Path to the glossary file for professional labels.\n\n    Returns:\n        A list of paths to the saved plot images, or an empty list on failure.\n\n    Note:\n        Converts time from hours to days. Generates bilingual plots (English and Chinese).\n        Overall view masks data exceeding 2x initial value. Zoomed view shows region from\n        t=0 to 2 days past minimum, with red rectangle indicator on overall view. Data is\n        converted from grams to kilograms for display.\n    \"\"\"\n    if glossary_path:\n        load_glossary(glossary_path)\n\n    try:\n        df = pd.read_csv(csv_path)\n    except FileNotFoundError:\n        print(f\"Error: Could not find results file at {csv_path}\")\n        return []\n\n    if \"time\" not in df.columns:\n        print(f\"Error: 'time' column not found in {csv_path}\")\n        return []\n\n    # Convert time from hours to days\n    time_days = df[\"time\"] / 24\n\n    # Use alias if provided, otherwise format the original name\n    raw_plot_alias = (\n        independent_var_alias if independent_var_alias else independent_var_name\n    )\n\n    if isinstance(y_var_name, str):\n        y_var_names = [y_var_name]\n    else:\n        y_var_names = y_var_name\n\n    y_var_columns = []\n    for y_var in y_var_names:\n        y_var_columns.extend(\n            [col for col in df.columns if col != \"time\" and y_var in col]\n        )\n    y_var_columns = list(dict.fromkeys(y_var_columns))\n\n    # If default_params are provided, filter columns to only plot baseline curves\n    if default_params:\n        filtered_columns = []\n        for col in y_var_columns:\n            try:\n                param_str = col.split(\"&amp;\", 1)[1]\n                col_params = dict(p.split(\"=\", 1) for p in param_str.split(\"&amp;\"))\n\n                # Check if all default_params match the parameters in the column name\n                is_match = all(\n                    col_params.get(key) == str(val)\n                    for key, val in default_params.items()\n                )\n\n                if is_match:\n                    filtered_columns.append(col)\n            except IndexError:\n                # This column does not have parameters in its name, so it can't be a match\n                continue\n        y_var_columns = filtered_columns\n\n    if not y_var_columns:\n        print(\n            f\"Warning: No columns found containing any of {y_var_names} in {csv_path} that match the criteria.\"\n        )\n        return []\n\n    # Convert y-axis data from grams to kilograms\n    for col in y_var_columns:\n        df[col] = df[col] / 1000.0\n\n    # Generate clean labels (values only) for the legend\n    plot_labels = []\n    for col in y_var_columns:\n        label = col\n        try:\n            param_parts = col.split(\"&amp;\")[1:]\n            for part in param_parts:\n                if part.startswith(independent_var_name + \"=\"):\n                    label = part.split(\"=\", 1)[1]  # Extract just the value\n                    break\n        except IndexError:\n            pass  # No parameters in name, use full column name\n        plot_labels.append(label)\n\n    print(\n        f\"Found {len(y_var_columns)} columns to plot containing {y_var_names}: {y_var_columns}\"\n    )\n\n    sns.set_theme(style=\"whitegrid\")\n    plot_paths = []\n    original_lang_is_chinese = _use_chinese_labels\n\n    for lang in [\"en\", \"cn\"]:\n        set_plot_language(lang)\n\n        colors = sns.color_palette(\"plasma\", len(y_var_columns))\n\n        # Create a figure with two subplots (overall and zoom)\n        fig, (ax1, ax2) = plt.subplots(\n            2, 1, figsize=(12, 16), sharex=False, gridspec_kw={\"height_ratios\": [2, 1]}\n        )\n        y_var_names_formatted = [_format_label(y) for y in y_var_names]\n\n        min_y_global = float(\"inf\")\n        min_x_global = float(\"inf\")\n\n        # Define the y-axis label with units\n        y_label = f\"{', '.join(y_var_names_formatted)} ({_get_text('kg')})\"\n\n        # --- Subplot 1: Overall View ---\n        for i, column in enumerate(y_var_columns):\n            y_data = df[column]\n\n            # For the global view, mask data that is more than 2x the initial value\n            if not y_data.empty:\n                initial_value = y_data.iloc[0]\n                threshold = 2 * initial_value\n                y_masked = y_data.where(y_data &lt;= threshold)\n            else:\n                y_masked = y_data\n\n            ax1.plot(\n                time_days,\n                y_masked,\n                label=plot_labels[i],\n                color=colors[i],\n                linewidth=1.2,\n                alpha=0.85,\n            )\n\n            # Calculations for zoom window should use the original, unmasked data\n            if not y_data.empty:\n                min_idx = y_data.idxmin()\n                current_min_y = y_data.loc[min_idx]\n                if current_min_y &lt; min_y_global:\n                    min_y_global = current_min_y\n                    min_x_global = time_days.loc[min_idx]\n\n        ax1.set_ylabel(y_label, fontsize=12)\n        ax1.set_title(_get_text(\"overall_view\"), fontsize=12)\n        ax1.legend(loc=\"best\", title=_format_label(independent_var_name))\n        ax1.grid(True)\n\n        # --- Subplot 2: Zoomed-in View (uses original data) ---\n        if min_y_global != float(\"inf\") and np.isfinite(min_y_global):\n            for i, column in enumerate(y_var_columns):\n                # Plot original, unmasked data in the zoom plot\n                ax2.plot(\n                    time_days,\n                    df[column],\n                    label=plot_labels[i],\n                    color=colors[i],\n                    linewidth=1.8,\n                    alpha=0.9,\n                )\n\n            # Define the zoom window from t=0 to a bit after the minimum\n            x1 = 0\n            x2 = min_x_global + 2  # Show 2 days past the minimum\n\n            # Filter the DataFrame to the new x-range to find the y-range\n            zoom_mask = (time_days &gt;= x1) &amp; (time_days &lt;= x2)\n            df_zoom_range = df[zoom_mask]\n\n            # Find y-min and y-max within this specific range\n            y_min_in_range = df_zoom_range[y_var_columns].min().min()\n            y_max_in_range = df_zoom_range[y_var_columns].max().max()\n\n            # Add padding to the y-axis\n            y_padding = (y_max_in_range - y_min_in_range) * 0.05\n            y1 = y_min_in_range - y_padding\n            y2 = y_max_in_range + y_padding\n\n            ax2.set_xlim(x1, x2)\n            ax2.set_ylim(y1, y2)\n\n            ax2.set_xlabel(_get_text(\"time_days\"), fontsize=12)\n            ax2.set_ylabel(y_label, fontsize=12)\n            ax2.set_title(_get_text(\"detailed_view\"), fontsize=12)\n            ax2.grid(True, linestyle=\"--\")\n\n            # Add a rectangle to the main plot to indicate the new zoom area\n            rect = patches.Rectangle(\n                (x1, y1),\n                (x2 - x1),\n                (y2 - y1),\n                linewidth=1,\n                edgecolor=\"r\",\n                facecolor=\"none\",\n                linestyle=\"--\",\n                alpha=0.7,\n            )\n            ax1.add_patch(rect)\n        else:\n            # If no zoom, hide the second subplot\n            ax2.set_visible(False)\n\n        ax1.set_xlabel(_get_text(\"time_days\"), fontsize=12)\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust for suptitle\n\n        # --- Save Figure ---\n        safe_y_vars = \"_\".join(\n            [\n                var.replace(\".\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\")\n                for var in y_var_names\n            ]\n        )\n        safe_param = raw_plot_alias.replace(\".\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\")\n        suffix = \"_zh\" if lang == \"cn\" else \"\"\n        svg_path = os.path.join(\n            save_dir, f\"sweep_{safe_y_vars}_vs_{safe_param}{suffix}.svg\"\n        )\n\n        try:\n            # Force text to be rendered as paths in SVG.\n            plt.rcParams[\"svg.fonttype\"] = \"path\"\n            plt.savefig(svg_path, format=\"svg\", bbox_inches=\"tight\")\n            print(f\"Successfully generated combined sweep plot: {svg_path}\")\n            plot_paths.append(svg_path)\n        except Exception as e:\n            print(f\"Error saving plot: {e}\")\n        finally:\n            plt.close(fig)\n\n    set_plot_language(\"cn\" if original_lang_is_chinese else \"en\")\n    return plot_paths\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.set_plot_language","title":"<code>set_plot_language(lang='en')</code>","text":"<p>Sets the preferred language for plot labels and text.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>lang</code> <code>str</code> <p>The language to set. 'en' for English (default), 'cn' for Chinese.</p> <code>'en'</code> Note <p>For Chinese language, sets font to SimHei and adjusts unicode_minus handling. For English, restores matplotlib default settings. Changes apply to all subsequent plots until called again.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/plot.py</code> <pre><code>def set_plot_language(lang: str = \"en\") -&gt; None:\n    \"\"\"Sets the preferred language for plot labels and text.\n\n    Args:\n        lang: The language to set. 'en' for English (default), 'cn' for Chinese.\n\n    Note:\n        For Chinese language, sets font to SimHei and adjusts unicode_minus handling.\n        For English, restores matplotlib default settings. Changes apply to all\n        subsequent plots until called again.\n    \"\"\"\n    global _use_chinese_labels\n    _use_chinese_labels = lang.lower() == \"cn\"\n\n    if _use_chinese_labels:\n        # To display Chinese characters correctly, specify a list of fallback fonts.\n        plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # \u66ff\u6362\u6210\u4f60\u7535\u8111\u4e0a\u6709\u7684\u5b57\u4f53\n        plt.rcParams[\"axes.unicode_minus\"] = False  # To display minus sign correctly.\n        plt.rcParams[\"font.family\"] = \"sans-serif\"  # \u786e\u4fdd\u5b57\u4f53\u5bb6\u65cf\u8bbe\u7f6e\u751f\u6548\n    else:\n        # Restore default settings\n        plt.rcParams[\"font.sans-serif\"] = plt.rcParamsDefault[\"font.sans-serif\"]\n        plt.rcParams[\"axes.unicode_minus\"] = plt.rcParamsDefault[\"axes.unicode_minus\"]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.call_openai_analysis_api","title":"<code>call_openai_analysis_api(case_name, df, api_key, base_url, ai_model, independent_variable, report_content, original_config, case_data, reference_col_for_turning_point=None)</code>","text":"<p>Constructs a text-only prompt, calls the OpenAI API for analysis, and returns the result string.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>case_name</code> <code>str</code> <p>Name of the analysis case.</p> \u5fc5\u9700 <code>df</code> <code>DataFrame</code> <p>DataFrame containing summary data.</p> \u5fc5\u9700 <code>api_key</code> <code>str</code> <p>OpenAI API key.</p> \u5fc5\u9700 <code>base_url</code> <code>str</code> <p>Base URL for the OpenAI API.</p> \u5fc5\u9700 <code>ai_model</code> <code>str</code> <p>Model name to use for analysis.</p> \u5fc5\u9700 <code>independent_variable</code> <code>str</code> <p>Name of the independent variable.</p> \u5fc5\u9700 <code>report_content</code> <code>str</code> <p>The report content to analyze.</p> \u5fc5\u9700 <code>original_config</code> <code>dict</code> <p>Original configuration dictionary.</p> \u5fc5\u9700 <code>case_data</code> <code>dict</code> <p>Case-specific data dictionary.</p> \u5fc5\u9700 <code>reference_col_for_turning_point</code> <code>str</code> <p>Optional reference column for turning point analysis.</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Optional[str]</code> <p>The combined prompt and LLM analysis result, or None if failed.</p> Note <p>Constructs dynamic prompts based on case configuration. Includes sections for global sensitivity analysis, interaction effects (if simulation parameters present), and dynamic process analysis (if reference column provided). Retries up to 3 times on failure with 5-second delays.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/report.py</code> <pre><code>def call_openai_analysis_api(\n    case_name: str,\n    df: pd.DataFrame,\n    api_key: str,\n    base_url: str,\n    ai_model: str,\n    independent_variable: str,\n    report_content: str,\n    original_config: dict,\n    case_data: dict,\n    reference_col_for_turning_point: str = None,\n) -&gt; Optional[str]:\n    \"\"\"Constructs a text-only prompt, calls the OpenAI API for analysis, and returns the result string.\n\n    Args:\n        case_name: Name of the analysis case.\n        df: DataFrame containing summary data.\n        api_key: OpenAI API key.\n        base_url: Base URL for the OpenAI API.\n        ai_model: Model name to use for analysis.\n        independent_variable: Name of the independent variable.\n        report_content: The report content to analyze.\n        original_config: Original configuration dictionary.\n        case_data: Case-specific data dictionary.\n        reference_col_for_turning_point: Optional reference column for turning point analysis.\n\n    Returns:\n        The combined prompt and LLM analysis result, or None if failed.\n\n    Note:\n        Constructs dynamic prompts based on case configuration. Includes sections for\n        global sensitivity analysis, interaction effects (if simulation parameters present),\n        and dynamic process analysis (if reference column provided). Retries up to 3 times\n        on failure with 5-second delays.\n    \"\"\"\n    try:\n        logger.info(f\"Proceeding with LLM analysis for case {case_name}.\")\n\n        # 1. Construct the prompt for the API\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u805a\u53d8\u53cd\u5e94\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u7684\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7**\u5b8c\u5168\u57fa\u4e8e**\u4e0b\u65b9\u63d0\u4f9b\u7684**\u4e24\u7c7b\u6570\u636e\u8868\u683c**\uff0c\u5bf9\u805a\u53d8\u5806\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684**\u654f\u611f\u6027\u5206\u6790**\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\u3002\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n**\u5206\u6790\u6570\u636e\uff1a**(\u6ce8\u610f\uff1a\u5206\u6790\u4e2d\u4e0d\u53ef\u4f7f\u7528\u4efb\u4f55\u56fe\u8868\u4fe1\u606f\uff0c\u6240\u6709\u7ed3\u8bba\u5fc5\u987b\u6e90\u4e8e\u6570\u636e\u8868\u683c\u3002)\n\n{report_content}\n\"\"\"\n\n        # --- Dynamic Prompt Construction ---\n\n        # 1. Detect analysis scenario\n        has_sim_params = bool(case_data.get(\"simulation_parameters\"))\n\n        # 2. Build prompt sections dynamically\n        prompt_sections = []\n\n        # Section 1: Global Sensitivity Analysis\n        global_sensitivity_points = [\n            \"1.  **\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (\u53c2\u8003\u201c\u6027\u80fd\u6307\u6807\u603b\u8868\u201d) :**\",\n            \"    *   \u5206\u6790\u6027\u80fd\u6307\u6807\u603b\u8868\uff08 `Startup_Inventory`, `Doubling_Time` \u4ee5\u53ca\u4ee5 `Required_` \u5f00\u5934\u7684\u6c42\u89e3\u6307\u6807\u7b49\uff09\u5448\u73b0\u51fa\u600e\u6837\u7684**\u603b\u4f53\u8d8b\u52bf**\uff1f\u8bf7\u8fdb\u884c\u91cf\u5316\u63cf\u8ff0\u3002\",\n            f\"    *   \u5982\u679c\u5b58\u5728\u591a\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u6790\u54ea\u4e2a\u6027\u80fd\u6307\u6807\u5bf9\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u7684\u53d8\u5316\u6700\u4e3a\u654f\u611f\uff1f\u54ea\u4e2a\u6700\u4e0d\u654f\u611f\uff1f\\n\",\n        ]\n\n        # Interaction effect analysis, with refined description\n        if has_sim_params:\n            param_names_list = []\n            for p in case_data[\"simulation_parameters\"].keys():\n                if p == \"Required_TBR\":\n                    label = \"`Required_TBR\u7ea6\u675f\u503c (hour)`\"\n                else:\n                    label = f\"`{p}`\"\n                param_names_list.append(label)\n            param_names = \", \".join(param_names_list)\n\n            interaction_text = (\n                f\"2.  **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a** \u672c\u6b21\u5206\u6790\u5305\u542b\u4e86\u591a\u53d8\u91cf\u7684\u4ea4\u4e92\u6548\u5e94\u3002\u8bf7\u5206\u6790\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \"\n                f\"\u4e0e\u80cc\u666f\u626b\u63cf\u53c2\u6570 ({param_names}) \u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u5404\u9879\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\u3002\"\n                \"\u8bf7\u6ce8\u610f\uff0c\u72ec\u7acb\u53d8\u91cf\u6216\u80cc\u666f\u626b\u63cf\u53c2\u6570\u4e2d\uff0c\u53ef\u80fd\u5305\u542b\u5e38\u89c4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u53ef\u80fd\u5305\u542b\u4e3a\u6ee1\u8db3\u7279\u5b9a\u6027\u80fd\u76ee\u6807\uff08\u9650\u5236\u500d\u589e\u65f6\u95f4Double_Time\u8fbe\u5230\u500d\u589e\uff09\u800c\u6c42\u89e3\u51fa\u7684\u7279\u6b8a\u53d8\u91cf\uff08\u7ea6\u675f\u9650\u5236\u53d8\u91cfDouble_Time\uff09\u3002\"\n                \"\u8bf7\u8ba8\u8bba\u5728\u4e0d\u540c\u7684\u53d8\u91cf\u7ec4\u5408\u4e0b\uff0c\u6027\u80fd\u6307\u6807\u7684\u654f\u611f\u6027\u6709\u4f55\u4e0d\u540c\uff1f\u662f\u5426\u5b58\u5728\u663e\u8457\u7684\u4ea4\u4e92\u6548\u5e94\uff1f\"\n            )\n            global_sensitivity_points.append(interaction_text)\n\n        prompt_sections.append(\"\\n\".join(global_sensitivity_points))\n\n        # Section 2: Dynamic Process Analysis\n        if reference_col_for_turning_point:\n            dynamic_process_points = [\n                \"3.  **\u52a8\u6001\u8fc7\u7a0b\u5206\u6790 (\u53c2\u8003\u201c\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u8fc7\u7a0b\u6570\u636e\u201d) :**\",\n                \"    *   \u89c2\u5bdf\u8fc7\u7a0b\u6570\u636e\u5207\u7247\uff1a\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u9636\u6bb5\u201d\u548c\u201c\u7ed3\u675f\u9636\u6bb5\u201d\u7684\u884c\u4e3a\u6709\u4f55\u4e0d\u540c\uff1f\",\n                f\"    *   \u4ee5 `{reference_col_for_turning_point}` \u4e3a\u53c2\u8003\uff0c\u5176\u201c\u8f6c\u6298\u70b9\u9636\u6bb5\u201d\u7684\u6570\u636e\u63ed\u793a\u4e86\u4ec0\u4e48\u7269\u7406\u8fc7\u7a0b\uff1f\uff08\u4f8b\u5982\uff0c\u5b83\u662f\u5426\u662f\u6c1a\u5e93\u5b58\u7531\u6d88\u8017\u8f6c\u4e3a\u51c0\u589e\u957f\u7684\u5173\u952e\u65f6\u523b\uff1f\uff09\",\n            ]\n            prompt_sections.append(\"\\n\".join(dynamic_process_points))\n\n        # Section 3: Overall Conclusion (renumbered from 4)\n        conclusion_points = [\"3.  **\u7efc\u5408\u7ed3\u8bba\uff1a**\"]\n        conclusion_intro = \"\u7ed3\u5408\u6240\u6709\u5206\u6790\uff08\u5305\u62ec\u4e3b\u8d8b\u52bf\"\n        if has_sim_params:\n            conclusion_intro += \"\u3001\u80cc\u666f\u53c2\u6570\u4ea4\u4e92\u6548\u5e94\"\n        conclusion_intro += \"\uff09\uff0c\"\n\n        conclusion_points.append(\n            conclusion_intro\n            + f\"\u603b\u7ed3\u5728\u4e0d\u540c\u7684\u8fd0\u884c\u573a\u666f\u4e0b\uff0c\u8c03\u6574 `{independent_variable}` \u5bf9\u6574\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u7684\u7efc\u5408\u5f71\u54cd\u548c\u6f5c\u5728\u7684\u5229\u5f0a\u6743\u8861\u3002\"\n        )\n        conclusion_points.append(\n            \"    *   \u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u53ef\u4ee5\u5f97\u51fa\u54ea\u4e9b\u5173\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\u6216\u8fd0\u884c\u4f18\u5316\u7684\u521d\u6b65\u5efa\u8bae\uff1f\"\n        )\n        prompt_sections.append(\"\\n\".join(conclusion_points))\n\n        # Assemble the final prompt\n        points_prompt = \"\\n\\n\".join(prompt_sections)\n        points_prompt = (\n            \"\\n**\u5206\u6790\u8981\u70b9 (\u5fc5\u987b\u4e25\u683c\u4f9d\u636e\u6570\u636e\u8868\u683c\u4f5c\u7b54)\uff1a**\\n\\n\" + points_prompt\n        )\n\n        # 2. Call API with retry logic\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for case {case_name} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, analysis_prompt, points_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                analysis_result = response.choices[0].message.content\n\n                logger.info(f\"LLM analysis successful for case {case_name}.\")\n                return (\n                    role_prompt\n                    + points_prompt\n                    + \"\\n```\\n\\n\"\n                    + \"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\"\n                    + analysis_result\n                )  # Return the result string\n\n            except Exception as e:\n                logger.error(f\"Error calling OpenAI API on attempt {attempt + 1}: {e}\")\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to call OpenAI API after {max_retries} attempts.\"\n                    )\n                    return None  # Return None on failure\n\n    except Exception as e:\n        logger.error(\n            f\"Error in call_openai_analysis_api for case {case_name}: {e}\",\n            exc_info=True,\n        )\n        return None\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.consolidate_reports","title":"<code>consolidate_reports(case_configs, original_config)</code>","text":"<p>Consolidates generated reports and their images into a 'report' directory for each case.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries.</p> \u5fc5\u9700 <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary.</p> \u5fc5\u9700 Note <p>Moves analysis reports, academic reports, and plot images from results directory to report directory. Uses move operation (not copy). Creates report directory if it doesn't exist. Skips cases where source directory not found.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/report.py</code> <pre><code>def consolidate_reports(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Consolidates generated reports and their images into a 'report' directory for each case.\n\n    Args:\n        case_configs: List of case configuration dictionaries.\n        original_config: Original configuration dictionary.\n\n    Note:\n        Moves analysis reports, academic reports, and plot images from results directory\n        to report directory. Uses move operation (not copy). Creates report directory\n        if it doesn't exist. Skips cases where source directory not found.\n    \"\"\"\n    logger.info(\"Consolidating analysis reports...\")\n    try:\n        for case_info in case_configs:\n            case_workspace = case_info[\"workspace\"]\n            source_dir = os.path.join(case_workspace, \"results\")\n            dest_dir = os.path.join(case_workspace, \"report\")\n\n            if not os.path.isdir(source_dir):\n                logger.warning(\n                    f\"Source directory not found, skipping consolidation for case: {case_workspace}\"\n                )\n                continue\n\n            # Find files to copy\n            files_to_copy = []\n            for filename in os.listdir(source_dir):\n                if (\n                    filename.startswith(\"analysis_report\")\n                    or filename.startswith(\"academic_report\")\n                ) and filename.endswith(\".md\"):\n                    files_to_copy.append(filename)\n                elif filename.endswith((\".svg\", \".png\")):\n                    files_to_copy.append(filename)\n\n            if not files_to_copy:\n                logger.info(\n                    f\"No reports or images found in {source_dir}, skipping consolidation.\"\n                )\n                continue\n\n            # Create destination directory and copy files\n            os.makedirs(dest_dir, exist_ok=True)\n            logger.info(f\"Consolidating reports into: {dest_dir}\")\n\n            for filename in files_to_copy:\n                source_path = os.path.join(source_dir, filename)\n                shutil.move(source_path, dest_dir)\n                logger.info(f\"Moved {filename} to {dest_dir}\")\n\n    except Exception as e:\n        logger.error(f\"Error during report consolidation: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.generate_analysis_cases_summary","title":"<code>generate_analysis_cases_summary(case_configs, original_config)</code>","text":"<p>Generate summary report for analysis_cases.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries.</p> \u5fc5\u9700 <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary containing run timestamp.</p> \u5fc5\u9700 Note <p>Creates an execution report with basic information, case details, and status. Saves report to {run_timestamp}/execution_report_{run_timestamp}.md in current working directory. Also triggers generate_prompt_templates and consolidate_reports. Logs summary of successfully executed cases.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/report.py</code> <pre><code>def generate_analysis_cases_summary(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Generate summary report for analysis_cases.\n\n    Args:\n        case_configs: List of case configuration dictionaries.\n        original_config: Original configuration dictionary containing run timestamp.\n\n    Note:\n        Creates an execution report with basic information, case details, and status.\n        Saves report to {run_timestamp}/execution_report_{run_timestamp}.md in current\n        working directory. Also triggers generate_prompt_templates and consolidate_reports.\n        Logs summary of successfully executed cases.\n    \"\"\"\n    try:\n        run_timestamp = original_config[\"run_timestamp\"]\n        # Generate report in current working directory\n        current_dir = os.getcwd()\n\n        # Create summary report\n        summary_data = []\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n            case_workspace = case_info[\"workspace\"]\n\n            # Check if case results exist\n            case_results_dir = os.path.join(case_workspace, \"results\")\n            has_results = (\n                os.path.exists(case_results_dir)\n                and len(os.listdir(case_results_dir)) &gt; 0\n            )\n\n            summary_entry = {\n                \"case_name\": case_data.get(\"name\", f\"Case{case_info['index']+1}\"),\n                \"independent_variable\": case_data[\"independent_variable\"],\n                \"independent_variable_sampling\": case_data[\n                    \"independent_variable_sampling\"\n                ],\n                \"workspace_path\": case_workspace,\n                \"has_results\": has_results,\n                \"config_file\": case_info[\"config_path\"],\n            }\n            summary_data.append(summary_entry)\n\n        # Generate text report\n        report_lines = [\n            \"# Analysis Cases Execution Report\",\n            \"\\n## Basic Information\",\n            f\"- Execution time: {run_timestamp}\",\n            f\"- Total cases: {len(case_configs)}\",\n            f\"- Successfully executed: {sum(1 for entry in summary_data if entry['has_results'])}\",\n            f\"- Working directory: {current_dir}\",\n            \"\\n## Case Details\",\n        ]\n\n        for i, entry in enumerate(summary_data, 1):\n            status = \"\u2713 Success\" if entry[\"has_results\"] else \"\u2717 Failed\"\n            report_lines.extend(\n                [\n                    f\"\\n### {i}. {entry['case_name']}\",\n                    f\"- Status: {status}\",\n                    f\"- Independent variable: {entry['independent_variable']}\",\n                    f\"- Sampling method: {entry['independent_variable_sampling']}\",\n                    f\"- Working directory: {entry['workspace_path']}\",\n                    f\"- Configuration file: {entry['config_file']}\",\n                ]\n            )\n\n        # Save report to current directory\n        report_path = os.path.join(\n            current_dir,\n            run_timestamp,\n            f\"execution_report_{run_timestamp}.md\",\n        )\n        os.makedirs(os.path.dirname(report_path), exist_ok=True)\n        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(report_lines))\n\n        logger.info(\"Summary report generated:\")\n        logger.info(f\"  - Detailed report: {report_path}\")\n\n        # Generate prompt engineering template for each case\n        generate_prompt_templates(case_configs, original_config)\n\n        # Consolidate all generated reports\n        consolidate_reports(case_configs, original_config)\n\n    except Exception as e:\n        logger.error(f\"Error generating summary report: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.generate_prompt_templates","title":"<code>generate_prompt_templates(case_configs, original_config)</code>","text":"<p>Generate detailed Markdown analysis reports for each analysis case.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries containing case data and workspace info.</p> \u5fc5\u9700 <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary with sensitivity analysis settings.</p> \u5fc5\u9700 Note <p>Skips SALib cases (those with analyzer.method defined). For each case, generates a detailed Markdown report including configuration details, optimization configs, time-series plots, performance metric plots, and data tables. Supports AI-enhanced reporting if API credentials are available. Creates bilingual plots prioritizing Chinese versions (_zh suffix).</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/report.py</code> <pre><code>def generate_prompt_templates(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Generate detailed Markdown analysis reports for each analysis case.\n\n    Args:\n        case_configs: List of case configuration dictionaries containing case data and workspace info.\n        original_config: Original configuration dictionary with sensitivity analysis settings.\n\n    Note:\n        Skips SALib cases (those with analyzer.method defined). For each case, generates\n        a detailed Markdown report including configuration details, optimization configs,\n        time-series plots, performance metric plots, and data tables. Supports AI-enhanced\n        reporting if API credentials are available. Creates bilingual plots prioritizing\n        Chinese versions (_zh suffix).\n    \"\"\"\n\n    def _find_unit_config(var_name: str, unit_map: dict) -&gt; dict | None:\n        \"\"\"\n        Finds the unit configuration for a variable name from the unit_map.\n        1. Checks for an exact match.\n        2. Checks if the last part of a dot-separated name matches.\n        3. Checks for a simple substring containment as a fallback, matching longest keys first.\n        \"\"\"\n        if not unit_map or not var_name:\n            return None\n        if var_name in unit_map:\n            return unit_map[var_name]\n        components = var_name.split(\".\")\n        if len(components) &gt; 1 and components[-1] in unit_map:\n            return unit_map[components[-1]]\n        for key in sorted(unit_map.keys(), key=len, reverse=True):\n            if key in var_name:\n                return unit_map[key]\n        return None\n\n    def _format_label(label: str) -&gt; str:\n        \"\"\"Formats a label for display, replacing underscores/dots with spaces and capitalizing each word.\"\"\"\n        if not isinstance(label, str):\n            return label\n        label = label.replace(\"_\", \" \")\n        label = re.sub(r\"(?&lt;!\\d)\\.|\\.(?!\\d)\", \" \", label)\n        return label  # .title()\n\n    try:\n        sensitivity_analysis_config = original_config.get(\"sensitivity_analysis\", {})\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n\n            if \"analyzer\" in case_data and case_data.get(\"analyzer\", {}).get(\"method\"):\n                logger.info(\n                    f\"Skipping default report generation for SALib case: {case_data.get('name', 'Unknown')}\"\n                )\n                continue\n\n            case_workspace = case_info[\"workspace\"]\n            case_name = case_data.get(\"name\", f\"Case{case_info['index']+1}\")\n\n            case_results_dir = os.path.join(case_workspace, \"results\")\n            if not os.path.exists(case_results_dir):\n                continue\n\n            summary_csv_path = os.path.join(\n                case_results_dir, \"sensitivity_analysis_summary.csv\"\n            )\n            sweep_csv_path = os.path.join(case_results_dir, \"sweep_results.csv\")\n\n            if not os.path.exists(summary_csv_path):\n                logger.warning(\n                    f\"summary_csv not found for case {case_name}, skipping report generation.\"\n                )\n                continue\n\n            summary_df = pd.read_csv(summary_csv_path)\n            independent_variable = case_data.get(\"independent_variable\", \"\u71c3\u70e7\u7387\")\n\n            # Use a dictionary to ensure we only get one version of each plot, prioritizing Chinese\n            all_plots_all_langs = [\n                f for f in os.listdir(case_results_dir) if f.endswith(\".svg\")\n            ]\n            plot_map = {}\n            for plot in sorted(\n                all_plots_all_langs, reverse=True\n            ):  # Process _zh.svg first\n                base_name = plot.replace(\"_zh.svg\", \".svg\")\n                if base_name not in plot_map:\n                    plot_map[base_name] = plot\n\n            all_plots = list(plot_map.values())\n            sweep_plots = [f for f in all_plots if f.startswith(\"sweep_\")]\n            combined_plots = [f for f in all_plots if f.startswith(\"combined_\")]\n            multi_metric_plots = [\n                f\n                for f in all_plots\n                if f.startswith(\"multi_\") and f.endswith(\"_analysis_by_param.svg\")\n            ]\n            all_individual_plots = [\n                f\n                for f in all_plots\n                if not f.startswith(\"sweep_\")\n                and not f.startswith(\"combined_\")\n                and not f.startswith(\"multi_\")\n            ]\n            required_individual_plots = [\n                f for f in all_individual_plots if f.startswith(\"line_Required_\")\n            ]\n            standard_individual_plots = [\n                f for f in all_individual_plots if not f.startswith(\"line_Required_\")\n            ]\n\n            # --- Markdown Generation (with dynamic title) ---\n            sim_params = case_data.get(\"simulation_parameters\")\n            if sim_params:\n                main_var_label = _format_label(independent_variable)\n\n                other_vars_labels_list = []\n                for p in sim_params.keys():\n                    if p == \"Required_TBR\":\n                        label = \"Required_TBR\u7ea6\u675f\u503c\"\n                    else:\n                        label = _format_label(p)\n                    other_vars_labels_list.append(label)\n                other_vars_labels = \"\u3001\".join(other_vars_labels_list)\n\n                report_title = (\n                    f\"# {main_var_label} \u4e0e {other_vars_labels} \u4ea4\u4e92\u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n                )\n            else:\n                report_title = (\n                    f\"# {_format_label(independent_variable)} \u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n                )\n\n            prompt_lines = [\n                report_title,\n                f\"\u751f\u6210\u65f6\u95f4: {pd.Timestamp.now()}\\n\\n\",\n            ]\n\n            config_details_lines = [\n                \"## \u5206\u6790\u6848\u4f8b\u914d\u7f6e\u8be6\u60c5\\n\\n\",\n                \"\u672c\u5206\u6790\u6848\u4f8b\u7684\u5177\u4f53\u914d\u7f6e\u5982\u4e0b\uff0c\u8fd9\u51b3\u5b9a\u4e86\u4eff\u771f\u7684\u626b\u63cf\u65b9\u5f0f\u548c\u5206\u6790\u7684\u91cd\u70b9\uff1a\\n\\n\",\n                \"| \u914d\u7f6e\u9879 | \u503c | \u8bf4\u660e |\",\n                \"| :--- | :--- | :--- |\",\n            ]\n\n            def format_for_md(value):\n                return f\"`{json.dumps(value, ensure_ascii=False)}`\".replace(\"|\", \"\\\\|\")\n\n            config_details_lines.extend(\n                [\n                    f\"| **`name`** | {format_for_md(case_name)} | \u672c\u6b21\u5206\u6790\u6848\u4f8b\u7684\u540d\u79f0\u3002 |\",\n                    f\"| **`independent_variable`** | {format_for_md(independent_variable)} | \u72ec\u7acb\u626b\u63cf\u53d8\u91cf\uff0c\u5373\u672c\u6b21\u5206\u6790\u4e2d\u4e3b\u8981\u6539\u53d8\u7684\u53c2\u6570\u3002 |\",\n                    f\"| **`independent_variable_sampling`** | {format_for_md(case_data.get('independent_variable_sampling'))} | \u72ec\u7acb\u53d8\u91cf\u7684\u91c7\u6837\u65b9\u6cd5\u548c\u8303\u56f4\u3002 |\",\n                ]\n            )\n            if \"default_independent_values\" in case_data:\n                config_details_lines.append(\n                    f\"| **`default_independent_values`** | {format_for_md(case_data['default_independent_values'])} | \u72ec\u7acb\u626b\u63cf\u53d8\u91cf\u5728\u6a21\u578b\u4e2d\u7684\u539f\u59cb\u9ed8\u8ba4\u503c\u3002 |\"\n                )\n            if (\n                \"simulation_parameters\" in case_data\n                and case_data[\"simulation_parameters\"]\n            ):\n                config_details_lines.append(\n                    f\"| **`simulation_parameters`** | {format_for_md(case_data['simulation_parameters'])} | \u80cc\u666f\u626b\u63cf\u53c2\u6570\uff0c\u4e0e\u72ec\u7acb\u53d8\u91cf\u7ec4\u5408\u5f62\u6210\u591a\u7ef4\u626b\u63cf\u3002 |\"\n                )\n            if (\n                \"default_simulation_values\" in case_data\n                and case_data[\"default_simulation_values\"]\n            ):\n                config_details_lines.append(\n                    f\"| **`default_simulation_values`** | {format_for_md(case_data['default_simulation_values'])} | \u80cc\u666f\u626b\u63cf\u53c2\u6570\u5728\u6a21\u578b\u4e2d\u7684\u539f\u59cb\u9ed8\u8ba4\u503c\u3002 |\"\n                )\n            config_details_lines.append(\n                f\"| **`dependent_variables`** | {format_for_md(case_data.get('dependent_variables'))} | \u56e0\u53d8\u91cf\uff0c\u5373\u6211\u4eec\u5173\u5fc3\u7684\u3001\u968f\u81ea\u53d8\u91cf\u53d8\u5316\u7684\u6027\u80fd\u6307\u6807\u3002 |\"\n            )\n            config_details_lines.append(\"\\n\")\n            prompt_lines.extend(config_details_lines)\n\n            optimization_metrics = [\n                v\n                for v in case_data.get(\"dependent_variables\", [])\n                if v.startswith(\"Required_\")\n            ]\n            if optimization_metrics:\n                for metric_name in optimization_metrics:\n                    metric_config = (\n                        original_config.get(\"sensitivity_analysis\", {})\n                        .get(\"metrics_definition\", {})\n                        .get(metric_name)\n                    )\n                    if metric_config:\n                        details_lines = [\n                            f\"## \u201c{metric_name}\u201d\u4f18\u5316\u914d\u7f6e\\n\",\n                            f\"\u5f53\u201c{metric_name}\u201d\u4f5c\u4e3a\u56e0\u53d8\u91cf\u65f6\uff0c\u7cfb\u7edf\u4f1a\u542f\u7528\u4e00\u4e2a\u4e8c\u5206\u67e5\u627e\u7b97\u6cd5\u6765\u5bfb\u627e\u6ee1\u8db3\u7279\u5b9a\u6027\u80fd\u6307\u6807\u7684\u6700\u5c0f`{metric_config.get('parameter_to_optimize', 'N/A')}`\u503c\u3002\u4ee5\u4e0b\u662f\u672c\u6b21\u4f18\u5316\u4efb\u52a1\u7684\u5177\u4f53\u914d\u7f6e\uff1a\\n\\n\",\n                            \"| \u914d\u7f6e\u9879 | \u503c | \u8bf4\u660e |\",\n                            \"| :--- | :--- | :--- |\",\n                        ]\n                        config_map = {\n                            \"source_column\": \"\u9650\u5236\u6761\u4ef6\u7684\u6570\u636e\u6e90\u5217\u3002\",\n                            \"parameter_to_optimize\": \"\u4f18\u5316\u7684\u76ee\u6807\u53c2\u6570\u3002\",\n                            \"search_range\": \"\u53c2\u6570\u7684\u641c\u7d22\u8303\u56f4\u3002\",\n                            \"tolerance\": \"\u641c\u7d22\u7684\u6536\u655b\u7cbe\u5ea6\u3002\",\n                            \"max_iterations\": \"\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002\",\n                            \"metric_name\": \"\u9650\u5236\u6761\u4ef6\u7684\u6027\u80fd\u6307\u6807\u3002\",\n                            \"metric_max_value\": \"\u9650\u5236\u6761\u4ef6\u6ee1\u8db3\u7684\u4e0a\u9650\u503c\u3002\uff08hour\uff09\",\n                        }\n                        for key, description in config_map.items():\n                            if key in metric_config:\n                                value = metric_config[key]\n                                details_lines.append(\n                                    f\"| **`{key}`** | {format_for_md(value)} | {description} |\"\n                                )\n\n                            metric_config_sim = case_data.get(\n                                \"simulation_parameters\", {}\n                            ).get(\"Required_TBR\", {})\n                            if metric_config_sim and key in metric_config_sim:\n                                value = metric_config_sim[key]\n                                details_lines.append(\n                                    f\"| **`{key} (from simulation_parameters)`** | {format_for_md(value)} | {description} |\"\n                                )\n\n                        details_lines.append(\"\\n\")\n                        prompt_lines.extend(details_lines)\n\n            for plot in sweep_plots:\n                prompt_lines.extend(\n                    [\n                        \"## SDS Inventory \u7684\u65f6\u95f4\u66f2\u7ebf\u56fe:\\n\\n\",\n                        f\"![SDS Inventory \u7684\u65f6\u95f4\u66f2\u7ebf\u56fe]({plot})\\n\\n\",\n                    ]\n                )\n                if \"default_simulation_values\" in case_data and case_data.get(\n                    \"default_simulation_values\"\n                ):\n                    default_values_str = json.dumps(\n                        case_data[\"default_simulation_values\"],\n                        ensure_ascii=False,\n                        indent=4,\n                    )\n                    note = (\n                        \"**\u7b5b\u9009\u8bf4\u660e**\uff1a\u5f53\u5b58\u5728\u591a\u4e2a\u80cc\u666f\u626b\u63cf\u53c2\u6570 (`simulation_parameters`) \u65f6\uff0c\u4e3a\u7a81\u51fa\u91cd\u70b9\uff0c\u4e0a\u56fe\u9ed8\u8ba4\u4ec5\u663e\u793a\u4e0e\u539f\u59cb\u9ed8\u8ba4\u503c \"\n                        f\"(`default_simulation_values`) \u76f8\u5339\u914d\u7684\u57fa\u51c6\u60c5\u666f\u66f2\u7ebf\u3002\u672c\u6b21\u5206\u6790\u4e2d\u7528\u4e8e\u7b5b\u9009\u7684\u9ed8\u8ba4\u503c\u4e3a\uff1a\\n\\n\"\n                        f\"```json\\n{default_values_str}\\n```\\n\\n\"\n                        \"\u6b64\u65b9\u6cd5\u6709\u52a9\u4e8e\u5728\u56fa\u5b9a\u7684\u57fa\u51c6\u6761\u4ef6\u4e0b\uff0c\u6e05\u6670\u5730\u89c2\u5bdf\u72ec\u7acb\u53d8\u91cf\u53d8\u5316\u5e26\u6765\u7684\u5f71\u54cd\u3002\\n\"\n                    )\n                    prompt_lines.append(note)\n\n            if combined_plots:\n                for plot in combined_plots:\n                    title = \"\u6027\u80fd\u6307\u6807\u8d8b\u52bf\u66f2\u7ebf\u56fe\"\n                    prompt_lines.extend([f\"## {title}\\n\\n\", f\"![{title}]({plot})\\n\"])\n            elif standard_individual_plots:\n                prompt_lines.append(\"## \u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\\n\\n\")\n                for plot in standard_individual_plots:\n                    title = _format_label(\n                        os.path.splitext(plot)[0].replace(\"line_\", \"\")\n                    )\n                    prompt_lines.extend([f\"### {title}\\n\", f\"![{title}]({plot})\\n\\n\"])\n\n            if multi_metric_plots or required_individual_plots:\n                prompt_lines.append(\"## \u7ea6\u675f\u6c42\u89e3\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\\n\\n\")\n                for plot_file in multi_metric_plots:\n                    try:\n                        base_metric_name = plot_file.replace(\"multi_\", \"\").replace(\n                            \"_analysis_by_param.svg\", \"\"\n                        )\n                        friendly_name = _format_label(base_metric_name)\n                    except Exception:\n                        friendly_name = \"Optimization\"\n                    prompt_lines.extend(\n                        [\n                            f\"### \u4e0d\u540c\u7ea6\u675f\u503c\u4e0b\u7684\u201c{friendly_name}\u201d\u5206\u6790 (\u6309\u53c2\u6570\u5206\u7ec4)\\n\",\n                            f\"\u4e0b\u56fe\u5c55\u793a\u4e86\u201c{friendly_name}\u201d\u6307\u6807\u968f\u72ec\u7acb\u53d8\u91cf\u53d8\u5316\u7684\u8d8b\u52bf\u3002\u6bcf\u4e2a\u5b50\u56fe\u5bf9\u5e94\u4e00\u7ec4\u7279\u5b9a\u7684\u80cc\u666f\u626b\u63cf\u53c2\u6570\u7ec4\u5408\uff0c\u5b50\u56fe\u5185\u7684\u6bcf\u6761\u66f2\u7ebf\u4ee3\u8868\u4e00\u4e2a\u5177\u4f53\u7684\u7ea6\u675f\u503c\u3002\\n\\n\",\n                            f\"![\u4e0d\u540c\u7ea6\u675f\u503c\u4e0b\u7684{friendly_name}\u5206\u6790]({plot_file})\\n\\n\",\n                        ]\n                    )\n                for plot_file in required_individual_plots:\n                    title = _format_label(\n                        os.path.splitext(plot_file)[0].replace(\"line_\", \"\")\n                    )\n                    prompt_lines.extend(\n                        [f\"### {title}\\n\", f\"![{title}]({plot_file})\\n\\n\"]\n                    )\n\n            def _format_df_to_md(\n                sub_df: pd.DataFrame,\n                ind_var: str,\n                case_data: dict,\n                current_unit_map: dict,\n            ) -&gt; str:\n                if sub_df.empty:\n                    return \"\u65e0\u6570\u636e\u3002\"\n                all_markdown_lines = []\n                all_cols = sub_df.columns.tolist()\n                if ind_var in all_cols:\n                    all_cols.remove(ind_var)\n                standard_cols = [\n                    c\n                    for c in all_cols\n                    if not (c.startswith(\"Required_\") or \"_for_Required_\" in c)\n                ]\n                required_groups = {}\n                required_base_names = [\n                    v\n                    for v in case_data.get(\"dependent_variables\", [])\n                    if v.startswith(\"Required_\")\n                ]\n                for base_name in required_base_names:\n                    group_cols = []\n                    # pattern = re.compile(f\"_for_{re.escape(base_name)}(?:\\\\(.*\\\\))?$\")\n                    for col in all_cols:\n                        if col == base_name or col.startswith(base_name + \"(\"):\n                            group_cols.append(col)\n                    if group_cols:\n                        required_groups[base_name] = group_cols\n\n                def _format_slice_to_md(df_slice: pd.DataFrame, umap: dict) -&gt; str:\n                    if df_slice.empty:\n                        return \"\"\n                    df_formatted = df_slice.copy()\n                    new_columns = {}\n                    for col_name in df_formatted.columns:\n                        unit_config = _find_unit_config(col_name, umap)\n                        new_col_name = _format_label(col_name)\n                        if unit_config:\n                            unit = unit_config.get(\"unit\")\n                            factor = unit_config.get(\"conversion_factor\")\n                            if factor and pd.api.types.is_numeric_dtype(\n                                df_formatted[col_name]\n                            ):\n                                df_formatted[col_name] = df_formatted[col_name] / float(\n                                    factor\n                                )\n                            if unit:\n                                new_col_name = f\"{new_col_name} ({unit})\"\n                        new_columns[col_name] = new_col_name\n                    df_formatted.rename(columns=new_columns, inplace=True)\n                    format_map = {}\n                    for original_col_name in df_slice.columns:\n                        if original_col_name.startswith(\"Required_\"):\n                            format_map[new_columns[original_col_name]] = \"{:.4f}\"\n                    default_format = \"{:.2f}\"\n                    for col in df_formatted.columns:\n                        if pd.api.types.is_numeric_dtype(df_formatted[col]):\n                            formatter = format_map.get(col, default_format)\n                            df_formatted[col] = df_formatted[col].apply(\n                                lambda x: formatter.format(x) if pd.notnull(x) else x\n                            )\n                    return df_formatted.to_markdown(index=False)\n\n                if standard_cols:\n                    all_markdown_lines.append(\"##### \u6027\u80fd\u6307\u6807\\n\")\n                    std_df_slice = sub_df[[ind_var] + sorted(standard_cols)]\n                    all_markdown_lines.append(\n                        _format_slice_to_md(std_df_slice, current_unit_map)\n                    )\n                    all_markdown_lines.append(\"\\n\")\n                if required_groups:\n                    for base_name, cols in required_groups.items():\n                        existing_cols = [c for c in cols if c in sub_df.columns]\n                        if not existing_cols:\n                            continue\n\n                        all_markdown_lines.append(\n                            f\"##### \u201c{_format_label(base_name)}\u201d \u76f8\u5173\u6570\u636e\\n\"\n                        )\n                        req_df_slice = sub_df[[ind_var] + sorted(existing_cols)]\n\n                        try:\n                            # --- PIVOT LOGIC to transform data from wide to long format ---\n                            # e.g., from [A, B(v1), B(v2)] to [A, new_col, B]\n\n                            # Columns to unpivot, e.g., ['Required_TBR(7.0)', 'Required_TBR(10.0)']\n                            value_vars = [\n                                c\n                                for c in req_df_slice.columns\n                                if c.startswith(base_name)\n                                and \"(\" in c\n                                and c.endswith(\")\")\n                            ]\n\n                            # If no columns are in the format B(v), pivot is not applicable.\n                            if not value_vars:\n                                all_markdown_lines.append(\n                                    _format_slice_to_md(req_df_slice, current_unit_map)\n                                )\n                                all_markdown_lines.append(\"\\n\")\n                                continue\n\n                            # Melt the dataframe from wide to long format\n                            melted_df = req_df_slice.melt(\n                                id_vars=[ind_var],\n                                value_vars=value_vars,\n                                var_name=\"variable_col\",\n                                value_name=base_name,\n                            )\n\n                            # Determine the name for the new column from config (e.g., 'Doubling_Time')\n                            new_col_name = \"Constraint\"  # Default name\n                            metric_def = case_data.get(\"simulation_parameters\").get(\n                                \"Required_TBR\"\n                            )\n                            if metric_def and metric_def.get(\"metric_name\"):\n                                new_col_name = \"Constraint \" + metric_def[\"metric_name\"]\n\n                            # Extract constraint value from old column name, e.g., '7.0' from 'Required_TBR(7.0)'\n                            pattern_str = f\"{re.escape(base_name)}\\\\((.*)\\\\)\"\n                            melted_df[new_col_name] = melted_df[\n                                \"variable_col\"\n                            ].str.extract(pat=pattern_str)\n\n                            # Create the final dataframe with the desired columns: [A, new_col, B]\n                            final_df = melted_df[\n                                [ind_var, new_col_name, base_name]\n                            ].copy()\n                            final_df.dropna(subset=[base_name], inplace=True)\n\n                            all_markdown_lines.append(final_df.to_markdown(index=False))\n                            all_markdown_lines.append(\"\\n\")\n\n                        except Exception as e:\n                            logger.warning(\n                                f\"Could not pivot data for '{base_name}', displaying in wide format. Error: {e}\"\n                            )\n                            all_markdown_lines.append(\n                                _format_slice_to_md(req_df_slice, current_unit_map)\n                            )\n                            all_markdown_lines.append(\"\\n\")\n                return \"\\n\".join(all_markdown_lines)\n\n            reference_col_for_turning_point = None\n            if case_data.get(\"sweep_time\") and os.path.exists(sweep_csv_path):\n                try:\n                    logger.info(\"Loading sweep_results.csv for dynamic slicing.\")\n                    sweep_df = pd.read_csv(sweep_csv_path)\n                    if \"time\" in sweep_df.columns and len(sweep_df.columns) &gt; 1:\n                        reference_col_for_turning_point = sweep_df.columns[\n                            len(sweep_df.columns) // 2\n                        ]\n                    if reference_col_for_turning_point:\n                        data_to_slice_df = sweep_df.copy()\n                        data_to_slice_df.reset_index(drop=True, inplace=True)\n                        if not data_to_slice_df.empty:\n                            prompt_lines.append(\"## \u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u8fc7\u7a0b\u6570\u636e\\n\\n\")\n                            prompt_lines.append(\n                                f\"\u4e0b\u8868\u5c55\u793a\u4e86\u8fc7\u7a0b\u6570\u636e\u4e2d\uff0c\u4ee5 `{reference_col_for_turning_point}` \u4e3a\u53c2\u8003\u53d8\u91cf\uff0c\u5728\u5173\u952e\u9636\u6bb5\u7684\u6570\u636e\u5207\u7247\u3002**\u6ce8\u610f\uff1a\u4e0b\u8868\u4e2d\u7684\u9ed8\u8ba4\u5355\u4f4d\u4e3a\uff1a\u65f6\u95f4(h), \u5e93\u5b58(g), \u529f\u7387(MW)\u3002**\\n\\n\"\n                            )\n                            base_var_name = reference_col_for_turning_point.split(\"&amp;\")[\n                                0\n                            ]\n                            cols_to_rename = [\n                                c for c in data_to_slice_df.columns if c != \"time\"\n                            ]\n                            rename_map = {\n                                col: f\"C{i+1}\" for i, col in enumerate(cols_to_rename)\n                            }\n                            legend_lines = [\n                                \"**\u8868\u683c\u56fe\u4f8b\u8bf4\u660e**\uff1a\",\n                                \"| \u7b80\u79f0 | \u53c2\u6570\u7ec4\u5408 |\",\n                                \"| :--- | :--- |\",\n                            ]\n                            for original_name, abbr in rename_map.items():\n                                param_parts = original_name.split(\"&amp;\", 1)\n                                param_str = (\n                                    param_parts[1] if len(param_parts) &gt; 1 else \"\u65e0\"\n                                )\n                                param_str_formatted = (\n                                    \"`\" + \"`, `\".join(param_str.split(\"&amp;\")) + \"`\"\n                                )\n                                legend_lines.append(\n                                    f\"| **{abbr}** | {param_str_formatted} |\"\n                                )\n                            base_var_info = f\"**\u6ce8**\uff1a\u8868\u683c\u4e2d\u6240\u6709\u7b80\u79f0\u5217\uff08C1, C2, ...\uff09\u7684\u6570\u636e\u5747\u4ee3\u8868\u53d8\u91cf `{base_var_name}` \u5728\u4e0d\u540c\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u503c\u3002\\n\"\n                            legend_md = base_var_info + \"\\n\".join(legend_lines) + \"\\n\\n\"\n                            prompt_lines.append(legend_md)\n                            primary_y_var = reference_col_for_turning_point\n                            min_idx = -1\n                            if primary_y_var in data_to_slice_df.columns:\n                                y_data = data_to_slice_df[primary_y_var]\n                                if not y_data.empty:\n                                    min_idx = y_data.idxmin()\n                            num_points, interval = 20, 2\n                            window_size = (num_points - 1) * interval + 1\n                            start_data = data_to_slice_df.iloc[:window_size:interval]\n                            end_data = data_to_slice_df.iloc[-(window_size)::interval]\n                            prompt_lines.append(\n                                f\"### 1. \u521d\u59cb\u9636\u6bb5 (\u524d {num_points} \u4e2a\u6570\u636e\u70b9, \u95f4\u9694 {interval})\\n\"\n                            )\n                            prompt_lines.append(\n                                start_data.rename(columns=rename_map).to_markdown(\n                                    index=False\n                                )\n                                + \"\\n\\n\"\n                            )\n                            if min_idx != -1:\n                                window_radius_indices = (num_points // 2) * interval\n                                start_idx = max(0, min_idx - window_radius_indices)\n                                end_idx = min(\n                                    len(data_to_slice_df),\n                                    min_idx + window_radius_indices,\n                                )\n                                turning_point_data = data_to_slice_df.iloc[\n                                    start_idx:end_idx:interval\n                                ]\n                                prompt_lines.append(\n                                    f\"### 2. \u8f6c\u6298\u70b9\u9636\u6bb5 (\u56f4\u7ed5 '{primary_y_var}' \u6700\u5c0f\u503c)\\n\"\n                                )\n                                prompt_lines.append(\n                                    turning_point_data.rename(\n                                        columns=rename_map\n                                    ).to_markdown(index=False)\n                                    + \"\\n\\n\"\n                                )\n                            prompt_lines.append(\n                                f\"### 3. \u7ed3\u675f\u9636\u6bb5 (\u540e {num_points} \u4e2a\u6570\u636e\u70b9, \u95f4\u9694 {interval})\\n\"\n                            )\n                            prompt_lines.append(\n                                end_data.rename(columns=rename_map).to_markdown(\n                                    index=False\n                                )\n                                + \"\\n\\n\"\n                            )\n                except Exception as e:\n                    logger.warning(\n                        f\"Could not generate dynamic data slices for case {case_name}: {e}\"\n                    )\n\n            grouping_vars = list(case_data.get(\"default_simulation_values\", {}).keys())\n            if not grouping_vars:\n                prompt_lines.append(\"## \u6027\u80fd\u6307\u6807\u603b\u8868\\n\\n\")\n                prompt_lines.append(\n                    _format_df_to_md(\n                        summary_df, independent_variable, case_data, unit_map\n                    )\n                )\n            else:\n                prompt_lines.append(\n                    f\"## \u6027\u80fd\u6307\u6807\u603b\u8868 (\u5206\u7ec4: `{'`, `'.join(grouping_vars)}`)\\n\\n\"\n                )\n                groups = dict(list(summary_df.groupby(grouping_vars)))\n                default_values = case_data.get(\"default_simulation_values\")\n                default_group_key = None\n                if default_values:\n                    try:\n                        default_group_key = tuple(\n                            default_values[key] for key in grouping_vars\n                        )\n                    except KeyError:\n                        logger.warning(\n                            \"Mismatch between default_simulation_values and grouping_vars. Cannot find default group.\"\n                        )\n                        default_group_key = None\n                if default_group_key and default_group_key in groups:\n                    default_group_df = groups.pop(default_group_key)\n                    header = \" &amp; \".join(\n                        f\"`{var}={val}`\"\n                        for var, val in zip(grouping_vars, default_group_key)\n                    )\n                    prompt_lines.append(f\"#### \u6570\u636e\u5b50\u8868 (\u539f\u59cb\u9ed8\u8ba4\u503c: {header})\\n\")\n                    sub_df_to_format = default_group_df.drop(\n                        columns=grouping_vars, errors=\"ignore\"\n                    )\n                    prompt_lines.append(\n                        _format_df_to_md(\n                            sub_df_to_format, independent_variable, case_data, unit_map\n                        )\n                    )\n                    prompt_lines.append(\"\\n---\\n\")\n                if groups:\n                    prompt_lines.append(\"&gt; \u5176\u4ed6\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u6570\u636e\u5b50\u8868\uff1a\\n\")\n                for group_name, group_df in groups.items():\n                    header = (\n                        \" &amp; \".join(\n                            f\"`{var}={val}`\"\n                            for var, val in zip(grouping_vars, group_name)\n                        )\n                        if isinstance(group_name, tuple)\n                        else f\"`{grouping_vars[0]}={group_name}`\"\n                    )\n                    prompt_lines.append(f\"#### \u6570\u636e\u5b50\u8868 (\u5f53 {header} \u65f6)\\n\")\n                    sub_df_to_format = group_df.drop(\n                        columns=grouping_vars, errors=\"ignore\"\n                    )\n                    prompt_lines.append(\n                        _format_df_to_md(\n                            sub_df_to_format, independent_variable, case_data, unit_map\n                        )\n                    )\n                    prompt_lines.append(\"\\n\")\n\n            base_report_content = \"\\n\".join(prompt_lines)\n\n            # --- AI Analysis and Report Writing ---\n            if not case_data.get(\"ai\", False):\n                # AI is off: write a single, simple report\n                report_path = os.path.join(\n                    case_results_dir, f\"analysis_report_{case_name}.md\"\n                )\n                with open(report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Detailed analysis report generated for {case_name}: {report_path}\"\n                )\n                continue  # Go to next case\n\n            # AI is ON: go into multi-model logic\n            load_dotenv()\n            api_key = os.environ.get(\"API_KEY\")\n            base_url = os.environ.get(\"BASE_URL\")\n\n            ai_models_str = os.environ.get(\"AI_MODELS\")\n            if not ai_models_str:\n                ai_models_str = os.environ.get(\"AI_MODEL\")\n\n            if not all((api_key, base_url, ai_models_str)):\n                logger.warning(\n                    \"API_KEY, BASE_URL, or AI_MODELS/AI_MODEL not found in environment variables. Skipping LLM analysis.\"\n                )\n                # Also write the base report here so something is generated\n                report_path = os.path.join(\n                    case_results_dir, f\"analysis_report_{case_name}.md\"\n                )\n                with open(report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Wrote base report for {case_name} because AI credentials were not found: {report_path}\"\n                )\n                continue\n\n            ai_models = [model.strip() for model in ai_models_str.split(\",\")]\n\n            for ai_model in ai_models:\n                logger.info(\n                    f\"Generating AI analysis for case '{case_name}' with model '{ai_model}'.\"\n                )\n\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                model_report_filename = (\n                    f\"analysis_report_{case_name}_{sanitized_model_name}.md\"\n                )\n                model_report_path = os.path.join(\n                    case_results_dir, model_report_filename\n                )\n\n                with open(model_report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Generated base report for model {ai_model}: {model_report_path}\"\n                )\n\n                llm_analysis = call_openai_analysis_api(\n                    case_name=case_name,\n                    df=summary_df,\n                    api_key=api_key,\n                    base_url=base_url,\n                    ai_model=ai_model,\n                    independent_variable=independent_variable,\n                    report_content=base_report_content,\n                    original_config=original_config,\n                    case_data=case_data,\n                    reference_col_for_turning_point=reference_col_for_turning_point,\n                )\n\n                if llm_analysis:\n                    with open(model_report_path, \"a\", encoding=\"utf-8\") as f:\n                        f.write(\n                            f\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd ({ai_model})\\n\\n```markdown\\n\"\n                        )\n                        f.write(llm_analysis)\n                        f.write(\"\\n```\\n\")\n                    logger.info(f\"Appended LLM analysis to {model_report_path}\")\n\n                    generate_sensitivity_academic_report(\n                        case_name=case_name,\n                        case_workspace=case_workspace,\n                        independent_variable=independent_variable,\n                        original_config=original_config,\n                        case_data=case_data,\n                        ai_model=ai_model,\n                        report_path=model_report_path,\n                    )\n\n    except Exception as e:\n        logger.error(f\"Error generating detailed analysis reports: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.generate_sensitivity_academic_report","title":"<code>generate_sensitivity_academic_report(case_name, case_workspace, independent_variable, original_config, case_data, ai_model, report_path)</code>","text":"<p>Generates a professional academic analysis summary for a sensitivity analysis case.</p> <p>Sends the existing report and a glossary of terms to an LLM for academic formatting.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>case_name</code> <code>str</code> <p>Name of the analysis case.</p> \u5fc5\u9700 <code>case_workspace</code> <code>str</code> <p>Path to the case workspace directory.</p> \u5fc5\u9700 <code>independent_variable</code> <code>str</code> <p>Name of the independent variable.</p> \u5fc5\u9700 <code>original_config</code> <code>dict</code> <p>Original configuration dictionary.</p> \u5fc5\u9700 <code>case_data</code> <code>dict</code> <p>Case-specific data dictionary.</p> \u5fc5\u9700 <code>ai_model</code> <code>str</code> <p>Model name to use for generating the report.</p> \u5fc5\u9700 <code>report_path</code> <code>str</code> <p>Path to the existing report file.</p> \u5fc5\u9700 Note <p>Requires report file and glossary file to exist. Loads API credentials from environment variables. Generates academic report with proper structure including title, abstract, introduction, methodology, results &amp; discussion, and conclusion. Retries up to 3 times on API failure. Saves result to academic_report_{case_name}_{model}.md.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/report.py</code> <pre><code>def generate_sensitivity_academic_report(\n    case_name: str,\n    case_workspace: str,\n    independent_variable: str,\n    original_config: dict,\n    case_data: dict,\n    ai_model: str,\n    report_path: str,\n) -&gt; None:\n    \"\"\"Generates a professional academic analysis summary for a sensitivity analysis case.\n\n    Sends the existing report and a glossary of terms to an LLM for academic formatting.\n\n    Args:\n        case_name: Name of the analysis case.\n        case_workspace: Path to the case workspace directory.\n        independent_variable: Name of the independent variable.\n        original_config: Original configuration dictionary.\n        case_data: Case-specific data dictionary.\n        ai_model: Model name to use for generating the report.\n        report_path: Path to the existing report file.\n\n    Note:\n        Requires report file and glossary file to exist. Loads API credentials from\n        environment variables. Generates academic report with proper structure including\n        title, abstract, introduction, methodology, results &amp; discussion, and conclusion.\n        Retries up to 3 times on API failure. Saves result to academic_report_{case_name}_{model}.md.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Starting generation of the academic analysis summary for case {case_name} with model {ai_model}.\"\n        )\n\n        # 1. Read the existing report\n        results_dir = os.path.join(case_workspace, \"results\")\n        report_filename = os.path.basename(report_path)\n\n        if not os.path.exists(report_path):\n            logger.error(\n                f\"Cannot generate academic summary: Original report '{report_path}' not found.\"\n            )\n            return\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            original_report_content = f.read()\n\n        # 2. Read the glossary\n        glossary_path = original_config.get(\"sensitivity_analysis\", {}).get(\n            \"glossary_path\", \"./sheets.csv\"\n        )\n        if not os.path.exists(glossary_path):\n            logger.error(\n                f\"Cannot generate academic summary: Glossary file '{glossary_path}' not found.\"\n            )\n            return\n        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n            glossary_content = f.read()\n\n        # 3. Check for API credentials\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        if not all([api_key, base_url, ai_model]):\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not found. Skipping academic summary generation.\"\n            )\n            return\n\n        # 4. Construct the prompt\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e**\u654f\u611f\u6027\u5206\u6790**\u7684\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7684\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\"\"\"\n\n        # Extract relevant details from case_data for the prompt\n        sampling_range = case_data.get(\"independent_variable_sampling\", {})\n        simulation_parameters = case_data.get(\"simulation_parameters\", {})\n        dependent_variables = case_data.get(\"dependent_variables\", [])\n\n        simulation_params_str = \"\"\n        if simulation_parameters:\n            params_list = []\n            # Access metric definitions from the original config\n            metrics_definitions = original_config.get(\"sensitivity_analysis\", {}).get(\n                \"metrics_definition\", {}\n            )\n\n            for k, v in simulation_parameters.items():\n                # Check if the parameter is a 'Required_' metric and has configurations defined\n                if (\n                    k.startswith(\"Required_\")\n                    and k in metrics_definitions\n                    and \"configurations\" in metrics_definitions[k]\n                ):\n                    try:\n                        metric_configs = metrics_definitions[k][\"configurations\"]\n                        # Look up the metric_max_value for each configuration key in the scan list `v`\n                        actual_values = [\n                            metric_configs.get(conf_name, {}).get(\n                                \"metric_max_value\", conf_name\n                            )\n                            for conf_name in v\n                        ]\n                        params_list.append(f\"`{k}` (\u7ea6\u675f\u626b\u63cf\u503c): {actual_values}\")\n                    except Exception:\n                        # If lookup fails for any reason, fall back to the original representation\n                        params_list.append(f\"`{k}`: {v}\")\n                else:\n                    # For regular parameters\n                    params_list.append(f\"`{k}`: {v}\")\n\n            simulation_params_str = (\n                \"\\n        *   **\u80cc\u666f\u626b\u63cf\u53c2\u6570 (Simulation Parameters):** \"\n                + \", \".join(params_list)\n            )\n\n        dependent_vars_str = \"\"\n        if dependent_variables:\n            dependent_vars_str = (\n                \"\\n        *   **\u56e0\u53d8\u91cf (Dependent Variables):** \"\n                + \", \".join([f\"`{v}`\" for v in dependent_variables])\n            )\n\n        # Find all plots to instruct the LLM to include them, prioritizing Chinese versions\n        all_files = [f for f in os.listdir(results_dir) if f.endswith((\".svg\", \".png\"))]\n\n        plot_map = {}\n        # Handle SVGs, prioritizing _zh versions\n        svg_plots = sorted([f for f in all_files if f.endswith(\".svg\")], reverse=True)\n        for plot in svg_plots:\n            base_name = plot.replace(\"_zh.svg\", \".svg\")\n            if base_name not in plot_map:\n                plot_map[base_name] = plot\n\n        # Add PNGs (which are not bilingual)\n        png_plots = [f for f in all_files if f.endswith(\".png\")]\n        for plot in png_plots:\n            plot_map[plot] = plot  # Use plot name as key for uniqueness\n\n        all_plots = list(plot_map.values())\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n\n        # Dynamically build the \"Results and Discussion\" section for the prompt\n        results_and_discussion_points = []\n\n        # 1. Main Effect Analysis (always included)\n        main_effect_text = (\n            f\"           *   **\u4e3b\u6548\u5e94\u5206\u6790\uff1a** \u8be6\u7ec6\u5206\u6790\u72ec\u7acb\u53d8\u91cf **`{independent_variable}`** \u7684\u53d8\u5316\u5bf9\u4e3b\u8981\u6027\u80fd\u6307\u6807\uff08\u5982 `Startup_Inventory`, `Doubling_Time` \u7b49\uff09\u7684\u603b\u4f53\u5f71\u54cd\u8d8b\u52bf\u3002\"\n            \"\u8bc4\u4f30\u4e0d\u540c\u6307\u6807\u5bf9\u81ea\u53d8\u91cf\u53d8\u5316\u7684\u654f\u611f\u5ea6\uff0c\u5e76\u8ba8\u8bba\u6307\u6807\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\"\n        )\n        results_and_discussion_points.append(main_effect_text)\n\n        # 2. Interaction Effect Analysis (conditional)\n        if simulation_parameters:\n            interaction_text = (\n                f\"           *   **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a** \u6df1\u5165\u63a2\u8ba8\u72ec\u7acb\u53d8\u91cf\u4e0e\u80cc\u666f\u53c2\u6570\u95f4\u7684**\u4ea4\u4e92\u6548\u5e94**\u3002\"\n                \"\u80cc\u666f\u53c2\u6570\u53ef\u80fd\u5305\u542b\u5e38\u89c4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u53ef\u80fd\u5305\u542b\u7ea6\u675f\u76f8\u5173\u7684\u53d8\u91cf\uff08\u4f8b\u5982 `Required_TBR`\uff09\u3002\"\n                f\"\u8bf7\u9610\u8ff0\u5728\u4e0d\u540c\u7684\u80cc\u666f\u53c2\u6570\u7ec4\u5408\u4e0b\uff0c`{independent_variable}` \u5bf9\u6027\u80fd\u6307\u6807\u7684\u654f\u611f\u6027\u662f\u5426\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08\u4f8b\u5982\uff0c\u662f\u88ab\u653e\u5927\u8fd8\u662f\u51cf\u5f31\uff09\u3002\"\n                \"\u8bf7\u7279\u522b\u5173\u6ce8\u5f53\u72ec\u7acb\u53d8\u91cf\u4e0e\u7ea6\u675f\u7c7b\u80cc\u666f\u53c2\u6570\u4ea4\u4e92\u65f6\uff0c\u5bf9\u7cfb\u7edf\u6027\u80fd\u548c\u8fbe\u6210\u5de5\u7a0b\u76ee\u6807\u7684\u5f71\u54cd\u3002\"\n            )\n            results_and_discussion_points.append(interaction_text)\n\n        # 3. Dynamic Behavior Analysis (conditional)\n        if \"\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\" in original_report_content:\n            dynamic_text = (\n                f\"           *   **\u52a8\u6001\u884c\u4e3a\u5206\u6790\uff1a** \u89e3\u8bfb\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u201d\u3001\u201c\u8f6c\u6298\u70b9\u201d\u548c\u201c\u7ed3\u675f\u201d\u9636\u6bb5\u7684\u884c\u4e3a\u53d8\u5316\u3002\"\n                f\"\u5206\u6790 **`{independent_variable}`** \u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u5982\u8fbe\u5230\u5e73\u8861\u7684\u65f6\u95f4\u3001\u5e93\u5b58\u7684\u8f6c\u6298\u70b9\u7b49\u3002\"\n            )\n            results_and_discussion_points.append(dynamic_text)\n\n        results_and_discussion_str = \"\\n\".join(results_and_discussion_points)\n\n        # Dynamically create the title instruction\n        if simulation_parameters:\n            title_instruction_text = \"\u8bf7\u5728\u6807\u9898\u4e2d\u660e\u786e\u6307\u51fa\uff0c\u672c\u6b21\u5206\u6790\u662f\u5173\u4e8e\u201c\u72ec\u7acb\u53d8\u91cf\u201d\u4e0e\u201c\u80cc\u666f\u626b\u63cf\u53c2\u6570\u201d\u7684\u3010\u4ea4\u4e92\u654f\u611f\u6027\u5206\u6790\u3011\u3002\"\n        else:\n            title_instruction_text = (\n                \"\u8bf7\u5728\u6807\u9898\u4e2d\u660e\u786e\u6307\u51fa\uff0c\u672c\u6b21\u5206\u6790\u662f\u5173\u4e8e\u201c\u72ec\u7acb\u53d8\u91cf\u201d\u7684\u3010\u654f\u611f\u6027\u5206\u6790\u3011\u3002\"\n            )\n\n        instructions_prompt = f\"\"\"**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\u4f8b\u5982\uff0c\u5e94\u5c06\u201c`sds`\u7684\u5e93\u5b58\u201d\u8868\u8ff0\u4e3a\u201c\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS) \u7684\u6c1a\u5e93\u5b58\u91cf (Tritium Inventory)\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\u907f\u514d\u4f7f\u7528\u201c\u770b\u8d77\u6765\u201d\u3001\u201c\u597d\u50cf\u201d\u7b49\u6a21\u7cca\u8bcd\u6c47\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u6027\u80fd\u6307\u6807\u603b\u8868\u6216\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u654f\u611f\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6807\u9898 (Title):** {title_instruction_text}\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u654f\u611f\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u660e\u72ec\u7acb\u53d8\u91cf\u662f **`{independent_variable}`** \u4ee5\u53ca\u80cc\u666f\u626b\u63cf\u53c2\u6570\uff0c\u603b\u7ed3\u5176\u5bf9\u54ea\u4e9b\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u542f\u52a8\u5e93\u5b58\u3001\u589e\u6b96\u65f6\u95f4\u7b49\uff09\u5f71\u54cd\u6700\u663e\u8457\uff0c\u5e76\u9648\u8ff0\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u5173\u4e8e **`{independent_variable}`** \u7684\u654f\u611f\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30 **`{independent_variable}`** \u7684\u53d8\u5316\u5bf9\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\n        *   **\u72ec\u7acb\u53d8\u91cf\u91c7\u6837 (Independent Variable Sampling):** \u672c\u6b21\u5206\u6790\u4e2d\uff0c\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u626b\u63cf\u8303\u56f4\u4e3a `{sampling_range}`\u3002\n{simulation_params_str}{dependent_vars_str}\n    *   **\u65b9\u6cd5 (Methodology):** \u7b80\u8981\u8bf4\u660e\u5206\u6790\u65b9\u6cd5\uff0c\u5305\u62ec\u63d0\u53ca **`{independent_variable}`** \u7684\u626b\u63cf\u8303\u56f4\u548c\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u6240\u6709\u56fe\u8868\u548c\u6570\u636e\u8868\u683c\uff0c\u5e76\u6839\u636e\u5206\u6790\u5185\u5bb9\uff0c\u7ec4\u7ec7\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n{results_and_discussion_str}\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u654f\u611f\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff0c\u5e76\u5bf9\u53cd\u5e94\u5806\u8bbe\u8ba1\u6216\u672a\u6765\u8fd0\u884c\u7b56\u7565\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\uff08\u5305\u62ec\u56fe\u8868\u548c\u8868\u683c\uff09\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n---\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a (`{report_filename}`)\n---\n{original_report_content}\n\n---\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868 (`sheets.csv`)\n---\n{glossary_content}\n\"\"\"\n\n        # 5. Call the API\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for academic summary for case {case_name} with model {ai_model} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, instructions_prompt, analysis_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                academic_summary = response.choices[0].message.content\n\n                # 6. Save the result\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                summary_filename = (\n                    f\"academic_report_{case_name}_{sanitized_model_name}.md\"\n                )\n                summary_path = os.path.join(results_dir, summary_filename)\n                with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(academic_summary)\n\n                logger.info(\n                    f\"Successfully generated academic analysis summary: {summary_path}\"\n                )\n                return  # Exit after success\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling OpenAI API for academic summary on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to generate academic summary for {case_name} after {max_retries} attempts.\"\n                    )\n                    return  # Exit after all retries failed\n\n    except Exception as e:\n        logger.error(\n            f\"Error in generate_sensitivity_academic_report for case {case_name}: {e}\",\n            exc_info=True,\n        )\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.retry_ai_analysis","title":"<code>retry_ai_analysis(case_configs, original_config)</code>","text":"<p>Retries AI analysis for cases where it might have failed due to network issues.</p> <p>Checks for existing reports and re-runs only the AI-dependent parts if they are missing. This function can be triggered by setting an environment variable.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries.</p> \u5fc5\u9700 <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary.</p> \u5fc5\u9700 Note <p>Routes to _retry_salib_case for SALib cases or _retry_standard_case for standard cases. Only regenerates missing AI analysis and academic reports. Does not re-run simulations. Logs all retry attempts and failures.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/report.py</code> <pre><code>def retry_ai_analysis(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Retries AI analysis for cases where it might have failed due to network issues.\n\n    Checks for existing reports and re-runs only the AI-dependent parts if they are missing.\n    This function can be triggered by setting an environment variable.\n\n    Args:\n        case_configs: List of case configuration dictionaries.\n        original_config: Original configuration dictionary.\n\n    Note:\n        Routes to _retry_salib_case for SALib cases or _retry_standard_case for standard cases.\n        Only regenerates missing AI analysis and academic reports. Does not re-run simulations.\n        Logs all retry attempts and failures.\n    \"\"\"\n    logger.info(\"Starting AI analysis retry process...\")\n    try:\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n            if \"analyzer\" in case_data and case_data.get(\"analyzer\", {}).get(\"method\"):\n                _retry_salib_case(case_info, original_config)\n            else:\n                _retry_standard_case(case_info, original_config)\n    except Exception as e:\n        logger.error(f\"Error during AI analysis retry process: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer","title":"<code>TricysSALibAnalyzer</code>","text":"<p>Integrated SALib's Tricys Sensitivity Analyzer.</p> <p>Supported Analysis Methods: - Sobol: Variance-based global sensitivity analysis - Morris: Screening-based sensitivity analysis - FAST: Fourier Amplitude Sensitivity Test - LHS: Latin Hypercube Sampling uncertainty analysis</p> <p>\u5c5e\u6027\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 <code>base_config</code> <p>Copy of the Tricys base configuration.</p> <code>problem</code> <p>SALib problem definition dictionary.</p> <code>parameter_samples</code> <p>Generated parameter samples array.</p> <code>simulation_results</code> <p>Results from simulations.</p> <code>sensitivity_results</code> <p>Dictionary storing sensitivity analysis results by method.</p> Note <p>Automatically sets up Chinese font support and validates Tricys configuration on initialization. Supports multiple sensitivity analysis methods with appropriate sampling strategies.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>class TricysSALibAnalyzer:\n    \"\"\"Integrated SALib's Tricys Sensitivity Analyzer.\n\n    Supported Analysis Methods:\n    - Sobol: Variance-based global sensitivity analysis\n    - Morris: Screening-based sensitivity analysis\n    - FAST: Fourier Amplitude Sensitivity Test\n    - LHS: Latin Hypercube Sampling uncertainty analysis\n\n    Attributes:\n        base_config: Copy of the Tricys base configuration.\n        problem: SALib problem definition dictionary.\n        parameter_samples: Generated parameter samples array.\n        simulation_results: Results from simulations.\n        sensitivity_results: Dictionary storing sensitivity analysis results by method.\n\n    Note:\n        Automatically sets up Chinese font support and validates Tricys configuration\n        on initialization. Supports multiple sensitivity analysis methods with appropriate\n        sampling strategies.\n    \"\"\"\n\n    def __init__(self, base_config: Dict[str, Any]) -&gt; None:\n        \"\"\"Initialize the analyzer.\n\n        Args:\n            base_config: Tricys base configuration dictionary.\n\n        Note:\n            Creates a deep copy of base_config. Initializes problem, samples, and results\n            to None. Calls _setup_chinese_font() and _validate_tricys_config() automatically.\n        \"\"\"\n        self.base_config = base_config.copy()\n        self.problem = None\n        self.parameter_samples = None\n        self.simulation_results = None\n        self.sensitivity_results = {}\n\n        self._setup_chinese_font()\n        self._validate_tricys_config()\n\n    def _setup_chinese_font(self) -&gt; None:\n        \"\"\"Set the Chinese font to ensure proper display of Chinese characters in charts.\n\n        Note:\n            Tries multiple Chinese fonts in order of preference. Falls back to default\n            if no Chinese font found. Also sets axes.unicode_minus to False for proper\n            minus sign display. Logs warnings if font setup fails.\n        \"\"\"\n        try:\n            import matplotlib.font_manager as fm\n\n            chinese_fonts = [\n                \"SimHei\",  # \u9ed1\u4f53\n                \"Microsoft YaHei\",  # \u5fae\u8f6f\u96c5\u9ed1\n                \"KaiTi\",  # \u6977\u4f53\n                \"FangSong\",  # \u4eff\u5b8b\n                \"STSong\",  # \u534e\u6587\u5b8b\u4f53\n                \"STKaiti\",  # \u534e\u6587\u6977\u4f53\n                \"STHeiti\",  # \u534e\u6587\u9ed1\u4f53\n                \"DejaVu Sans\",  # \u5907\u7528\u5b57\u4f53\n                \"Arial Unicode MS\",  # \u5907\u7528\u5b57\u4f53\n            ]\n\n            available_font = None\n            system_fonts = [f.name for f in fm.fontManager.ttflist]\n\n            for font in chinese_fonts:\n                if font in system_fonts:\n                    available_font = font\n                    break\n\n            if available_font:\n                plt.rcParams[\"font.sans-serif\"] = [available_font] + plt.rcParams[\n                    \"font.sans-serif\"\n                ]\n                logger.info(\"Using Chinese font\", extra={\"font\": available_font})\n            else:\n                logger.warning(\n                    \"No suitable Chinese font found, which may affect Chinese display\"\n                )\n\n            plt.rcParams[\"axes.unicode_minus\"] = False\n\n        except Exception as e:\n            logger.warning(\n                \"Failed to set Chinese font, using default font\",\n                extra={\"error\": str(e)},\n            )\n\n    def _handle_nan_values(\n        self, Y: np.ndarray, method_name: str = \"Sensitivity analysis\"\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Handling NaN values with maximum interpolation\n\n        Args:\n            Y: Output array that may contain NaN values\n            method_name: Analysis method name for logging\n\n        Returns:\n            Processed output array\n        \"\"\"\n        nan_indices = np.isnan(Y)\n        if np.any(nan_indices):\n            n_nan = np.sum(nan_indices)\n            logger.info(\n                \"Found NaN values, using maximum value for imputation\",\n                extra={\n                    \"method_name\": method_name,\n                    \"nan_count\": n_nan,\n                },\n            )\n\n            valid_values = Y[~nan_indices]\n\n            if len(valid_values) &gt; 0:\n                max_value = np.max(valid_values)\n                Y_processed = Y.copy()\n                Y_processed[nan_indices] = max_value\n                return Y_processed\n            else:\n                logger.error(\n                    \"All values are NaN, analysis cannot be performed\",\n                    extra={\n                        \"method_name\": method_name,\n                    },\n                )\n                raise ValueError(\n                    f\"{method_name}: All simulation results are NaN, sensitivity analysis cannot be performed\"\n                )\n        return Y\n\n    def _validate_tricys_config(self) -&gt; None:\n        \"\"\"Validate the Tricys configuration for required sections and keys.\"\"\"\n        required_keys = {\n            \"paths\": [\"package_path\"],\n            \"simulation\": [\"model_name\", \"stop_time\"],\n        }\n\n        for section, keys in required_keys.items():\n            if section not in self.base_config:\n                logger.warning(\n                    \"Missing configuration section, default values will be used\",\n                    extra={\n                        \"section\": section,\n                    },\n                )\n                continue\n\n            for key in keys:\n                if key not in self.base_config[section]:\n                    logger.warning(\n                        \"Missing configuration item, using default value\",\n                        extra={\n                            \"section\": section,\n                            \"key\": key,\n                        },\n                    )\n\n        package_path = self.base_config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            logger.warning(\n                \"Model file does not exist, which may cause simulation failure\",\n                extra={\n                    \"package_path\": package_path,\n                },\n            )\n\n    def _find_unit_config(self, var_name: str, unit_map: dict) -&gt; dict | None:\n        \"\"\"\n        Finds the unit configuration for a variable name from the unit_map.\n        1. Checks for an exact match.\n        2. Checks if the last part of a dot-separated name matches.\n        3. Checks for a simple substring containment as a fallback, matching longest keys first.\n        \"\"\"\n        if not unit_map or not var_name:\n            return None\n        if var_name in unit_map:\n            return unit_map[var_name]\n        components = var_name.split(\".\")\n        if len(components) &gt; 1 and components[-1] in unit_map:\n            return unit_map[components[-1]]\n        # Fallback to substring match, longest key first\n        for key in sorted(unit_map.keys(), key=len, reverse=True):\n            if key in var_name:\n                return unit_map[key]\n        return None\n\n    def define_problem(\n        self,\n        param_bounds: Dict[str, Tuple[float, float]],\n        param_distributions: Dict[str, str] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Define SALib problem space.\n\n        Args:\n            param_bounds: Parameter bounds dictionary {'param_name': (min_val, max_val)}.\n            param_distributions: Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}.\n                Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'.\n\n        Returns:\n            SALib problem definition dictionary.\n\n        Note:\n            Defaults to 'unif' distribution if not specified. Validates distribution types\n            and warns if invalid. Logs parameter definitions including bounds and distributions.\n        \"\"\"\n        if param_distributions is None:\n            param_distributions = {name: \"unif\" for name in param_bounds.keys()}\n\n        valid_dists = [\"unif\", \"triang\", \"norm\", \"truncnorm\", \"lognorm\"]\n        for name, dist in param_distributions.items():\n            if dist not in valid_dists:\n                logger.warning(\n                    \"Invalid distribution type, using 'unif' instead\",\n                    extra={\n                        \"parameter_name\": name,\n                        \"invalid_distribution\": dist,\n                    },\n                )\n                param_distributions[name] = \"unif\"\n\n        self.problem = {\n            \"num_vars\": len(param_bounds),\n            \"names\": list(param_bounds.keys()),\n            \"bounds\": list(param_bounds.values()),\n            \"dists\": [\n                param_distributions.get(name, \"unif\") for name in param_bounds.keys()\n            ],\n        }\n\n        logger.info(\n            \"Defined a problem space\",\n            extra={\n                \"num_parameters\": self.problem[\"num_vars\"],\n            },\n        )\n        for i, name in enumerate(self.problem[\"names\"]):\n            logger.info(\n                \"Parameter definition\",\n                extra={\n                    \"parameter_name\": name,\n                    \"bounds\": self.problem[\"bounds\"][i],\n                    \"distribution\": self.problem[\"dists\"][i],\n                },\n            )\n\n        return self.problem\n\n    def generate_samples(\n        self, method: str = \"sobol\", N: int = 1024, **kwargs\n    ) -&gt; np.ndarray:\n        \"\"\"Generate parameter samples.\n\n        Args:\n            method: Sampling method ('sobol', 'morris', 'fast', 'latin').\n            N: Number of samples (for Sobol this is the base sample count, actual count is N*(2*D+2)).\n            **kwargs: Method-specific parameters.\n\n        Returns:\n            Parameter sample array (n_samples, n_params).\n\n        Raises:\n            ValueError: If problem not defined or unsupported method.\n\n        Note:\n            Sobol generates N*(2*D+2) samples. Morris generates N trajectories. Samples are\n            rounded to 5 decimal places. Stores last sampling method for compatibility checking.\n        \"\"\"\n        if self.problem is None:\n            raise ValueError(\n                \"You must first call define_problem() to define the problem space.\"\n            )\n\n        logger.info(\n            \"Generating samples\",\n            extra={\n                \"method\": method,\n                \"base_sample_count\": N,\n            },\n        )\n\n        if method.lower() == \"sobol\":\n            # Sobol method: generate N*(2*D+2) samples\n            self.parameter_samples = saltelli.sample(self.problem, N, **kwargs)\n            actual_samples = N * (2 * self.problem[\"num_vars\"] + 2)\n\n        elif method.lower() == \"morris\":\n            # Morris method: Generate N trajectories\n            # Note: Different versions of SALib may have different parameter names\n            morris_kwargs = {\"num_levels\": 4}\n            # Check the SALib version and use the correct parameter names\n            try:\n                morris_kwargs.update(kwargs)\n                self.parameter_samples = morris.sample(self.problem, N, **morris_kwargs)\n            except TypeError as e:\n                if \"grid_jump\" in str(e):\n                    morris_kwargs = {\n                        k: v for k, v in morris_kwargs.items() if k != \"grid_jump\"\n                    }\n                    morris_kwargs.update(\n                        {k: v for k, v in kwargs.items() if k != \"grid_jump\"}\n                    )\n                    self.parameter_samples = morris.sample(\n                        self.problem, N, **morris_kwargs\n                    )\n                else:\n                    raise e\n\n            actual_samples = len(self.parameter_samples)\n\n        elif method.lower() == \"fast\":\n            # FAST method\n            fast_kwargs = {\"M\": 4}\n            fast_kwargs.update(kwargs)\n            self.parameter_samples = fast_sampler.sample(self.problem, N, **fast_kwargs)\n            actual_samples = len(self.parameter_samples)\n\n        elif method.lower() == \"latin\":\n            # Latin Hypercube Sampling\n            self.parameter_samples = latin.sample(self.problem, N, **kwargs)\n            actual_samples = N\n\n        else:\n            raise ValueError(f\"Unsupported sampling method: {method}\")\n\n        logger.info(\n            \"Successfully generated samples\", extra={\"actual_samples\": actual_samples}\n        )\n\n        if self.parameter_samples is not None:\n            self.parameter_samples = np.round(self.parameter_samples, decimals=5)\n            logger.info(\"Parameter sample precision adjusted to 5 decimal places\")\n\n        self._last_sampling_method = method.lower()\n\n        return self.parameter_samples\n\n    def run_tricys_simulations(self, output_metrics: List[str] = None) -&gt; str:\n        \"\"\"\n        Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.\n\n        Args:\n            output_metrics: List of output metrics to be extracted (for recording but does not affect CSV generation)\n            max_workers: Number of concurrent worker processes (reserved for compatibility, currently unused)\n\n        Returns:\n            Path to the generated CSV file\n        \"\"\"\n        if self.parameter_samples is None:\n            raise ValueError(\n                \"You must first call generate_samples() to generate samples.\"\n            )\n\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        logger.info(\"Target output metrics\", extra={\"output_metrics\": output_metrics})\n\n        sampled_param_names = self.problem[\"names\"]\n\n        base_params = self.base_config.get(\"simulation_parameters\", {}).copy()\n        csv_output_path = (\n            Path(self.base_config.get(\"paths\", {}).get(\"temp_dir\"))\n            / \"salib_sampling.csv\"\n        )\n\n        os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n\n        param_data = []\n        for i, sample in enumerate(self.parameter_samples):\n            sampled_params = {\n                sampled_param_names[j]: sample[j]\n                for j in range(len(sampled_param_names))\n            }\n\n            job_params = base_params.copy()\n            job_params.update(sampled_params)\n\n            param_data.append(job_params)\n\n        df = pd.DataFrame(param_data)\n\n        for col in df.columns:\n            if df[col].dtype in [\"float64\", \"float32\"]:\n                df[col] = df[col].round(5)\n\n        df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n\n        logger.info(\n            \"Successfully generated parameter samples\",\n            extra={\"num_samples\": len(param_data)},\n        )\n        logger.info(\"Parameter file saved\", extra={\"file_path\": csv_output_path})\n        logger.info(\"Parameter file columns\", extra={\"columns\": list(df.columns)})\n        logger.info(\"Parameter precision set to 5 decimal places\")\n        logger.info(\"Sample statistics\", extra={\"statistics\": df.describe().to_dict()})\n\n        self.sampling_csv_path = csv_output_path\n\n        return csv_output_path\n\n    def generate_tricys_config(\n        self, csv_file_path: str = None, output_metrics: List[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Generate Tricys configuration file for reading CSV parameter files and executing simulations\n        This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs\n\n        Args:\n            csv_file_path: Path to the CSV parameter file. If None, the last generated file is used\n            output_metrics: List of output metrics to be calculated\n\n        Returns:\n            Path of the generated configuration file\n        \"\"\"\n        if csv_file_path is None:\n            if hasattr(self, \"sampling_csv_path\"):\n                csv_file_path = self.sampling_csv_path\n            else:\n                raise ValueError(\n                    \"CSV file path not found, please first call run_tricys_simulations() or specify csv_file_path\"\n                )\n\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        csv_abs_path = os.path.abspath(csv_file_path)\n\n        import copy\n\n        tricys_config = copy.deepcopy(self.base_config)\n        tricys_config[\"simulation_parameters\"] = {\"file\": csv_abs_path}\n\n        if \"sensitivity_analysis\" not in tricys_config:\n            tricys_config[\"sensitivity_analysis\"] = {\"enabled\": True}\n\n        tricys_config[\"sensitivity_analysis\"][\"analysis_case\"] = {\n            \"name\": \"SALib_Analysis\",\n            \"independent_variable\": \"file\",\n            \"independent_variable_sampling\": csv_abs_path,\n            \"dependent_variables\": output_metrics,\n        }\n\n        return tricys_config\n\n    def load_tricys_results(\n        self, sensitivity_summary_csv: str, output_metrics: List[str] = None\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys\n\n        Args:\n            sensitivity_summary_csv: Path to the sensitivity analysis summary CSV file output by Tricys\n            output_metrics: List of output metrics to extract\n\n        Returns:\n            Simulation result array (n_samples, n_metrics)\n        \"\"\"\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        logger.info(f\"Read data from the Tricys result file: {sensitivity_summary_csv}\")\n\n        df = pd.read_csv(sensitivity_summary_csv)\n\n        logger.info(f\"Read {len(df)} simulation results\")\n        logger.info(f\"Result file columns: {list(df.columns)}\")\n\n        param_cols = []\n        metric_cols = []\n\n        for col in df.columns:\n            if col in output_metrics:\n                metric_cols.append(col)\n            elif col in self.problem[\"names\"] if self.problem else False:\n                param_cols.append(col)\n\n        logger.info(f\"Recognized parameter columns: {param_cols}\")\n        logger.info(f\"Identified metric columns: {metric_cols}\")\n\n        ordered_metric_cols = []\n        for metric in output_metrics:\n            if metric in metric_cols:\n                ordered_metric_cols.append(metric)\n            else:\n                logger.warning(f\"Metric column not found: {metric}\")\n\n        if not ordered_metric_cols:\n            raise ValueError(f\"No valid output metrics columns found: {output_metrics}\")\n\n        results_data = df[ordered_metric_cols].values\n\n        self.simulation_results = results_data\n\n        logger.info(f\"Successfully loaded simulation results: {results_data.shape}\")\n        logger.info(\n            f\"Result Statistics:\\n{pd.DataFrame(results_data, columns=ordered_metric_cols).describe()}\"\n        )\n        logger.info(\n            f\"Result preview:\\n{pd.DataFrame(results_data, columns=metric_cols).head()}\"\n        )\n        return self.simulation_results\n\n    def get_compatible_analysis_methods(self, sampling_method: str) -&gt; List[str]:\n        \"\"\"\n        Get analysis methods compatible with the specified sampling method.\n\n        Args:\n            sampling_method: Sampling method\n\n        Returns:\n            List of compatible analysis methods\n        \"\"\"\n        compatibility_map = {\n            \"sobol\": [\"sobol\"],\n            \"morris\": [\"morris\"],\n            \"fast\": [\"fast\"],\n            \"latin\": [\"latin\"],\n            \"unknown\": [],\n        }\n\n        return compatibility_map.get(sampling_method, [])\n\n    def run_tricys_analysis(\n        self, csv_file_path: str = None, output_metrics: List[str] = None\n    ) -&gt; str:\n        \"\"\"\n        Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results\n\n        Args:\n            csv_file_path: Path to the CSV parameter file. If None, the last generated file will be used\n            output_metrics: List of output metrics to be calculated\n            config_output_path: Path for the configuration file output. If None, it will be automatically generated\n\n        Returns:\n            Path to the sensitivity_analysis_summary.csv file\n        \"\"\"\n        # Generate Tricys configuration file\n        tricys_config = self.generate_tricys_config(\n            csv_file_path=csv_file_path, output_metrics=output_metrics\n        )\n\n        logger.info(\"Starting Tricys simulation analysis...\")\n\n        try:\n            # Call the Tricys simulation engine\n            from datetime import datetime\n\n            from tricys.simulation.simulation_analysis import run_simulation\n\n            tricys_config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n            run_simulation(tricys_config)\n\n            results_dir = tricys_config[\"paths\"][\"results_dir\"]\n\n            return Path(results_dir) / \"sensitivity_analysis_summary.csv\"\n\n        except Exception as e:\n            logger.error(f\"Tricys simulation execution failed: {e}\")\n            raise\n\n    def analyze_sobol(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform Sobol Sensitivity Analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Sobol analysis parameters\n\n        Returns:\n            Sobol sensitivity analysis results\n\n        Note:\n            Sobol analysis requires samples generated using the Saltelli sampling method!\n            Results from Morris or FAST sampling cannot be used.\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        # Check sampling method compatibility\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"sobol\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f Currently using {self._last_sampling_method} sampling, but Sobol analysis requires Saltelli sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('sobol')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"Sobol\u5206\u6790\")\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n        #    X = self.parameter_samples[valid_indices]\n        # else:\n        #    X = self.parameter_samples\n\n        try:\n            Si = sobol.analyze(self.problem, Y, **kwargs)\n\n            if \"sobol\" not in self.sensitivity_results:\n                self.sensitivity_results[\"sobol\"] = {}\n\n            metric_name = f\"metric_{output_index}\"\n            self.sensitivity_results[\"sobol\"][metric_name] = {\n                \"output_index\": output_index,\n                \"Si\": Si,\n                \"S1\": Si[\"S1\"],\n                \"ST\": Si[\"ST\"],\n                \"S2\": Si.get(\"S2\", None),\n                \"S1_conf\": Si[\"S1_conf\"],\n                \"ST_conf\": Si[\"ST_conf\"],\n                \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n            }\n\n            logger.info(f\"Sobol sensitivity analysis completed (index {output_index})\")\n            return self.sensitivity_results[\"sobol\"][metric_name]\n\n        except Exception as e:\n            if \"saltelli\" in str(e).lower() or \"sample\" in str(e).lower():\n                raise ValueError(\n                    f\"Sobol analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('sobol')\"\n                ) from e\n            else:\n                raise\n\n    def analyze_morris(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform Morris sensitivity analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Morris analysis parameters\n\n        Returns:\n            Morris sensitivity analysis results\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"Morris\u5206\u6790\")\n        X = self.parameter_samples\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n        #    X = self.parameter_samples[valid_indices]\n        # else:\n        #    X = self.parameter_samples\n\n        # Perform Morris analysis\n        logger.info(\n            f\"Start Morris sensitivity analysis: X.shape={X.shape}, Y.shape={Y.shape}, X.dtype={X.dtype}\"\n        )\n\n        try:\n            Si = morris_analyze.analyze(self.problem, X, Y, **kwargs)\n        except Exception as e:\n            logger.error(f\"Morris analysis execution failed: {e}\")\n            logger.error(f\"problem: {self.problem}\")\n            logger.error(f\"X shape: {X.shape}, type: {X.dtype}\")\n            logger.error(f\"Yshape: {Y.shape}, type: {Y.dtype}\")\n            if hasattr(X, \"dtype\") and X.dtype == \"object\":\n                logger.error(\n                    \"X contains non-numeric data, please check the sampled data\"\n                )\n            raise\n\n        if \"morris\" not in self.sensitivity_results:\n            self.sensitivity_results[\"morris\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"morris\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"mu\": Si[\"mu\"],\n            \"mu_star\": Si[\"mu_star\"],\n            \"sigma\": Si[\"sigma\"],\n            \"mu_star_conf\": Si[\"mu_star_conf\"],\n        }\n\n        logger.info(f\"Morris sensitivity analysis completed (metric {output_index})\")\n        return self.sensitivity_results[\"morris\"][metric_name]\n\n    def analyze_fast(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform FAST sensitivity analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: FAST analysis parameters\n\n        Returns:\n            FAST sensitivity analysis results\n\n        Note:\n            FAST analysis requires samples generated by the fast_sampler sampling method!\n            Results from Morris or Sobol sampling cannot be used.\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"fast\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but FAST analysis requires FAST sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('fast')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"FAST\u5206\u6790\")\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n\n        try:\n            # Perform FAST analysis\n            Si = fast.analyze(self.problem, Y, **kwargs)\n\n            if \"fast\" not in self.sensitivity_results:\n                self.sensitivity_results[\"fast\"] = {}\n\n            metric_name = f\"metric_{output_index}\"\n            self.sensitivity_results[\"fast\"][metric_name] = {\n                \"output_index\": output_index,\n                \"Si\": Si,\n                \"S1\": Si[\"S1\"],\n                \"ST\": Si[\"ST\"],\n                \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n            }\n\n            logger.info(\n                f\"FAST sensitivity analysis completed (indicator {output_index})\"\n            )\n            return self.sensitivity_results[\"fast\"][metric_name]\n\n        except Exception as e:\n            if \"fast\" in str(e).lower() or \"sample\" in str(e).lower():\n                raise ValueError(\n                    f\"FAST analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('fast')\"\n                ) from e\n            else:\n                raise\n\n    def analyze_lhs(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform LHS (Latin Hypercube Sampling) uncertainty analysis\n\n        Note: This is a basic statistical analysis method for LHS samples,\n        providing descriptive statistics and basic sensitivity indices.\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Analysis parameters (reserved for future use)\n\n        Returns:\n            LHS uncertainty analysis results\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"latin\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but LHS analysis is designed for Latin Hypercube Sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('latin')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        # Handle NaN values\n        Y = self._handle_nan_values(Y, \"LHS\u5206\u6790\")\n\n        # Basic statistical analysis\n        mean_val = np.mean(Y)\n        std_val = np.std(Y)\n        min_val = np.min(Y)\n        max_val = np.max(Y)\n        percentile_5 = np.percentile(Y, 5)\n        percentile_95 = np.percentile(Y, 95)\n\n        # Create results dictionary\n        Si = {\n            \"mean\": mean_val,\n            \"std\": std_val,\n            \"min\": min_val,\n            \"max\": max_val,\n            \"percentile_5\": percentile_5,\n            \"percentile_95\": percentile_95,\n        }\n\n        if \"latin\" not in self.sensitivity_results:\n            self.sensitivity_results[\"latin\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"latin\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"mean\": mean_val,\n            \"std\": std_val,\n            \"min\": min_val,\n            \"max\": max_val,\n            \"percentile_5\": percentile_5,\n            \"percentile_95\": percentile_95,\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(f\"LHS uncertainty analysis completed (\u6307\u6807 {output_index})\")\n        return self.sensitivity_results[\"latin\"][metric_name]\n\n    def run_salib_analysis_from_tricys_results(\n        self,\n        sensitivity_summary_csv: str,\n        param_bounds: Dict[str, Tuple[float, float]] = None,\n        output_metrics: List[str] = None,\n        methods: List[str] = [\"sobol\", \"morris\", \"fast\"],\n        save_dir: str = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys\n\n        Args:\n            sensitivity_summary_csv: Path to the sensitivity summary CSV file output by Tricys\n            param_bounds: Dictionary of parameter bounds, inferred from the CSV file if None\n            output_metrics: List of output metrics to analyze\n            methods: List of sensitivity analysis methods to execute\n            save_dir: Directory to save the results\n\n        Returns:\n            Dictionary containing all analysis results\n        \"\"\"\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        if save_dir is None:\n            save_dir = os.path.join(\n                os.path.dirname(sensitivity_summary_csv), \"salib_analysis\"\n            )\n        os.makedirs(save_dir, exist_ok=True)\n\n        df = pd.read_csv(sensitivity_summary_csv)\n\n        if param_bounds is None:\n            param_bounds = {}\n            param_candidates = []\n            for col in df.columns:\n                if col not in output_metrics and \".\" in col:\n                    param_candidates.append(col)\n\n            for param in param_candidates:\n                param_data = df[param].dropna()\n                if len(param_data) &gt; 0:\n                    param_bounds[param] = (param_data.min(), param_data.max())\n\n        if not param_bounds:\n            raise ValueError(\n                \"Unable to determine parameter boundaries, please provide the param_bounds parameter\"\n            )\n\n        self.define_problem(param_bounds)\n\n        self.load_tricys_results(sensitivity_summary_csv, output_metrics)\n\n        detected_method = self._last_sampling_method\n\n        methods = self.get_compatible_analysis_methods(detected_method)\n\n        all_results = {}\n\n        for metric_idx, metric_name in enumerate(output_metrics):\n            if metric_idx &gt;= self.simulation_results.shape[1]:\n                logger.warning(f\"The metric {metric_name} is out of range, skipping\")\n                continue\n\n            logger.info(f\"\\n=== Analysis indicators: {metric_name} ===\")\n            metric_results = {}\n\n            # Check data validity\n            Y = self.simulation_results[:, metric_idx]\n            valid_ratio = np.sum(~np.isnan(Y)) / len(Y)\n            logger.info(f\"Valid data ratio: {valid_ratio:.2%}\")\n\n            if valid_ratio &lt; 0.5:\n                logger.warning(\n                    f\"The metric {metric_name} has less than 50% valid data, which may affect the analysis quality.\"\n                )\n\n            # Sobol analysis\n            if \"sobol\" in methods:\n                try:\n                    logger.info(\"Performing Sobol sensitivity analysis...\")\n                    sobol_result = self.analyze_sobol(output_index=metric_idx)\n                    metric_results[\"sobol\"] = sobol_result\n\n                    # Display Sobol results summary\n                    logger.info(\"\\nSobol sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        s1 = sobol_result[\"S1\"][i]\n                        st = sobol_result[\"ST\"][i]\n                        logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"Sobol analysis failed: {e}\")\n\n            # Morris analysis\n            if \"morris\" in methods:\n                try:\n                    logger.info(\"Performing Morris sensitivity analysis...\")\n                    morris_result = self.analyze_morris(output_index=metric_idx)\n                    metric_results[\"morris\"] = morris_result\n\n                    # Display Morris results summary\n                    logger.info(\"\\nMorris sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        mu_star = morris_result[\"mu_star\"][i]\n                        sigma = morris_result[\"sigma\"][i]\n                        logger.info(f\"  {param_name}: \u03bc*={mu_star:.4f}, \u03c3={sigma:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"Morris analysis failed: {e}\")\n\n            # FAST analysis\n            if \"fast\" in methods:\n                try:\n                    logger.info(\"Performing FAST sensitivity analysis...\")\n                    fast_result = self.analyze_fast(output_index=metric_idx)\n                    metric_results[\"fast\"] = fast_result\n\n                    # Display FAST results summary\n                    logger.info(\"\\nFAST sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        s1 = fast_result[\"S1\"][i]\n                        st = fast_result[\"ST\"][i]\n                        logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"FAST analysis failed: {e}\")\n\n            # LHS analysis\n            if \"latin\" in methods:\n                try:\n                    logger.info(\"Performing LHS uncertainty analysis...\")\n                    lhs_result = self.analyze_lhs(output_index=metric_idx)\n                    metric_results[\"latin\"] = lhs_result\n\n                    # Display LHS results summary\n                    logger.info(\"\\nLHS\u5206\u6790\u7ed3\u679c:\")\n                    logger.info(f\"  \u5747\u503c: {lhs_result['mean']:.4f}\")\n                    logger.info(f\"  \u6807\u51c6\u5dee: {lhs_result['std']:.4f}\")\n                    logger.info(f\"  \u6700\u5c0f\u503c: {lhs_result['min']:.4f}\")\n                    logger.info(f\"  \u6700\u5927\u503c: {lhs_result['max']:.4f}\")\n                    logger.info(f\"  5%\u5206\u4f4d\u6570: {lhs_result['percentile_5']:.4f}\")\n                    logger.info(f\"  95%\u5206\u4f4d\u6570: {lhs_result['percentile_95']:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"LHS\u5206\u6790\u5931\u8d25: {e}\")\n\n            all_results[metric_name] = metric_results\n\n        try:\n            if \"sobol\" in methods and \"sobol\" in self.sensitivity_results:\n                self.plot_sobol_results(save_dir=save_dir, metric_names=output_metrics)\n\n            if \"morris\" in methods and \"morris\" in self.sensitivity_results:\n                self.plot_morris_results(save_dir=save_dir, metric_names=output_metrics)\n\n            if \"fast\" in methods and \"fast\" in self.sensitivity_results:\n                self.plot_fast_results(save_dir=save_dir, metric_names=output_metrics)\n\n            # Plot LHS results\n            if \"latin\" in methods and \"latin\" in self.sensitivity_results:\n                self.plot_lhs_results(save_dir=save_dir, metric_names=output_metrics)\n\n        except Exception as e:\n            logger.warning(f\"Drawing failed: {e}\")\n\n        try:\n            self.save_results(\n                save_dir=save_dir, format=\"csv\", metric_names=output_metrics\n            )\n\n            report_content = self._save_sensitivity_report(all_results, save_dir)\n            report_path = os.path.join(save_dir, \"analysis_report.md\")\n\n            load_dotenv()\n\n            # --- LLM Calls for analysis ---\n            api_key = os.environ.get(\"API_KEY\")\n            base_url = os.environ.get(\"BASE_URL\")\n            ai_model = os.environ.get(\"AI_MODEL\")\n\n            sa_config = self.base_config.get(\"sensitivity_analysis\", {})\n            case_config = sa_config.get(\"analysis_case\", {})\n            ai_config = case_config.get(\"ai\")\n\n            ai_enabled = False\n            if isinstance(ai_config, bool):\n                ai_enabled = ai_config\n            elif isinstance(ai_config, dict):\n                ai_enabled = ai_config.get(\"enabled\", False)\n\n            if api_key and base_url and ai_model and ai_enabled:\n                # First LLM call for initial analysis\n                wrapper_prompt, llm_summary = call_llm_for_salib_analysis(\n                    report_content=report_content,\n                    api_key=api_key,\n                    base_url=base_url,\n                    ai_model=ai_model,\n                    method=detected_method,\n                )\n                if wrapper_prompt and llm_summary:\n                    with open(report_path, \"a\", encoding=\"utf-8\") as f:\n                        f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd\\n\\n\")\n                        f.write(\"```markdown\\n\")\n                        f.write(wrapper_prompt)\n                        f.write(\"\\n```\\n\\n\")\n                        f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\")\n                        f.write(llm_summary)\n                    logger.info(f\"Appended LLM prompt and summary to {report_path}\")\n\n                    # Second LLM call for academic report\n                    glossary_path = None\n                    if isinstance(case_config, dict):\n                        glossary_path = sa_config.get(\"glossary_path\")\n\n                    if glossary_path and os.path.exists(glossary_path):\n                        try:\n                            with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n                                glossary_content = f.read()\n\n                            (\n                                academic_wrapper_prompt,\n                                academic_report,\n                            ) = call_llm_for_academic_report(\n                                analysis_report=llm_summary,\n                                glossary_content=glossary_content,\n                                api_key=api_key,\n                                base_url=base_url,\n                                ai_model=ai_model,\n                                problem_details=self.problem,\n                                metric_names=output_metrics,\n                                method=detected_method,\n                                save_dir=save_dir,\n                            )\n\n                            if academic_wrapper_prompt and academic_report:\n                                academic_report_path = os.path.join(\n                                    save_dir, \"academic_report.md\"\n                                )\n                                with open(\n                                    academic_report_path, \"w\", encoding=\"utf-8\"\n                                ) as f:\n                                    f.write(academic_report)\n                                logger.info(\n                                    f\"Generated academic report: {academic_report_path}\"\n                                )\n                        except Exception as e:\n                            logger.error(\n                                f\"Failed to generate or save academic report: {e}\"\n                            )\n                    elif glossary_path:\n                        logger.warning(\n                            f\"Glossary file not found at {glossary_path}, skipping academic report generation.\"\n                        )\n\n            else:\n                logger.warning(\n                    \"API_KEY, BASE_URL, or AI_MODEL not set, or AI analysis is disabled. Skipping LLM summary generation.\"\n                )\n\n        except Exception as e:\n            logger.warning(f\"Failed to save result: {e}\")\n\n        logger.info(\"\\n\u2705 SALib sensitivity analysis completed!\")\n        logger.info(f\"\ud83d\udcc1 The result has been saved to: {save_dir}\")\n\n        return all_results\n\n    def _save_sensitivity_report(\n        self, all_results: Dict[str, Any], save_dir: str\n    ) -&gt; str:\n        \"\"\"The result has been saved to: {save_dir}\"\"\"\n        report_file = os.path.join(save_dir, \"analysis_report.md\")\n        # Determine analysis type based on sampling method\n        is_uncertainty_analysis = (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method == \"latin\"\n        )\n        report_title = (\n            \"# SALib \u4e0d\u786e\u5b9a\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n            if is_uncertainty_analysis\n            else \"# SALib \u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n        )\n        report_lines = []\n        report_lines.append(report_title)\n        report_lines.append(f\"\u751f\u6210\u65f6\u95f4: {pd.Timestamp.now()}\\n\\n\")\n        # Get unit_map from config\n        sensitivity_analysis_config = self.base_config.get(\"sensitivity_analysis\", {})\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n        report_lines.append(\"## \u5206\u6790\u53c2\u6570\\n\\n\")\n        if self.problem:\n            for i, param_name in enumerate(self.problem[\"names\"]):\n                bounds = self.problem[\"bounds\"][i]\n                # --- Unit Conversion Logic for Bounds ---\n                unit_config = self._find_unit_config(param_name, unit_map)\n                display_bounds = list(bounds)\n                unit_str = \"\"\n                if unit_config:\n                    unit = unit_config.get(\"unit\")\n                    factor = unit_config.get(\"conversion_factor\")\n                    if factor:\n                        display_bounds[0] /= float(factor)\n                        display_bounds[1] /= float(factor)\n                    if unit:\n                        unit_str = f\" ({unit})\"\n                # --- End Conversion Logic ---\n                report_lines.append(\n                    f\"- **{param_name}**: [{display_bounds[0]:.4f}, {display_bounds[1]:.4f}]{unit_str}\\n\"\n                )\n        report_lines.append(\"\\n\")\n        for metric_name, metric_results in all_results.items():\n            metric_section_title = (\n                f\"## {metric_name} \u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7ed3\u679c\\n\\n\"\n                if is_uncertainty_analysis\n                else f\"## {metric_name} \u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\\n\\n\"\n            )\n            report_lines.append(metric_section_title)\n            if \"sobol\" in metric_results:\n                report_lines.append(\"### Sobol\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\n                    \"| \u53c2\u6570 | S1 (\u4e00\u9636) | ST (\u603b) | S1\u7f6e\u4fe1\u533a\u95f4 | ST\u7f6e\u4fe1\u533a\u95f4 |\\n\"\n                )\n                report_lines.append(\n                    \"|------|----------|---------|------------|------------|\\n\"\n                )\n                sobol_data = metric_results[\"sobol\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = sobol_data[\"S1\"][i]\n                    st = sobol_data[\"ST\"][i]\n                    s1_conf = sobol_data[\"S1_conf\"][i]\n                    st_conf = sobol_data[\"ST_conf\"][i]\n                    report_lines.append(\n                        f\"| {param_name} | {s1:.4f} | {st:.4f} | \u00b1{s1_conf:.4f} | \u00b1{st_conf:.4f} |\\n\"\n                    )\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'sobol_sensitivity_indices_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![Sobol Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"morris\" in metric_results:\n                report_lines.append(\"### Morris\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\n                    \"| \u53c2\u6570 | \u03bc* (\u5e73\u5747\u7edd\u5bf9\u6548\u5e94) | \u03c3 (\u6807\u51c6\u5dee) | \u03bc*\u7f6e\u4fe1\u533a\u95f4 |\\n\"\n                )\n                report_lines.append(\n                    \"|------|-------------------|------------|------------|\\n\"\n                )\n                morris_data = metric_results[\"morris\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    mu_star = morris_data[\"mu_star\"][i]\n                    sigma = morris_data[\"sigma\"][i]\n                    mu_star_conf = morris_data[\"mu_star_conf\"][i]\n                    report_lines.append(\n                        f\"| {param_name} | {mu_star:.4f} | {sigma:.4f} | \u00b1{mu_star_conf:.4f} |\\n\"\n                    )\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'morris_sensitivity_analysis_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![Morris Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"fast\" in metric_results:\n                report_lines.append(\"### FAST\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\"| \u53c2\u6570 | S1 (\u4e00\u9636) | ST (\u603b) |\\n\")\n                report_lines.append(\"|------|----------|---------|\\n\")\n                fast_data = metric_results[\"fast\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = fast_data[\"S1\"][i]\n                    st = fast_data[\"ST\"][i]\n                    report_lines.append(f\"| {param_name} | {s1:.4f} | {st:.4f} |\\n\")\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'fast_sensitivity_indices_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![FAST Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"latin\" in metric_results:\n                # --- Unit Conversion Logic for Metrics ---\n                unit_config = self._find_unit_config(metric_name, unit_map)\n                unit_str = \"\"\n                factor = 1.0\n                if unit_config:\n                    unit = unit_config.get(\"unit\")\n                    conv_factor = unit_config.get(\"conversion_factor\")\n                    if conv_factor:\n                        factor = float(conv_factor)\n                    if unit:\n                        unit_str = f\" ({unit})\"\n                # --- End Conversion Logic ---\n                # 1. Get raw data and clean it\n                output_index = metric_results[\"latin\"][\"output_index\"]\n                Y = self.simulation_results[:, output_index]\n                Y_clean = Y[~np.isnan(Y)]\n                # --- Modify report generation ---\n                report_lines.append(\"### \u7edf\u8ba1\u6458\u8981\\n\\n\")\n                lhs_data = metric_results[\"latin\"]\n                report_lines.append(\n                    f\"- \u5747\u503c: {lhs_data['mean']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6807\u51c6\u5dee: {lhs_data['std']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6700\u5c0f\u503c: {lhs_data['min']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6700\u5927\u503c: {lhs_data['max']/factor:.4f}{unit_str}\\n\\n\"\n                )\n                # 2. Calculate more percentiles\n                if len(Y_clean) &gt; 0:\n                    percentiles_to_calc = [5, 10, 25, 50, 75, 90, 95]\n                    percentile_values = np.percentile(Y_clean, percentiles_to_calc)\n                    report_lines.append(\"### \u5206\u5e03\u5173\u952e\u70b9 (CDF)\\n\\n\")\n                    report_lines.append(\n                        f\"- 5%\u5206\u4f4d\u6570: {percentile_values[0]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 10%\u5206\u4f4d\u6570: {percentile_values[1]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 25%\u5206\u4f4d\u6570 (Q1): {percentile_values[2]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 50%\u5206\u4f4d\u6570 (\u4e2d\u4f4d\u6570): {percentile_values[3]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 75%\u5206\u4f4d\u6570 (Q3): {percentile_values[4]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 90%\u5206\u4f4d\u6570: {percentile_values[5]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 95%\u5206\u4f4d\u6570: {percentile_values[6]/factor:.4f}{unit_str}\\n\\n\"\n                    )\n                    # 3. Calculate histogram data\n                    hist_freq, bin_edges = np.histogram(Y_clean, bins=10)\n                    report_lines.append(\"### \u8f93\u51fa\u5206\u5e03 (\u76f4\u65b9\u56fe\u6570\u636e)\\n\\n\")\n                    report_lines.append(\"| \u6570\u503c\u8303\u56f4 | \u9891\u6570 |\\n\")\n                    report_lines.append(\"|:---|---:|\\n\")\n                    for i in range(len(hist_freq)):\n                        lower_bound = bin_edges[i] / factor\n                        upper_bound = bin_edges[i + 1] / factor\n                        freq = hist_freq[i]\n                        report_lines.append(\n                            f\"| {lower_bound:.2f} - {upper_bound:.2f} | {freq} |\\n\"\n                        )\n                    report_lines.append(\"\\n\")\n                plot_filename = f'lhs_analysis_{metric_name.replace(\" \", \"_\")}.png'\n                report_lines.append(\n                    f\"![LHS Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n        report_content = \"\".join(report_lines)\n        with open(report_file, \"w\", encoding=\"utf-8\") as f:\n            f.write(report_content)\n        logger.info(f\"The sensitivity analysis report has been saved.: {report_file}\")\n        return report_content\n\n    def plot_sobol_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot Sobol analysis results\"\"\"\n        if \"sobol\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results for the Sobol method were found.\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        sobol_results = self.sensitivity_results[\"sobol\"]\n\n        if not sobol_results:\n            raise ValueError(\"Sobol analysis results not found\")\n\n        # Generate charts for each metric\n        for metric_key, results in sobol_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Bar chart of first-order and total sensitivity indices\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # First-order sensitivity index\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax1.barh(y_pos, Si[\"S1\"], xerr=Si[\"S1_conf\"], alpha=0.7, color=\"skyblue\")\n            ax1.set_yticks(y_pos)\n            ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax1.set_xlabel(\"First-order sensitivity index (S1)\", fontsize=12)\n            ax1.set_title(\n                f\"First-order Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax1.grid(True, alpha=0.3)\n\n            # # Total Sensitivity Index\n            ax2.barh(y_pos, Si[\"ST\"], xerr=Si[\"ST_conf\"], alpha=0.7, color=\"orange\")\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"Total Sensitivity Index (ST)\", fontsize=12)\n            ax2.set_title(\n                f\"Total Sensitivity Indices\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = (\n                f'sobol_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n            )\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"Sobol result chart has been saved: {filename}\")\n\n    def plot_morris_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot the Morris analysis results\"\"\"\n        if \"morris\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results were found for the Morris method.\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Obtain the results of all indicators\n        morris_results = self.sensitivity_results[\"morris\"]\n\n        if not morris_results:\n            raise ValueError(\"No Morris analysis results found\")\n\n        for metric_key, results in morris_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Morris \u03bc*-\u03c3 diagram\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # \u03bc*-\u03c3 scatter plot\n            ax1.scatter(Si[\"mu_star\"], Si[\"sigma\"], s=100, alpha=0.7, color=\"red\")\n            for i, name in enumerate(self.problem[\"names\"]):\n                ax1.annotate(\n                    name,\n                    (Si[\"mu_star\"][i], Si[\"sigma\"][i]),\n                    xytext=(5, 5),\n                    textcoords=\"offset points\",\n                    fontsize=9,\n                )\n\n            ax1.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n            ax1.set_ylabel(\"\u03c3 (Standard Deviation)\", fontsize=12)\n            ax1.set_title(\n                f\"Morris \u03bc*-\u03c3 Plot\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax1.grid(True, alpha=0.3)\n\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax2.barh(\n                y_pos, Si[\"mu_star\"], xerr=Si[\"mu_star_conf\"], alpha=0.7, color=\"green\"\n            )\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n            ax2.set_title(\n                f\"Morris Elementary Effects\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = f'morris_sensitivity_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"Morris result chart has been saved: {filename}\")\n\n    def plot_fast_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot FAST analysis results\"\"\"\n        if \"fast\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results found for the FAST method\")\n\n        # No analysis results found for the FAST method\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        fast_results = self.sensitivity_results[\"fast\"]\n\n        if not fast_results:\n            raise ValueError(\"FAST analysis results not found\")\n\n        # Generate a chart for each metric\n        for metric_key, results in fast_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            # Determine the indicator name\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Bar charts of first-order and total sensitivity indices\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # first-order sensitivity index\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax1.barh(y_pos, Si[\"S1\"], alpha=0.7, color=\"purple\")\n            ax1.set_yticks(y_pos)\n            ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax1.set_xlabel(\"\u4e00\u9636\u654f\u611f\u6027\u6307\u6570 (S1)\", fontsize=12)\n            ax1.set_title(\n                f\"FAST First-order Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax1.grid(True, alpha=0.3)\n\n            # Total Sensitivity Index\n            ax2.barh(y_pos, Si[\"ST\"], alpha=0.7, color=\"darkgreen\")\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"\u603b\u654f\u611f\u6027\u6307\u6570 (ST)\", fontsize=12)\n            ax2.set_title(\n                f\"FAST Total Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = (\n                f'fast_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n            )\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"The FAST result chart has been saved: {filename}\")\n\n    def plot_lhs_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot LHS (Latin Hypercube Sampling) uncertainty analysis results\"\"\"\n        if \"latin\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results found for the LHS method\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        lhs_results = self.sensitivity_results[\"latin\"]\n\n        if not lhs_results:\n            raise ValueError(\"LHS analysis results not found\")\n\n        # Generate charts for each metric\n        for metric_key, results in lhs_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            # Determine the indicator name\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Get unit from config\n            sensitivity_analysis_config = self.base_config.get(\n                \"sensitivity_analysis\", {}\n            )\n            unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n            unit_config = self._find_unit_config(metric_display_name, unit_map)\n            unit_str = \"\"\n            if unit_config:\n                unit = unit_config.get(\"unit\")\n                if unit:\n                    unit_str = f\" ({unit})\"\n\n            xlabel = f\"{metric_display_name}{unit_str}\"\n\n            # Create a figure with two subplots\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # Plot 1: Distribution histogram\n            ax1.hist(\n                self.simulation_results[:, output_index],\n                bins=30,\n                alpha=0.7,\n                color=\"skyblue\",\n                edgecolor=\"black\",\n            )\n            ax1.set_xlabel(xlabel, fontsize=12)\n            ax1.set_ylabel(\"\u9891\u7387\", fontsize=12)\n            ax1.set_title(\"\u8f93\u51fa\u5206\u5e03\u76f4\u65b9\u56fe\", fontsize=14, pad=10)\n            ax1.grid(True, alpha=0.3)\n\n            # Add statistics text to the histogram plot\n            stats_text = f\"\u5747\u503c: {Si['mean']:.4f}\\n\u6807\u51c6\u5dee: {Si['std']:.4f}\\n\u6700\u5c0f\u503c: {Si['min']:.4f}\\n\u6700\u5927\u503c: {Si['max']:.4f}\"\n            ax1.text(\n                0.05,\n                0.95,\n                stats_text,\n                transform=ax1.transAxes,\n                fontsize=10,\n                verticalalignment=\"top\",\n                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n            )\n\n            # Plot 2: Cumulative distribution function\n            sorted_data = np.sort(self.simulation_results[:, output_index])\n            y_vals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n            ax2.plot(sorted_data, y_vals, linewidth=2, color=\"darkgreen\")\n            ax2.set_xlabel(xlabel, fontsize=12)\n            ax2.set_ylabel(\"\u7d2f\u79ef\u6982\u7387\", fontsize=12)\n            ax2.set_title(\"\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\", fontsize=14, pad=10)\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = f'lhs_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"LHS\u5206\u6790\u7ed3\u679c\u56fe\u8868\u5df2\u4fdd\u5b58: {filename}\")\n\n    def save_results(\n        self, save_dir: str = None, format: str = \"csv\", metric_names: List[str] = None\n    ) -&gt; None:\n        \"\"\"\n        Save sensitivity analysis results\n\n        Args:\n            save_dir: Save directory\n            format: Save format ('csv\n        \"\"\"\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        for method, method_results in self.sensitivity_results.items():\n            if not method_results:\n                continue\n\n            for metric_key, results in method_results.items():\n                output_index = results[\"output_index\"]\n\n                if metric_names and output_index &lt; len(metric_names):\n                    metric_display_name = metric_names[output_index]\n                else:\n                    metric_display_name = f\"Metric_{output_index}\"\n\n                if format == \"csv\":\n                    if method == \"sobol\":\n                        sobol_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"S1\": results[\"S1\"],\n                                \"ST\": results[\"ST\"],\n                                \"S1_conf\": results[\"S1_conf\"],\n                                \"ST_conf\": results[\"ST_conf\"],\n                            }\n                        )\n                        filename = (\n                            f'sobol_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        sobol_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"Sobol results have been saved: {filename}\")\n\n                    elif method == \"morris\":\n                        morris_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"mu\": results[\"mu\"],\n                                \"mu_star\": results[\"mu_star\"],\n                                \"sigma\": results[\"sigma\"],\n                                \"mu_star_conf\": results[\"mu_star_conf\"],\n                            }\n                        )\n                        filename = f'morris_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        morris_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"Morris results have been saved: {filename}\")\n\n                    elif method == \"fast\":\n                        fast_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"S1\": results[\"S1\"],\n                                \"ST\": results[\"ST\"],\n                            }\n                        )\n                        filename = (\n                            f'fast_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        fast_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"FAST results have been saved: {filename}\")\n\n                    elif method == \"latin\":\n                        # Save LHS statistics\n                        lhs_stats_df = pd.DataFrame(\n                            {\n                                \"Metric\": [metric_display_name],\n                                \"Mean\": [results[\"mean\"]],\n                                \"Std\": [results[\"std\"]],\n                                \"Min\": [results[\"min\"]],\n                                \"Max\": [results[\"max\"]],\n                                \"Percentile_5\": [results[\"percentile_5\"]],\n                                \"Percentile_95\": [results[\"percentile_95\"]],\n                            }\n                        )\n                        filename_stats = (\n                            f'lhs_stats_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        lhs_stats_df.to_csv(\n                            os.path.join(save_dir, filename_stats), index=False\n                        )\n                        logger.info(f\"LHS\u7edf\u8ba1\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_stats}\")\n\n                        # Remove LHS sensitivity indices saving\n                        # lhs_sens_df = pd.DataFrame({\n                        #     \"Parameter\": self.problem[\"names\"],\n                        #     \"Partial_Correlation\": results[\"partial_correlations\"]\n                        # })\n                        # filename_sens = f'lhs_sensitivity_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        # lhs_sens_df.to_csv(os.path.join(save_dir, filename_sens), index=False)\n                        # logger.info(f\"LHS\u654f\u611f\u6027\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_sens}\")\n\n        logger.info(f\"The result has been saved to: {save_dir}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.__init__","title":"<code>__init__(base_config)</code>","text":"<p>Initialize the analyzer.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>base_config</code> <code>Dict[str, Any]</code> <p>Tricys base configuration dictionary.</p> \u5fc5\u9700 Note <p>Creates a deep copy of base_config. Initializes problem, samples, and results to None. Calls _setup_chinese_font() and _validate_tricys_config() automatically.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def __init__(self, base_config: Dict[str, Any]) -&gt; None:\n    \"\"\"Initialize the analyzer.\n\n    Args:\n        base_config: Tricys base configuration dictionary.\n\n    Note:\n        Creates a deep copy of base_config. Initializes problem, samples, and results\n        to None. Calls _setup_chinese_font() and _validate_tricys_config() automatically.\n    \"\"\"\n    self.base_config = base_config.copy()\n    self.problem = None\n    self.parameter_samples = None\n    self.simulation_results = None\n    self.sensitivity_results = {}\n\n    self._setup_chinese_font()\n    self._validate_tricys_config()\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_fast","title":"<code>analyze_fast(output_index=0, **kwargs)</code>","text":"<p>Perform FAST sensitivity analysis</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>FAST analysis parameters</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>FAST sensitivity analysis results</p> Note <p>FAST analysis requires samples generated by the fast_sampler sampling method! Results from Morris or Sobol sampling cannot be used.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def analyze_fast(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform FAST sensitivity analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: FAST analysis parameters\n\n    Returns:\n        FAST sensitivity analysis results\n\n    Note:\n        FAST analysis requires samples generated by the fast_sampler sampling method!\n        Results from Morris or Sobol sampling cannot be used.\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"fast\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but FAST analysis requires FAST sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('fast')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"FAST\u5206\u6790\")\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n\n    try:\n        # Perform FAST analysis\n        Si = fast.analyze(self.problem, Y, **kwargs)\n\n        if \"fast\" not in self.sensitivity_results:\n            self.sensitivity_results[\"fast\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"fast\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"S1\": Si[\"S1\"],\n            \"ST\": Si[\"ST\"],\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(\n            f\"FAST sensitivity analysis completed (indicator {output_index})\"\n        )\n        return self.sensitivity_results[\"fast\"][metric_name]\n\n    except Exception as e:\n        if \"fast\" in str(e).lower() or \"sample\" in str(e).lower():\n            raise ValueError(\n                f\"FAST analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('fast')\"\n            ) from e\n        else:\n            raise\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_lhs","title":"<code>analyze_lhs(output_index=0, **kwargs)</code>","text":"<p>Perform LHS (Latin Hypercube Sampling) uncertainty analysis</p> <p>Note: This is a basic statistical analysis method for LHS samples, providing descriptive statistics and basic sensitivity indices.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Analysis parameters (reserved for future use)</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>LHS uncertainty analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def analyze_lhs(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform LHS (Latin Hypercube Sampling) uncertainty analysis\n\n    Note: This is a basic statistical analysis method for LHS samples,\n    providing descriptive statistics and basic sensitivity indices.\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Analysis parameters (reserved for future use)\n\n    Returns:\n        LHS uncertainty analysis results\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"latin\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but LHS analysis is designed for Latin Hypercube Sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('latin')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    # Handle NaN values\n    Y = self._handle_nan_values(Y, \"LHS\u5206\u6790\")\n\n    # Basic statistical analysis\n    mean_val = np.mean(Y)\n    std_val = np.std(Y)\n    min_val = np.min(Y)\n    max_val = np.max(Y)\n    percentile_5 = np.percentile(Y, 5)\n    percentile_95 = np.percentile(Y, 95)\n\n    # Create results dictionary\n    Si = {\n        \"mean\": mean_val,\n        \"std\": std_val,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"percentile_5\": percentile_5,\n        \"percentile_95\": percentile_95,\n    }\n\n    if \"latin\" not in self.sensitivity_results:\n        self.sensitivity_results[\"latin\"] = {}\n\n    metric_name = f\"metric_{output_index}\"\n    self.sensitivity_results[\"latin\"][metric_name] = {\n        \"output_index\": output_index,\n        \"Si\": Si,\n        \"mean\": mean_val,\n        \"std\": std_val,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"percentile_5\": percentile_5,\n        \"percentile_95\": percentile_95,\n        \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n    }\n\n    logger.info(f\"LHS uncertainty analysis completed (\u6307\u6807 {output_index})\")\n    return self.sensitivity_results[\"latin\"][metric_name]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_morris","title":"<code>analyze_morris(output_index=0, **kwargs)</code>","text":"<p>Perform Morris sensitivity analysis</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Morris analysis parameters</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>Morris sensitivity analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def analyze_morris(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform Morris sensitivity analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Morris analysis parameters\n\n    Returns:\n        Morris sensitivity analysis results\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"Morris\u5206\u6790\")\n    X = self.parameter_samples\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n    #    X = self.parameter_samples[valid_indices]\n    # else:\n    #    X = self.parameter_samples\n\n    # Perform Morris analysis\n    logger.info(\n        f\"Start Morris sensitivity analysis: X.shape={X.shape}, Y.shape={Y.shape}, X.dtype={X.dtype}\"\n    )\n\n    try:\n        Si = morris_analyze.analyze(self.problem, X, Y, **kwargs)\n    except Exception as e:\n        logger.error(f\"Morris analysis execution failed: {e}\")\n        logger.error(f\"problem: {self.problem}\")\n        logger.error(f\"X shape: {X.shape}, type: {X.dtype}\")\n        logger.error(f\"Yshape: {Y.shape}, type: {Y.dtype}\")\n        if hasattr(X, \"dtype\") and X.dtype == \"object\":\n            logger.error(\n                \"X contains non-numeric data, please check the sampled data\"\n            )\n        raise\n\n    if \"morris\" not in self.sensitivity_results:\n        self.sensitivity_results[\"morris\"] = {}\n\n    metric_name = f\"metric_{output_index}\"\n    self.sensitivity_results[\"morris\"][metric_name] = {\n        \"output_index\": output_index,\n        \"Si\": Si,\n        \"mu\": Si[\"mu\"],\n        \"mu_star\": Si[\"mu_star\"],\n        \"sigma\": Si[\"sigma\"],\n        \"mu_star_conf\": Si[\"mu_star_conf\"],\n    }\n\n    logger.info(f\"Morris sensitivity analysis completed (metric {output_index})\")\n    return self.sensitivity_results[\"morris\"][metric_name]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_sobol","title":"<code>analyze_sobol(output_index=0, **kwargs)</code>","text":"<p>Perform Sobol Sensitivity Analysis</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Sobol analysis parameters</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>Sobol sensitivity analysis results</p> Note <p>Sobol analysis requires samples generated using the Saltelli sampling method! Results from Morris or FAST sampling cannot be used.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def analyze_sobol(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform Sobol Sensitivity Analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Sobol analysis parameters\n\n    Returns:\n        Sobol sensitivity analysis results\n\n    Note:\n        Sobol analysis requires samples generated using the Saltelli sampling method!\n        Results from Morris or FAST sampling cannot be used.\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    # Check sampling method compatibility\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"sobol\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f Currently using {self._last_sampling_method} sampling, but Sobol analysis requires Saltelli sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('sobol')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"Sobol\u5206\u6790\")\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n    #    X = self.parameter_samples[valid_indices]\n    # else:\n    #    X = self.parameter_samples\n\n    try:\n        Si = sobol.analyze(self.problem, Y, **kwargs)\n\n        if \"sobol\" not in self.sensitivity_results:\n            self.sensitivity_results[\"sobol\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"sobol\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"S1\": Si[\"S1\"],\n            \"ST\": Si[\"ST\"],\n            \"S2\": Si.get(\"S2\", None),\n            \"S1_conf\": Si[\"S1_conf\"],\n            \"ST_conf\": Si[\"ST_conf\"],\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(f\"Sobol sensitivity analysis completed (index {output_index})\")\n        return self.sensitivity_results[\"sobol\"][metric_name]\n\n    except Exception as e:\n        if \"saltelli\" in str(e).lower() or \"sample\" in str(e).lower():\n            raise ValueError(\n                f\"Sobol analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('sobol')\"\n            ) from e\n        else:\n            raise\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.define_problem","title":"<code>define_problem(param_bounds, param_distributions=None)</code>","text":"<p>Define SALib problem space.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>param_bounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Parameter bounds dictionary {'param_name': (min_val, max_val)}.</p> \u5fc5\u9700 <code>param_distributions</code> <code>Dict[str, str]</code> <p>Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}. Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'.</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>SALib problem definition dictionary.</p> Note <p>Defaults to 'unif' distribution if not specified. Validates distribution types and warns if invalid. Logs parameter definitions including bounds and distributions.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def define_problem(\n    self,\n    param_bounds: Dict[str, Tuple[float, float]],\n    param_distributions: Dict[str, str] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Define SALib problem space.\n\n    Args:\n        param_bounds: Parameter bounds dictionary {'param_name': (min_val, max_val)}.\n        param_distributions: Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}.\n            Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'.\n\n    Returns:\n        SALib problem definition dictionary.\n\n    Note:\n        Defaults to 'unif' distribution if not specified. Validates distribution types\n        and warns if invalid. Logs parameter definitions including bounds and distributions.\n    \"\"\"\n    if param_distributions is None:\n        param_distributions = {name: \"unif\" for name in param_bounds.keys()}\n\n    valid_dists = [\"unif\", \"triang\", \"norm\", \"truncnorm\", \"lognorm\"]\n    for name, dist in param_distributions.items():\n        if dist not in valid_dists:\n            logger.warning(\n                \"Invalid distribution type, using 'unif' instead\",\n                extra={\n                    \"parameter_name\": name,\n                    \"invalid_distribution\": dist,\n                },\n            )\n            param_distributions[name] = \"unif\"\n\n    self.problem = {\n        \"num_vars\": len(param_bounds),\n        \"names\": list(param_bounds.keys()),\n        \"bounds\": list(param_bounds.values()),\n        \"dists\": [\n            param_distributions.get(name, \"unif\") for name in param_bounds.keys()\n        ],\n    }\n\n    logger.info(\n        \"Defined a problem space\",\n        extra={\n            \"num_parameters\": self.problem[\"num_vars\"],\n        },\n    )\n    for i, name in enumerate(self.problem[\"names\"]):\n        logger.info(\n            \"Parameter definition\",\n            extra={\n                \"parameter_name\": name,\n                \"bounds\": self.problem[\"bounds\"][i],\n                \"distribution\": self.problem[\"dists\"][i],\n            },\n        )\n\n    return self.problem\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.generate_samples","title":"<code>generate_samples(method='sobol', N=1024, **kwargs)</code>","text":"<p>Generate parameter samples.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>method</code> <code>str</code> <p>Sampling method ('sobol', 'morris', 'fast', 'latin').</p> <code>'sobol'</code> <code>N</code> <code>int</code> <p>Number of samples (for Sobol this is the base sample count, actual count is N(2D+2)).</p> <code>1024</code> <code>**kwargs</code> <p>Method-specific parameters.</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>ndarray</code> <p>Parameter sample array (n_samples, n_params).</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>ValueError</code> <p>If problem not defined or unsupported method.</p> Note <p>Sobol generates N(2D+2) samples. Morris generates N trajectories. Samples are rounded to 5 decimal places. Stores last sampling method for compatibility checking.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def generate_samples(\n    self, method: str = \"sobol\", N: int = 1024, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"Generate parameter samples.\n\n    Args:\n        method: Sampling method ('sobol', 'morris', 'fast', 'latin').\n        N: Number of samples (for Sobol this is the base sample count, actual count is N*(2*D+2)).\n        **kwargs: Method-specific parameters.\n\n    Returns:\n        Parameter sample array (n_samples, n_params).\n\n    Raises:\n        ValueError: If problem not defined or unsupported method.\n\n    Note:\n        Sobol generates N*(2*D+2) samples. Morris generates N trajectories. Samples are\n        rounded to 5 decimal places. Stores last sampling method for compatibility checking.\n    \"\"\"\n    if self.problem is None:\n        raise ValueError(\n            \"You must first call define_problem() to define the problem space.\"\n        )\n\n    logger.info(\n        \"Generating samples\",\n        extra={\n            \"method\": method,\n            \"base_sample_count\": N,\n        },\n    )\n\n    if method.lower() == \"sobol\":\n        # Sobol method: generate N*(2*D+2) samples\n        self.parameter_samples = saltelli.sample(self.problem, N, **kwargs)\n        actual_samples = N * (2 * self.problem[\"num_vars\"] + 2)\n\n    elif method.lower() == \"morris\":\n        # Morris method: Generate N trajectories\n        # Note: Different versions of SALib may have different parameter names\n        morris_kwargs = {\"num_levels\": 4}\n        # Check the SALib version and use the correct parameter names\n        try:\n            morris_kwargs.update(kwargs)\n            self.parameter_samples = morris.sample(self.problem, N, **morris_kwargs)\n        except TypeError as e:\n            if \"grid_jump\" in str(e):\n                morris_kwargs = {\n                    k: v for k, v in morris_kwargs.items() if k != \"grid_jump\"\n                }\n                morris_kwargs.update(\n                    {k: v for k, v in kwargs.items() if k != \"grid_jump\"}\n                )\n                self.parameter_samples = morris.sample(\n                    self.problem, N, **morris_kwargs\n                )\n            else:\n                raise e\n\n        actual_samples = len(self.parameter_samples)\n\n    elif method.lower() == \"fast\":\n        # FAST method\n        fast_kwargs = {\"M\": 4}\n        fast_kwargs.update(kwargs)\n        self.parameter_samples = fast_sampler.sample(self.problem, N, **fast_kwargs)\n        actual_samples = len(self.parameter_samples)\n\n    elif method.lower() == \"latin\":\n        # Latin Hypercube Sampling\n        self.parameter_samples = latin.sample(self.problem, N, **kwargs)\n        actual_samples = N\n\n    else:\n        raise ValueError(f\"Unsupported sampling method: {method}\")\n\n    logger.info(\n        \"Successfully generated samples\", extra={\"actual_samples\": actual_samples}\n    )\n\n    if self.parameter_samples is not None:\n        self.parameter_samples = np.round(self.parameter_samples, decimals=5)\n        logger.info(\"Parameter sample precision adjusted to 5 decimal places\")\n\n    self._last_sampling_method = method.lower()\n\n    return self.parameter_samples\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.generate_tricys_config","title":"<code>generate_tricys_config(csv_file_path=None, output_metrics=None)</code>","text":"<p>Generate Tricys configuration file for reading CSV parameter files and executing simulations This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>csv_file_path</code> <code>str</code> <p>Path to the CSV parameter file. If None, the last generated file is used</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be calculated</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>Path of the generated configuration file</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def generate_tricys_config(\n    self, csv_file_path: str = None, output_metrics: List[str] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Generate Tricys configuration file for reading CSV parameter files and executing simulations\n    This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs\n\n    Args:\n        csv_file_path: Path to the CSV parameter file. If None, the last generated file is used\n        output_metrics: List of output metrics to be calculated\n\n    Returns:\n        Path of the generated configuration file\n    \"\"\"\n    if csv_file_path is None:\n        if hasattr(self, \"sampling_csv_path\"):\n            csv_file_path = self.sampling_csv_path\n        else:\n            raise ValueError(\n                \"CSV file path not found, please first call run_tricys_simulations() or specify csv_file_path\"\n            )\n\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    csv_abs_path = os.path.abspath(csv_file_path)\n\n    import copy\n\n    tricys_config = copy.deepcopy(self.base_config)\n    tricys_config[\"simulation_parameters\"] = {\"file\": csv_abs_path}\n\n    if \"sensitivity_analysis\" not in tricys_config:\n        tricys_config[\"sensitivity_analysis\"] = {\"enabled\": True}\n\n    tricys_config[\"sensitivity_analysis\"][\"analysis_case\"] = {\n        \"name\": \"SALib_Analysis\",\n        \"independent_variable\": \"file\",\n        \"independent_variable_sampling\": csv_abs_path,\n        \"dependent_variables\": output_metrics,\n    }\n\n    return tricys_config\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.get_compatible_analysis_methods","title":"<code>get_compatible_analysis_methods(sampling_method)</code>","text":"<p>Get analysis methods compatible with the specified sampling method.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>sampling_method</code> <code>str</code> <p>Sampling method</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[str]</code> <p>List of compatible analysis methods</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def get_compatible_analysis_methods(self, sampling_method: str) -&gt; List[str]:\n    \"\"\"\n    Get analysis methods compatible with the specified sampling method.\n\n    Args:\n        sampling_method: Sampling method\n\n    Returns:\n        List of compatible analysis methods\n    \"\"\"\n    compatibility_map = {\n        \"sobol\": [\"sobol\"],\n        \"morris\": [\"morris\"],\n        \"fast\": [\"fast\"],\n        \"latin\": [\"latin\"],\n        \"unknown\": [],\n    }\n\n    return compatibility_map.get(sampling_method, [])\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.load_tricys_results","title":"<code>load_tricys_results(sensitivity_summary_csv, output_metrics=None)</code>","text":"<p>Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>sensitivity_summary_csv</code> <code>str</code> <p>Path to the sensitivity analysis summary CSV file output by Tricys</p> \u5fc5\u9700 <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to extract</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>ndarray</code> <p>Simulation result array (n_samples, n_metrics)</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def load_tricys_results(\n    self, sensitivity_summary_csv: str, output_metrics: List[str] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys\n\n    Args:\n        sensitivity_summary_csv: Path to the sensitivity analysis summary CSV file output by Tricys\n        output_metrics: List of output metrics to extract\n\n    Returns:\n        Simulation result array (n_samples, n_metrics)\n    \"\"\"\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    logger.info(f\"Read data from the Tricys result file: {sensitivity_summary_csv}\")\n\n    df = pd.read_csv(sensitivity_summary_csv)\n\n    logger.info(f\"Read {len(df)} simulation results\")\n    logger.info(f\"Result file columns: {list(df.columns)}\")\n\n    param_cols = []\n    metric_cols = []\n\n    for col in df.columns:\n        if col in output_metrics:\n            metric_cols.append(col)\n        elif col in self.problem[\"names\"] if self.problem else False:\n            param_cols.append(col)\n\n    logger.info(f\"Recognized parameter columns: {param_cols}\")\n    logger.info(f\"Identified metric columns: {metric_cols}\")\n\n    ordered_metric_cols = []\n    for metric in output_metrics:\n        if metric in metric_cols:\n            ordered_metric_cols.append(metric)\n        else:\n            logger.warning(f\"Metric column not found: {metric}\")\n\n    if not ordered_metric_cols:\n        raise ValueError(f\"No valid output metrics columns found: {output_metrics}\")\n\n    results_data = df[ordered_metric_cols].values\n\n    self.simulation_results = results_data\n\n    logger.info(f\"Successfully loaded simulation results: {results_data.shape}\")\n    logger.info(\n        f\"Result Statistics:\\n{pd.DataFrame(results_data, columns=ordered_metric_cols).describe()}\"\n    )\n    logger.info(\n        f\"Result preview:\\n{pd.DataFrame(results_data, columns=metric_cols).head()}\"\n    )\n    return self.simulation_results\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_fast_results","title":"<code>plot_fast_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot FAST analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def plot_fast_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot FAST analysis results\"\"\"\n    if \"fast\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results found for the FAST method\")\n\n    # No analysis results found for the FAST method\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    fast_results = self.sensitivity_results[\"fast\"]\n\n    if not fast_results:\n        raise ValueError(\"FAST analysis results not found\")\n\n    # Generate a chart for each metric\n    for metric_key, results in fast_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        # Determine the indicator name\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Bar charts of first-order and total sensitivity indices\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # first-order sensitivity index\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax1.barh(y_pos, Si[\"S1\"], alpha=0.7, color=\"purple\")\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax1.set_xlabel(\"\u4e00\u9636\u654f\u611f\u6027\u6307\u6570 (S1)\", fontsize=12)\n        ax1.set_title(\n            f\"FAST First-order Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax1.grid(True, alpha=0.3)\n\n        # Total Sensitivity Index\n        ax2.barh(y_pos, Si[\"ST\"], alpha=0.7, color=\"darkgreen\")\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"\u603b\u654f\u611f\u6027\u6307\u6570 (ST)\", fontsize=12)\n        ax2.set_title(\n            f\"FAST Total Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = (\n            f'fast_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n        )\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"The FAST result chart has been saved: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_lhs_results","title":"<code>plot_lhs_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot LHS (Latin Hypercube Sampling) uncertainty analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def plot_lhs_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot LHS (Latin Hypercube Sampling) uncertainty analysis results\"\"\"\n    if \"latin\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results found for the LHS method\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    lhs_results = self.sensitivity_results[\"latin\"]\n\n    if not lhs_results:\n        raise ValueError(\"LHS analysis results not found\")\n\n    # Generate charts for each metric\n    for metric_key, results in lhs_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        # Determine the indicator name\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Get unit from config\n        sensitivity_analysis_config = self.base_config.get(\n            \"sensitivity_analysis\", {}\n        )\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n        unit_config = self._find_unit_config(metric_display_name, unit_map)\n        unit_str = \"\"\n        if unit_config:\n            unit = unit_config.get(\"unit\")\n            if unit:\n                unit_str = f\" ({unit})\"\n\n        xlabel = f\"{metric_display_name}{unit_str}\"\n\n        # Create a figure with two subplots\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # Plot 1: Distribution histogram\n        ax1.hist(\n            self.simulation_results[:, output_index],\n            bins=30,\n            alpha=0.7,\n            color=\"skyblue\",\n            edgecolor=\"black\",\n        )\n        ax1.set_xlabel(xlabel, fontsize=12)\n        ax1.set_ylabel(\"\u9891\u7387\", fontsize=12)\n        ax1.set_title(\"\u8f93\u51fa\u5206\u5e03\u76f4\u65b9\u56fe\", fontsize=14, pad=10)\n        ax1.grid(True, alpha=0.3)\n\n        # Add statistics text to the histogram plot\n        stats_text = f\"\u5747\u503c: {Si['mean']:.4f}\\n\u6807\u51c6\u5dee: {Si['std']:.4f}\\n\u6700\u5c0f\u503c: {Si['min']:.4f}\\n\u6700\u5927\u503c: {Si['max']:.4f}\"\n        ax1.text(\n            0.05,\n            0.95,\n            stats_text,\n            transform=ax1.transAxes,\n            fontsize=10,\n            verticalalignment=\"top\",\n            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n        )\n\n        # Plot 2: Cumulative distribution function\n        sorted_data = np.sort(self.simulation_results[:, output_index])\n        y_vals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n        ax2.plot(sorted_data, y_vals, linewidth=2, color=\"darkgreen\")\n        ax2.set_xlabel(xlabel, fontsize=12)\n        ax2.set_ylabel(\"\u7d2f\u79ef\u6982\u7387\", fontsize=12)\n        ax2.set_title(\"\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\", fontsize=14, pad=10)\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = f'lhs_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"LHS\u5206\u6790\u7ed3\u679c\u56fe\u8868\u5df2\u4fdd\u5b58: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_morris_results","title":"<code>plot_morris_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot the Morris analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def plot_morris_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot the Morris analysis results\"\"\"\n    if \"morris\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results were found for the Morris method.\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Obtain the results of all indicators\n    morris_results = self.sensitivity_results[\"morris\"]\n\n    if not morris_results:\n        raise ValueError(\"No Morris analysis results found\")\n\n    for metric_key, results in morris_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Morris \u03bc*-\u03c3 diagram\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # \u03bc*-\u03c3 scatter plot\n        ax1.scatter(Si[\"mu_star\"], Si[\"sigma\"], s=100, alpha=0.7, color=\"red\")\n        for i, name in enumerate(self.problem[\"names\"]):\n            ax1.annotate(\n                name,\n                (Si[\"mu_star\"][i], Si[\"sigma\"][i]),\n                xytext=(5, 5),\n                textcoords=\"offset points\",\n                fontsize=9,\n            )\n\n        ax1.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n        ax1.set_ylabel(\"\u03c3 (Standard Deviation)\", fontsize=12)\n        ax1.set_title(\n            f\"Morris \u03bc*-\u03c3 Plot\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax1.grid(True, alpha=0.3)\n\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax2.barh(\n            y_pos, Si[\"mu_star\"], xerr=Si[\"mu_star_conf\"], alpha=0.7, color=\"green\"\n        )\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n        ax2.set_title(\n            f\"Morris Elementary Effects\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = f'morris_sensitivity_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"Morris result chart has been saved: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_sobol_results","title":"<code>plot_sobol_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot Sobol analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def plot_sobol_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot Sobol analysis results\"\"\"\n    if \"sobol\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results for the Sobol method were found.\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    sobol_results = self.sensitivity_results[\"sobol\"]\n\n    if not sobol_results:\n        raise ValueError(\"Sobol analysis results not found\")\n\n    # Generate charts for each metric\n    for metric_key, results in sobol_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Bar chart of first-order and total sensitivity indices\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # First-order sensitivity index\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax1.barh(y_pos, Si[\"S1\"], xerr=Si[\"S1_conf\"], alpha=0.7, color=\"skyblue\")\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax1.set_xlabel(\"First-order sensitivity index (S1)\", fontsize=12)\n        ax1.set_title(\n            f\"First-order Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax1.grid(True, alpha=0.3)\n\n        # # Total Sensitivity Index\n        ax2.barh(y_pos, Si[\"ST\"], xerr=Si[\"ST_conf\"], alpha=0.7, color=\"orange\")\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"Total Sensitivity Index (ST)\", fontsize=12)\n        ax2.set_title(\n            f\"Total Sensitivity Indices\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = (\n            f'sobol_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n        )\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"Sobol result chart has been saved: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.run_salib_analysis_from_tricys_results","title":"<code>run_salib_analysis_from_tricys_results(sensitivity_summary_csv, param_bounds=None, output_metrics=None, methods=['sobol', 'morris', 'fast'], save_dir=None)</code>","text":"<p>Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>sensitivity_summary_csv</code> <code>str</code> <p>Path to the sensitivity summary CSV file output by Tricys</p> \u5fc5\u9700 <code>param_bounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Dictionary of parameter bounds, inferred from the CSV file if None</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to analyze</p> <code>None</code> <code>methods</code> <code>List[str]</code> <p>List of sensitivity analysis methods to execute</p> <code>['sobol', 'morris', 'fast']</code> <code>save_dir</code> <code>str</code> <p>Directory to save the results</p> <code>None</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>Dictionary containing all analysis results</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def run_salib_analysis_from_tricys_results(\n    self,\n    sensitivity_summary_csv: str,\n    param_bounds: Dict[str, Tuple[float, float]] = None,\n    output_metrics: List[str] = None,\n    methods: List[str] = [\"sobol\", \"morris\", \"fast\"],\n    save_dir: str = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys\n\n    Args:\n        sensitivity_summary_csv: Path to the sensitivity summary CSV file output by Tricys\n        param_bounds: Dictionary of parameter bounds, inferred from the CSV file if None\n        output_metrics: List of output metrics to analyze\n        methods: List of sensitivity analysis methods to execute\n        save_dir: Directory to save the results\n\n    Returns:\n        Dictionary containing all analysis results\n    \"\"\"\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    if save_dir is None:\n        save_dir = os.path.join(\n            os.path.dirname(sensitivity_summary_csv), \"salib_analysis\"\n        )\n    os.makedirs(save_dir, exist_ok=True)\n\n    df = pd.read_csv(sensitivity_summary_csv)\n\n    if param_bounds is None:\n        param_bounds = {}\n        param_candidates = []\n        for col in df.columns:\n            if col not in output_metrics and \".\" in col:\n                param_candidates.append(col)\n\n        for param in param_candidates:\n            param_data = df[param].dropna()\n            if len(param_data) &gt; 0:\n                param_bounds[param] = (param_data.min(), param_data.max())\n\n    if not param_bounds:\n        raise ValueError(\n            \"Unable to determine parameter boundaries, please provide the param_bounds parameter\"\n        )\n\n    self.define_problem(param_bounds)\n\n    self.load_tricys_results(sensitivity_summary_csv, output_metrics)\n\n    detected_method = self._last_sampling_method\n\n    methods = self.get_compatible_analysis_methods(detected_method)\n\n    all_results = {}\n\n    for metric_idx, metric_name in enumerate(output_metrics):\n        if metric_idx &gt;= self.simulation_results.shape[1]:\n            logger.warning(f\"The metric {metric_name} is out of range, skipping\")\n            continue\n\n        logger.info(f\"\\n=== Analysis indicators: {metric_name} ===\")\n        metric_results = {}\n\n        # Check data validity\n        Y = self.simulation_results[:, metric_idx]\n        valid_ratio = np.sum(~np.isnan(Y)) / len(Y)\n        logger.info(f\"Valid data ratio: {valid_ratio:.2%}\")\n\n        if valid_ratio &lt; 0.5:\n            logger.warning(\n                f\"The metric {metric_name} has less than 50% valid data, which may affect the analysis quality.\"\n            )\n\n        # Sobol analysis\n        if \"sobol\" in methods:\n            try:\n                logger.info(\"Performing Sobol sensitivity analysis...\")\n                sobol_result = self.analyze_sobol(output_index=metric_idx)\n                metric_results[\"sobol\"] = sobol_result\n\n                # Display Sobol results summary\n                logger.info(\"\\nSobol sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = sobol_result[\"S1\"][i]\n                    st = sobol_result[\"ST\"][i]\n                    logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"Sobol analysis failed: {e}\")\n\n        # Morris analysis\n        if \"morris\" in methods:\n            try:\n                logger.info(\"Performing Morris sensitivity analysis...\")\n                morris_result = self.analyze_morris(output_index=metric_idx)\n                metric_results[\"morris\"] = morris_result\n\n                # Display Morris results summary\n                logger.info(\"\\nMorris sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    mu_star = morris_result[\"mu_star\"][i]\n                    sigma = morris_result[\"sigma\"][i]\n                    logger.info(f\"  {param_name}: \u03bc*={mu_star:.4f}, \u03c3={sigma:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"Morris analysis failed: {e}\")\n\n        # FAST analysis\n        if \"fast\" in methods:\n            try:\n                logger.info(\"Performing FAST sensitivity analysis...\")\n                fast_result = self.analyze_fast(output_index=metric_idx)\n                metric_results[\"fast\"] = fast_result\n\n                # Display FAST results summary\n                logger.info(\"\\nFAST sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = fast_result[\"S1\"][i]\n                    st = fast_result[\"ST\"][i]\n                    logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"FAST analysis failed: {e}\")\n\n        # LHS analysis\n        if \"latin\" in methods:\n            try:\n                logger.info(\"Performing LHS uncertainty analysis...\")\n                lhs_result = self.analyze_lhs(output_index=metric_idx)\n                metric_results[\"latin\"] = lhs_result\n\n                # Display LHS results summary\n                logger.info(\"\\nLHS\u5206\u6790\u7ed3\u679c:\")\n                logger.info(f\"  \u5747\u503c: {lhs_result['mean']:.4f}\")\n                logger.info(f\"  \u6807\u51c6\u5dee: {lhs_result['std']:.4f}\")\n                logger.info(f\"  \u6700\u5c0f\u503c: {lhs_result['min']:.4f}\")\n                logger.info(f\"  \u6700\u5927\u503c: {lhs_result['max']:.4f}\")\n                logger.info(f\"  5%\u5206\u4f4d\u6570: {lhs_result['percentile_5']:.4f}\")\n                logger.info(f\"  95%\u5206\u4f4d\u6570: {lhs_result['percentile_95']:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"LHS\u5206\u6790\u5931\u8d25: {e}\")\n\n        all_results[metric_name] = metric_results\n\n    try:\n        if \"sobol\" in methods and \"sobol\" in self.sensitivity_results:\n            self.plot_sobol_results(save_dir=save_dir, metric_names=output_metrics)\n\n        if \"morris\" in methods and \"morris\" in self.sensitivity_results:\n            self.plot_morris_results(save_dir=save_dir, metric_names=output_metrics)\n\n        if \"fast\" in methods and \"fast\" in self.sensitivity_results:\n            self.plot_fast_results(save_dir=save_dir, metric_names=output_metrics)\n\n        # Plot LHS results\n        if \"latin\" in methods and \"latin\" in self.sensitivity_results:\n            self.plot_lhs_results(save_dir=save_dir, metric_names=output_metrics)\n\n    except Exception as e:\n        logger.warning(f\"Drawing failed: {e}\")\n\n    try:\n        self.save_results(\n            save_dir=save_dir, format=\"csv\", metric_names=output_metrics\n        )\n\n        report_content = self._save_sensitivity_report(all_results, save_dir)\n        report_path = os.path.join(save_dir, \"analysis_report.md\")\n\n        load_dotenv()\n\n        # --- LLM Calls for analysis ---\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n        ai_model = os.environ.get(\"AI_MODEL\")\n\n        sa_config = self.base_config.get(\"sensitivity_analysis\", {})\n        case_config = sa_config.get(\"analysis_case\", {})\n        ai_config = case_config.get(\"ai\")\n\n        ai_enabled = False\n        if isinstance(ai_config, bool):\n            ai_enabled = ai_config\n        elif isinstance(ai_config, dict):\n            ai_enabled = ai_config.get(\"enabled\", False)\n\n        if api_key and base_url and ai_model and ai_enabled:\n            # First LLM call for initial analysis\n            wrapper_prompt, llm_summary = call_llm_for_salib_analysis(\n                report_content=report_content,\n                api_key=api_key,\n                base_url=base_url,\n                ai_model=ai_model,\n                method=detected_method,\n            )\n            if wrapper_prompt and llm_summary:\n                with open(report_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd\\n\\n\")\n                    f.write(\"```markdown\\n\")\n                    f.write(wrapper_prompt)\n                    f.write(\"\\n```\\n\\n\")\n                    f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\")\n                    f.write(llm_summary)\n                logger.info(f\"Appended LLM prompt and summary to {report_path}\")\n\n                # Second LLM call for academic report\n                glossary_path = None\n                if isinstance(case_config, dict):\n                    glossary_path = sa_config.get(\"glossary_path\")\n\n                if glossary_path and os.path.exists(glossary_path):\n                    try:\n                        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n                            glossary_content = f.read()\n\n                        (\n                            academic_wrapper_prompt,\n                            academic_report,\n                        ) = call_llm_for_academic_report(\n                            analysis_report=llm_summary,\n                            glossary_content=glossary_content,\n                            api_key=api_key,\n                            base_url=base_url,\n                            ai_model=ai_model,\n                            problem_details=self.problem,\n                            metric_names=output_metrics,\n                            method=detected_method,\n                            save_dir=save_dir,\n                        )\n\n                        if academic_wrapper_prompt and academic_report:\n                            academic_report_path = os.path.join(\n                                save_dir, \"academic_report.md\"\n                            )\n                            with open(\n                                academic_report_path, \"w\", encoding=\"utf-8\"\n                            ) as f:\n                                f.write(academic_report)\n                            logger.info(\n                                f\"Generated academic report: {academic_report_path}\"\n                            )\n                    except Exception as e:\n                        logger.error(\n                            f\"Failed to generate or save academic report: {e}\"\n                        )\n                elif glossary_path:\n                    logger.warning(\n                        f\"Glossary file not found at {glossary_path}, skipping academic report generation.\"\n                    )\n\n        else:\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not set, or AI analysis is disabled. Skipping LLM summary generation.\"\n            )\n\n    except Exception as e:\n        logger.warning(f\"Failed to save result: {e}\")\n\n    logger.info(\"\\n\u2705 SALib sensitivity analysis completed!\")\n    logger.info(f\"\ud83d\udcc1 The result has been saved to: {save_dir}\")\n\n    return all_results\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.run_tricys_analysis","title":"<code>run_tricys_analysis(csv_file_path=None, output_metrics=None)</code>","text":"<p>Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>csv_file_path</code> <code>str</code> <p>Path to the CSV parameter file. If None, the last generated file will be used</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be calculated</p> <code>None</code> <code>config_output_path</code> <p>Path for the configuration file output. If None, it will be automatically generated</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>str</code> <p>Path to the sensitivity_analysis_summary.csv file</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def run_tricys_analysis(\n    self, csv_file_path: str = None, output_metrics: List[str] = None\n) -&gt; str:\n    \"\"\"\n    Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results\n\n    Args:\n        csv_file_path: Path to the CSV parameter file. If None, the last generated file will be used\n        output_metrics: List of output metrics to be calculated\n        config_output_path: Path for the configuration file output. If None, it will be automatically generated\n\n    Returns:\n        Path to the sensitivity_analysis_summary.csv file\n    \"\"\"\n    # Generate Tricys configuration file\n    tricys_config = self.generate_tricys_config(\n        csv_file_path=csv_file_path, output_metrics=output_metrics\n    )\n\n    logger.info(\"Starting Tricys simulation analysis...\")\n\n    try:\n        # Call the Tricys simulation engine\n        from datetime import datetime\n\n        from tricys.simulation.simulation_analysis import run_simulation\n\n        tricys_config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        run_simulation(tricys_config)\n\n        results_dir = tricys_config[\"paths\"][\"results_dir\"]\n\n        return Path(results_dir) / \"sensitivity_analysis_summary.csv\"\n\n    except Exception as e:\n        logger.error(f\"Tricys simulation execution failed: {e}\")\n        raise\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.run_tricys_simulations","title":"<code>run_tricys_simulations(output_metrics=None)</code>","text":"<p>Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be extracted (for recording but does not affect CSV generation)</p> <code>None</code> <code>max_workers</code> <p>Number of concurrent worker processes (reserved for compatibility, currently unused)</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>str</code> <p>Path to the generated CSV file</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def run_tricys_simulations(self, output_metrics: List[str] = None) -&gt; str:\n    \"\"\"\n    Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.\n\n    Args:\n        output_metrics: List of output metrics to be extracted (for recording but does not affect CSV generation)\n        max_workers: Number of concurrent worker processes (reserved for compatibility, currently unused)\n\n    Returns:\n        Path to the generated CSV file\n    \"\"\"\n    if self.parameter_samples is None:\n        raise ValueError(\n            \"You must first call generate_samples() to generate samples.\"\n        )\n\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    logger.info(\"Target output metrics\", extra={\"output_metrics\": output_metrics})\n\n    sampled_param_names = self.problem[\"names\"]\n\n    base_params = self.base_config.get(\"simulation_parameters\", {}).copy()\n    csv_output_path = (\n        Path(self.base_config.get(\"paths\", {}).get(\"temp_dir\"))\n        / \"salib_sampling.csv\"\n    )\n\n    os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n\n    param_data = []\n    for i, sample in enumerate(self.parameter_samples):\n        sampled_params = {\n            sampled_param_names[j]: sample[j]\n            for j in range(len(sampled_param_names))\n        }\n\n        job_params = base_params.copy()\n        job_params.update(sampled_params)\n\n        param_data.append(job_params)\n\n    df = pd.DataFrame(param_data)\n\n    for col in df.columns:\n        if df[col].dtype in [\"float64\", \"float32\"]:\n            df[col] = df[col].round(5)\n\n    df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n\n    logger.info(\n        \"Successfully generated parameter samples\",\n        extra={\"num_samples\": len(param_data)},\n    )\n    logger.info(\"Parameter file saved\", extra={\"file_path\": csv_output_path})\n    logger.info(\"Parameter file columns\", extra={\"columns\": list(df.columns)})\n    logger.info(\"Parameter precision set to 5 decimal places\")\n    logger.info(\"Sample statistics\", extra={\"statistics\": df.describe().to_dict()})\n\n    self.sampling_csv_path = csv_output_path\n\n    return csv_output_path\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.save_results","title":"<code>save_results(save_dir=None, format='csv', metric_names=None)</code>","text":"<p>Save sensitivity analysis results</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>save_dir</code> <code>str</code> <p>Save directory</p> <code>None</code> <code>format</code> <code>str</code> <p>Save format ('csv</p> <code>'csv'</code> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def save_results(\n    self, save_dir: str = None, format: str = \"csv\", metric_names: List[str] = None\n) -&gt; None:\n    \"\"\"\n    Save sensitivity analysis results\n\n    Args:\n        save_dir: Save directory\n        format: Save format ('csv\n    \"\"\"\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    for method, method_results in self.sensitivity_results.items():\n        if not method_results:\n            continue\n\n        for metric_key, results in method_results.items():\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            if format == \"csv\":\n                if method == \"sobol\":\n                    sobol_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"S1\": results[\"S1\"],\n                            \"ST\": results[\"ST\"],\n                            \"S1_conf\": results[\"S1_conf\"],\n                            \"ST_conf\": results[\"ST_conf\"],\n                        }\n                    )\n                    filename = (\n                        f'sobol_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    sobol_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"Sobol results have been saved: {filename}\")\n\n                elif method == \"morris\":\n                    morris_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"mu\": results[\"mu\"],\n                            \"mu_star\": results[\"mu_star\"],\n                            \"sigma\": results[\"sigma\"],\n                            \"mu_star_conf\": results[\"mu_star_conf\"],\n                        }\n                    )\n                    filename = f'morris_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    morris_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"Morris results have been saved: {filename}\")\n\n                elif method == \"fast\":\n                    fast_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"S1\": results[\"S1\"],\n                            \"ST\": results[\"ST\"],\n                        }\n                    )\n                    filename = (\n                        f'fast_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    fast_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"FAST results have been saved: {filename}\")\n\n                elif method == \"latin\":\n                    # Save LHS statistics\n                    lhs_stats_df = pd.DataFrame(\n                        {\n                            \"Metric\": [metric_display_name],\n                            \"Mean\": [results[\"mean\"]],\n                            \"Std\": [results[\"std\"]],\n                            \"Min\": [results[\"min\"]],\n                            \"Max\": [results[\"max\"]],\n                            \"Percentile_5\": [results[\"percentile_5\"]],\n                            \"Percentile_95\": [results[\"percentile_95\"]],\n                        }\n                    )\n                    filename_stats = (\n                        f'lhs_stats_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    lhs_stats_df.to_csv(\n                        os.path.join(save_dir, filename_stats), index=False\n                    )\n                    logger.info(f\"LHS\u7edf\u8ba1\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_stats}\")\n\n                    # Remove LHS sensitivity indices saving\n                    # lhs_sens_df = pd.DataFrame({\n                    #     \"Parameter\": self.problem[\"names\"],\n                    #     \"Partial_Correlation\": results[\"partial_correlations\"]\n                    # })\n                    # filename_sens = f'lhs_sensitivity_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    # lhs_sens_df.to_csv(os.path.join(save_dir, filename_sens), index=False)\n                    # logger.info(f\"LHS\u654f\u611f\u6027\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_sens}\")\n\n    logger.info(f\"The result has been saved to: {save_dir}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.call_llm_for_academic_report","title":"<code>call_llm_for_academic_report(analysis_report, glossary_content, api_key, base_url, ai_model, problem_details, metric_names, method, save_dir)</code>","text":"<p>Sends an analysis report and a glossary to an LLM to generate a professional academic report.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def call_llm_for_academic_report(\n    analysis_report: str,\n    glossary_content: str,\n    api_key: str,\n    base_url: str,\n    ai_model: str,\n    problem_details: dict,\n    metric_names: list,\n    method: str,\n    save_dir: str,\n) -&gt; Tuple[str, str]:\n    \"\"\"Sends an analysis report and a glossary to an LLM to generate a professional academic report.\"\"\"\n    try:\n        logger.info(\"Proceeding with LLM for academic report generation.\")\n\n        param_names_str = \", \".join(\n            [f\"`{name}`\" for name in problem_details.get(\"names\", [])]\n        )\n        metric_names_str = \", \".join([f\"`{name}`\" for name in metric_names])\n\n        all_plots = [f for f in os.listdir(save_dir) if f.endswith((\".svg\", \".png\"))]\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n\n        method_details = {\n            \"sobol\": {\n                \"name\": \"Sobol\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**Sobol\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u6280\u672f\uff0c\u80fd\u591f\u91cf\u5316\u5355\u4e2a\u53c2\u6570\u4ee5\u53ca\u53c2\u6570\u95f4\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u548c\u603b\u4f53\u654f\u611f\u6027\uff08ST\uff09\u6700\u9ad8\uff1f\u8bf7\u7ed3\u5408\u56fe\u8868\uff08\u5982\u6761\u5f62\u56fe\uff09\u8fdb\u884c\u89e3\u8bfb\u3002\n        *   S1\u548cST\u6307\u6570\u4e4b\u95f4\u7684\u5dee\u5f02\u63ed\u793a\u4e86\u4ec0\u4e48\uff1f\uff08\u4f8b\u5982\uff0cST\u663e\u8457\u5927\u4e8eS1\u610f\u5473\u7740\u8be5\u53c2\u6570\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u663e\u8457\u7684\u4ea4\u4e92\u4f5c\u7528\u6216\u5176\u5f71\u54cd\u662f\u975e\u7ebf\u6027\u7684\uff09\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n            \"morris\": {\n                \"name\": \"Morris\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**Morris\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8f68\u8ff9\u7684\u201c\u4e00\u6b21\u6027\u201d\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e38\u7528\u4e8e\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53c2\u6570\u7b5b\u9009\uff0c\u4ee5\u8bc6\u522b\u51fa\u5f71\u54cd\u6700\u5927\u7684\u5c11\u6570\u51e0\u4e2a\u53c2\u6570\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u53c2\u6570\u7684 `\u03bc*` (mu_star) \u503c\u6700\u9ad8\uff0c\u8868\u660e\u5176\u5bf9\u8f93\u51fa\u7684\u603b\u4f53\u5f71\u54cd\u6700\u91cd\u8981\uff1f\n        *   `\u03c3` (sigma) \u503c\u7684\u5927\u5c0f\u53c8\u8bf4\u660e\u4e86\u4ec0\u4e48\uff1f\u8f83\u9ad8\u7684 `\u03c3` \u503c\u901a\u5e38\u8868\u660e\u53c2\u6570\u5177\u6709\u975e\u7ebf\u6027\u6548\u5e94\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\n        *   \u8bf7\u7ed3\u5408 `\u03bc*-\u03c3` \u56fe\u8fdb\u884c\u5206\u6790\uff0c\u5bf9\u53c2\u6570\u8fdb\u884c\u5206\u7c7b\uff08\u4f8b\u5982\uff0c\u9ad8 `\u03bc*`/\u9ad8 `\u03c3` vs. \u9ad8 `\u03bc*`/\u4f4e `\u03c3`\uff09\uff0c\u5e76\u89e3\u91ca\u5176\u542b\u4e49\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n            \"fast\": {\n                \"name\": \"FAST\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**FAST\uff08\u5085\u91cc\u53f6\u5e45\u5ea6\u654f\u611f\u6027\u68c0\u9a8c\uff09\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u6280\u672f\uff0c\u901a\u8fc7\u5c06\u53c2\u6570\u5728\u5085\u91cc\u53f6\u7ea7\u6570\u4e2d\u5c55\u5f00\u6765\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u6700\u9ad8\uff1f\n        *   \uff08\u5982\u679c\u53ef\u7528\uff09\u603b\u4f53\u654f\u611f\u6027\uff08ST\uff09\u4e0e\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u7684\u6bd4\u8f83\u63ed\u793a\u4e86\u4ec0\u4e48\uff1f\u8f83\u5927\u7684\u5dee\u5f02\u901a\u5e38\u8868\u660e\u5b58\u5728\u53c2\u6570\u4ea4\u4e92\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n        }\n\n        if method == \"latin\":\n            ACADEMIC_REPORT_PROMPT_WRAPPER = f\"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\uff0c\u64c5\u957f\u8fdb\u884c**\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (UQ)** \u548c\u98ce\u9669\u8bc4\u4f30\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u57fa\u4e8e**\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837 (LHS)** \u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\n**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u4e13\u4e1a\u8bcd\u6c47\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\uff0c\u805a\u7126\u4e8e**\u4e0d\u786e\u5b9a\u6027**\u7684\u91cf\u5316\u548c\u89e3\u8bfb\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u7edf\u8ba1\u6458\u8981\u3001\u5206\u5e03\u6570\u636e\u7b49\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u4e0d\u786e\u5b9a\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u4e0d\u786e\u5b9a\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u51fa\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u662f {param_names_str}\uff0c\u603b\u7ed3\u8fd9\u4e9b\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u5173\u952e\u6027\u80fd\u6307\u6807 ({metric_names_str}) \u7684\u8f93\u51fa\u5206\u5e03\uff08\u5982\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u7f6e\u4fe1\u533a\u95f4\uff09\u6709\u4f55\u5f71\u54cd\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30\u5f53\u8f93\u5165\u53c2\u6570 {param_names_str} \u5728\u5176\u5b9a\u4e49\u57df\u5185\u53d8\u5316\u65f6\uff0c\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u5173\u952e\u6027\u80fd\u6307\u6807\u7684\u7edf\u8ba1\u5206\u5e03\u548c\u7a33\u5b9a\u6027\u3002\n    *   **\u65b9\u6cd5 (Methodology):** \u7b80\u8981\u8bf4\u660e\u5206\u6790\u65b9\u6cd5\u3002\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\uff08LHS\uff09\u65b9\u6cd5\u6765\u5bf9\u8f93\u5165\u53c2\u6570\u7a7a\u95f4\u8fdb\u884c\u62bd\u6837\u3002\u8bf4\u660e\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u662f {metric_names_str}\uff0c\u4ee5\u53ca\u8f93\u5165\u53c2\u6570\u7684\u6982\u7387\u5206\u5e03\u548c\u8303\u56f4\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u7edf\u8ba1\u6570\u636e\u548c\u60a8\u5d4c\u5165\u7684\u56fe\u8868\uff08\u5982\u76f4\u65b9\u56fe\u3001\u7d2f\u79ef\u5206\u5e03\u56fe\uff09\uff0c\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n        *   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5176\u8f93\u51fa\u7684**\u6982\u7387\u5206\u5e03**\u662f\u600e\u6837\u7684\uff1f\uff08\u4f8b\u5982\uff0c\u662f\u6b63\u6001\u5206\u5e03\u3001\u504f\u6001\u5206\u5e03\u8fd8\u662f\u53cc\u5cf0\u5206\u5e03\uff1f\uff09\n        *   \u8f93\u51fa\u6307\u6807\u7684**\u4e0d\u786e\u5b9a\u6027\u8303\u56f4**\u6709\u591a\u5927\uff1f\uff08\u53c2\u8003\u6807\u51c6\u5dee\u548c5%-95%\u767e\u5206\u4f4d\u6570\u533a\u95f4\uff09\u3002\u8fd9\u4e2a\u8303\u56f4\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u662f\u5426\u53ef\u4ee5\u63a5\u53d7\uff1f\n        *   \u662f\u5426\u5b58\u5728\u67d0\u4e9b\u6307\u6807\u7684\u6ce2\u52a8\u8303\u56f4\u8fc7\u5927\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u6027\u80fd\u4f4e\u4e8e\u8bbe\u8ba1\u8981\u6c42\u6216\u5b58\u5728\u8fd0\u884c\u98ce\u9669\uff1f\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff08\u4f8b\u5982\uff0c\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u3001\u8f93\u51fa\u6307\u6807\u7684\u53ef\u9760\u6027\u7b49\uff09\uff0c\u5e76\u5bf9\u964d\u4f4e\u5173\u952e\u6307\u6807\u4e0d\u786e\u5b9a\u6027\u6216\u672a\u6765\u7684\u98ce\u9669\u8bc4\u4f30\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n        else:\n            selected_method = method_details.get(method)\n            if not selected_method:\n                # Fallback for unknown methods\n                selected_method = {\n                    \"name\": method.capitalize(),\n                    \"methodology\": f\"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u63d0\u53ca\u5177\u4f53\u7684\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\u4e3a**{method.capitalize()}**\u3002\",\n                    \"results_discussion\": \"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u8bc6\u522b\u51fa\u6700\u91cd\u8981\u7684\u8f93\u5165\u53c2\u6570\u3002\\n*   \u8ba8\u8bba\u8fd9\u4e9b\u53d1\u73b0\u7684\u610f\u4e49\u3002\",\n                }\n\n            ACADEMIC_REPORT_PROMPT_WRAPPER = f\"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e**SALib {selected_method['name']} \u65b9\u6cd5\u654f\u611f\u6027\u5206\u6790**\u7684\u7a0b\u5e8f\u751f\u6210\u7684\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\n**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u654f\u611f\u6027\u6307\u6570\u8868\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u654f\u611f\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u654f\u611f\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u660e\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u662f {param_names_str}\uff0c\u603b\u7ed3\u54ea\u4e9b\u53c2\u6570\u5bf9\u5173\u952e\u6027\u80fd\u6307\u6807 ({metric_names_str}) \u5f71\u54cd\u6700\u663e\u8457\uff0c\u5e76\u9648\u8ff0\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u654f\u611f\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30\u8f93\u5165\u53c2\u6570\u7684\u53d8\u5316\u5bf9\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\n    *   **\u65b9\u6cd5 (Methodology):** {selected_method['methodology']} \u8bf4\u660e\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u662f {metric_names_str}\uff0c\u4ee5\u53ca\u8f93\u5165\u53c2\u6570 {param_names_str} \u7684\u53d8\u5316\u8303\u56f4\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u548c\u60a8\u5d4c\u5165\u7684\u56fe\u8868\uff0c\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n{selected_method['results_discussion']}\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u654f\u611f\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff0c\u5e76\u5bf9\u53cd\u5e94\u5806\u8bbe\u8ba1\u6216\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        full_prompt = f\"{ACADEMIC_REPORT_PROMPT_WRAPPER}\\n\\n---\\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a\\n---\\n{analysis_report}\\n\\n---\\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868\\n---\\n{glossary_content}\"\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending data for academic report to LLM (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_prompt}],\n                    max_tokens=4000,\n                )\n                academic_report = response.choices[0].message.content\n\n                logger.info(\"LLM academic report generation successful.\")\n                return ACADEMIC_REPORT_PROMPT_WRAPPER, academic_report\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling LLM for academic report on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to get LLM academic report after {max_retries} attempts.\"\n                    )\n                    return None, None\n\n    except Exception as e:\n        logger.error(f\"Error in call_llm_for_academic_report: {e}\", exc_info=True)\n        return None, None\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.call_llm_for_salib_analysis","title":"<code>call_llm_for_salib_analysis(report_content, api_key, base_url, ai_model, method)</code>","text":"<p>Sends a SALib analysis report to an LLM for summarization and returns the prompt and summary.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def call_llm_for_salib_analysis(\n    report_content: str, api_key: str, base_url: str, ai_model: str, method: str\n) -&gt; Tuple[str, str]:\n    \"\"\"Sends a SALib analysis report to an LLM for summarization and returns the prompt and summary.\"\"\"\n    try:\n        logger.info(\"Proceeding with LLM analysis for SALib report.\")\n\n        PROMPT_TEMPLATES = {\n            \"sobol\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**Sobol\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684**\u4e00\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1\uff09**\u548c**\u603b\u654f\u611f\u6027\u6307\u6570\uff08ST\uff09**\u6700\u9ad8\u3002\n3.  **\u89e3\u8bfb\u6307\u6570\u542b\u4e49**\uff1a\u89e3\u91caS1\u548cST\u6307\u6570\u7684\u542b\u4e49\u3002\u4f8b\u5982\uff0c\u9ad8S1\u503c\u8868\u793a\u53c2\u6570\u5bf9\u8f93\u51fa\u6709\u91cd\u8981\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u800cST\u4e0eS1\u7684\u663e\u8457\u5dee\u5f02\u8868\u793a\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u4ea4\u4e92\u4f5c\u7528\u6216\u975e\u7ebf\u6027\u6548\u5e94\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"morris\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**Morris\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u6839\u636e**\u03bc* (mu_star)**\u503c\u5bf9\u53c2\u6570\u8fdb\u884c\u6392\u5e8f\uff0c\u8bc6\u522b\u51fa\u5bf9\u6a21\u578b\u8f93\u51fa\u5f71\u54cd\u6700\u5927\u7684\u53c2\u6570\u3002\n3.  **\u89e3\u8bfb\u53c2\u6570\u6548\u5e94**\uff1a\u89e3\u91ca**\u03bc***\u548c**\u03c3 (sigma)**\u7684\u542b\u4e49\u3002\u9ad8\u03bc*\u8868\u793a\u53c2\u6570\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9ad8\u03c3\u8868\u793a\u53c2\u6570\u5b58\u5728\u975e\u7ebf\u6027\u5f71\u54cd\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u6709\u4ea4\u4e92\u4f5c\u7528\u3002\u7ed3\u5408\u03bc*-\u03c3\u56fe\u8fdb\u884c\u5206\u6790\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"fast\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**FAST\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684**\u4e00\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1\uff09**\u548c**\u603b\u654f\u611f\u6027\u6307\u6570\uff08ST\uff09**\u6700\u9ad8\u3002\n3.  **\u89e3\u8bfb\u6307\u6570\u542b\u4e49**\uff1a\u89e3\u91caS1\u548cST\u6307\u6570\u7684\u542b\u4e49\u3002\u9ad8S1\u503c\u8868\u793a\u53c2\u6570\u5bf9\u8f93\u51fa\u6709\u91cd\u8981\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u800cST\u4e0eS1\u7684\u5dee\u5f02\u8868\u793a\u53c2\u6570\u53ef\u80fd\u5b58\u5728\u4ea4\u4e92\u4f5c\u7528\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"latin\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u7edf\u8ba1\u5b66\u548c\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\uff08LHS\uff09\u751f\u6210\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u89e3\u8bfb\u7edf\u8ba1\u6570\u636e**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u89e3\u8bfb\u5176\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5927/\u6700\u5c0f\u503c\u548c\u767e\u5206\u4f4d\u6570\u3002\n2.  **\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027**\uff1a\u57fa\u4e8e\u6807\u51c6\u5dee\u548c5%/95%\u767e\u5206\u4f4d\u6570\u7684\u8303\u56f4\uff0c\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u6ce2\u52a8\u8303\u56f4\u6709\u591a\u5927\u3002\n3.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u603b\u7ed3\u5728\u7ed9\u5b9a\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4e0b\uff0c\u6a21\u578b\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPIs\uff09\u8868\u73b0\u5982\u4f55\uff0c\u662f\u5426\u5b58\u5728\u8f83\u5927\u7684\u98ce\u9669\uff08\u4f8b\u5982\uff0c\u8f93\u51fa\u503c\u6ce2\u52a8\u8303\u56f4\u8fc7\u5927\uff09\uff0c\u5e76\u5bf9\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u7ed9\u51fa\u8bc4\u4ef7\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u805a\u7126\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\u548c\u89e3\u8bfb\uff0c\u800c\u4e0d\u662f\u53c2\u6570\u7684\u654f\u611f\u6027\u6392\u5e8f\u3002\n\"\"\",\n        }\n\n        wrapper_prompt = PROMPT_TEMPLATES.get(\n            method,\n            \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684\u654f\u611f\u6027\u5206\u6790\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u7b80\u660e\u627c\u8981\u5730\u603b\u7ed3\u62a5\u544a\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u3001\u201c\u500d\u589e\u65f6\u95f4\u201d\u7b49\uff09\uff0c\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u5bf9\u5b83\u7684\u5f71\u54cd\u6700\u5927\uff08\u5373\u6700\u654f\u611f\uff09\u3002\n3.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff08\u5982\u679c\u53ef\u80fd\uff09\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n        )\n\n        full_prompt = f\"{wrapper_prompt}\\n\\n---\\n**\u5206\u6790\u62a5\u544a\u539f\u6587\uff1a**\\n\\n{report_content}\"\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending SALib report to LLM (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_prompt}],\n                    max_tokens=4000,\n                )\n                llm_summary = response.choices[0].message.content\n\n                logger.info(\"LLM analysis successful for SALib report.\")\n                return wrapper_prompt, llm_summary  # Return wrapper prompt and summary\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling LLM for SALib report on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to get LLM summary for SALib report after {max_retries} attempts.\"\n                    )\n                    return None, None  # Return None on failure\n\n    except Exception as e:\n        logger.error(f\"Error in call_llm_for_salib_analysis: {e}\", exc_info=True)\n        return None, None\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.run_salib_analysis","title":"<code>run_salib_analysis(config)</code>","text":"<p>Orchestrates the SALib sensitivity analysis workflow.</p> <p>This function extracts the necessary configuration, defines the problem space for SALib, and then runs the analysis.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary.</p> \u5fc5\u9700 \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/analysis/salib.py</code> <pre><code>def run_salib_analysis(config: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Orchestrates the SALib sensitivity analysis workflow.\n\n    This function extracts the necessary configuration, defines the problem\n    space for SALib, and then runs the analysis.\n\n    Args:\n        config: The main configuration dictionary.\n    \"\"\"\n    # 1. Extract sensitivity analysis configuration\n    sa_config = config.get(\"sensitivity_analysis\")\n    if not sa_config or not sa_config.get(\"enabled\"):\n        logger.info(\"Sensitivity analysis is not enabled in the configuration file.\")\n        return\n\n    # 2. Create analyzer\n    analyzer = TricysSALibAnalyzer(config)\n\n    # 3. Define the problem space from configuration\n    analysis_case = sa_config.get(\"analysis_case\", {})\n    param_names = analysis_case.get(\"independent_variable\")\n    sampling_details = analysis_case.get(\"independent_variable_sampling\")\n\n    if not isinstance(param_names, list):\n        raise ValueError(\"'independent_variable' must be a list of parameter names.\")\n    if not isinstance(sampling_details, dict):\n        raise ValueError(\n            \"'independent_variable_sampling' must be an object with parameter details.\"\n        )\n\n    param_bounds = {\n        name: sampling_details[name][\"bounds\"]\n        for name in param_names\n        if name in sampling_details\n    }\n    param_dists = {\n        name: sampling_details[name].get(\"distribution\", \"unif\")\n        for name in param_names\n        if name in sampling_details\n    }\n\n    if len(param_bounds) != len(param_names):\n        raise ValueError(\n            \"The keys of 'independent_variable' and 'independent_variable_sampling' do not match\"\n        )\n\n    problem = analyzer.define_problem(param_bounds, param_dists)\n    logger.info(\n        f\"\\n\ud83d\udd0d The problem space with {problem['num_vars']} parameters was defined from the configuration file\"\n    )\n\n    # 4. Generate samples from configuration\n    analyzer_config = analysis_case.get(\"analyzer\", {})\n    enabled_method_name = analyzer_config.get(\"method\")\n    if not enabled_method_name:\n        raise ValueError(\n            \"No method found in 'sensitivity_analysis.analysis_case.analyzer'\"\n        )\n\n    N = analyzer_config.get(\"sample_N\", 1024)\n\n    sample_kwargs = {}\n\n    samples = analyzer.generate_samples(\n        method=enabled_method_name, N=N, **sample_kwargs\n    )\n    logger.info(f\"\u2713 Generated {len(samples)} parameter samples\")\n\n    # 5. Run Tricys simulation\n    output_metrics = analysis_case.get(\"dependent_variables\", [])\n\n    csv_file_path = analyzer.run_tricys_simulations(output_metrics=output_metrics)\n    logger.info(f\"\u2713 Parameter file has been generated: {csv_file_path}\")\n\n    summary_file = None\n    try:\n        logger.info(\"\\nAttempting to run Tricys analysis directly...\")\n        summary_file = analyzer.run_tricys_analysis(\n            csv_file_path=csv_file_path, output_metrics=output_metrics\n        )\n        if summary_file:\n            logger.info(f\"\u2713 Tricys analysis completed, result file: {summary_file}\")\n        else:\n            logger.info(\"\u26a0\ufe0f  Tricys analysis result file not found\")\n            return\n    except Exception as e:\n        logger.info(f\"\u26a0\ufe0f  Tricys analysis failed: {e}\")\n        logger.info(\"Please check if the model path and configuration are correct\")\n        return\n\n    # 6. Run SALib analysis from Tricys results\n    try:\n        logger.info(\"\\nRunning SALib analysis from Tricys results...\")\n        all_results = analyzer.run_salib_analysis_from_tricys_results(\n            sensitivity_summary_csv=summary_file,\n            param_bounds=param_bounds,\n            output_metrics=output_metrics,\n            methods=[enabled_method_name],\n            save_dir=os.path.dirname(summary_file),\n        )\n\n        logger.info(f\"\\n\u2705 SALib {enabled_method_name.upper()} analysis completed!\")\n        logger.info(\n            f\"\ud83d\udcc1 The results have been saved to: {os.path.join(os.path.dirname(summary_file), f'salib_analysis_{enabled_method_name}')}\"\n        )\n\n        logger.info(\"\\n\ud83d\udcc8 Brief results:\")\n        for metric_name, metric_results in all_results.items():\n            logger.info(f\"\\n--- {metric_name} ---\")\n            if enabled_method_name in metric_results:\n                result_data = metric_results[enabled_method_name]\n                if enabled_method_name == \"sobol\":\n                    logger.info(\"\ud83d\udd25 Most sensitive parameters (Sobol ST):\")\n                    st_values = list(zip(analyzer.problem[\"names\"], result_data[\"ST\"]))\n                    st_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, st in st_values[:3]:\n                        logger.info(f\"   {param}: {st:.4f}\")\n                elif enabled_method_name == \"morris\":\n                    logger.info(\"\ud83d\udcca Most Sensitive Parameter (Morris \u03bc*):\")\n                    mu_star_values = list(\n                        zip(analyzer.problem[\"names\"], result_data[\"mu_star\"])\n                    )\n                    mu_star_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, mu_star in mu_star_values[:3]:\n                        logger.info(f\"   {param}: {mu_star:.4f}\")\n                elif enabled_method_name == \"fast\":\n                    logger.info(\"\u26a1 Most Sensitive Parameter (Morris \u03bc*):\")\n                    st_values = list(zip(analyzer.problem[\"names\"], result_data[\"ST\"]))\n                    st_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, st in st_values[:3]:\n                        logger.info(f\"   {param}: {st:.4f}\")\n\n        return analyzer, all_results\n\n    except Exception as e:\n        logger.error(f\"SALib analysis failed: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"api/tricys_core.html","title":"API \u53c2\u8003 - \u6838\u5fc3\u6a21\u5757 (Core)","text":"<p>\u6838\u5fc3\u6a21\u5757 (Core)</p> <p>\u6838\u5fc3\u6a21\u5757 (Core) \u5305\u542b\u4e86 TRICYS \u7684\u6838\u5fc3\u529f\u80fd\uff0c\u5982\u4f5c\u4e1a\u7ba1\u7406\u3001Modelica \u4ea4\u4e92\u548c\u4e8b\u4ef6\u62e6\u622a\u5668\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Jobs (\u4f5c\u4e1a\u7ba1\u7406)Modelica (\u6a21\u578b\u4ea4\u4e92)Interceptor (\u62e6\u622a\u5668) <p>Utilities for interacting with OpenModelica via OMPython.</p> <p>This module provides a set of functions to manage an OpenModelica session, load models, retrieve parameter details, and format parameter values for simulation.</p>"},{"location":"api/tricys_core.html#tricys.core.jobs.generate_simulation_jobs","title":"<code>generate_simulation_jobs(simulation_params)</code>","text":"<p>Generates a list of simulation jobs from parameters, handling sweeps and array expansion.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>simulation_params</code> <code>Dict[str, Any]</code> <p>Dictionary of simulation parameters. Can include: - \"file\": Path to CSV file for batch job loading - Parameter names with values (single values, lists, or special format strings) - Array-like parameters in format \"{value1, value2, ...}\"</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[Dict[str, Any]]</code> <p>A list of job dictionaries. Each job contains one combination of parameter</p> <code>List[Dict[str, Any]]</code> <p>values for simulation. Single-value parameters are included in all jobs.</p> Note <p>If \"file\" parameter is present, jobs are loaded from CSV and other parameters are merged into each CSV job. For parameter sweeps, generates all combinations using Cartesian product. Array-like parameters are expanded using 1-based indexing before sweep generation. Returns empty dict list [{}] if no parameters provided.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/jobs.py</code> <pre><code>def generate_simulation_jobs(\n    simulation_params: Dict[str, Any],\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Generates a list of simulation jobs from parameters, handling sweeps and array expansion.\n\n    Args:\n        simulation_params: Dictionary of simulation parameters. Can include:\n            - \"file\": Path to CSV file for batch job loading\n            - Parameter names with values (single values, lists, or special format strings)\n            - Array-like parameters in format \"{value1, value2, ...}\"\n\n    Returns:\n        A list of job dictionaries. Each job contains one combination of parameter\n        values for simulation. Single-value parameters are included in all jobs.\n\n    Note:\n        If \"file\" parameter is present, jobs are loaded from CSV and other parameters\n        are merged into each CSV job. For parameter sweeps, generates all combinations\n        using Cartesian product. Array-like parameters are expanded using 1-based indexing\n        before sweep generation. Returns empty dict list [{}] if no parameters provided.\n    \"\"\"\n\n    logger.info(\n        \"Generating simulation jobs\",\n        extra={\n            \"simulation_parameters\": simulation_params,\n        },\n    )\n    if \"file\" in simulation_params:\n        file_value = simulation_params[\"file\"]\n        if isinstance(file_value, str):\n            csv_jobs = _load_jobs_from_csv(file_value)\n\n            other_params = {k: v for k, v in simulation_params.items() if k != \"file\"}\n            for job in csv_jobs:\n                job.update(other_params)\n\n            return csv_jobs\n\n    # First, expand any array-like parameters before processing.\n    processed_params = _expand_array_parameters(simulation_params)\n\n    sweep_params = {}\n    single_value_params = {}\n\n    for name, value in processed_params.items():\n        parsed_values = parse_parameter_value(value)\n        if len(parsed_values) &gt; 1:\n            sweep_params[name] = parsed_values\n        else:\n            single_value_params[name] = parsed_values[0] if parsed_values else None\n\n    if not sweep_params:\n        return [single_value_params] if single_value_params else [{}]\n\n    sweep_names = list(sweep_params.keys())\n    sweep_values = list(sweep_params.values())\n    jobs = []\n    for combo in itertools.product(*sweep_values):\n        job = single_value_params.copy()\n        job.update(dict(zip(sweep_names, combo)))\n        jobs.append(job)\n    return jobs\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.jobs.parse_parameter_value","title":"<code>parse_parameter_value(value)</code>","text":"<p>Parses a parameter value which can be a single value, a list, or a string with special formats.</p> Supported special string formats <ul> <li>\"start:stop:step\" -&gt; e.g., \"1:10:2\" for a linear range with step</li> <li>\"linspace:start:stop:num\" -&gt; e.g., \"linspace:0:10:5\" for 5 evenly spaced points</li> <li>\"log:start:stop:num\" -&gt; e.g., \"log:1:1000:4\" for 4 points on log scale</li> <li>\"rand:min:max:count\" -&gt; e.g., \"rand:0:1:10\" for 10 random uniform values</li> <li>\"file:path:column\" -&gt; e.g., \"file:data.csv:voltage\" to read a CSV column</li> <li>\"file:path\" -&gt; e.g., \"file:sampling.csv\" to read all parameters from CSV</li> </ul> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>value</code> <code>Any</code> <p>The parameter value to parse. Can be a single value, list, or special format string.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[Any]</code> <p>A list of parsed values. Single values and strings without colons return</p> <code>List[Any]</code> <p>a single-element list. Special format strings return expanded value lists.</p> Note <p>Numbers are rounded to 8 decimal places to avoid floating point precision issues. If parsing fails, returns the original value as a single-element list and logs an error. For \"file:\" format, Windows paths with drive letters (C:) are handled.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/jobs.py</code> <pre><code>def parse_parameter_value(value: Any) -&gt; List[Any]:\n    \"\"\"Parses a parameter value which can be a single value, a list, or a string with special formats.\n\n    Supported special string formats:\n        - \"start:stop:step\" -&gt; e.g., \"1:10:2\" for a linear range with step\n        - \"linspace:start:stop:num\" -&gt; e.g., \"linspace:0:10:5\" for 5 evenly spaced points\n        - \"log:start:stop:num\" -&gt; e.g., \"log:1:1000:4\" for 4 points on log scale\n        - \"rand:min:max:count\" -&gt; e.g., \"rand:0:1:10\" for 10 random uniform values\n        - \"file:path:column\" -&gt; e.g., \"file:data.csv:voltage\" to read a CSV column\n        - \"file:path\" -&gt; e.g., \"file:sampling.csv\" to read all parameters from CSV\n\n    Args:\n        value: The parameter value to parse. Can be a single value, list, or special\n            format string.\n\n    Returns:\n        A list of parsed values. Single values and strings without colons return\n        a single-element list. Special format strings return expanded value lists.\n\n    Note:\n        Numbers are rounded to 8 decimal places to avoid floating point precision issues.\n        If parsing fails, returns the original value as a single-element list and logs\n        an error. For \"file:\" format, Windows paths with drive letters (C:\\\\) are handled.\n    \"\"\"\n    if not isinstance(value, str):\n        return value if isinstance(value, list) else [value]\n\n    if \":\" not in value:\n        return [value]  # Just a plain string\n\n    try:\n        prefix, args_str = value.split(\":\", 1)\n        prefix = prefix.lower()\n\n        if prefix == \"linspace\":\n            start, stop, num = map(float, args_str.split(\":\"))\n            return np.linspace(start, stop, int(num)).round(8).tolist()\n\n        if prefix == \"log\":\n            start, stop, num = map(float, args_str.split(\":\"))\n            if start &lt;= 0 or stop &lt;= 0:\n                raise ValueError(\"Log scale start and stop values must be positive.\")\n            return (\n                np.logspace(np.log10(start), np.log10(stop), int(num)).round(8).tolist()\n            )\n\n        if prefix == \"rand\":\n            low, high, count = map(float, args_str.split(\":\"))\n            return np.random.uniform(low, high, int(count)).round(8).tolist()\n\n        if prefix == \"file\":\n            # Handle file paths that may contain colons (e.g., Windows C:\\...)\n            try:\n                # Check if there's a column name specified\n                if \":\" in args_str:\n                    file_path, column_name = args_str.rsplit(\":\", 1)\n                    if not os.path.isabs(file_path.strip()):\n                        abs_file_path = os.path.abspath(\n                            os.path.join(os.getcwd(), file_path.strip())\n                        )\n                    else:\n                        abs_file_path = file_path.strip()\n                    df = pd.read_csv(abs_file_path)\n                    return df[column_name.strip()].tolist()\n                else:\n                    # Return the file path for later processing\n                    return [args_str.strip()]\n            except (ValueError, FileNotFoundError, KeyError):\n                # Re-raise to be caught by the outer try-except block\n                raise\n\n        # Fallback to original start:stop:step logic if no prefix matches\n        start, stop, step = map(float, value.split(\":\"))\n        return np.arange(start, stop + step / 2, step).round(8).tolist()\n\n    except (ValueError, FileNotFoundError, KeyError, IndexError) as e:\n        logger.error(\n            \"Invalid format or error processing parameter value\",\n            extra={\n                \"value\": value,\n                \"error\": str(e),\n            },\n        )\n        return [value]  # On any error, treat as a single literal value\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.format_parameter_value","title":"<code>format_parameter_value(name, value)</code>","text":"<p>Formats a parameter value into a string recognized by OpenModelica.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>name</code> <code>str</code> <p>The name of the parameter.</p> \u5fc5\u9700 <code>value</code> <code>Any</code> <p>The value of the parameter (can be number, string, list, or bool).</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>str</code> <p>A formatted string for use in simulation overrides (e.g., \"p=1.0\",</p> <code>str</code> <p>\"name={1,2,3}\", or 'path=\"value\"').</p> Note <p>Lists are formatted as {v1,v2,...}. Strings are quoted with double quotes. Numbers and booleans use direct string conversion.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/modelica.py</code> <pre><code>def format_parameter_value(name: str, value: Any) -&gt; str:\n    \"\"\"Formats a parameter value into a string recognized by OpenModelica.\n\n    Args:\n        name: The name of the parameter.\n        value: The value of the parameter (can be number, string, list, or bool).\n\n    Returns:\n        A formatted string for use in simulation overrides (e.g., \"p=1.0\",\n        \"name={1,2,3}\", or 'path=\"value\"').\n\n    Note:\n        Lists are formatted as {v1,v2,...}. Strings are quoted with double quotes.\n        Numbers and booleans use direct string conversion.\n    \"\"\"\n    if isinstance(value, list):\n        # Format lists as {v1,v2,...}\n        return f\"{name}={{{','.join(map(str, value))}}}\"\n    elif isinstance(value, str):\n        # Format strings as \"value\"\n        return f'{name}=\"{value}\"'\n    # For numbers and booleans, direct string conversion is fine\n    return f\"{name}={value}\"\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_all_parameters_details","title":"<code>get_all_parameters_details(omc, model_name)</code>","text":"<p>Recursively retrieves detailed information for all parameters in a given model.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> \u5fc5\u9700 <code>model_name</code> <code>str</code> <p>The full name of the model.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[Dict[str, Any]]</code> <p>A list of dictionaries, where each dictionary contains the detailed</p> <code>List[Dict[str, Any]]</code> <p>information of a single parameter including name, type, defaultValue,</p> <code>List[Dict[str, Any]]</code> <p>comment, and dimensions.</p> Note <p>Uses _recursive_get_parameters() to traverse the model hierarchy. Returns empty list if model is not found or on error. Each parameter dict includes 'name' (hierarchical), 'type', 'defaultValue', 'comment', and 'dimensions' fields.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/modelica.py</code> <pre><code>def get_all_parameters_details(\n    omc: OMCSessionZMQ, model_name: str\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Recursively retrieves detailed information for all parameters in a given model.\n\n    Args:\n        omc: The active OpenModelica session object.\n        model_name: The full name of the model.\n\n    Returns:\n        A list of dictionaries, where each dictionary contains the detailed\n        information of a single parameter including name, type, defaultValue,\n        comment, and dimensions.\n\n    Note:\n        Uses _recursive_get_parameters() to traverse the model hierarchy.\n        Returns empty list if model is not found or on error. Each parameter\n        dict includes 'name' (hierarchical), 'type', 'defaultValue', 'comment',\n        and 'dimensions' fields.\n    \"\"\"\n    logger.info(\n        \"Getting detailed parameters via recursion\", extra={\"model_name\": model_name}\n    )\n    all_params_details = []\n    try:\n        if not omc.sendExpression(f\"isModel({model_name})\"):\n            logger.error(\"Model not found in package\", extra={\"model_name\": model_name})\n            return []\n        _recursive_get_parameters(omc, model_name, \"\", all_params_details)\n        logger.info(\n            \"Successfully found parameter details\",\n            extra={\"count\": len(all_params_details)},\n        )\n        return all_params_details\n    except Exception as e:\n        logger.error(\n            \"Failed to get detailed parameters via recursion\",\n            exc_info=True,\n            extra={\"error\": str(e)},\n        )\n        return []\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_model_default_parameters","title":"<code>get_model_default_parameters(omc, model_name)</code>","text":"<p>Retrieves the default values for all parameters in a given model.</p> <p>This function leverages get_all_parameters_details to fetch detailed parameter information and then extracts and parses the name and default value into a dictionary.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> \u5fc5\u9700 <code>model_name</code> <code>str</code> <p>The full name of the model.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>A dictionary mapping parameter names to their default values</p> <code>Dict[str, Any]</code> <p>(e.g., float, list, bool, str). Returns an empty dictionary if</p> <code>Dict[str, Any]</code> <p>the model is not found or has no parameters.</p> Note <p>Values are parsed from OpenModelica string format to Python types using _parse_om_value(). Handles arrays, booleans, strings, and numeric values.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/modelica.py</code> <pre><code>def get_model_default_parameters(omc: OMCSessionZMQ, model_name: str) -&gt; Dict[str, Any]:\n    \"\"\"Retrieves the default values for all parameters in a given model.\n\n    This function leverages get_all_parameters_details to fetch detailed\n    parameter information and then extracts and parses the name and default value\n    into a dictionary.\n\n    Args:\n        omc: The active OpenModelica session object.\n        model_name: The full name of the model.\n\n    Returns:\n        A dictionary mapping parameter names to their default values\n        (e.g., float, list, bool, str). Returns an empty dictionary if\n        the model is not found or has no parameters.\n\n    Note:\n        Values are parsed from OpenModelica string format to Python types using\n        _parse_om_value(). Handles arrays, booleans, strings, and numeric values.\n    \"\"\"\n    logger.info(\n        \"Getting and parsing default parameter values\", extra={\"model_name\": model_name}\n    )\n\n    # Use the existing detailed function to get all parameter info\n    all_params_details = get_all_parameters_details(omc, model_name)\n\n    if not all_params_details:\n        logger.warning(\n            \"No parameters found for model\", extra={\"model_name\": model_name}\n        )\n        return {}\n\n    # Convert the list of dicts into a single dict of name: parsed_defaultValue\n    default_params = {\n        param[\"name\"]: _parse_om_value(param[\"defaultValue\"])\n        for param in all_params_details\n    }\n\n    logger.info(\n        \"Found and parsed default parameters\",\n        extra={\n            \"count\": len(default_params),\n            \"model_name\": model_name,\n        },\n    )\n    return default_params\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_model_parameter_names","title":"<code>get_model_parameter_names(omc, model_name)</code>","text":"<p>Parses and returns all subcomponent parameter names for a given model.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> \u5fc5\u9700 <code>model_name</code> <code>str</code> <p>The full name of the model (e.g., 'example.Cycle').</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[str]</code> <p>A list of all available parameter names in hierarchical format</p> <code>List[str]</code> <p>(e.g., ['blanket.TBR', 'divertor.heatLoad']).</p> Note <p>Only traverses components whose type starts with the package name. Returns empty list if model is not found or has no components. Uses getComponents() and getParameterNames() OMC API calls.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/modelica.py</code> <pre><code>def get_model_parameter_names(omc: OMCSessionZMQ, model_name: str) -&gt; List[str]:\n    \"\"\"Parses and returns all subcomponent parameter names for a given model.\n\n    Args:\n        omc: The active OpenModelica session object.\n        model_name: The full name of the model (e.g., 'example.Cycle').\n\n    Returns:\n        A list of all available parameter names in hierarchical format\n        (e.g., ['blanket.TBR', 'divertor.heatLoad']).\n\n    Note:\n        Only traverses components whose type starts with the package name.\n        Returns empty list if model is not found or has no components. Uses\n        getComponents() and getParameterNames() OMC API calls.\n    \"\"\"\n    logger.info(\"Getting parameter names for model\", extra={\"model_name\": model_name})\n    all_params = []\n    try:\n        if not omc.sendExpression(f\"isModel({model_name})\"):\n            logger.warning(\n                \"Model not found in package\", extra={\"model_name\": model_name}\n            )\n            return []\n\n        components = omc.sendExpression(f\"getComponents({model_name})\")\n        if not components:\n            logger.warning(\n                \"No components found for model\", extra={\"model_name\": model_name}\n            )\n            return []\n\n        for comp in components:\n            comp_type, comp_name = comp[0], comp[1]\n            if comp_type.startswith(model_name.split(\".\")[0]):\n                params = omc.sendExpression(f\"getParameterNames({comp_type})\")\n                for param in params:\n                    full_param = f\"{comp_name}.{param}\"\n                    if full_param not in all_params:\n                        all_params.append(full_param)\n\n        logger.info(\"Found parameter names\", extra={\"count\": len(all_params)})\n        return all_params\n\n    except Exception as e:\n        logger.error(\n            \"Failed to get parameter names\", exc_info=True, extra={\"error\": str(e)}\n        )\n        return []\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_om_session","title":"<code>get_om_session()</code>","text":"<p>Initializes and returns a new OMCSessionZMQ session.</p> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>OMCSessionZMQ</code> <p>An active OpenModelica session object.</p> Note <p>Creates a new ZMQ-based connection to OpenModelica Compiler. Each call creates an independent session that should be properly closed after use.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/modelica.py</code> <pre><code>def get_om_session() -&gt; OMCSessionZMQ:\n    \"\"\"Initializes and returns a new OMCSessionZMQ session.\n\n    Returns:\n        An active OpenModelica session object.\n\n    Note:\n        Creates a new ZMQ-based connection to OpenModelica Compiler. Each call\n        creates an independent session that should be properly closed after use.\n    \"\"\"\n    logger.debug(\"Initializing new OMCSessionZMQ session\")\n    return OMCSessionZMQ()\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.load_modelica_package","title":"<code>load_modelica_package(omc, package_path)</code>","text":"<p>Loads a Modelica package into the OpenModelica session.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> \u5fc5\u9700 <code>package_path</code> <code>str</code> <p>The file path to the Modelica package (<code>package.mo</code>).</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>bool</code> <p>True if the package was loaded successfully, False otherwise.</p> Note <p>Uses sendExpression('loadFile(...)') command. Logs error if loading fails. The package must be a valid Modelica package file.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/modelica.py</code> <pre><code>def load_modelica_package(omc: OMCSessionZMQ, package_path: str) -&gt; bool:\n    \"\"\"Loads a Modelica package into the OpenModelica session.\n\n    Args:\n        omc: The active OpenModelica session object.\n        package_path: The file path to the Modelica package (`package.mo`).\n\n    Returns:\n        True if the package was loaded successfully, False otherwise.\n\n    Note:\n        Uses sendExpression('loadFile(...)') command. Logs error if loading fails.\n        The package must be a valid Modelica package file.\n    \"\"\"\n    logger.info(\"Loading package\", extra={\"package_path\": package_path})\n    load_result = omc.sendExpression(f'loadFile(\"{package_path}\")')\n    if not load_result:\n        logger.error(\"Failed to load package\", extra={\"package_path\": package_path})\n        return False\n    return True\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.interceptor.integrate_interceptor_model","title":"<code>integrate_interceptor_model(package_path, model_name, interception_configs)</code>","text":"<p>Integrates CSV data replacement into a system model.</p> <p>This function supports two modes (all handlers must use the same mode): 1. \"interceptor\" (default): Creates interceptor models between submodels and system. 2. \"replacement\": Directly modifies submodels to use CSV data.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>package_path</code> <code>str</code> <p>The file path to the Modelica package. For multi-file packages, this should be the path to <code>package.mo</code>. For single-file packages, this should be the path to the <code>.mo</code> file containing the package.</p> \u5fc5\u9700 <code>model_name</code> <code>str</code> <p>The full name of the system model to be modified.</p> \u5fc5\u9700 <code>interception_configs</code> <code>list[Dict[str, Any]]</code> <p>A list of dictionaries, each defining an interception task. All configs must have the same 'mode' field. Each dict should contain 'submodel_name', 'csv_uri', 'instance_name', 'output_placeholder', and optionally 'mode' (defaults to 'interceptor').</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>A dictionary containing the paths to modified models. Structure varies by mode: - interceptor mode: interceptor_model_paths, system_model_path - replacement mode: replaced_models, system_model_path</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>ValueError</code> <p>If interception_configs is empty or if mixed modes are detected.</p> <code>FileNotFoundError</code> <p>If package_path is invalid or package.mo not found.</p> Note <p>Mode is determined from the first config's 'mode' field. All configs must use the same mode or ValueError is raised. Automatically detects single-file vs multi-file package structure and routes to appropriate handler.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/interceptor.py</code> <pre><code>def integrate_interceptor_model(\n    package_path: str, model_name: str, interception_configs: list[Dict[str, Any]]\n) -&gt; Dict[str, Any]:\n    \"\"\"Integrates CSV data replacement into a system model.\n\n    This function supports two modes (all handlers must use the same mode):\n    1. \"interceptor\" (default): Creates interceptor models between submodels and system.\n    2. \"replacement\": Directly modifies submodels to use CSV data.\n\n    Args:\n        package_path: The file path to the Modelica package. For multi-file packages,\n            this should be the path to `package.mo`. For single-file packages,\n            this should be the path to the `.mo` file containing the package.\n        model_name: The full name of the system model to be modified.\n        interception_configs: A list of dictionaries, each defining an interception task.\n            All configs must have the same 'mode' field. Each dict should contain\n            'submodel_name', 'csv_uri', 'instance_name', 'output_placeholder', and\n            optionally 'mode' (defaults to 'interceptor').\n\n    Returns:\n        A dictionary containing the paths to modified models. Structure varies by mode:\n            - interceptor mode: interceptor_model_paths, system_model_path\n            - replacement mode: replaced_models, system_model_path\n\n    Raises:\n        ValueError: If interception_configs is empty or if mixed modes are detected.\n        FileNotFoundError: If package_path is invalid or package.mo not found.\n\n    Note:\n        Mode is determined from the first config's 'mode' field. All configs must use\n        the same mode or ValueError is raised. Automatically detects single-file vs\n        multi-file package structure and routes to appropriate handler.\n    \"\"\"\n    if not interception_configs:\n        raise ValueError(\"interception_configs cannot be empty\")\n\n    # Get mode from first config (all should be the same)\n    mode = interception_configs[0].get(\"mode\", \"interceptor\")\n\n    # Validate that all configs use the same mode\n    for config in interception_configs:\n        config_mode = config.get(\"mode\", \"interceptor\")\n        if config_mode != mode:\n            raise ValueError(\n                f\"Mixed modes are not supported. All handlers must use the same mode. \"\n                f\"Expected '{mode}', but found '{config_mode}' in config for '{config.get('submodel_name')}'\"\n            )\n\n    logger.info(\n        \"Integrating CSV data replacement\",\n        extra={\n            \"mode\": mode,\n            \"num_submodels\": len(interception_configs),\n        },\n    )\n\n    # Route to appropriate handler based on mode\n    if mode == \"replacement\":\n        return _integrate_replacement(package_path, model_name, interception_configs)\n    else:  # mode == \"interceptor\"\n        # Determine package type and route to appropriate handler\n        if os.path.isdir(package_path):\n            package_file = os.path.join(package_path, \"package.mo\")\n            if os.path.exists(package_file):\n                return _integrate_interceptor_multi_file(\n                    package_file, model_name, interception_configs\n                )\n            else:\n                raise FileNotFoundError(\n                    f\"No package.mo found in directory: {package_path}\"\n                )\n        elif os.path.isfile(package_path) and package_path.endswith(\"package.mo\"):\n            return _integrate_interceptor_multi_file(\n                package_path, model_name, interception_configs\n            )\n        elif os.path.isfile(package_path):\n            return _integrate_interceptor_single_file(\n                package_path, model_name, interception_configs\n            )\n        else:\n            raise FileNotFoundError(f\"Invalid package path: {package_path}\")\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.interceptor.replace_submodels_with_csv","title":"<code>replace_submodels_with_csv(package_path, replacement_configs)</code>","text":"<p>Replaces multiple submodels with CSV data sources.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>package_path</code> <code>str</code> <p>Path to the Modelica package directory or package.mo file.</p> \u5fc5\u9700 <code>replacement_configs</code> <code>list[Dict[str, Any]]</code> <p>A list of dictionaries, each defining a replacement task: - submodel_name: Full name of the submodel (e.g., 'MyPackage.MyModel') - output_ports: List of output port definitions - csv_file: Path to the CSV file</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>A dictionary containing: - replaced_models: List of results from each replacement - package_path: Original package path</p> Note <p>Automatically determines if package is directory-based or single-file. Continues processing remaining models if one fails, but re-raises the error after logging. Each submodel file is identified by splitting the full name and locating {ModelName}.mo in the package directory.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/core/interceptor.py</code> <pre><code>def replace_submodels_with_csv(\n    package_path: str,\n    replacement_configs: list[Dict[str, Any]],\n) -&gt; Dict[str, Any]:\n    \"\"\"Replaces multiple submodels with CSV data sources.\n\n    Args:\n        package_path: Path to the Modelica package directory or package.mo file.\n        replacement_configs: A list of dictionaries, each defining a replacement task:\n            - submodel_name: Full name of the submodel (e.g., 'MyPackage.MyModel')\n            - output_ports: List of output port definitions\n            - csv_file: Path to the CSV file\n\n    Returns:\n        A dictionary containing:\n            - replaced_models: List of results from each replacement\n            - package_path: Original package path\n\n    Note:\n        Automatically determines if package is directory-based or single-file.\n        Continues processing remaining models if one fails, but re-raises the error\n        after logging. Each submodel file is identified by splitting the full name\n        and locating {ModelName}.mo in the package directory.\n    \"\"\"\n    logger.info(\n        \"Starting batch submodel replacement\",\n        extra={\"num_configs\": len(replacement_configs)},\n    )\n\n    # Determine package directory\n    if os.path.isdir(package_path):\n        package_dir = package_path\n    elif os.path.isfile(package_path) and package_path.endswith(\"package.mo\"):\n        package_dir = os.path.dirname(package_path)\n    elif os.path.isfile(package_path):\n        package_dir = os.path.dirname(package_path)\n    else:\n        raise FileNotFoundError(f\"Invalid package path: {package_path}\")\n\n    replaced_models = []\n\n    for config in replacement_configs:\n        submodel_name = config[\"submodel_name\"]\n        output_ports = config[\"output_ports\"]\n        csv_file = config[\"csv_file\"]\n\n        # Construct submodel file path\n        model_simple_name = submodel_name.split(\".\")[-1]\n        submodel_file = os.path.join(package_dir, f\"{model_simple_name}.mo\")\n\n        if not os.path.exists(submodel_file):\n            logger.warning(\n                \"Submodel file not found, skipping\",\n                extra={\"submodel_name\": submodel_name, \"expected_path\": submodel_file},\n            )\n            continue\n\n        try:\n            result = _replace_submodel_with_csv(\n                submodel_path=submodel_file,\n                output_ports=output_ports,\n                csv_file=csv_file,\n            )\n            result[\"submodel_name\"] = submodel_name\n            replaced_models.append(result)\n\n            logger.info(\n                \"Successfully replaced submodel\",\n                extra={\"submodel_name\": submodel_name},\n            )\n\n        except Exception as e:\n            logger.error(\n                \"Failed to replace submodel\",\n                extra={\"submodel_name\": submodel_name, \"error\": str(e)},\n            )\n            raise\n\n    logger.info(\n        \"Batch replacement completed\",\n        extra={\"num_replaced\": len(replaced_models)},\n    )\n\n    return {\n        \"replaced_models\": replaced_models,\n        \"package_path\": package_path,\n    }\n</code></pre>"},{"location":"api/tricys_handlers.html","title":"API \u53c2\u8003 - \u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers)","text":"<p>\u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers)</p> <p>\u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers) \u63d0\u4f9b\u4e86\u7528\u4e8e\u4e0e\u5916\u90e8\u4eff\u771f\u5de5\u5177\uff08\u5982 Aspen Plus\uff09\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u548c\u534f\u540c\u4eff\u771f\u7684\u63a5\u53e3\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> DIV HandlerI_ISS Handler"},{"location":"api/tricys_handlers.html#tricys.handlers.div_handler.run_div_simulation","title":"<code>run_div_simulation(temp_input_csv, temp_output_csv, **kwargs)</code>","text":"<p>Runs a simulation based on fake divertor data.</p> <p>Reads data from a source CSV, selects specific columns, and writes them to a temporary output CSV.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>temp_input_csv</code> <code>str</code> <p>Path to the temporary input CSV file (unused).</p> \u5fc5\u9700 <code>temp_output_csv</code> <code>str</code> <p>Path to the temporary output CSV file.</p> \u5fc5\u9700 <code>**kwargs</code> <p>Additional keyword arguments (unused).</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>dict</code> <p>A placeholder dictionary with output variable mappings.</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>FileNotFoundError</code> <p>If the source CSV file cannot be found.</p> <code>ValueError</code> <p>If the source CSV is missing required columns.</p> Note <p>The temp_input_csv parameter is kept for interface consistency but not used. Reads from div_handler.csv in the same directory as this module. Returns a placeholder dict with format {\"to_CL\": \"{1,2,3,4,5,6}\"}.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/div_handler.py</code> <pre><code>def run_div_simulation(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"Runs a simulation based on fake divertor data.\n\n    Reads data from a source CSV, selects specific columns, and writes them\n    to a temporary output CSV.\n\n    Args:\n        temp_input_csv: Path to the temporary input CSV file (unused).\n        temp_output_csv: Path to the temporary output CSV file.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        A placeholder dictionary with output variable mappings.\n\n    Raises:\n        FileNotFoundError: If the source CSV file cannot be found.\n        ValueError: If the source CSV is missing required columns.\n\n    Note:\n        The temp_input_csv parameter is kept for interface consistency but not used.\n        Reads from div_handler.csv in the same directory as this module. Returns\n        a placeholder dict with format {\"to_CL\": \"{1,2,3,4,5,6}\"}.\n    \"\"\"\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"div_handler.csv\")\n\n    try:\n        source_df = pd.read_csv(source_csv_path)\n    except FileNotFoundError:\n        pd.DataFrame({\"time\": []}).to_csv(temp_output_csv, index=False)\n        raise\n\n    columns_to_select = [\n        \"time\",\n        \"div.to_CL[1]\",\n        \"div.to_CL[2]\",\n        \"div.to_CL[3]\",\n        \"div.to_CL[4]\",\n        \"div.to_CL[5]\",\n    ]\n\n    if not all(col in source_df.columns for col in columns_to_select):\n        missing_cols = [\n            col for col in columns_to_select if col not in source_df.columns\n        ]\n        raise ValueError(\n            f\"The source file {source_csv_path} is missing required columns: \"\n            f\"{missing_cols}\"\n        )\n\n    output_df = source_df[columns_to_select].copy()\n\n    output_df.to_csv(temp_output_csv, index=False)\n\n    output_placeholder = {\"to_CL\": \"{1,2,3,4,5,6}\"}\n\n    return output_placeholder\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced","title":"<code>AspenEnhanced</code>","text":"<p>A helper class to encapsulate interactions with an Aspen Plus COM server.</p> <p>\u5c5e\u6027\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 <code>aspen</code> <p>The Aspen Plus COM object instance.</p> <code>M_T</code> <p>Molar mass of Tritium (3.016 g/mol).</p> <code>M_D</code> <p>Molar mass of Deuterium (2.014 g/mol).</p> <code>M_H</code> <p>Molar mass of Hydrogen (1.008 g/mol).</p> Note <p>Requires Aspen Plus COM interface to be available on the system. Sets visibility to 0 and suppresses dialogs for automation.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>class AspenEnhanced:\n    \"\"\"A helper class to encapsulate interactions with an Aspen Plus COM server.\n\n    Attributes:\n        aspen: The Aspen Plus COM object instance.\n        M_T: Molar mass of Tritium (3.016 g/mol).\n        M_D: Molar mass of Deuterium (2.014 g/mol).\n        M_H: Molar mass of Hydrogen (1.008 g/mol).\n\n    Note:\n        Requires Aspen Plus COM interface to be available on the system.\n        Sets visibility to 0 and suppresses dialogs for automation.\n    \"\"\"\n\n    def __init__(self, bkp_path: str) -&gt; None:\n        \"\"\"Initialize Aspen connection and define molar masses.\n\n        Args:\n            bkp_path: Path to the Aspen backup file (.bkp).\n\n        Note:\n            Converts path to absolute before loading. Suppresses Aspen GUI and dialogs.\n            COM object version \"Apwn.Document.40.0\" may need adjustment for different\n            Aspen Plus versions.\n        \"\"\"\n        logger.info(\"Dispatching Aspen COM object...\")\n        self.aspen = win32.Dispatch(\"Apwn.Document.40.0\")  # Adjust version if necessary\n        logger.info(f\"Loading Aspen backup file: {os.path.abspath(bkp_path)}\")\n        self.aspen.InitFromArchive2(os.path.abspath(bkp_path))\n        self.aspen.Visible = 0\n        self.aspen.SuppressDialogs = 1\n        logger.info(\"Aspen initialized successfully.\")\n\n        # \u5b9a\u4e49\u6469\u5c14\u8d28\u91cf (g/mol)\n        self.M_T, self.M_D, self.M_H = 3.016, 2.014, 1.008\n\n    def set_composition(self, ratios: list) -&gt; None:\n        \"\"\"Set six-component input composition.\n\n        Args:\n            ratios: List of 7 values [EH2, EHD, ED2, EHT, EDT, ET2, total_flow].\n\n        Note:\n            Updates Aspen stream FROMTEP with H2, HD, D2, HT, DT, T2 flows and total flow.\n            Total flow is divided by 2 when setting TOTFLOW/MIXED node.\n        \"\"\"\n        nodes = {\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\H2\": ratios[0],  # EH2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HD\": ratios[1],  # EHD\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\D2\": ratios[2],  # ED2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HT\": ratios[3],  # EHT\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\DT\": ratios[4],  # EDT\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\T2\": ratios[5],  # ET2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\TOTFLOW\\MIXED\": ratios[6] / 2,  # \u603b\u6d41\u91cf/2\n        }\n        for path, value in nodes.items():\n            self.aspen.Tree.FindNode(path).Value = value\n\n    def run_step(self) -&gt; None:\n        \"\"\"Execute single-step simulation and wait for completion.\n\n        Note:\n            Uses busy-wait polling with 0.1 second intervals to check if engine is running.\n            Blocks until simulation step completes.\n        \"\"\"\n        self.aspen.Engine.Run2()\n        while self.aspen.Engine.IsRunning:\n            time.sleep(0.1)\n\n    def get_stream_results(self) -&gt; dict:\n        \"\"\"Get H/D/T mass flow rates (g/h) from key streams.\n\n        Returns:\n            Dictionary mapping stream names to [H, D, T] mass flow lists.\n            Format: {\"WDS\": [H, D, T], \"SDST2\": [H, D, T], \"SDSD2\": [H, D, T]}.\n\n        Note:\n            Retrieves mole flows in kmol/h, converts to mol/h (*1000), then calculates\n            mass flows using isotope-specific molar masses. Streams mapped are:\n            WDS-&gt;S4, SDST2-&gt;S17, SDSD2-&gt;S16.\n        \"\"\"\n\n        def calc_stream(stream_name):\n            \"\"\"\u8ba1\u7b97\u5355\u4e2a\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf\"\"\"\n            nodes = self.aspen.Tree.FindNode(\n                rf\"\\Data\\Streams\\{stream_name}\\Output\\MOLEFLOW\\MIXED\"\n            )\n            Q1 = 1000 * nodes.FindNode(\"H2\").Value\n            Q2 = 1000 * nodes.FindNode(\"HD\").Value\n            Q3 = 1000 * nodes.FindNode(\"D2\").Value\n            Q4 = 1000 * nodes.FindNode(\"HT\").Value\n            Q5 = 1000 * nodes.FindNode(\"DT\").Value\n            Q6 = 1000 * nodes.FindNode(\"T2\").Value\n\n            H = (2 * Q1 + 1 * Q2 + 1 * Q4) * self.M_H\n            D = (1 * Q2 + 2 * Q3 + 1 * Q5) * self.M_D\n            T = (1 * Q4 + 1 * Q5 + 2 * Q6) * self.M_T\n            return [H, D, T]\n\n        streams = {\"WDS\": \"S4\", \"SDST2\": \"S17\", \"SDSD2\": \"S16\"}\n        return {name: calc_stream(path) for name, path in streams.items()}\n\n    def close(self) -&gt; None:\n        \"\"\"Closes the Aspen connection.\n\n        Note:\n            Should always be called to properly clean up COM resources.\n            Typically used in finally block to ensure cleanup even on errors.\n        \"\"\"\n        if self.aspen:\n            self.aspen.Close()\n            logger.info(\"Closed Aspen session.\")\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.__init__","title":"<code>__init__(bkp_path)</code>","text":"<p>Initialize Aspen connection and define molar masses.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>bkp_path</code> <code>str</code> <p>Path to the Aspen backup file (.bkp).</p> \u5fc5\u9700 Note <p>Converts path to absolute before loading. Suppresses Aspen GUI and dialogs. COM object version \"Apwn.Document.40.0\" may need adjustment for different Aspen Plus versions.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def __init__(self, bkp_path: str) -&gt; None:\n    \"\"\"Initialize Aspen connection and define molar masses.\n\n    Args:\n        bkp_path: Path to the Aspen backup file (.bkp).\n\n    Note:\n        Converts path to absolute before loading. Suppresses Aspen GUI and dialogs.\n        COM object version \"Apwn.Document.40.0\" may need adjustment for different\n        Aspen Plus versions.\n    \"\"\"\n    logger.info(\"Dispatching Aspen COM object...\")\n    self.aspen = win32.Dispatch(\"Apwn.Document.40.0\")  # Adjust version if necessary\n    logger.info(f\"Loading Aspen backup file: {os.path.abspath(bkp_path)}\")\n    self.aspen.InitFromArchive2(os.path.abspath(bkp_path))\n    self.aspen.Visible = 0\n    self.aspen.SuppressDialogs = 1\n    logger.info(\"Aspen initialized successfully.\")\n\n    # \u5b9a\u4e49\u6469\u5c14\u8d28\u91cf (g/mol)\n    self.M_T, self.M_D, self.M_H = 3.016, 2.014, 1.008\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.close","title":"<code>close()</code>","text":"<p>Closes the Aspen connection.</p> Note <p>Should always be called to properly clean up COM resources. Typically used in finally block to ensure cleanup even on errors.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the Aspen connection.\n\n    Note:\n        Should always be called to properly clean up COM resources.\n        Typically used in finally block to ensure cleanup even on errors.\n    \"\"\"\n    if self.aspen:\n        self.aspen.Close()\n        logger.info(\"Closed Aspen session.\")\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.get_stream_results","title":"<code>get_stream_results()</code>","text":"<p>Get H/D/T mass flow rates (g/h) from key streams.</p> <p>\u8fd4\u56de\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 <code>dict</code> <p>Dictionary mapping stream names to [H, D, T] mass flow lists.</p> <code>Format</code> <code>dict</code> <p>{\"WDS\": [H, D, T], \"SDST2\": [H, D, T], \"SDSD2\": [H, D, T]}.</p> Note <p>Retrieves mole flows in kmol/h, converts to mol/h (*1000), then calculates mass flows using isotope-specific molar masses. Streams mapped are: WDS-&gt;S4, SDST2-&gt;S17, SDSD2-&gt;S16.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def get_stream_results(self) -&gt; dict:\n    \"\"\"Get H/D/T mass flow rates (g/h) from key streams.\n\n    Returns:\n        Dictionary mapping stream names to [H, D, T] mass flow lists.\n        Format: {\"WDS\": [H, D, T], \"SDST2\": [H, D, T], \"SDSD2\": [H, D, T]}.\n\n    Note:\n        Retrieves mole flows in kmol/h, converts to mol/h (*1000), then calculates\n        mass flows using isotope-specific molar masses. Streams mapped are:\n        WDS-&gt;S4, SDST2-&gt;S17, SDSD2-&gt;S16.\n    \"\"\"\n\n    def calc_stream(stream_name):\n        \"\"\"\u8ba1\u7b97\u5355\u4e2a\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf\"\"\"\n        nodes = self.aspen.Tree.FindNode(\n            rf\"\\Data\\Streams\\{stream_name}\\Output\\MOLEFLOW\\MIXED\"\n        )\n        Q1 = 1000 * nodes.FindNode(\"H2\").Value\n        Q2 = 1000 * nodes.FindNode(\"HD\").Value\n        Q3 = 1000 * nodes.FindNode(\"D2\").Value\n        Q4 = 1000 * nodes.FindNode(\"HT\").Value\n        Q5 = 1000 * nodes.FindNode(\"DT\").Value\n        Q6 = 1000 * nodes.FindNode(\"T2\").Value\n\n        H = (2 * Q1 + 1 * Q2 + 1 * Q4) * self.M_H\n        D = (1 * Q2 + 2 * Q3 + 1 * Q5) * self.M_D\n        T = (1 * Q4 + 1 * Q5 + 2 * Q6) * self.M_T\n        return [H, D, T]\n\n    streams = {\"WDS\": \"S4\", \"SDST2\": \"S17\", \"SDSD2\": \"S16\"}\n    return {name: calc_stream(path) for name, path in streams.items()}\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.run_step","title":"<code>run_step()</code>","text":"<p>Execute single-step simulation and wait for completion.</p> Note <p>Uses busy-wait polling with 0.1 second intervals to check if engine is running. Blocks until simulation step completes.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_step(self) -&gt; None:\n    \"\"\"Execute single-step simulation and wait for completion.\n\n    Note:\n        Uses busy-wait polling with 0.1 second intervals to check if engine is running.\n        Blocks until simulation step completes.\n    \"\"\"\n    self.aspen.Engine.Run2()\n    while self.aspen.Engine.IsRunning:\n        time.sleep(0.1)\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.set_composition","title":"<code>set_composition(ratios)</code>","text":"<p>Set six-component input composition.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>ratios</code> <code>list</code> <p>List of 7 values [EH2, EHD, ED2, EHT, EDT, ET2, total_flow].</p> \u5fc5\u9700 Note <p>Updates Aspen stream FROMTEP with H2, HD, D2, HT, DT, T2 flows and total flow. Total flow is divided by 2 when setting TOTFLOW/MIXED node.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def set_composition(self, ratios: list) -&gt; None:\n    \"\"\"Set six-component input composition.\n\n    Args:\n        ratios: List of 7 values [EH2, EHD, ED2, EHT, EDT, ET2, total_flow].\n\n    Note:\n        Updates Aspen stream FROMTEP with H2, HD, D2, HT, DT, T2 flows and total flow.\n        Total flow is divided by 2 when setting TOTFLOW/MIXED node.\n    \"\"\"\n    nodes = {\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\H2\": ratios[0],  # EH2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HD\": ratios[1],  # EHD\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\D2\": ratios[2],  # ED2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HT\": ratios[3],  # EHT\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\DT\": ratios[4],  # EDT\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\T2\": ratios[5],  # ET2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\TOTFLOW\\MIXED\": ratios[6] / 2,  # \u603b\u6d41\u91cf/2\n    }\n    for path, value in nodes.items():\n        self.aspen.Tree.FindNode(path).Value = value\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.run_aspen_simulation","title":"<code>run_aspen_simulation(temp_input_csv, temp_output_csv, bkp_path='example_aspenbkp/T2-Threetowers4.bkp', aspen_results_csv=None, base=20, retime=60, time_step=3, min_stable_steps=100, stable_threshold=1e-06)</code>","text":"<p>Runs an Aspen Plus simulation based on inputs from a Modelica simulation.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>temp_input_csv</code> <code>str</code> <p>Path to the input CSV file with time-series data.</p> \u5fc5\u9700 <code>temp_output_csv</code> <code>str</code> <p>Path to save the final summarized output CSV.</p> \u5fc5\u9700 <code>bkp_path</code> <code>str</code> <p>Path to the Aspen backup file (.bkp). Defaults to example path.</p> <code>'example_aspenbkp/T2-Threetowers4.bkp'</code> <code>aspen_results_csv</code> <code>str</code> <p>Path to save detailed Aspen results. Defaults to None.</p> <code>None</code> <code>base</code> <code>float</code> <p>Minimum inventory (heel) to start simulation (mol). Defaults to 20.</p> <code>20</code> <code>retime</code> <code>int</code> <p>Lag time in minutes for output results. Defaults to 60.</p> <code>60</code> <code>time_step</code> <code>int</code> <p>Time step in minutes. Defaults to 3.</p> <code>3</code> <code>min_stable_steps</code> <code>int</code> <p>Consecutive stable steps to confirm stability. Defaults to 100.</p> <code>100</code> <code>stable_threshold</code> <code>float</code> <p>Relative difference threshold for stability. Defaults to 1e-6.</p> <code>1e-06</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>dict</code> <p>A dictionary mapping output variable names to their final values,</p> <code>dict</code> <p>formatted as Modelica vector strings.</p> <code>dict</code> <p>e.g., {'to_SDS': '{v1,v2,v3}', 'to_WDS': '{v4,v5,v6}'}.</p> Note <p>Implements delayed feedback with retime lag. Skips simulation until inventory reaches base level. Stops early if system stabilizes (T_flow change &lt; threshold for min_stable_steps). Input CSV encoding is 'gbk'. Creates cumulative inventory tracking columns I_H, I_D, I_T. Output columns use 1-indexed array notation [1], [2], [3].</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_aspen_simulation(\n    temp_input_csv: str,\n    temp_output_csv: str,\n    bkp_path: str = r\"example_aspenbkp/T2-Threetowers4.bkp\",\n    aspen_results_csv: str = None,\n    base: float = 20,\n    retime: int = 60,\n    time_step: int = 3,\n    min_stable_steps: int = 100,\n    stable_threshold: float = 1e-6,\n) -&gt; dict:\n    \"\"\"Runs an Aspen Plus simulation based on inputs from a Modelica simulation.\n\n    Args:\n        temp_input_csv: Path to the input CSV file with time-series data.\n        temp_output_csv: Path to save the final summarized output CSV.\n        bkp_path: Path to the Aspen backup file (.bkp). Defaults to example path.\n        aspen_results_csv: Path to save detailed Aspen results. Defaults to None.\n        base: Minimum inventory (heel) to start simulation (mol). Defaults to 20.\n        retime: Lag time in minutes for output results. Defaults to 60.\n        time_step: Time step in minutes. Defaults to 3.\n        min_stable_steps: Consecutive stable steps to confirm stability. Defaults to 100.\n        stable_threshold: Relative difference threshold for stability. Defaults to 1e-6.\n\n    Returns:\n        A dictionary mapping output variable names to their final values,\n        formatted as Modelica vector strings.\n        e.g., {'to_SDS': '{v1,v2,v3}', 'to_WDS': '{v4,v5,v6}'}.\n\n    Note:\n        Implements delayed feedback with retime lag. Skips simulation until inventory\n        reaches base level. Stops early if system stabilizes (T_flow change &lt; threshold\n        for min_stable_steps). Input CSV encoding is 'gbk'. Creates cumulative inventory\n        tracking columns I_H, I_D, I_T. Output columns use 1-indexed array notation [1], [2], [3].\n    \"\"\"\n    aspen = None\n    all_results = []\n    output_placeholder = {}\n\n    try:\n        # 1. \u521d\u59cb\u5316Aspen\n        aspen = AspenEnhanced(bkp_path)\n\n        # 2. \u8bfb\u53d6OpenModelica\u6570\u636e\n        logger.info(f\"Reading input data from: {temp_input_csv}\")\n        df_input = pd.read_csv(temp_input_csv, encoding=\"gbk\")\n\n        time_step_h = time_step / 60\n        N = int(retime / time_step)\n\n        df_input = df_input[\n            (df_input[\"time\"] / time_step_h).apply(lambda x: round(x, 9).is_integer())\n        ].copy()\n        required_cols = [\n            \"time\",\n            \"tep_fcu.outflow[1]\",\n            \"tep_fcu.outflow[2]\",\n            \"tep_fcu.outflow[3]\",\n        ]\n        input_data = df_input[required_cols].values\n\n        prev_T_flow = None\n        stable_count = 0\n        I_stock = 0\n        count = 0\n\n        # 3. \u4e3b\u5faa\u73af\u5904\u7406\n        logger.info(\"Starting main simulation loop...\")\n        for time_val, T_flow, D_flow, H_flow in input_data:\n            time_aspen = time_val * time_step\n            M_T, M_D, M_H = 3.016, 2.014, 1.008\n            T_flow_mol, D_flow_mol, H_flow_mol = (\n                T_flow / M_T,\n                D_flow / M_D,\n                H_flow / M_H,\n            )\n            total_flow = T_flow_mol + D_flow_mol + H_flow_mol\n\n            if prev_T_flow is not None and abs(prev_T_flow) &gt; 1e-9:\n                relative_diff = abs(T_flow - prev_T_flow) / abs(prev_T_flow)\n                if relative_diff &lt; stable_threshold:\n                    stable_count += 1\n                else:\n                    stable_count = 0\n                if stable_count &gt;= min_stable_steps:\n                    logger.info(\n                        f\"System stabilized at Time={time_val:.1f}h. Stopping simulation.\"\n                    )\n                    break\n            prev_T_flow = T_flow\n\n            I_stock += total_flow * time_step_h\n            if I_stock &lt;= base:\n                # Record zeros and skip simulation until inventory builds up\n                record = {\n                    \"Time\": time_val,\n                    \"Time_Aspen\": time_aspen,\n                    \"Input_T\": T_flow,\n                    \"Input_D\": D_flow,\n                    \"Input_H\": H_flow,\n                }\n                # ... (add other zero-ed out columns for consistency)\n                all_results.append(record)\n                continue\n\n            if not count:\n                count += 1\n                I_input = (I_stock - base) / time_step_h\n                logger.info(\n                    f\"Inventory base reached. Effective input flow: {I_input:.2f} mol/h\"\n                )\n                ET, ED, EH = (\n                    T_flow_mol / total_flow,\n                    D_flow_mol / total_flow,\n                    H_flow_mol / total_flow,\n                )\n                ratios = [\n                    EH**2,\n                    2 * EH * ED,\n                    ED**2,\n                    2 * EH * ET,\n                    2 * ED * ET,\n                    ET**2,\n                    I_input,\n                ]\n            else:\n                ET, ED, EH = (\n                    T_flow_mol / total_flow,\n                    D_flow_mol / total_flow,\n                    H_flow_mol / total_flow,\n                )\n                ratios = [\n                    EH**2,\n                    2 * EH * ED,\n                    ED**2,\n                    2 * EH * ET,\n                    2 * ED * ET,\n                    ET**2,\n                    total_flow,\n                ]\n\n            aspen.set_composition(ratios)\n            aspen.run_step()\n            stream_results = aspen.get_stream_results()\n\n            record = {\n                \"Time\": time_val,\n                \"Time_Aspen\": time_aspen,\n                \"Input_T\": T_flow,\n                \"Input_D\": D_flow,\n                \"Input_H\": H_flow,\n                **{\n                    f\"Input_{comp}\": val\n                    for comp, val in zip(\n                        [\"EH2\", \"EHD\", \"ED2\", \"EHT\", \"EDT\", \"ET2\", \"TOTAL\"], ratios\n                    )\n                },\n                **{\n                    f\"{stream}_{iso}_raw\": values[i]\n                    for stream, values in stream_results.items()\n                    for i, iso in enumerate([\"H\", \"D\", \"T\"])\n                },\n            }\n            all_results.append(record)\n            logger.debug(\n                f\"Progress: {len(all_results)}/{len(input_data)} | Time={time_val:.1f}h\"\n            )\n\n        # 4. \u540e\u5904\u7406\n        logger.info(\"Simulation loop finished. Starting post-processing...\")\n        if not all_results:\n            logger.warning(\n                \"No results were generated. The simulation might have been skipped entirely.\"\n            )\n            return output_placeholder\n\n        df = pd.DataFrame(all_results).fillna(0)\n\n        raw_cols = [\n            f\"{stream}_{iso}_raw\"\n            for stream in [\"WDS\", \"SDST2\", \"SDSD2\"]\n            for iso in [\"H\", \"D\", \"T\"]\n        ]\n        for col in raw_cols:\n            stream, iso, _ = col.split(\"_\")\n            df[f\"{stream}_{iso}\"] = df[col].shift(N).fillna(0)\n\n        df[\"delta_I_H\"] = (\n            df[\"Input_H\"]\n            - df.get(\"WDS_H\", 0)\n            - df.get(\"SDST2_H\", 0)\n            - df.get(\"SDSD2_H\", 0)\n        ) * time_step_h\n        df[\"delta_I_D\"] = (\n            df[\"Input_D\"]\n            - df.get(\"WDS_D\", 0)\n            - df.get(\"SDST2_D\", 0)\n            - df.get(\"SDSD2_D\", 0)\n        ) * time_step_h\n        df[\"delta_I_T\"] = (\n            df[\"Input_T\"]\n            - df.get(\"WDS_T\", 0)\n            - df.get(\"SDST2_T\", 0)\n            - df.get(\"SDSD2_T\", 0)\n        ) * time_step_h\n        df[\"I_H\"] = df[\"delta_I_H\"].cumsum()\n        df[\"I_D\"] = df[\"delta_I_D\"].cumsum()\n        df[\"I_T\"] = df[\"delta_I_T\"].cumsum()\n\n        df[\"to_SDS[1]\"] = df.get(\"SDST2_T\", 0) + df.get(\"SDSD2_T\", 0)\n        df[\"to_SDS[2]\"] = df.get(\"SDST2_D\", 0) + df.get(\"SDSD2_D\", 0)\n        df[\"to_SDS[3]\"] = df.get(\"SDST2_H\", 0) + df.get(\"SDSD2_H\", 0)\n        df[\"to_WDS[1]\"] = df.get(\"WDS_T\", 0)\n        df[\"to_WDS[2]\"] = df.get(\"WDS_D\", 0)\n        df[\"to_WDS[3]\"] = df.get(\"WDS_H\", 0)\n\n        # 5. \u4fdd\u5b58\u8f93\u51fa\u6587\u4ef6\n        out_df = df[\n            [\n                \"Time\",\n                \"to_SDS[1]\",\n                \"to_SDS[2]\",\n                \"to_SDS[3]\",\n                \"to_WDS[1]\",\n                \"to_WDS[2]\",\n                \"to_WDS[3]\",\n            ]\n        ]\n        out_df.to_csv(temp_output_csv, index=False)\n        logger.info(f\"Summary output saved to {temp_output_csv}\")\n\n        if aspen_results_csv:\n            df.drop(columns=raw_cols, errors=\"ignore\").to_csv(\n                aspen_results_csv, index=False\n            )\n            logger.info(f\"Detailed results saved to {aspen_results_csv}\")\n\n        # 6. \u6784\u5efa\u8fd4\u56de\u5b57\u5178\n        output_placeholder = {\n            \"to_SDS\": \"{1,2,3,4,1,1}\",\n            \"to_WDS\": \"{1,5,6,7,1,1}\",\n        }\n        logger.info(f\"Returning final values: {output_placeholder}\")\n\n    except Exception as e:\n        logger.error(\n            f\"An error occurred during the Aspen simulation: {str(e)}\", exc_info=True\n        )\n    finally:\n        if aspen:\n            aspen.close()\n\n    return output_placeholder\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.run_dummy_simulation","title":"<code>run_dummy_simulation(temp_input_csv, temp_output_csv, **kwargs)</code>","text":"<p>Runs a simulation based on fake i_ISS data.</p> <p>Reads data from a source CSV, selects specific columns, and writes them to a temporary output CSV.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>temp_input_csv</code> <code>str</code> <p>Path to the temporary input CSV file (unused).</p> \u5fc5\u9700 <code>temp_output_csv</code> <code>str</code> <p>Path to the temporary output CSV file.</p> \u5fc5\u9700 <code>**kwargs</code> <p>Additional keyword arguments (unused).</p> <code>{}</code> <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>dict</code> <p>A placeholder dictionary with output variable mappings.</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>FileNotFoundError</code> <p>If the source CSV file cannot be found.</p> <code>ValueError</code> <p>If the source CSV is missing required columns.</p> Note <p>The temp_input_csv parameter is kept for interface consistency but not used. Reads from i_iss_handler.csv in the same directory as this module. Selects columns for to_SDS[1-5] and to_WDS[1-5]. Returns placeholder dict with format {\"to_SDS\": \"{1,2,3,4,5,6}\", \"to_WDS\": \"{1,7,8,9,10,11}\"}.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_dummy_simulation(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"Runs a simulation based on fake i_ISS data.\n\n    Reads data from a source CSV, selects specific columns, and writes them\n    to a temporary output CSV.\n\n    Args:\n        temp_input_csv: Path to the temporary input CSV file (unused).\n        temp_output_csv: Path to the temporary output CSV file.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        A placeholder dictionary with output variable mappings.\n\n    Raises:\n        FileNotFoundError: If the source CSV file cannot be found.\n        ValueError: If the source CSV is missing required columns.\n\n    Note:\n        The temp_input_csv parameter is kept for interface consistency but not used.\n        Reads from i_iss_handler.csv in the same directory as this module. Selects\n        columns for to_SDS[1-5] and to_WDS[1-5]. Returns placeholder dict with format\n        {\"to_SDS\": \"{1,2,3,4,5,6}\", \"to_WDS\": \"{1,7,8,9,10,11}\"}.\n    \"\"\"\n    import os\n\n    import pandas as pd\n\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"i_iss_handler.csv\")\n\n    try:\n        source_df = pd.read_csv(source_csv_path)\n    except FileNotFoundError:\n        pd.DataFrame({\"time\": []}).to_csv(temp_output_csv, index=False)\n        raise\n\n    columns_to_select = [\n        \"time\",\n        \"i_iss.to_SDS[1]\",\n        \"i_iss.to_SDS[2]\",\n        \"i_iss.to_SDS[3]\",\n        \"i_iss.to_SDS[4]\",\n        \"i_iss.to_SDS[5]\",\n        \"i_iss.to_WDS[1]\",\n        \"i_iss.to_WDS[2]\",\n        \"i_iss.to_WDS[3]\",\n        \"i_iss.to_WDS[4]\",\n        \"i_iss.to_WDS[5]\",\n    ]\n\n    if not all(col in source_df.columns for col in columns_to_select):\n        missing_cols = [\n            col for col in columns_to_select if col not in source_df.columns\n        ]\n        raise ValueError(\n            f\"The source file {source_csv_path} is missing required columns: \"\n            f\"{missing_cols}\"\n        )\n\n    output_df = source_df[columns_to_select].copy()\n\n    output_df.to_csv(temp_output_csv, index=False)\n\n    output_placeholder = {\n        \"to_SDS\": \"{1,2,3,4,5,6}\",\n        \"to_WDS\": \"{1,7,8,9,10,11}\",\n    }\n    return output_placeholder\n</code></pre>"},{"location":"api/tricys_postprocess.html","title":"API \u53c2\u8003 - \u540e\u5904\u7406\u6a21\u5757 (Post-processing)","text":"<p>\u540e\u5904\u7406\u6a21\u5757 (Post-processing)</p> <p>\u540e\u5904\u7406\u6a21\u5757 (Post-processing) \u63d0\u4f9b\u4e86\u5728\u4eff\u771f\u8fd0\u884c\u540e\u81ea\u52a8\u6267\u884c\u7684\u5206\u6790\u548c\u62a5\u544a\u529f\u80fd\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Baseline Analysis (\u57fa\u51c6\u5206\u6790)Rise Analysis (\u4e0a\u5347\u65f6\u95f4\u5206\u6790)Static Alarm (\u9759\u6001\u8b66\u62a5) <p>This module provides functions for plotting simulation results.</p>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.baseline_analysis","title":"<code>baseline_analysis(results_df, output_dir, **kwargs)</code>","text":"<p>Generates baseline analysis plots and reports.</p> <p>Creates three outputs: 1. A time-series plot with overall view and detailed zoom around turning point 2. A bar chart showing final values of all variables, sorted 3. An optional Markdown report with AI analysis (if 'ai' flag is True)</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>results_df</code> <code>DataFrame</code> <p>The combined DataFrame of simulation results.</p> \u5fc5\u9700 <code>output_dir</code> <code>str</code> <p>The directory to save the plots and report.</p> \u5fc5\u9700 <code>**kwargs</code> <p>Additional parameters from config, including 'ai' flag, 'detailed_var', 'glossary_path', and AI model settings.</p> <code>{}</code> Note <p>Removes duplicate rows before processing. Creates bilingual plots (English and Chinese). If AI analysis enabled, requires API_KEY, BASE_URL, and AI_MODELS/AI_MODEL environment variables. Generates both initial LLM analysis and academic summary.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def baseline_analysis(results_df: pd.DataFrame, output_dir: str, **kwargs) -&gt; None:\n    \"\"\"Generates baseline analysis plots and reports.\n\n    Creates three outputs:\n    1. A time-series plot with overall view and detailed zoom around turning point\n    2. A bar chart showing final values of all variables, sorted\n    3. An optional Markdown report with AI analysis (if 'ai' flag is True)\n\n    Args:\n        results_df: The combined DataFrame of simulation results.\n        output_dir: The directory to save the plots and report.\n        **kwargs: Additional parameters from config, including 'ai' flag, 'detailed_var',\n            'glossary_path', and AI model settings.\n\n    Note:\n        Removes duplicate rows before processing. Creates bilingual plots (English and\n        Chinese). If AI analysis enabled, requires API_KEY, BASE_URL, and AI_MODELS/AI_MODEL\n        environment variables. Generates both initial LLM analysis and academic summary.\n    \"\"\"\n    if \"time\" not in results_df.columns:\n        logger.error(\"Plotting failed: 'time' column not found in results DataFrame.\")\n        return\n\n    if \"glossary_path\" in kwargs:\n        load_glossary(kwargs[\"glossary_path\"])\n\n    os.removedirs(output_dir) if os.path.exists(output_dir) else None\n    p = Path(output_dir)\n    output_dir = p.parent / \"report\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    df = results_df.copy()\n    # Remove duplicate rows before processing\n    df.drop_duplicates(inplace=True)\n    df.reset_index(drop=True, inplace=True)\n\n    # Create a unified color map for all variables\n    all_plot_columns = sorted([col for col in df.columns if col != \"time\"])\n    colors = sns.color_palette(\"turbo\", len(all_plot_columns))\n    color_map = dict(zip(all_plot_columns, colors))\n\n    # Add the color map to kwargs to pass it to the helper functions\n    plot_kwargs = kwargs.copy()\n    plot_kwargs[\"color_map\"] = color_map\n\n    # Generate the time-series plot with zoom\n    _plot_time_series_with_zoom(df, output_dir, **plot_kwargs)\n\n    # Generate the bar chart of final values\n    _plot_final_values_bar_chart(df, output_dir, **plot_kwargs)\n\n    # --- Report Generation and AI Analysis ---\n    base_report_path, base_report_content = _generate_postprocess_report(\n        df, output_dir, **kwargs\n    )\n\n    if base_report_path and kwargs.get(\"ai\", False):\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        # Prioritize AI_MODELS, fallback to AI_MODEL\n        ai_models_str = os.environ.get(\"AI_MODELS\")\n        if not ai_models_str:\n            ai_models_str = os.environ.get(\"AI_MODEL\")\n\n        if not api_key or not base_url or not ai_models_str:\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODELS/AI_MODEL not found in environment variables. Skipping LLM analysis.\"\n            )\n            return\n\n        ai_models = [model.strip() for model in ai_models_str.split(\",\")]\n\n        for ai_model in ai_models:\n            logger.info(f\"Generating AI analysis for model: {ai_model}\")\n\n            sanitized_model_name = \"\".join(\n                c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n            ).rstrip()\n\n            model_report_filename = (\n                f\"analysis_report_baseline_condition_{sanitized_model_name}.md\"\n            )\n            model_report_path = os.path.join(output_dir, model_report_filename)\n\n            with open(model_report_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(base_report_content)\n\n            llm_analysis = _call_openai_for_postprocess_analysis(\n                api_key=api_key,\n                base_url=base_url,\n                ai_model=ai_model,\n                report_content=base_report_content,\n                **kwargs,\n            )\n\n            if llm_analysis:\n                with open(model_report_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(f\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd ({ai_model})\\n\\n\")\n                    f.write(\"```markdown\\n\")\n                    f.write(llm_analysis)\n                    f.write(\"\\n```\\n\")\n                logger.info(\n                    f\"Appended LLM analysis for model {ai_model} to {model_report_path}\"\n                )\n\n                # --- ADDED: Second AI call for academic summary ---\n                academic_kwargs = kwargs.copy()\n                academic_kwargs[\"report_filename\"] = model_report_filename\n                generate_academic_report(\n                    output_dir, ai_model=ai_model, **academic_kwargs\n                )\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.generate_academic_report","title":"<code>generate_academic_report(output_dir, ai_model, **kwargs)</code>","text":"<p>Generates a professional academic analysis summary by sending the existing report and a glossary of terms to an LLM.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def generate_academic_report(output_dir: str, ai_model: str, **kwargs) -&gt; None:\n    \"\"\"\n    Generates a professional academic analysis summary by sending the existing report\n    and a glossary of terms to an LLM.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Starting generation of the academic analysis summary for model {ai_model}.\"\n        )\n\n        # 1. Read the existing report\n        report_filename = kwargs.get(\n            \"report_filename\", \"baseline_condition_analysis_report.md\"\n        )\n        report_path = os.path.join(output_dir, report_filename)\n        if not os.path.exists(report_path):\n            logger.error(\n                f\"Cannot generate academic summary: Original report '{report_path}' not found.\"\n            )\n            return\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            original_report_content = f.read()\n\n        # 2. Read the glossary\n        glossary_path = kwargs.get(\"glossary_path\", \"sheets.csv\")\n        if not os.path.exists(glossary_path):\n            logger.error(\n                f\"Cannot generate academic summary: Glossary file '{glossary_path}' not found.\"\n            )\n            return\n        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n            glossary_content = f.read()\n\n        # 3. Check for API credentials\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        if not all([api_key, base_url, ai_model]):\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not found. Skipping academic summary generation.\"\n            )\n            return\n\n        # 4. Construct the prompt\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u7531\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7684\u521d\u6b65\u5206\u6790\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\"\"\"\n\n        # Find all plots to instruct the LLM to include them\n        all_plots = [f for f in os.listdir(output_dir) if f.endswith((\".svg\", \".png\"))]\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n        instructions_prompt = f\"\"\"**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `detailed_var`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\u4f8b\u5982\uff0c\u5e94\u5c06\u201c`sds`\u7684\u5e93\u5b58\u201d\u8868\u8ff0\u4e3a\u201c\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS) \u7684\u6c1a\u5e93\u5b58\u91cf (Tritium Inventory)\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\u907f\u514d\u4f7f\u7528\u201c\u770b\u8d77\u6765\u201d\u3001\u201c\u597d\u50cf\u201d\u7b49\u6a21\u7cca\u8bcd\u6c47\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u5173\u952e\u9636\u6bb5\u7684\u62bd\u6837\u6570\u636e\u6216\u6700\u7ec8\u503c\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u4e2a**\u57fa\u51c6\u5de5\u51b5\uff08Baseline Operating Condition\uff09**\u7684\u6a21\u62df\u5206\u6790\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21**\u57fa\u51c6\u5de5\u51b5**\u6a21\u62df\u7684\u76ee\u7684\u3001\u5173\u952e\u53d1\u73b0\u548c\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0**\u57fa\u51c6\u5de5\u51b5**\u6a21\u62df\u7684\u80cc\u666f\u548c\u76ee\u6807\uff0c\u63d0\u53ca\u5173\u952e\u7684\u8f93\u5165\u53c2\u6570\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n        *   \u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u6c1a\u81ea\u6301\u65f6\u95f4\u3001\u500d\u589e\u65f6\u95f4\u7b49\uff0c\u5982\u679c\u6570\u636e\u53ef\u7528\uff09\u7684\u603b\u4f53\u8d8b\u52bf\u3002\n        *   \u5bf9\u5173\u952e\u8f6c\u6298\u70b9\uff08\u4f8b\u5982\u6c1a\u5e93\u5b58\u7684\u6700\u4f4e\u70b9\uff09\u7684\u7269\u7406\u610f\u4e49\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002\n        *   \u8bc4\u4f30\u7cfb\u7edf\u5728\u6a21\u62df\u7ed3\u675f\u65f6\u7684\u6700\u7ec8\u72b6\u6001\uff0c\u5e76\u8ba8\u8bba\u6c1a\u5728\u5404\u5b50\u7cfb\u7edf\u4e2d\u7684\u5206\u5e03\u60c5\u51b5\u3002\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u6a21\u62df\u7814\u7a76\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\uff08\u5305\u62ec\u56fe\u8868\u548c\u8868\u683c\uff09\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n---\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a (`baseline_condition_analysis_report.md`)\n---\n{original_report_content}\n\n---\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868 (`sheets.csv`)\n---\n{glossary_content}\n\"\"\"\n\n        # 5. Call the API\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for academic summary for model {ai_model} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, instructions_prompt, analysis_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                academic_summary = response.choices[0].message.content\n\n                # 6. Save the result\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                summary_filename = (\n                    f\"academic_analysis_summary_{sanitized_model_name}.md\"\n                )\n                summary_path = os.path.join(output_dir, summary_filename)\n                with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(academic_summary)\n\n                logger.info(\n                    f\"Successfully generated academic analysis summary: {summary_path}\"\n                )\n                return  # Exit after success\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling OpenAI API for academic summary on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to generate academic summary for {ai_model} after {max_retries} attempts.\"\n                    )\n                    return  # Exit after all retries failed\n\n    except Exception as e:\n        logger.error(\n            f\"Error in generate_academic_report for model {ai_model}: {e}\",\n            exc_info=True,\n        )\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.load_glossary","title":"<code>load_glossary(glossary_path)</code>","text":"<p>Loads glossary data from the specified CSV path into global dictionaries.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>glossary_path</code> <code>str</code> <p>Path to the glossary CSV file.</p> \u5fc5\u9700 Note <p>Expected columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\", \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Clears existing glossaries on error. Updates global _english_glossary_map and _chinese_glossary_map.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def load_glossary(glossary_path: str) -&gt; None:\n    \"\"\"Loads glossary data from the specified CSV path into global dictionaries.\n\n    Args:\n        glossary_path: Path to the glossary CSV file.\n\n    Note:\n        Expected columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\",\n        \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Clears existing glossaries on error.\n        Updates global _english_glossary_map and _chinese_glossary_map.\n    \"\"\"\n    global _english_glossary_map, _chinese_glossary_map\n\n    if not glossary_path or not os.path.exists(glossary_path):\n        logger.warning(\n            f\"Glossary file not found at {glossary_path}. No labels will be loaded.\"\n        )\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n        return\n\n    try:\n        df = pd.read_csv(glossary_path)\n        if (\n            \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\" in df.columns\n            and \"\u82f1\u6587\u672f\u8bed (English Term)\" in df.columns\n            and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\" in df.columns\n        ):\n            df.dropna(subset=[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"], inplace=True)\n            _english_glossary_map = pd.Series(\n                df[\"\u82f1\u6587\u672f\u8bed (English Term)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            _chinese_glossary_map = pd.Series(\n                df[\"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            logger.info(f\"Successfully loaded glossary from {glossary_path}.\")\n        else:\n            logger.warning(\"Glossary CSV does not contain expected columns.\")\n            _english_glossary_map = {}\n            _chinese_glossary_map = {}\n    except Exception as e:\n        logger.warning(f\"Failed to load or parse glossary file. Error: {e}\")\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.set_plot_language","title":"<code>set_plot_language(lang='en')</code>","text":"<p>Sets the preferred language for plot labels.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>lang</code> <code>str</code> <p>'en' for English (default), 'cn' for Chinese.</p> <code>'en'</code> Note <p>For Chinese, sets font to SimHei and adjusts unicode_minus. For English, restores matplotlib defaults. Changes apply globally to all subsequent plots.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def set_plot_language(lang: str = \"en\") -&gt; None:\n    \"\"\"Sets the preferred language for plot labels.\n\n    Args:\n        lang: 'en' for English (default), 'cn' for Chinese.\n\n    Note:\n        For Chinese, sets font to SimHei and adjusts unicode_minus. For English,\n        restores matplotlib defaults. Changes apply globally to all subsequent plots.\n    \"\"\"\n    global _use_chinese_labels\n    _use_chinese_labels = lang.lower() == \"cn\"\n\n    if _use_chinese_labels:\n        # To display Chinese characters correctly, specify a list of fallback fonts.\n        plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # \u66ff\u6362\u6210\u4f60\u7535\u8111\u4e0a\u6709\u7684\u5b57\u4f53\n        plt.rcParams[\"axes.unicode_minus\"] = False  # To display minus sign correctly.\n        plt.rcParams[\"font.family\"] = \"sans-serif\"  # \u786e\u4fdd\u5b57\u4f53\u5bb6\u65cf\u8bbe\u7f6e\u751f\u6548\n    else:\n        # Restore default settings\n        plt.rcParams[\"font.sans-serif\"] = plt.rcParamsDefault[\"font.sans-serif\"]\n        plt.rcParams[\"axes.unicode_minus\"] = plt.rcParamsDefault[\"axes.unicode_minus\"]\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.rise_analysis.analyze_rise_dip","title":"<code>analyze_rise_dip(results_df, output_dir, **kwargs)</code>","text":"<p>Analyzes parameter sweep results to identify curves that fail to exhibit 'dip and rise' feature.</p> <p>A curve exhibits the 'dip and rise' feature if: 1. It has a clear minimum point (not at boundaries) 2. Values at both start and end are higher than the minimum (with tolerance)</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>results_df</code> <code>DataFrame</code> <p>The combined DataFrame of simulation results, including time and multiple parameter combinations.</p> \u5fc5\u9700 <code>output_dir</code> <code>str</code> <p>The directory to save the analysis report.</p> \u5fc5\u9700 <code>**kwargs</code> <p>Additional parameters from config, e.g., 'output_filename'.</p> <code>{}</code> Note <p>Uses 0.1% smoothing window to handle noisy data. Column names expected in format 'variable&amp;param1=v1&amp;param2=v2'. Logs ERROR for each curve without the feature. Always generates rise_report.json with analysis results for all curves, including 'rises' boolean flag.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/postprocess/rise_analysis.py</code> <pre><code>def analyze_rise_dip(results_df: pd.DataFrame, output_dir: str, **kwargs) -&gt; None:\n    \"\"\"Analyzes parameter sweep results to identify curves that fail to exhibit 'dip and rise' feature.\n\n    A curve exhibits the 'dip and rise' feature if:\n    1. It has a clear minimum point (not at boundaries)\n    2. Values at both start and end are higher than the minimum (with tolerance)\n\n    Args:\n        results_df: The combined DataFrame of simulation results, including time and\n            multiple parameter combinations.\n        output_dir: The directory to save the analysis report.\n        **kwargs: Additional parameters from config, e.g., 'output_filename'.\n\n    Note:\n        Uses 0.1% smoothing window to handle noisy data. Column names expected in\n        format 'variable&amp;param1=v1&amp;param2=v2'. Logs ERROR for each curve without\n        the feature. Always generates rise_report.json with analysis results for\n        all curves, including 'rises' boolean flag.\n    \"\"\"\n    logger.info(\"Starting post-processing: Analyzing curve rise/dip features...\")\n    all_curves_info = []\n    error_count = 0\n\n    # Iterate over each column of the DataFrame (except for the 'time' column)\n    for col_name in results_df.columns:\n        if col_name == \"time\":\n            continue\n\n        # Parse parameters from the column name 'variable&amp;param1=v1&amp;param2=v2'\n        try:\n            parts = col_name.split(\"&amp;\")\n            if len(parts) &lt; 2:  # Must have at least one variable name and one parameter\n                logger.warning(\n                    f\"Column name '{col_name}' has an incorrect format, skipping.\"\n                )\n                continue\n\n            # parts[0] is the variable name, parse parameters from parts[1:]\n            param_parts = parts[1:]\n            job_params = dict(item.split(\"=\") for item in param_parts)\n            job_params[\"variable\"] = parts[\n                0\n            ]  # Also add the original variable name to the info\n\n        except (ValueError, IndexError):\n            logger.warning(\n                f\"Could not parse parameters from column name '{col_name}', skipping.\"\n            )\n            continue\n\n        series = results_df[col_name]\n        rises = False\n        if len(series) &gt; 2:\n            # This logic is inspired by `time_of_turning_point` from `tricys/analysis/metric.py`.\n            # It uses a smoothed series to determine if there is a 'dip and rise' trend.\n            window_size = max(1, int(len(series) * 0.001))  # 0.1% smoothing window\n            smoothed = series.rolling(\n                window=window_size, center=True, min_periods=1\n            ).mean()\n\n            min_pos_index = smoothed.idxmin()\n            min_val = smoothed.loc[min_pos_index]\n\n            logger.info(\n                f\"Analyzing curve '{col_name}': min at index {min_pos_index} with value {min_val}\"\n            )\n\n            # Check if the minimum is at the beginning or end of the series\n            is_min_at_boundary = (min_pos_index == smoothed.index[0]) or (\n                min_pos_index == smoothed.index[-1]\n            )\n\n            if not is_min_at_boundary:\n                # Check if it dips from the start and rises to the end.\n                # A small tolerance is used to avoid issues with noise.\n                series_range = smoothed.max() - smoothed.min()\n                # Avoid division by zero or NaN tolerance if series is flat\n                if series_range &gt; 1e-9:\n                    tolerance = series_range * 0.001  # 0.1% of range as tolerance\n                else:\n                    tolerance = 0\n\n                start_val = smoothed.iloc[0]\n                end_val = smoothed.iloc[-1]\n\n                if start_val &gt; min_val + tolerance and end_val &gt; min_val + tolerance:\n                    rises = True\n\n        # Record the analysis result for every curve\n        info = job_params.copy()\n        info[\"rises\"] = bool(rises)\n        all_curves_info.append(info)\n\n        # If the feature is not detected, log it at the ERROR level\n        if not rises:\n            error_count += 1\n            logger.error(\n                f\"Feature not detected: 'Dip and rise' feature was not found for the curve with parameters {job_params}.\"\n            )\n\n    # Generate a report file with all information unconditionally\n    output_filename = kwargs.get(\"output_filename\", \"rise_report.json\")\n    report_path = os.path.join(output_dir, output_filename)\n\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(all_curves_info, f, indent=4, ensure_ascii=False)\n\n    if error_count &gt; 0:\n        logger.info(\n            f\"{error_count} curves did not exhibit the expected feature. See report for details: {report_path}\"\n        )\n    else:\n        logger.info(\n            f\"All curves exhibit the expected 'dip and rise' feature. Report generated at: {report_path}\"\n        )\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.static_alarm.check_thresholds","title":"<code>check_thresholds(results_df, output_dir, rules, **kwargs)</code>","text":"<p>Analyzes simulation results to check if specified columns fall within threshold ranges.</p> <p>Supports both single tasks (column name as 'var') and parameter sweep tasks (column name as 'var&amp;param=value').</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>results_df</code> <code>DataFrame</code> <p>Merged simulation results DataFrame.</p> \u5fc5\u9700 <code>output_dir</code> <code>str</code> <p>Directory for saving alert reports.</p> \u5fc5\u9700 <code>rules</code> <code>List[Dict[str, Any]]</code> <p>List of rules, where each rule defines columns and their min/max thresholds. Format: [{\"columns\": [\"var1\", \"var2\"], \"min\": value, \"max\": value}, ...]</p> \u5fc5\u9700 <code>**kwargs</code> <p>Additional parameters from configuration, such as 'output_filename'.</p> <code>{}</code> Note <p>Logs ERROR for each threshold violation with peak/dip values. Generates alarm_report.json with parsed parameter information and 'has_alarm' flags. For columns matching 'base_col_name&amp;param=value', extracts parameters into separate fields in the report. Reports total alarm count in logs.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/postprocess/static_alarm.py</code> <pre><code>def check_thresholds(\n    results_df: pd.DataFrame, output_dir: str, rules: List[Dict[str, Any]], **kwargs\n) -&gt; None:\n    \"\"\"Analyzes simulation results to check if specified columns fall within threshold ranges.\n\n    Supports both single tasks (column name as 'var') and parameter sweep tasks\n    (column name as 'var&amp;param=value').\n\n    Args:\n        results_df: Merged simulation results DataFrame.\n        output_dir: Directory for saving alert reports.\n        rules: List of rules, where each rule defines columns and their min/max thresholds.\n            Format: [{\"columns\": [\"var1\", \"var2\"], \"min\": value, \"max\": value}, ...]\n        **kwargs: Additional parameters from configuration, such as 'output_filename'.\n\n    Note:\n        Logs ERROR for each threshold violation with peak/dip values. Generates\n        alarm_report.json with parsed parameter information and 'has_alarm' flags.\n        For columns matching 'base_col_name&amp;param=value', extracts parameters into\n        separate fields in the report. Reports total alarm count in logs.\n    \"\"\"\n    logger.info(\"Starting post-processing: Checking thresholds...\")\n\n    # Use a dictionary to track the alarm status of each checked column\n    checked_columns_status = {}\n\n    for i, rule in enumerate(rules):\n        min_val = rule.get(\"min\")\n        max_val = rule.get(\"max\")\n        columns_to_check = rule.get(\"columns\", [])\n\n        if not columns_to_check:\n            logger.warning(f\"Rule {i+1} does not specify 'columns', skipping.\")\n            continue\n\n        # Iterate over each base column name specified in the rule\n        for base_col_name in columns_to_check:\n            # Iterate over all actual column names in the DataFrame to find matches\n            for df_col_name in results_df.columns:\n                if df_col_name == base_col_name or df_col_name.startswith(\n                    base_col_name + \"&amp;\"\n                ):\n\n                    # Initialize status for this column if it's the first time being checked\n                    if df_col_name not in checked_columns_status:\n                        checked_columns_status[df_col_name] = (\n                            False  # Default to no alarm\n                        )\n\n                    # Check for values exceeding the maximum threshold\n                    if max_val is not None:\n                        exceeded_max = results_df[results_df[df_col_name] &gt; max_val]\n                        if not exceeded_max.empty:\n                            peak_value = exceeded_max[df_col_name].max()\n                            logger.error(\n                                f\"ALARM: Column '{df_col_name}' exceeds maximum threshold (Threshold: {max_val}, Value: {peak_value})\"\n                            )\n                            checked_columns_status[df_col_name] = True\n\n                    # Check for values falling below the minimum threshold\n                    if min_val is not None:\n                        exceeded_min = results_df[results_df[df_col_name] &lt; min_val]\n                        if not exceeded_min.empty:\n                            dip_value = exceeded_min[df_col_name].min()\n                            logger.error(\n                                f\"ALARM: Column '{df_col_name}' is below minimum threshold (Threshold: {min_val}, Value: {dip_value})\"\n                            )\n                            checked_columns_status[df_col_name] = True\n\n    # Convert to the final report format, parsing column names to include parameters\n    final_report = []\n    for col, status in checked_columns_status.items():\n        try:\n            report_item = {}\n            parts = col.split(\"&amp;\")\n\n            # For single runs, the column name may not contain '&amp;'\n            if len(parts) == 1:\n                report_item[\"variable\"] = parts[0]\n            else:\n                variable_name = parts[0]\n                param_parts = parts[1:]\n                report_item = dict(item.split(\"=\") for item in param_parts)\n                report_item[\"variable\"] = variable_name\n\n            report_item[\"has_alarm\"] = status\n            final_report.append(report_item)\n\n        except (ValueError, IndexError):\n            logger.warning(\n                f\"Could not parse column name '{col}' for the report, using the original name as a fallback.\"\n            )\n            # Fallback to the old format if parsing fails\n            final_report.append({\"column\": col, \"has_alarm\": status})\n\n    output_filename = kwargs.get(\"output_filename\", \"alarm_report.json\")\n    report_path = os.path.join(output_dir, output_filename)\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(final_report, f, indent=4, ensure_ascii=False)\n\n    total_alarms = sum(1 for entry in final_report if entry[\"has_alarm\"])\n    if total_alarms &gt; 0:\n        logger.info(\n            f\"{total_alarms} columns with alarms were found. See logs for details. Report generated at: {report_path}\"\n        )\n    else:\n        logger.info(\n            f\"Threshold check complete. All checked columns are within their thresholds. Report generated at: {report_path}\"\n        )\n</code></pre>"},{"location":"api/tricys_simulation.html","title":"API \u53c2\u8003 - \u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation)","text":"<p>\u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation)</p> <p>\u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation) \u5305\u542b\u4e86 TRICYS \u7684\u4e3b\u8981\u6267\u884c\u811a\u672c\uff0c\u8d1f\u8d23\u542f\u52a8\u6807\u51c6\u4eff\u771f\u548c\u5206\u6790\u5de5\u4f5c\u6d41\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Standard Simulation (\u6807\u51c6\u4eff\u771f)Simulation Analysis (\u4eff\u771f\u5206\u6790)"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation.main","title":"<code>main(config_path)</code>","text":"<p>Main entry point for a standard simulation run.</p> <p>This function prepares the configuration, sets up logging, and calls the main <code>run_simulation</code> orchestrator.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config_path</code> <code>str</code> <p>The path to the JSON configuration file.</p> \u5fc5\u9700 \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/simulation/simulation.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point for a standard simulation run.\n\n    This function prepares the configuration, sets up logging, and calls\n    the main `run_simulation` orchestrator.\n\n    Args:\n        config_path (str): The path to the JSON configuration file.\n    \"\"\"\n    config, original_config = basic_prepare_config(config_path)\n    setup_logging(config, original_config)\n    logger.info(\n        \"Loading configuration\",\n        extra={\n            \"config_path\": os.path.abspath(config_path),\n        },\n    )\n    try:\n        run_simulation(config)\n        logger.info(\"Main execution completed successfully\")\n    except Exception as e:\n        logger.error(\n            \"Main execution failed\", exc_info=True, extra={\"exception\": str(e)}\n        )\n        sys.exit(1)\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation.run_simulation","title":"<code>run_simulation(config)</code>","text":"<p>Orchestrates the main simulation workflow.</p> <p>This function serves as the primary orchestrator for running simulations. It generates jobs from parameters, executes them (concurrently or sequentially, as standard or co-simulations), merges the results into a single DataFrame, and triggers any configured post-processing steps.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary for the run.</p> \u5fc5\u9700 Note <p>Supports concurrent (ThreadPoolExecutor) and sequential execution modes. Co-simulations use ProcessPoolExecutor for better isolation. Merges all job results into single CSV with parameter-labeled columns. Triggers post-processing tasks if configured. Results saved to paths.results_dir.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/simulation/simulation.py</code> <pre><code>def run_simulation(config: Dict[str, Any]) -&gt; None:\n    \"\"\"Orchestrates the main simulation workflow.\n\n    This function serves as the primary orchestrator for running simulations.\n    It generates jobs from parameters, executes them (concurrently or sequentially,\n    as standard or co-simulations), merges the results into a single DataFrame,\n    and triggers any configured post-processing steps.\n\n    Args:\n        config: The main configuration dictionary for the run.\n\n    Note:\n        Supports concurrent (ThreadPoolExecutor) and sequential execution modes.\n        Co-simulations use ProcessPoolExecutor for better isolation. Merges all job\n        results into single CSV with parameter-labeled columns. Triggers post-processing\n        tasks if configured. Results saved to paths.results_dir.\n    \"\"\"\n    jobs = generate_simulation_jobs(config.get(\"simulation_parameters\", {}))\n\n    try:\n        results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n    except KeyError as e:\n        logger.error(f\"Missing required path key in configuration file: {e}\")\n        sys.exit(1)\n\n    simulation_results = {}\n    use_concurrent = config[\"simulation\"].get(\"concurrent\", False)\n\n    try:\n        max_workers = config[\"simulation\"].get(\"max_workers\", os.cpu_count())\n        if config.get(\"co_simulation\") is None:\n            if use_concurrent:\n                logger.info(\n                    \"Starting simulation\",\n                    extra={\n                        \"mode\": \"CONCURRENT\",\n                        \"max_workers\": max_workers,\n                    },\n                )\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_single_job, config, job_params, i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            result_path = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n            else:\n                logger.info(\"Starting simulation\", extra={\"mode\": \"SEQUENTIAL\"})\n                result_paths = _run_sequential_sweep(config, jobs)\n                for i, result_path in enumerate(result_paths):\n                    if result_path:\n                        simulation_results[tuple(sorted(jobs[i].items()))] = result_path\n        else:\n            if use_concurrent:\n                logger.info(\n                    \"Starting co-simulation\",\n                    extra={\n                        \"mode\": \"CONCURRENT\",\n                        \"max_workers\": max_workers,\n                    },\n                )\n\n                with concurrent.futures.ProcessPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_co_simulation, config, job_params, job_id=i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            result_path = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                                logger.info(\n                                    \"Successfully finished co-simulation job\",\n                                    extra={\n                                        \"job_params\": job_params,\n                                    },\n                                )\n                            else:\n                                logger.warning(\n                                    \"Co-simulation job did not return a result path\",\n                                    extra={\n                                        \"job_params\": job_params,\n                                    },\n                                )\n                        except Exception as exc:\n                            logger.error(\n                                \"Co-simulation job generated an exception\",\n                                exc_info=True,\n                                extra={\n                                    \"job_params\": job_params,\n                                    \"exception\": str(exc),\n                                },\n                            )\n            else:\n                logger.info(\"Starting co-simulation\", extra={\"mode\": \"SEQUENTIAL\"})\n                for i, job_params in enumerate(jobs):\n                    job_id = i + 1\n                    logger.info(\n                        \"Starting Sequential Co-simulation Job\",\n                        extra={\n                            \"job_index\": f\"{job_id}/{len(jobs)}\",\n                        },\n                    )\n                    try:\n                        result_path = _run_co_simulation(\n                            config, job_params, job_id=job_id\n                        )\n                        if result_path:\n                            simulation_results[tuple(sorted(job_params.items()))] = (\n                                result_path\n                            )\n                            logger.info(\n                                \"Successfully finished co-simulation job\",\n                                extra={\n                                    \"job_params\": job_params,\n                                },\n                            )\n                        else:\n                            logger.warning(\n                                \"Co-simulation job did not return a result path\",\n                                extra={\n                                    \"job_params\": job_params,\n                                },\n                            )\n                    except Exception as exc:\n                        logger.error(\n                            \"Co-simulation job generated an exception\",\n                            exc_info=True,\n                            extra={\n                                \"job_params\": job_params,\n                                \"exception\": str(exc),\n                            },\n                        )\n                    logger.info(\n                        \"Finished Sequential Co-simulation Job\",\n                        extra={\n                            \"job_index\": f\"{job_id}/{len(jobs)}\",\n                        },\n                    )\n    except Exception as e:\n        raise RuntimeError(\"Failed to run simulation\", e)\n\n    # --- Result Handling ---\n    # The simulation_results dictionary now contains paths to results inside temporary job workspaces.\n    # The results_dir from the config is now the self-contained workspace's results folder.\n    run_results_dir = results_dir\n    os.makedirs(run_results_dir, exist_ok=True)\n\n    # Unified result processing for both single and multiple jobs\n    logger.info(\n        \"Processing jobs and combining results\",\n        extra={\n            \"num_jobs\": len(jobs),\n        },\n    )\n    combined_df = None\n\n    all_dfs = []\n    time_df_added = False\n\n    for job_params in jobs:\n        job_key = tuple(sorted(job_params.items()))\n        result_path = simulation_results.get(job_key)\n\n        if not result_path or not os.path.exists(result_path):\n            logger.warning(\n                \"Job produced no result file\",\n                extra={\n                    \"job_params\": job_params,\n                },\n            )\n            continue\n\n        # Read the current job's result file\n        df = pd.read_csv(result_path)\n\n        # From the very first valid DataFrame, grab the 'time' column\n        if not time_df_added and \"time\" in df.columns:\n            all_dfs.append(df[[\"time\"]])\n            time_df_added = True\n\n        # Prepare the parameter string for column renaming\n        param_string = \"&amp;\".join([f\"{k}={v}\" for k, v in job_params.items()])\n\n        # Isolate the data columns (everything except 'time')\n        data_columns = df.drop(columns=[\"time\"], errors=\"ignore\")\n\n        # Create a dictionary to map old column names to new ones\n        # e.g., {'voltage': 'voltage&amp;param1=A&amp;param2=B'}\n        rename_mapping = {\n            col: f\"{col}&amp;{param_string}\" if param_string else col\n            for col in data_columns.columns\n        }\n\n        # Rename the columns and add the resulting DataFrame to our list\n        all_dfs.append(data_columns.rename(columns=rename_mapping))\n\n    # Concatenate all the DataFrames in the list along the columns axis (axis=1)\n    if all_dfs:\n        combined_df = pd.concat(all_dfs, axis=1)\n    else:\n        combined_df = pd.DataFrame()  # Or None, as you had before\n\n    if combined_df is not None and not combined_df.empty:\n        if len(jobs) == 1:\n            # For single job, save as simulation_result.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"simulation_result.csv\"\n            )\n        else:\n            # For multiple jobs, save as sweep_results.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"sweep_results.csv\"\n            )\n\n        combined_df.to_csv(combined_csv_path, index=False)\n        logger.info(\n            \"Combined results saved\",\n            extra={\n                \"file_path\": combined_csv_path,\n            },\n        )\n    else:\n        logger.warning(\"No valid results found to combine\")\n\n    # --- Post-Processing ---\n    if combined_df is not None:\n        # Calculate the top-level post-processing directory\n        top_level_run_workspace = os.path.abspath(config[\"run_timestamp\"])\n        top_level_post_processing_dir = os.path.join(\n            top_level_run_workspace, \"post_processing\"\n        )\n        _run_post_processing(config, combined_df, top_level_post_processing_dir)\n    else:\n        logger.warning(\"No simulation results generated, skipping post-processing\")\n\n    # --- Final Cleanup ---\n    # The primary cleanup of job workspaces is handled by the `finally` block in `_run_co_simulation`.\n    # This is an additional safeguard.\n    if not config[\"simulation\"].get(\"keep_temp_files\", True):\n        temp_dir_path = os.path.abspath(config[\"paths\"].get(\"temp_dir\", \"temp\"))\n        logger.info(\n            \"Cleaning up temporary directory\",\n            extra={\n                \"directory\": temp_dir_path,\n            },\n        )\n        if os.path.exists(temp_dir_path):\n            try:\n                shutil.rmtree(temp_dir_path)\n                os.makedirs(temp_dir_path)  # Recreate for next run\n            except OSError as e:\n                logger.error(\n                    \"Error cleaning up temporary directory\",\n                    extra={\n                        \"directory\": temp_dir_path,\n                        \"error\": str(e),\n                    },\n                )\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation_analysis.main","title":"<code>main(config_path)</code>","text":"<p>Main entry point for a simulation analysis run.</p> <p>This function prepares the configuration for an analysis run, sets up logging, and calls the main <code>run_simulation</code> orchestrator for analysis.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config_path</code> <code>str</code> <p>The path to the JSON configuration file.</p> \u5fc5\u9700 \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point for a simulation analysis run.\n\n    This function prepares the configuration for an analysis run, sets up\n    logging, and calls the main `run_simulation` orchestrator for analysis.\n\n    Args:\n        config_path (str): The path to the JSON configuration file.\n    \"\"\"\n    config, original_config = analysis_prepare_config(config_path)\n    setup_logging(config, original_config)\n    logger.info(\n        \"Loading configuration\",\n        extra={\n            \"config_path\": os.path.abspath(config_path),\n        },\n    )\n    try:\n        run_simulation(config)\n        logger.info(\"Main execution completed successfully\")\n    except Exception as e:\n        logger.error(\n            \"Main execution failed\", exc_info=True, extra={\"exception\": str(e)}\n        )\n        sys.exit(1)\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation_analysis.retry_analysis","title":"<code>retry_analysis(timestamp)</code>","text":"<p>Retries a failed AI analysis for a given run timestamp.</p> <p>This function restores the configuration from the log file of a previous run and re-triggers the AI-dependent parts of the analysis, including report generation and consolidation.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>timestamp</code> <code>str</code> <p>The timestamp of the run to retry (e.g., \"20230101_120000\").</p> \u5fc5\u9700 \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def retry_analysis(timestamp: str) -&gt; None:\n    \"\"\"Retries a failed AI analysis for a given run timestamp.\n\n    This function restores the configuration from the log file of a previous\n    run and re-triggers the AI-dependent parts of the analysis, including\n    report generation and consolidation.\n\n    Args:\n        timestamp (str): The timestamp of the run to retry (e.g., \"20230101_120000\").\n    \"\"\"\n    config, original_config = restore_configs_from_log(timestamp)\n    if not config or not original_config:\n        # Error is printed inside the helper function\n        sys.exit(1)\n\n    config[\"run_timestamp\"] = timestamp\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        stream=sys.stdout,\n    )\n    logger = logging.getLogger(__name__)\n    logger.info(\n        f\"Successfully restored configuration for timestamp {timestamp} for retry.\"\n    )\n\n    logger.info(\"Starting in AI analysis retry mode...\")\n    if not analysis_validate_config(config):\n        sys.exit(1)\n\n    case_configs = analysis_setup_analysis_cases_workspaces(config)\n    if not case_configs:\n        logger.error(\"Could not set up case workspaces for retry. Aborting.\")\n        sys.exit(1)\n\n    retry_ai_analysis(case_configs, config)\n    consolidate_reports(case_configs, config)\n\n    logger.info(\"AI analysis retry and consolidation complete.\")\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation_analysis.run_simulation","title":"<code>run_simulation(config)</code>","text":"<p>Orchestrates the simulation analysis workflow.</p> <p>This is the main orchestrator for a simulation analysis run. It handles different execution paths based on the configuration: - If 'analysis_cases' are defined, it sets up and executes each case,   potentially in parallel. - If a SALib analysis is defined, it delegates to the SALib workflow. - Otherwise, it runs a standard parameter sweep, merges results,   generates plots, and triggers sensitivity analysis and post-processing.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary for the run.</p> \u5fc5\u9700 Note <p>Supports three modes: multi-case analysis (analysis_cases), SALib analysis (independent_variable as list with analyzer), or standard parameter sweep. For multi-case mode, creates isolated workspaces and can run cases in parallel with ProcessPoolExecutor. Generates summary reports and handles AI analysis retries if configured.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def run_simulation(config: Dict[str, Any]) -&gt; None:\n    \"\"\"Orchestrates the simulation analysis workflow.\n\n    This is the main orchestrator for a simulation analysis run. It handles\n    different execution paths based on the configuration:\n    - If 'analysis_cases' are defined, it sets up and executes each case,\n      potentially in parallel.\n    - If a SALib analysis is defined, it delegates to the SALib workflow.\n    - Otherwise, it runs a standard parameter sweep, merges results,\n      generates plots, and triggers sensitivity analysis and post-processing.\n\n    Args:\n        config: The main configuration dictionary for the run.\n\n    Note:\n        Supports three modes: multi-case analysis (analysis_cases), SALib analysis\n        (independent_variable as list with analyzer), or standard parameter sweep.\n        For multi-case mode, creates isolated workspaces and can run cases in parallel\n        with ProcessPoolExecutor. Generates summary reports and handles AI analysis retries\n        if configured.\n    \"\"\"\n\n    # 1. Split analysis_cases and determine salib_analysis_case\n    has_analysis_cases = (\n        \"sensitivity_analysis\" in config\n        and \"analysis_cases\" in config[\"sensitivity_analysis\"]\n        and (\n            # Support list format\n            (\n                isinstance(config[\"sensitivity_analysis\"][\"analysis_cases\"], list)\n                and len(config[\"sensitivity_analysis\"][\"analysis_cases\"]) &gt; 0\n            )\n            or\n            # Support single object format\n            isinstance(config[\"sensitivity_analysis\"][\"analysis_cases\"], dict)\n        )\n    )\n\n    # Check if it's a SALib analysis case (and not a multi-case analysis)\n    sa_config = config.get(\"sensitivity_analysis\", {})\n    analysis_case = sa_config.get(\"analysis_case\")\n\n    has_salib_analysis_case = (\n        not has_analysis_cases\n        and isinstance(analysis_case, dict)\n        and isinstance(analysis_case.get(\"independent_variable\"), list)\n        and isinstance(analysis_case.get(\"independent_variable_sampling\"), dict)\n        and \"analyzer\" in analysis_case\n    )\n\n    if has_analysis_cases and not has_salib_analysis_case:\n        logger.info(\n            \"Detected analysis_cases field, starting to create independent working directories for each analysis case...\"\n        )\n\n        # Create independent working directories and configuration files for each analysis_case\n        case_configs = analysis_setup_analysis_cases_workspaces(config)\n\n        if not case_configs:\n            logger.error(\n                \"Unable to create analysis_cases working directories, stopping execution\"\n            )\n            return\n\n        logger.info(f\"Starting execution of {len(case_configs)} analysis cases...\")\n\n        sa_config = config.get(\"sensitivity_analysis\", {})\n        run_cases_concurrently = sa_config.get(\"concurrent_cases\", False)\n        successful_cases = 0\n\n        if run_cases_concurrently:\n            logger.info(\n                f\"Starting execution of {len(case_configs)} analysis cases in PARALLEL.\"\n            )\n            max_workers = sa_config.get(\"max_case_workers\", os.cpu_count())\n            logger.info(\n                f\"Using up to {max_workers} parallel processes for analysis cases.\"\n            )\n\n            with concurrent.futures.ProcessPoolExecutor(\n                max_workers=max_workers\n            ) as executor:\n                future_to_case = {\n                    executor.submit(_execute_analysis_case, case_info): case_info\n                    for case_info in case_configs\n                }\n                for future in concurrent.futures.as_completed(future_to_case):\n                    case_info = future_to_case[future]\n                    case_name = case_info[\"case_data\"].get(\"name\", case_info[\"index\"])\n                    try:\n                        if future.result():\n                            successful_cases += 1\n                            logger.info(\n                                f\"Parallel case '{case_name}' completed successfully.\"\n                            )\n                        else:\n                            logger.warning(\n                                f\"Parallel case '{case_name}' completed with errors.\"\n                            )\n                    except Exception as exc:\n                        logger.error(\n                            f\"Parallel case '{case_name}' failed in executor with: {exc}\",\n                            exc_info=True,\n                        )\n        else:\n            logger.info(\n                f\"Starting execution of {len(case_configs)} analysis cases SEQUENTIALLY.\"\n            )\n            for case_info in case_configs:\n                try:\n                    case_index = case_info[\"index\"]\n                    case_workspace = case_info[\"workspace\"]\n                    case_config = case_info[\"config\"]\n                    case_data = case_info[\"case_data\"]\n\n                    logger.info(\n                        f\"\\n=== Starting execution of analysis case {case_index + 1}/{len(case_configs)} ===\"\n                    )\n                    logger.info(\n                        f\"Case name: {case_data.get('name', f'Case{case_index+1}')}\"\n                    )\n                    logger.info(\n                        f\"Independent variable: {case_data['independent_variable']}\"\n                    )\n                    logger.info(f\"Working directory: {case_workspace}\")\n\n                    original_cwd = os.getcwd()\n                    os.chdir(case_workspace)\n\n                    try:\n                        setup_logging(case_config)\n                        run_simulation(case_config)\n                        successful_cases += 1\n                        logger.info(\n                            f\"\u2713 Analysis case {case_index + 1} executed successfully\"\n                        )\n                    except Exception as case_e:\n                        logger.error(\n                            f\"\u2717 Analysis case {case_index + 1} execution failed: {case_e}\",\n                            exc_info=True,\n                        )\n                    finally:\n                        os.chdir(original_cwd)\n                        setup_logging(config)\n\n                except Exception as e:\n                    logger.error(\n                        f\"\u2717 Error processing analysis case {case_index + 1}: {e}\",\n                        exc_info=True,\n                    )\n\n        logger.info(\"\\n=== Analysis Cases Execution Completed ===\")\n        logger.info(\n            f\"Successfully executed: {successful_cases}/{len(case_configs)} cases\"\n        )\n\n        generate_analysis_cases_summary(case_configs, config)\n\n        return  # End analysis_cases processing\n    elif has_salib_analysis_case:\n        logger.info(\"Detected SALib analysis case, diverting to SALib workflow...\")\n        run_salib_analysis(config)\n        return  # SALib workflow is self-contained, so we exit here.\n\n    # 2. Core operational logic\n    jobs = generate_simulation_jobs(config.get(\"simulation_parameters\", {}))\n\n    # --- START: Add baseline jobs based on default parameter values ---\n    analysis_case = config.get(\"sensitivity_analysis\", {}).get(\"analysis_case\", {})\n    default_values = analysis_case.get(\"default_simulation_values\")\n\n    if default_values:\n        logger.info(\n            \"Found default_simulation_values, generating additional baseline jobs.\"\n        )\n\n        # Prepare simulation parameters for the baseline run, starting with default values\n        baseline_params = default_values.copy()\n\n        # Add the main independent variable sweep to the baseline parameters\n        independent_var = analysis_case.get(\"independent_variable\")\n        independent_sampling = analysis_case.get(\"independent_variable_sampling\")\n\n        if independent_var and independent_sampling:\n            baseline_params[independent_var] = independent_sampling\n\n            # Generate the additional jobs using the baseline config\n            default_jobs = generate_simulation_jobs(baseline_params)\n\n            # Combine with existing jobs and deduplicate\n            combined_jobs = jobs + default_jobs\n\n            # Deduplicate the list of job dictionaries\n            seen = set()\n            unique_jobs = []\n            for job in combined_jobs:\n                job_tuple = tuple(sorted(job.items()))\n                if job_tuple not in seen:\n                    seen.add(job_tuple)\n                    unique_jobs.append(job)\n\n            logger.info(\n                f\"Original jobs: {len(jobs)}, Combined jobs: {len(combined_jobs)}, Unique jobs after deduplication: {len(unique_jobs)}\"\n            )\n            jobs = unique_jobs\n    # --- END: Add baseline jobs ---\n\n    try:\n        results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n    except KeyError as e:\n        logger.error(f\"Missing required path key in configuration file: {e}\")\n        sys.exit(1)\n\n    simulation_results = {}\n    use_concurrent = config[\"simulation\"].get(\"concurrent\", False)\n\n    try:\n        if config.get(\"co_simulation\") is None:\n            if use_concurrent:\n                logger.info(\"Starting simulation in CONCURRENT mode.\")\n                max_workers = config[\"simulation\"].get(\"max_workers\", os.cpu_count())\n                logger.info(f\"Using up to {max_workers} parallel workers.\")\n                final_results = []\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_single_job, config, job_params, i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            (\n                                optimal_params,\n                                optimal_values,\n                                result_path,\n                            ) = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n\n                if _get_optimization_tasks(config):\n                    results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n                    os.makedirs(results_dir, exist_ok=True)\n                    if final_results:\n                        final_df = pd.DataFrame(final_results)\n                        output_path = os.path.join(\n                            results_dir, \"requierd_tbr_summary.csv\"\n                        )\n                        final_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n                        logger.info(\n                            f\"Sweep optimization summary saved to: {output_path}\"\n                        )\n            else:\n                logger.info(\"Starting simulation in SEQUENTIAL mode.\")\n                result_paths = _run_sequential_sweep(config, jobs)\n                for i, result_path in enumerate(result_paths):\n                    if result_path:\n                        simulation_results[tuple(sorted(jobs[i].items()))] = result_path\n        else:\n            if use_concurrent:\n                logger.info(\"Starting co-simulation in CONCURRENT mode.\")\n                max_workers = config[\"simulation\"].get(\"max_workers\", 4)\n                logger.info(f\"Using up to {max_workers} parallel processes.\")\n\n                final_results = []\n\n                with concurrent.futures.ProcessPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_co_simulation, config, job_params, job_id=i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            (\n                                optimal_params,\n                                optimal_values,\n                                result_path,\n                            ) = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                                logger.info(\n                                    f\"Successfully finished job for params: {job_params}\"\n                                )\n                            else:\n                                logger.warning(\n                                    f\"Job for params {job_params} did not return a result path.\"\n                                )\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for params {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n            else:\n                logger.info(\"Starting co-simulation in SEQUENTIAL mode.\")\n                final_results = []\n                for i, job_params in enumerate(jobs):\n                    job_id = i + 1\n                    logger.info(f\"--- Starting Sequential Job {job_id}/{len(jobs)} ---\")\n                    try:\n                        (\n                            optimal_params,\n                            optimal_values,\n                            result_path,\n                        ) = _run_co_simulation(config, job_params, job_id=job_id)\n                        if result_path:\n                            simulation_results[tuple(sorted(job_params.items()))] = (\n                                result_path\n                            )\n                            logger.info(\n                                f\"Successfully finished job for params: {job_params}\"\n                            )\n                        else:\n                            logger.warning(\n                                f\"Job for params {job_params} did not return a result path.\"\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n                    except Exception as exc:\n                        logger.error(\n                            f\"Job for params {job_params} generated an exception: {exc}\",\n                            exc_info=True,\n                        )\n                    logger.info(f\"--- Finished Sequential Job {job_id}/{len(jobs)} ---\")\n\n            if _get_optimization_tasks(config):\n                results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n                os.makedirs(results_dir, exist_ok=True)\n                if final_results:\n                    final_df = pd.DataFrame(final_results)\n                    output_path = os.path.join(results_dir, \"requierd_tbr_summary.csv\")\n                    final_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n                    logger.info(f\"Sweep optimization summary saved to: {output_path}\")\n    except Exception as e:\n        raise RuntimeError(f\"Failed to run simualtion: {e}\")\n\n    # 3. Data merging and processing\n    run_results_dir = results_dir\n    os.makedirs(run_results_dir, exist_ok=True)\n\n    # Unified result processing for both single and multiple jobs\n    logger.info(f\"Processing {len(jobs)} job(s). Combining results.\")\n    combined_df = None\n\n    all_dfs = []\n    time_df_added = False\n\n    for job_params in jobs:\n        job_key = tuple(sorted(job_params.items()))\n        result_path = simulation_results.get(job_key)\n\n        if not result_path or not os.path.exists(result_path):\n            logger.warning(f\"Job {job_params} produced no result file. Skipping.\")\n            continue\n\n        # Read the current job's result file\n        df = pd.read_csv(result_path)\n\n        # From the very first valid DataFrame, grab the 'time' column\n        if not time_df_added and \"time\" in df.columns:\n            all_dfs.append(df[[\"time\"]])\n            time_df_added = True\n\n        # Prepare the parameter string for column renaming\n        param_string = \"&amp;\".join([f\"{k}={v}\" for k, v in job_params.items()])\n\n        # Isolate the data columns (everything except 'time')\n        data_columns = df.drop(columns=[\"time\"], errors=\"ignore\")\n\n        # Create a dictionary to map old column names to new ones\n        # e.g., {'voltage': 'voltage&amp;param1=A&amp;param2=B'}\n        rename_mapping = {\n            col: f\"{col}&amp;{param_string}\" if param_string else col\n            for col in data_columns.columns\n        }\n\n        # Rename the columns and add the resulting DataFrame to our list\n        all_dfs.append(data_columns.rename(columns=rename_mapping))\n\n    # Concatenate all the DataFrames in the list along the columns axis (axis=1)\n    if all_dfs:\n        combined_df = pd.concat(all_dfs, axis=1)\n    else:\n        combined_df = pd.DataFrame()  # Or None, as you had before\n\n    if combined_df is not None and not combined_df.empty:\n        if len(jobs) == 1:\n            # For single job, save as simulation_result.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"simulation_result.csv\"\n            )\n        else:\n            # For multiple jobs, save as sweep_results.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"sweep_results.csv\"\n            )\n\n        # Clean up rows where the 'time' column is blank, which often occurs as redundant rows at the end of the file.\n        combined_df.dropna(subset=[\"time\"], inplace=True)\n        combined_df.to_csv(combined_csv_path, index=False)\n        logger.info(f\"Combined results saved to: {combined_csv_path}\")\n    else:\n        logger.warning(\"No valid results found to combine.\")\n\n    # Check if sweep_time plotting is enabled\n    analysis_case = config[\"sensitivity_analysis\"].get(\"analysis_case\", {})\n    sweep_time_list = analysis_case.get(\"sweep_time\", None)\n    if sweep_time_list and len(sweep_time_list) &gt;= 1:\n        # Get parameters for plot_sweep_time_series\n        independent_var = analysis_case.get(\"independent_variable\")\n        dependent_vars = analysis_case.get(\"dependent_variables\", [])\n        independent_var_alias = analysis_case.get(\"independent_variable_alias\")\n\n        if (\n            independent_var\n            and dependent_vars\n            and combined_csv_path\n            and os.path.exists(combined_csv_path)\n        ):\n\n            try:\n                # Get default values if they exist to filter the plot\n                default_values = analysis_case.get(\"default_simulation_values\")\n\n                plot_path = plot_sweep_time_series(\n                    csv_path=combined_csv_path,\n                    save_dir=run_results_dir,\n                    y_var_name=sweep_time_list,\n                    independent_var_name=independent_var,\n                    independent_var_alias=independent_var_alias,\n                    default_params=default_values,  # Pass default values to the plot function\n                    glossary_path=config[\"sensitivity_analysis\"].get(\n                        \"glossary_path\", None\n                    ),\n                )\n                if plot_path:\n                    logger.info(f\"Sweep time series plot generated: {plot_path}\")\n                else:\n                    logger.warning(\"Failed to generate sweep time series plot\")\n            except Exception as e:\n                logger.error(f\"Error generating sweep time series plot: {e}\")\n\n    # 4. Sensitivity analysis\n    _run_sensitivity_analysis(config, run_results_dir, jobs)\n\n    # 5. Post-processing\n    if combined_df is not None:\n        # Calculate the top-level post-processing directory\n        top_level_run_workspace = os.path.abspath(\"post_processing\")\n        _run_post_processing(config, combined_df, top_level_run_workspace)\n    else:\n        logger.warning(\n            \"No simulation results were generated, skipping post-processing.\"\n        )\n\n    # 6. Intermediate data cleaning\n    if not config[\"simulation\"].get(\"keep_temp_files\", True):\n        logger.info(\"Cleaning up temporary directory...\")\n        temp_dir_path = os.path.abspath(config[\"paths\"].get(\"temp_dir\", \"temp\"))\n        if os.path.exists(temp_dir_path):\n            try:\n                shutil.rmtree(temp_dir_path)\n                os.makedirs(temp_dir_path)  # Recreate for next run\n            except OSError as e:\n                logger.error(f\"Error cleaning up temp directory: {e}\")\n</code></pre>"},{"location":"api/tricys_utils.html","title":"API \u53c2\u8003 - \u5de5\u5177\u51fd\u6570 (Utilities)","text":"<p>\u5de5\u5177\u51fd\u6570 (Utilities)</p> <p>\u5de5\u5177\u51fd\u6570 (Utilities) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u7528\u4e8e\u914d\u7f6e\u5904\u7406\u3001\u6587\u4ef6\u64cd\u4f5c\u3001\u65e5\u5fd7\u8bb0\u5f55\u548c\u6570\u636e\u5e93\u4ea4\u4e92\u7684\u8f85\u52a9\u51fd\u6570\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Config Utils (\u914d\u7f6e\u5de5\u5177)File Utils (\u6587\u4ef6\u5de5\u5177)Log Utils (\u65e5\u5fd7\u5de5\u5177)SQLite Utils (\u6570\u636e\u5e93\u5de5\u5177) <p>Configuration utility functions for tricys.</p> <p>Utility functions for file and directory management.</p> <p>This module provides helper functions for creating unique filenames and managing log file rotation.</p> <p>Utilities for interacting with the simulation parameter SQLite database.</p> <p>This module provides functions to create, store, update, and retrieve simulation parameter data from a SQLite database file.</p>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_prepare_config","title":"<code>analysis_prepare_config(config_path)</code>","text":"<p>Loads, validates, and prepares the configuration from the given path.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_prepare_config(config_path: str) -&gt; tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Loads, validates, and prepares the configuration from the given path.\"\"\"\n    try:\n        config_path = os.path.abspath(config_path)\n        with open(config_path, \"r\") as f:\n            base_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        print(\n            f\"ERROR: Failed to load or parse config file {config_path}: {e}\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    original_config_dir = os.path.dirname(config_path)\n    absolute_config = convert_relative_paths_to_absolute(\n        base_config, original_config_dir\n    )\n\n    # Perform all validation on the config with absolute paths\n    analysis_validate_config(absolute_config)\n\n    config = json.loads(json.dumps(absolute_config))\n    config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    config[\"paths\"][\"log_dir\"] = run_workspace\n    if \"paths\" not in config:\n        config[\"paths\"] = {}\n\n    original_string = config[\"simulation\"][\"variableFilter\"]\n    config[\"simulation\"][\"variableFilter\"] = original_string.replace(\n        \"[\", \"\\\\[[\"\n    ).replace(\"]\", \"]\\\\]\")\n\n    return config, base_config\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_setup_analysis_cases_workspaces","title":"<code>analysis_setup_analysis_cases_workspaces(config)</code>","text":"<p>Set up independent working directories and configuration files for multiple analysis_cases</p> <p>This function will: 1. Create independent working directories for each analysis_case in the current working directory 2. Convert relative paths in the original configuration to absolute paths 3. Convert analysis_cases format to standard analysis_case format 4. Generate independent config.json files for each case</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary containing analysis_cases</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[Dict[str, Any]]</code> <p>List containing information for each case, each element contains:</p> <code>List[Dict[str, Any]]</code> <ul> <li>index: Case index</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>workspace: Working directory path</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>config_path: Configuration file path</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>config: Configuration applicable to this case</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>case_data: Original case data</li> </ul> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_setup_analysis_cases_workspaces(\n    config: Dict[str, Any],\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Set up independent working directories and configuration files for multiple analysis_cases\n\n    This function will:\n    1. Create independent working directories for each analysis_case in the current working directory\n    2. Convert relative paths in the original configuration to absolute paths\n    3. Convert analysis_cases format to standard analysis_case format\n    4. Generate independent config.json files for each case\n\n    Args:\n        config: Original configuration dictionary containing analysis_cases\n\n    Returns:\n        List containing information for each case, each element contains:\n        - index: Case index\n        - workspace: Working directory path\n        - config_path: Configuration file path\n        - config: Configuration applicable to this case\n        - case_data: Original case data\n    \"\"\"\n\n    analysis_cases_raw = config[\"sensitivity_analysis\"][\"analysis_cases\"]\n\n    # Unified processing into list format\n    if isinstance(analysis_cases_raw, dict):\n        # Single analysis_case object\n        analysis_cases = [analysis_cases_raw]\n        logger.info(\n            \"Detected single analysis_case object, converting to list format for processing\"\n        )\n    else:\n        # Already in list format\n        analysis_cases = analysis_cases_raw\n\n    # The main run workspace is the timestamped directory, already created by initialize_run.\n    # We will create the case workspaces inside it.\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    # Determine the main log file path to be shared with all cases\n    main_log_file_name = f\"simulation_{config['run_timestamp']}.log\"\n    main_log_path = os.path.join(run_workspace, main_log_file_name)\n\n    logger.info(\n        f\"Detected {len(analysis_cases)} analysis cases, creating independent workspaces inside: {run_workspace}\"\n    )\n\n    case_configs = []\n\n    for i, analysis_case in enumerate(analysis_cases):\n        try:\n            # Generate case working directory name\n            workspace_name = analysis_case.get(\"name\", f\"case_{i}\")\n            # Create the case workspace directly inside the main run workspace\n            case_workspace = os.path.join(run_workspace, workspace_name)\n            os.makedirs(case_workspace, exist_ok=True)\n\n            # Create standard configuration (inlined from _create_standard_config_for_case)\n            base_config = config\n            original_config_dir = os.path.dirname(\n                base_config.get(\"paths\", {}).get(\"package_path\", os.getcwd())\n            )\n            absolute_config = convert_relative_paths_to_absolute(\n                base_config, original_config_dir\n            )\n            standard_config = json.loads(json.dumps(absolute_config))\n\n            # if analysis_case.get(\"name\") == \"SALib_Analysis\":\n            if isinstance(\n                analysis_case.get(\"independent_variable\"), list\n            ) and isinstance(analysis_case.get(\"independent_variable_sampling\"), dict):\n                sensitivity_analysis = standard_config[\"sensitivity_analysis\"]\n                if \"analysis_cases\" in sensitivity_analysis:\n                    del sensitivity_analysis[\"analysis_cases\"]\n                sensitivity_analysis[\"analysis_case\"] = analysis_case.copy()\n            else:\n                # Get independent variable and sampling from the current analysis case\n                independent_var = analysis_case[\"independent_variable\"]\n                independent_sampling = analysis_case[\"independent_variable_sampling\"]\n                logger.debug(\n                    f\"independent_sampling configuration: {independent_sampling}\"\n                )\n\n                # Ensure simulation_parameters exists at the top level\n                if \"simulation_parameters\" not in standard_config:\n                    standard_config[\"simulation_parameters\"] = {}\n\n                # If the specific analysis_case has its own simulation_parameters, merge them into the top-level ones\n                # This allows for case-specific parameter overrides or additions\n                if \"simulation_parameters\" in analysis_case:\n                    case_sim_params = analysis_case.get(\"simulation_parameters\", {})\n\n                    # Identify and handle virtual parameters (e.g., Required_TBR) used for metric configuration\n                    virtual_params = {\n                        k: v\n                        for k, v in case_sim_params.items()\n                        if k.startswith(\"Required_\") and isinstance(v, dict)\n                    }\n\n                    if virtual_params:\n                        # Merge virtual parameter config into the case's metrics_definition\n                        metrics_def = standard_config.setdefault(\n                            \"sensitivity_analysis\", {}\n                        ).setdefault(\"metrics_definition\", {})\n                        for key, value in virtual_params.items():\n                            if key in metrics_def:\n                                metrics_def[key].update(value)\n                            else:\n                                metrics_def[key] = value\n\n                    # Get real parameters by excluding virtual ones\n                    real_params = {\n                        k: v\n                        for k, v in case_sim_params.items()\n                        if k not in virtual_params\n                    }\n\n                    # Update standard_config's simulation_parameters with only real parameters for job generation\n                    standard_config[\"simulation_parameters\"].update(real_params)\n\n                # Fetch default values for both independent and simulation parameters\n                omc = None\n                try:\n                    # Get all sim params from the case, which may include virtual parameters\n                    all_case_sim_params = analysis_case.get(\"simulation_parameters\", {})\n                    # Filter out virtual parameters before fetching default values\n                    sim_param_keys = [\n                        k\n                        for k, v in all_case_sim_params.items()\n                        if not (k.startswith(\"Required_\") and isinstance(v, dict))\n                    ]\n                    # Ensure independent_var is a list for consistent processing, as it can be a list in SALib cases\n                    ind_param_keys = (\n                        [independent_var]\n                        if isinstance(independent_var, str)\n                        else independent_var\n                    )\n\n                    param_keys_to_fetch = sim_param_keys + ind_param_keys\n\n                    if param_keys_to_fetch:\n                        logger.info(\n                            f\"Fetching default values for parameters: {param_keys_to_fetch}\"\n                        )\n                        omc = get_om_session()\n                        if load_modelica_package(\n                            omc,\n                            Path(standard_config[\"paths\"][\"package_path\"]).as_posix(),\n                        ):\n                            all_defaults = get_model_default_parameters(\n                                omc, standard_config[\"simulation\"][\"model_name\"]\n                            )\n\n                            # Helper function to handle array access like 'param[1]'\n                            def get_specific_default(key, defaults):\n                                if key in defaults:\n                                    return defaults[key]\n                                if \"[\" in key and key.endswith(\"]\"):\n                                    try:\n                                        base_name, index_str = key.rsplit(\"[\", 1)\n                                        # Modelica is 1-based, Python is 0-based\n                                        index = int(index_str[:-1]) - 1\n                                        if base_name in defaults:\n                                            default_array = defaults[base_name]\n                                            if isinstance(\n                                                default_array, list\n                                            ) and 0 &lt;= index &lt; len(default_array):\n                                                return default_array[index]\n                                    except (ValueError, IndexError):\n                                        pass  # Malformed index or out of bounds\n                                return \"N/A\"\n\n                            # Get defaults for simulation_parameters\n                            default_sim_values = {\n                                p: get_specific_default(p, all_defaults)\n                                for p in sim_param_keys\n                            }\n                            analysis_case[\"default_simulation_values\"] = (\n                                default_sim_values\n                            )\n\n                            # Get defaults for independent_variable\n                            default_ind_values = {\n                                p: get_specific_default(p, all_defaults)\n                                for p in ind_param_keys\n                            }\n                            analysis_case[\"default_independent_values\"] = (\n                                default_ind_values\n                            )\n\n                except Exception as e:\n                    logger.warning(\n                        f\"Could not fetch default parameter values. Defaults will be empty. Error: {e}\"\n                    )\n                    analysis_case[\"default_simulation_values\"] = {}\n                    analysis_case[\"default_independent_values\"] = {}\n                finally:\n                    if omc:\n                        omc.sendExpression(\"quit()\")\n\n                # Add the primary independent_variable_sampling for the current analysis case\n                standard_config[\"simulation_parameters\"][\n                    independent_var\n                ] = independent_sampling\n\n                # Update sensitivity_analysis configuration\n                sensitivity_analysis = standard_config[\"sensitivity_analysis\"]\n\n                # Remove analysis_cases and replace with single analysis_case\n                if \"analysis_cases\" in sensitivity_analysis:\n                    del sensitivity_analysis[\"analysis_cases\"]\n\n                sensitivity_analysis[\"analysis_case\"] = analysis_case.copy()\n\n            # Update paths in configuration to be relative to case working directory\n            case_config = standard_config.copy()\n            case_config[\"paths\"][\"results_dir\"] = os.path.join(\n                case_workspace, \"results\"\n            )\n            case_config[\"paths\"][\"temp_dir\"] = os.path.join(case_workspace, \"temp\")\n            case_config[\"paths\"][\"db_path\"] = os.path.join(\n                case_workspace, \"data\", \"parameters.db\"\n            )\n\n            # If there's logging configuration, also update log directory\n            if \"paths\" in case_config and \"log_dir\" in case_config[\"paths\"]:\n                case_config[\"paths\"][\"log_dir\"] = os.path.join(case_workspace, \"log\")\n                # Inject the main log path for dual logging\n                if \"logging\" in case_config:\n                    case_config[\"logging\"][\"main_log_path\"] = main_log_path\n\n            # Save standard configuration file to case working directory\n            config_file_path = os.path.join(case_workspace, \"config.json\")\n            with open(config_file_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(standard_config, f, indent=4, ensure_ascii=False)\n\n            # Record case information\n            case_info = {\n                \"index\": i,\n                \"workspace\": case_workspace,\n                \"config_path\": config_file_path,\n                \"config\": case_config,\n                \"case_data\": analysis_case,\n            }\n            case_configs.append(case_info)\n\n            logger.info(\n                f\"Workspace for case {i+1} created successfully\",\n                extra={\n                    \"case_index\": i,\n                    \"case_name\": analysis_case.get(\"name\", f\"case_{i}\"),\n                    \"workspace\": case_workspace,\n                    \"config_path\": config_file_path,\n                },\n            )\n\n        except Exception as e:\n            logger.error(f\"\u2717 Error processing case {i}: {e}\", exc_info=True)\n            continue\n\n    logger.info(\n        f\"Successfully created independent working directories for {len(case_configs)} analysis cases\"\n    )\n    return case_configs\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_validate_analysis_cases_config","title":"<code>analysis_validate_analysis_cases_config(config)</code>","text":"<p>Validates analysis_cases configuration format supporting both list and single object.</p> <p>This function validates: 1. Basic structure and required fields of analysis_cases 2. Simulation parameters compatibility (single job requirement) 3. Required_TBR configuration completeness if used in dependent_variables</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to validate.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>bool</code> <p>True if configuration is valid, False otherwise.</p> Note <p>Supports both single analysis_case dict or list of cases. Required fields per case: name, independent_variable, independent_variable_sampling. Validates simulation_parameters contain only single job (no sweep). Checks Required_TBR completeness in metrics_definition.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_validate_analysis_cases_config(config: Dict[str, Any]) -&gt; bool:\n    \"\"\"Validates analysis_cases configuration format supporting both list and single object.\n\n    This function validates:\n    1. Basic structure and required fields of analysis_cases\n    2. Simulation parameters compatibility (single job requirement)\n    3. Required_TBR configuration completeness if used in dependent_variables\n\n    Args:\n        config: Configuration dictionary to validate.\n\n    Returns:\n        True if configuration is valid, False otherwise.\n\n    Note:\n        Supports both single analysis_case dict or list of cases. Required fields per case:\n        name, independent_variable, independent_variable_sampling. Validates simulation_parameters\n        contain only single job (no sweep). Checks Required_TBR completeness in metrics_definition.\n    \"\"\"\n    if \"sensitivity_analysis\" not in config:\n        logger.error(\"Missing sensitivity_analysis\")\n        return False\n\n    sensitivity_analysis = config[\"sensitivity_analysis\"]\n    if \"analysis_cases\" not in sensitivity_analysis:\n        logger.error(\"Missing analysis_cases\")\n        return False\n\n    analysis_cases = sensitivity_analysis[\"analysis_cases\"]\n\n    # Support both single object and list formats\n    if isinstance(analysis_cases, dict):\n        # Single analysis_case object\n        cases_to_check = [analysis_cases]\n    elif isinstance(analysis_cases, list) and len(analysis_cases) &gt; 0:\n        # analysis_cases list\n        cases_to_check = analysis_cases\n    else:\n        logger.error(\"analysis_cases must be a non-empty list or a single object\")\n        return False\n\n    # Check required fields for each analysis_case\n    required_fields = [\"name\", \"independent_variable\", \"independent_variable_sampling\"]\n    for i, case in enumerate(cases_to_check):\n        if not isinstance(case, dict):\n            logger.error(f\"analysis_cases[{i}] must be an object\")\n            return False\n        for field in required_fields:\n            if field not in case:\n                logger.error(f\"Missing required field '{field}' in analysis_cases[{i}]\")\n                return False\n\n    # Check if top-level simulation_parameters are used, which is disallowed in analysis_cases mode\n    if config.get(\"simulation_parameters\"):\n        logger.error(\n            \"The top-level 'simulation_parameters' field cannot be used when 'analysis_cases' is defined. \"\n            \"Please move any shared or case-specific parameters into the 'simulation_parameters' field \"\n            \"inside each object within the 'analysis_cases' list.\"\n        )\n        return False\n\n    # Check Required_TBR configuration completeness if it exists in dependent_variables\n    metrics_definition = sensitivity_analysis.get(\"metrics_definition\", {})\n    for i, case in enumerate(cases_to_check):\n        dependent_vars = case.get(\"dependent_variables\", [])\n        if \"Required_TBR\" in dependent_vars:\n            # Check if Required_TBR exists in metrics_definition\n            if \"Required_TBR\" not in metrics_definition:\n                logger.error(\n                    f\"Required_TBR is in dependent_variables of analysis_cases[{i}] but missing from metrics_definition\"\n                )\n                return False\n\n            # Check if Required_TBR configuration is complete\n            required_tbr_config = metrics_definition[\"Required_TBR\"]\n            required_fields = [\n                \"method\",\n                \"parameter_to_optimize\",\n                \"search_range\",\n                \"tolerance\",\n                \"max_iterations\",\n            ]\n            missing_fields = [\n                field for field in required_fields if field not in required_tbr_config\n            ]\n            if missing_fields:\n                logger.error(\n                    f\"Required_TBR configuration in metrics_definition is incomplete. Missing fields: {missing_fields}\"\n                )\n                return False\n\n    return True\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_validate_config","title":"<code>analysis_validate_config(config, required_keys=ANALYSIS_REQUIRED_CONFIG_KEYS, parent_key='')</code>","text":"<p>Recursively validates the configuration's structure and values.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_validate_config(\n    config: Dict[str, Any],\n    required_keys: Dict = ANALYSIS_REQUIRED_CONFIG_KEYS,\n    parent_key: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Recursively validates the configuration's structure and values.\n    \"\"\"\n    # --- Structural Validation ---\n    for key, expected in required_keys.items():\n        full_key_path = f\"{parent_key}.{key}\" if parent_key else key\n        if key not in config:\n            print(\n                f\"ERROR: Missing required configuration key: '{full_key_path}'\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if isinstance(expected, dict):\n            if not isinstance(config[key], dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' must be a dictionary.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            analysis_validate_config(config[key], expected, parent_key=full_key_path)\n        elif not isinstance(config[key], expected):\n            print(\n                f\"ERROR: Configuration key '{full_key_path}' has incorrect type. Expected {expected}, got {type(config[key])}.\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n    # 2. Validate variableFilter format\n    variable_filter = config.get(\"simulation\", {}).get(\"variableFilter\")\n    if variable_filter:\n        # Regex for a valid Modelica identifier (simplified)\n        ident = r\"[a-zA-Z_][a-zA-Z0-9_]*\"\n        # Regex for a valid substring in the filter:\n        # - time\n        # - class.name\n        # - class.name[index]\n        # - class.name[start-end]\n        valid_substring_re = re.compile(rf\"^time$|^{ident}\\.{ident}(\\[\\d+(-\\d+)?\\])?$\")\n\n        substrings = variable_filter.split(\"|\")\n        for sub in substrings:\n            if not valid_substring_re.match(sub):\n                print(\n                    f\"ERROR: Invalid format in 'simulation.variableFilter'. Substring '{sub}' does not match required format. \"\n                    f\"Valid formats are 'time', 'classname.typename', 'classname.typename[1]', or 'classname.typename[1-5]'.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    # --- Value and Conditional Validation (only on top-level call) ---\n    if not parent_key:\n        # Check for package_path existence\n        package_path = config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            print(\n                f\"ERROR: File specified in 'paths.package_path' not found: {package_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        # Analysis-specific validation\n        sa_config = config.get(\"sensitivity_analysis\", {})\n        if sa_config.get(\"enabled\", False):\n            has_sim_params = (\n                \"simulation_parameters\" in config and config[\"simulation_parameters\"]\n            )\n            has_analysis_cases = (\n                \"analysis_cases\" in sa_config and sa_config[\"analysis_cases\"]\n            )\n\n            if not has_sim_params and not has_analysis_cases:\n                print(\n                    \"ERROR: When 'sensitivity_analysis' is enabled, either 'simulation_parameters' or 'sensitivity_analysis.analysis_cases' must be defined.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n            if has_analysis_cases:\n                if not analysis_validate_analysis_cases_config(config):\n                    # The original function uses a logger which is not yet configured.\n                    # Add a print statement to ensure the user sees an error.\n                    print(\n                        \"ERROR: 'analysis_cases' configuration is invalid. See previous logs for details.\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n\n        check_ai_config(config)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.basic_prepare_config","title":"<code>basic_prepare_config(config_path)</code>","text":"<p>Loads and prepares the configuration from the given path.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config_path</code> <code>str</code> <p>Path to the JSON configuration file.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>tuple[Dict[str, Any], Dict[str, Any]]</code> <p>A tuple of (runtime_config, original_config).</p> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>SystemExit</code> <p>If config file loading/parsing fails or validation fails.</p> Note <p>Converts relative paths to absolute, validates config structure, adds run_timestamp, creates workspace directories, and processes variableFilter for regex escaping. Sets up log_dir, temp_dir, and results_dir within run workspace.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def basic_prepare_config(config_path: str) -&gt; tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Loads and prepares the configuration from the given path.\n\n    Args:\n        config_path: Path to the JSON configuration file.\n\n    Returns:\n        A tuple of (runtime_config, original_config).\n\n    Raises:\n        SystemExit: If config file loading/parsing fails or validation fails.\n\n    Note:\n        Converts relative paths to absolute, validates config structure, adds run_timestamp,\n        creates workspace directories, and processes variableFilter for regex escaping.\n        Sets up log_dir, temp_dir, and results_dir within run workspace.\n    \"\"\"\n    try:\n        config_path = os.path.abspath(config_path)\n        with open(config_path, \"r\") as f:\n            base_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        # Logger is not set up yet, so print directly to stderr\n        print(\n            f\"ERROR: Failed to load or parse config file {config_path}: {e}\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    original_config_dir = os.path.dirname(config_path)\n\n    absolute_config = convert_relative_paths_to_absolute(\n        base_config, original_config_dir\n    )\n\n    # Perform all validation on the config with absolute paths\n    basic_validate_config(absolute_config)\n\n    config = json.loads(json.dumps(absolute_config))\n    config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    if \"paths\" not in config:\n        config[\"paths\"] = {}\n\n    original_string = config[\"simulation\"][\"variableFilter\"]\n    config[\"simulation\"][\"variableFilter\"] = original_string.replace(\n        \"[\", \"\\\\[[\"\n    ).replace(\"]\", \"]\\\\]\")\n\n    config[\"paths\"][\"log_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"log_dir\", \"log\")\n    )\n    config[\"paths\"][\"temp_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"temp_dir\", \"temp\")\n    )\n    config[\"paths\"][\"results_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"results_dir\", \"results\")\n    )\n\n    os.makedirs(config[\"paths\"][\"log_dir\"], exist_ok=True)\n    os.makedirs(config[\"paths\"][\"temp_dir\"], exist_ok=True)\n    os.makedirs(config[\"paths\"][\"results_dir\"], exist_ok=True)\n\n    return config, base_config\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.basic_validate_config","title":"<code>basic_validate_config(config, required_keys=BASIC_REQUIRED_CONFIG_KEYS, parent_key='')</code>","text":"<p>Recursively validates the configuration against required structure.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to validate.</p> \u5fc5\u9700 <code>required_keys</code> <code>Dict</code> <p>Dictionary defining required keys and their expected types.</p> <code>BASIC_REQUIRED_CONFIG_KEYS</code> <code>parent_key</code> <code>str</code> <p>Parent key path for nested validation (used internally).</p> <code>''</code> <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>SystemExit</code> <p>If validation fails (exits with code 1).</p> Note <p>Performs structural validation (required keys and types) and value validation (path existence, variableFilter format). Uses regex to validate variableFilter against Modelica identifier patterns. Only validates values on top-level call.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def basic_validate_config(\n    config: Dict[str, Any],\n    required_keys: Dict = BASIC_REQUIRED_CONFIG_KEYS,\n    parent_key: str = \"\",\n) -&gt; None:\n    \"\"\"Recursively validates the configuration against required structure.\n\n    Args:\n        config: Configuration dictionary to validate.\n        required_keys: Dictionary defining required keys and their expected types.\n        parent_key: Parent key path for nested validation (used internally).\n\n    Raises:\n        SystemExit: If validation fails (exits with code 1).\n\n    Note:\n        Performs structural validation (required keys and types) and value validation\n        (path existence, variableFilter format). Uses regex to validate variableFilter\n        against Modelica identifier patterns. Only validates values on top-level call.\n    \"\"\"\n    # --- Structural Validation ---\n    for key, expected_type_or_dict in required_keys.items():\n        full_key_path = f\"{parent_key}.{key}\" if parent_key else key\n\n        if key not in config:\n            print(\n                f\"ERROR: Missing required configuration key: '{full_key_path}'\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if isinstance(expected_type_or_dict, dict):\n            if not isinstance(config[key], dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' must be a dictionary.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            # Recurse for nested dictionaries\n            basic_validate_config(\n                config[key], expected_type_or_dict, parent_key=full_key_path\n            )\n        else:\n            # Perform type checking for leaf keys\n            if not isinstance(config[key], expected_type_or_dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' has incorrect type. \"\n                    f\"Expected {expected_type_or_dict}, but got {type(config[key])}.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    # --- Value Validation (only on top-level call) ---\n    if not parent_key:\n        # 1. Check if package_path exists\n        package_path = config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            print(\n                f\"ERROR: File specified in 'paths.package_path' not found: {package_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        # 2. Validate variableFilter format\n        variable_filter = config.get(\"simulation\", {}).get(\"variableFilter\")\n        if variable_filter:\n            # Regex for a valid Modelica identifier (simplified)\n            ident = r\"[a-zA-Z_][a-zA-Z0-9_]*\"\n            # Regex for a valid substring in the filter:\n            # - time\n            # - class.name\n            # - class.name[index]\n            # - class.name[start-end]\n            valid_substring_re = re.compile(\n                rf\"^time$|^{ident}\\.{ident}(\\[\\d+(-\\d+)?\\])?$\"\n            )\n\n            substrings = variable_filter.split(\"|\")\n            for sub in substrings:\n                if not valid_substring_re.match(sub):\n                    print(\n                        f\"ERROR: Invalid format in 'simulation.variableFilter'. Substring '{sub}' does not match required format. \"\n                        f\"Valid formats are 'time', 'classname.typename', 'classname.typename[1]', or 'classname.typename[1-5]'.\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n\n        check_ai_config(config)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.check_ai_config","title":"<code>check_ai_config(config)</code>","text":"<p>Checks for AI-related environment variables if 'ai: true' is found in the config.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>The configuration dictionary.</p> \u5fc5\u9700 <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>SystemExit</code> <p>If AI is enabled in the config but required environment         variables are missing.</p> Note <p>If any part of the configuration contains <code>\"ai\": true</code>, this function verifies that <code>API_KEY</code>, <code>BASE_URL</code>, and either <code>AI_MODEL</code> or <code>AI_MODELS</code> are set as environment variables.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def check_ai_config(config: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Checks for AI-related environment variables if 'ai: true' is found in the config.\n\n    Args:\n        config: The configuration dictionary.\n\n    Raises:\n        SystemExit: If AI is enabled in the config but required environment\n                    variables are missing.\n\n    Note:\n        If any part of the configuration contains `\"ai\": true`, this function verifies\n        that `API_KEY`, `BASE_URL`, and either `AI_MODEL` or `AI_MODELS` are set as\n        environment variables.\n    \"\"\"\n    if _search_dict(config, \"ai\", True):\n        logger.info(\n            \"AI feature enabled in config, checking for required environment variables...\"\n        )\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n        ai_model = os.environ.get(\"AI_MODEL\")\n        ai_models = os.environ.get(\"AI_MODELS\")\n\n        missing_vars = []\n        if not api_key:\n            missing_vars.append(\"API_KEY\")\n        if not base_url:\n            missing_vars.append(\"BASE_URL\")\n        if not ai_model and not ai_models:\n            missing_vars.append(\"AI_MODEL or AI_MODELS\")\n\n        if missing_vars:\n            print(\n                f\"ERROR: 'ai: true' is set in the configuration, but the following required environment variables are missing: {', '.join(missing_vars)}. \"\n                \"Please set them in your environment or a .env file.\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n        else:\n            logger.info(\"All required AI environment variables are present.\")\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.convert_relative_paths_to_absolute","title":"<code>convert_relative_paths_to_absolute(config, base_dir)</code>","text":"<p>Recursively converts relative paths to absolute paths in configuration.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to process.</p> \u5fc5\u9700 <code>base_dir</code> <code>str</code> <p>Base directory path for resolving relative paths.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Dict[str, Any]</code> <p>Configuration dictionary with converted absolute paths.</p> Note <p>Processes path keys including package_path, db_path, results_dir, temp_dir, log_dir, glossary_path, and any key ending with '_path'. Converts relative paths to absolute using base_dir. Handles nested dictionaries and lists recursively.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/config_utils.py</code> <pre><code>def convert_relative_paths_to_absolute(\n    config: Dict[str, Any], base_dir: str\n) -&gt; Dict[str, Any]:\n    \"\"\"Recursively converts relative paths to absolute paths in configuration.\n\n    Args:\n        config: Configuration dictionary to process.\n        base_dir: Base directory path for resolving relative paths.\n\n    Returns:\n        Configuration dictionary with converted absolute paths.\n\n    Note:\n        Processes path keys including package_path, db_path, results_dir, temp_dir,\n        log_dir, glossary_path, and any key ending with '_path'. Converts relative\n        paths to absolute using base_dir. Handles nested dictionaries and lists recursively.\n    \"\"\"\n\n    def _process_value(value, key_name=\"\", parent_dict=None):\n        if isinstance(value, dict):\n            return {k: _process_value(v, k, value) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [_process_value(item, parent_dict=parent_dict) for item in value]\n        elif isinstance(value, str):\n            # Check if it's a path-related key name (extended support for more path fields)\n            path_keys = [\n                \"package_path\",\n                \"db_path\",\n                \"results_dir\",\n                \"temp_dir\",\n                \"log_dir\",\n                \"glossary_path\",\n            ]\n\n            if key_name.endswith(\"_path\") or key_name in path_keys:\n                # If it's a relative path, convert to absolute path\n                if not os.path.isabs(value) and value:\n                    abs_path = os.path.abspath(os.path.join(base_dir, value))\n                    logger.debug(\n                        \"Converted path\",\n                        extra={\n                            \"key_name\": key_name,\n                            \"original_value\": value,\n                            \"absolute_path\": abs_path,\n                        },\n                    )\n                    return abs_path\n            return value\n        else:\n            return value\n\n    return _process_value(config)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.file_utils.archive_run","title":"<code>archive_run(timestamp)</code>","text":"<p>Archives a run (simulation or analysis) based on its configuration.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>timestamp</code> <code>str</code> <p>The timestamp directory name of the run to archive.</p> \u5fc5\u9700 Note <p>Determines run type (analysis vs simulation) from configuration. Delegates to _archive_run() with appropriate run_type. Extracts configuration from log files using restore_configs_from_log().</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/file_utils.py</code> <pre><code>def archive_run(timestamp: str) -&gt; None:\n    \"\"\"Archives a run (simulation or analysis) based on its configuration.\n\n    Args:\n        timestamp: The timestamp directory name of the run to archive.\n\n    Note:\n        Determines run type (analysis vs simulation) from configuration. Delegates\n        to _archive_run() with appropriate run_type. Extracts configuration from\n        log files using restore_configs_from_log().\n    \"\"\"\n\n    configs = restore_configs_from_log(timestamp)\n    if not configs:\n        return\n    runtime_config, original_config = configs\n    logger.info(\"Successfully extracted both runtime and original configurations.\")\n\n    is_analysis = \"sensitivity_analysis\" in original_config and original_config.get(\n        \"sensitivity_analysis\", {}\n    ).get(\"enabled\", False)\n\n    if is_analysis:\n        _archive_run(timestamp, \"analysis\")\n    else:\n        _archive_run(timestamp, \"simulation\")\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.file_utils.get_unique_filename","title":"<code>get_unique_filename(base_path, filename)</code>","text":"<p>Generates a unique filename by appending a counter if the file already exists.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>base_path</code> <code>str</code> <p>The directory path where the file will be saved.</p> \u5fc5\u9700 <code>filename</code> <code>str</code> <p>The desired filename, including the extension.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>str</code> <p>A unique, non-existing file path.</p> Note <p>Appends _1, _2, etc. before the extension until a non-existing filename is found. Example: if \"data.csv\" exists, returns \"data_1.csv\", then \"data_2.csv\", etc.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/file_utils.py</code> <pre><code>def get_unique_filename(base_path: str, filename: str) -&gt; str:\n    \"\"\"Generates a unique filename by appending a counter if the file already exists.\n\n    Args:\n        base_path: The directory path where the file will be saved.\n        filename: The desired filename, including the extension.\n\n    Returns:\n        A unique, non-existing file path.\n\n    Note:\n        Appends _1, _2, etc. before the extension until a non-existing filename is found.\n        Example: if \"data.csv\" exists, returns \"data_1.csv\", then \"data_2.csv\", etc.\n    \"\"\"\n    base_name, ext = os.path.splitext(filename)\n    counter = 0\n    new_filename = filename\n    new_filepath = os.path.join(base_path, new_filename)\n\n    while os.path.exists(new_filepath):\n        counter += 1\n        new_filename = f\"{base_name}_{counter}{ext}\"\n        new_filepath = os.path.join(base_path, new_filename)\n\n    return new_filepath\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.file_utils.unarchive_run","title":"<code>unarchive_run(zip_file)</code>","text":"<p>Unarchives a simulation run from a zip file.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>zip_file</code> <code>str</code> <p>Path to the zip file to extract.</p> \u5fc5\u9700 <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>SystemExit</code> <p>If zip file not found or extraction fails.</p> Note <p>Extracts to current directory if empty, otherwise creates new directory named after the zip file. Sets up basic logging for the unarchive process. Handles BadZipFile exceptions gracefully.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/file_utils.py</code> <pre><code>def unarchive_run(zip_file: str) -&gt; None:\n    \"\"\"Unarchives a simulation run from a zip file.\n\n    Args:\n        zip_file: Path to the zip file to extract.\n\n    Raises:\n        SystemExit: If zip file not found or extraction fails.\n\n    Note:\n        Extracts to current directory if empty, otherwise creates new directory\n        named after the zip file. Sets up basic logging for the unarchive process.\n        Handles BadZipFile exceptions gracefully.\n    \"\"\"\n    # Basic logging setup for unarchive command\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        stream=sys.stdout,\n    )\n    logger = logging.getLogger(__name__)\n\n    if not os.path.isfile(zip_file):\n        logger.error(f\"Archive file not found: {zip_file}\")\n        sys.exit(1)\n\n    target_dir = \".\"\n    if os.listdir(\".\"):  # If the list of CWD contents is not empty\n        dir_name = os.path.splitext(os.path.basename(zip_file))[0]\n        target_dir = dir_name\n        logger.info(\n            f\"Current directory is not empty. Extracting to new directory: {target_dir}\"\n        )\n        os.makedirs(target_dir, exist_ok=True)\n    else:\n        logger.info(\"Current directory is empty. Extracting to current directory.\")\n\n    # Unzip the file\n    try:\n        with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n            zip_ref.extractall(target_dir)\n        logger.info(\n            f\"Successfully unarchived '{zip_file}' to '{os.path.abspath(target_dir)}'\"\n        )\n    except zipfile.BadZipFile:\n        logger.error(f\"Error: '{zip_file}' is not a valid zip file.\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"An error occurred during unarchiving: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.delete_old_logs","title":"<code>delete_old_logs(log_path, max_files)</code>","text":"<p>Deletes the oldest log files in a directory to meet a specified limit.</p> <p>Checks the number of <code>.log</code> files in the given directory and removes the oldest ones based on modification time until the file count matches the <code>max_files</code> limit.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>log_path</code> <code>str</code> <p>The path to the directory containing log files.</p> \u5fc5\u9700 <code>max_files</code> <code>int</code> <p>The maximum number of <code>.log</code> files to retain.</p> \u5fc5\u9700 Note <p>Only processes files with .log extension. Sorts by modification time (oldest first) before deletion. Does nothing if current count &lt;= max_files.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/log_utils.py</code> <pre><code>def delete_old_logs(log_path: str, max_files: int) -&gt; None:\n    \"\"\"Deletes the oldest log files in a directory to meet a specified limit.\n\n    Checks the number of `.log` files in the given directory and removes the\n    oldest ones based on modification time until the file count matches the\n    `max_files` limit.\n\n    Args:\n        log_path: The path to the directory containing log files.\n        max_files: The maximum number of `.log` files to retain.\n\n    Note:\n        Only processes files with .log extension. Sorts by modification time\n        (oldest first) before deletion. Does nothing if current count &lt;= max_files.\n    \"\"\"\n    log_files = [\n        os.path.join(log_path, f) for f in os.listdir(log_path) if f.endswith(\".log\")\n    ]\n\n    if len(log_files) &gt; max_files:\n        # Sort by modification time, oldest first\n        log_files.sort(key=os.path.getmtime)\n\n        # Calculate how many files to delete\n        files_to_delete_count = len(log_files) - max_files\n\n        # Delete the oldest files\n        for i in range(files_to_delete_count):\n            os.remove(log_files[i])\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.log_execution_time","title":"<code>log_execution_time(func)</code>","text":"<p>A decorator to log the execution time of a function.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>func</code> <code>Callable</code> <p>The function to be decorated.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Callable</code> <p>The wrapped function that logs execution time.</p> Note <p>Measures execution time using time.perf_counter(). Logs function name, module, and duration in milliseconds. Uses structured logging with extra fields.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/log_utils.py</code> <pre><code>def log_execution_time(func: Callable) -&gt; Callable:\n    \"\"\"A decorator to log the execution time of a function.\n\n    Args:\n        func: The function to be decorated.\n\n    Returns:\n        The wrapped function that logs execution time.\n\n    Note:\n        Measures execution time using time.perf_counter(). Logs function name,\n        module, and duration in milliseconds. Uses structured logging with extra fields.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        duration_ms = (end_time - start_time) * 1000\n\n        logger.info(\n            \"Function executed\",\n            extra={\n                \"function_name\": func.__name__,\n                \"function_module\": func.__module__,\n                \"duration_ms\": round(duration_ms, 2),\n            },\n        )\n        return result\n\n    return wrapper\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.restore_configs_from_log","title":"<code>restore_configs_from_log(timestamp)</code>","text":"<p>Finds the log file for a given timestamp and restores configurations.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>timestamp</code> <code>str</code> <p>The timestamp directory name to search for log files.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>tuple[Dict[str, Any] | None, Dict[str, Any] | None]</code> <p>A tuple of (runtime_config, original_config) or (None, None) if not found.</p> Note <p>Searches in timestamp/simulation_{timestamp}.log and timestamp/log/ directory. Parses JSON log entries to find \"Runtime Configuration\" and \"Original Configuration\" messages. Returns parsed configurations as dictionaries.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/log_utils.py</code> <pre><code>def restore_configs_from_log(\n    timestamp: str,\n) -&gt; tuple[Dict[str, Any] | None, Dict[str, Any] | None]:\n    \"\"\"Finds the log file for a given timestamp and restores configurations.\n\n    Args:\n        timestamp: The timestamp directory name to search for log files.\n\n    Returns:\n        A tuple of (runtime_config, original_config) or (None, None) if not found.\n\n    Note:\n        Searches in timestamp/simulation_{timestamp}.log and timestamp/log/ directory.\n        Parses JSON log entries to find \"Runtime Configuration\" and \"Original Configuration\"\n        messages. Returns parsed configurations as dictionaries.\n    \"\"\"\n    log_file_path = None\n    # Define potential locations for the log file\n    search_paths = [\n        os.path.join(timestamp, f\"simulation_{timestamp}.log\"),  # analysis style\n        os.path.join(timestamp, \"log\"),  # simulation style\n    ]\n\n    for path in search_paths:\n        if os.path.isfile(path):\n            log_file_path = path\n            break\n        if os.path.isdir(path):\n            for f in os.listdir(path):\n                if f.startswith(\"simulation_\") and f.endswith(\".log\"):\n                    log_file_path = os.path.join(path, f)\n                    break\n            if log_file_path:\n                break\n\n    if not log_file_path:\n        print(\n            f\"ERROR: Main log file not found for timestamp {timestamp}\", file=sys.stderr\n        )\n        return None, None\n\n    runtime_config_str = None\n    original_config_str = None\n    try:\n        with open(log_file_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                try:\n                    log_entry = json.loads(line)\n                    if \"message\" in log_entry:\n                        if log_entry[\"message\"].startswith(\n                            \"Runtime Configuration (compact JSON):\"\n                        ):\n                            runtime_config_str = log_entry[\"message\"].replace(\n                                \"Runtime Configuration (compact JSON): \", \"\"\n                            )\n                        elif log_entry[\"message\"].startswith(\n                            \"Original Configuration (compact JSON):\"\n                        ):\n                            original_config_str = log_entry[\"message\"].replace(\n                                \"Original Configuration (compact JSON): \", \"\"\n                            )\n                    if runtime_config_str and original_config_str:\n                        break\n                except json.JSONDecodeError:\n                    continue\n    except Exception as e:\n        print(f\"ERROR: Failed to read log file {log_file_path}: {e}\", file=sys.stderr)\n        return None, None\n\n    if not runtime_config_str or not original_config_str:\n        print(\n            \"ERROR: Could not find runtime and/or original configuration in log file.\",\n            file=sys.stderr,\n        )\n        return None, None\n\n    try:\n        runtime_config = json.loads(runtime_config_str)\n        original_config = json.loads(original_config_str)\n        return runtime_config, original_config\n    except json.JSONDecodeError as e:\n        print(\n            f\"ERROR: Failed to parse configuration from log file: {e}\", file=sys.stderr\n        )\n        return None, None\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.setup_logging","title":"<code>setup_logging(config, original_config=None)</code>","text":"<p>Configures the logging module based on the application configuration.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary containing logging settings.</p> \u5fc5\u9700 <code>original_config</code> <code>Dict[str, Any]</code> <p>Optional original configuration for additional logging.</p> <code>None</code> Note <p>Sets up JSON formatted logging to console and/or file. Manages log file rotation via delete_old_logs(). Supports main_log_path for analysis cases. Logs both runtime and original configurations in compact JSON format. Clears existing handlers to prevent duplicates.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/log_utils.py</code> <pre><code>def setup_logging(\n    config: Dict[str, Any], original_config: Dict[str, Any] = None\n) -&gt; None:\n    \"\"\"Configures the logging module based on the application configuration.\n\n    Args:\n        config: The main configuration dictionary containing logging settings.\n        original_config: Optional original configuration for additional logging.\n\n    Note:\n        Sets up JSON formatted logging to console and/or file. Manages log file rotation\n        via delete_old_logs(). Supports main_log_path for analysis cases. Logs both\n        runtime and original configurations in compact JSON format. Clears existing\n        handlers to prevent duplicates.\n    \"\"\"\n    log_config = config.get(\"logging\", {})\n    log_level_str = log_config.get(\"log_level\", \"INFO\").upper()\n    log_level = getattr(logging, log_level_str, logging.INFO)\n    log_to_console = log_config.get(\"log_to_console\", True)\n    run_timestamp = config.get(\"run_timestamp\")\n\n    log_dir_path = config.get(\"paths\", {}).get(\"log_dir\")\n    log_count = log_config.get(\"log_count\", 5)\n\n    root_logger = logging.getLogger()\n    root_logger.setLevel(log_level)\n\n    # Clear any existing handlers to prevent duplicate logs\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n        handler.close()\n\n    formatter = jsonlogger.JsonFormatter(\n        \"%(asctime)s %(name)s %(levelname)s %(message)s\"\n    )\n\n    if log_to_console:\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setFormatter(formatter)\n        root_logger.addHandler(console_handler)\n\n    if log_dir_path:\n        abs_log_dir = os.path.abspath(log_dir_path)\n        os.makedirs(abs_log_dir, exist_ok=True)\n        delete_old_logs(abs_log_dir, log_count)\n        log_file_path = os.path.join(abs_log_dir, f\"simulation_{run_timestamp}.log\")\n\n        file_handler = logging.FileHandler(log_file_path, mode=\"a\", encoding=\"utf-8\")\n        file_handler.setFormatter(formatter)\n        root_logger.addHandler(file_handler)\n\n        # If a main log path is provided (for analysis cases), add it as an additional handler\n        main_log_path = log_config.get(\"main_log_path\")\n        if main_log_path:\n            try:\n                # Ensure the directory for the main log exists, just in case\n                os.makedirs(os.path.dirname(main_log_path), exist_ok=True)\n\n                main_log_handler = logging.FileHandler(\n                    main_log_path, mode=\"a\", encoding=\"utf-8\"\n                )\n                main_log_handler.setFormatter(formatter)\n                root_logger.addHandler(main_log_handler)\n                logger.info(f\"Also logging to main log file: {main_log_path}\")\n            except Exception as e:\n                logger.warning(\n                    f\"Failed to attach main log handler for {main_log_path}: {e}\"\n                )\n\n        logger.info(f\"Logging to file: {log_file_path}\")\n        # Log the full runtime configuration in a compact JSON format\n        logger.info(\n            f\"Runtime Configuration (compact JSON): {json.dumps(config, separators=(',', ':'), ensure_ascii=False)}\"\n        )\n        if original_config:\n            logger.info(\n                f\"Original Configuration (compact JSON): {json.dumps(original_config, separators=(',', ':'), ensure_ascii=False)}\"\n            )\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.create_parameters_table","title":"<code>create_parameters_table(db_path)</code>","text":"<p>Creates the parameters table in the database if it does not exist.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> \u5fc5\u9700 <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Error</code> <p>If a database error occurs during table creation.</p> Note <p>Creates parent directories if they don't exist. Table schema includes: name (TEXT PRIMARY KEY), type, default_value, sweep_values, description, dimensions. Uses CREATE TABLE IF NOT EXISTS for safe repeated calls.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/sqlite_utils.py</code> <pre><code>def create_parameters_table(db_path: str) -&gt; None:\n    \"\"\"Creates the parameters table in the database if it does not exist.\n\n    Args:\n        db_path: The path to the SQLite database file.\n\n    Raises:\n        sqlite3.Error: If a database error occurs during table creation.\n\n    Note:\n        Creates parent directories if they don't exist. Table schema includes:\n        name (TEXT PRIMARY KEY), type, default_value, sweep_values, description, dimensions.\n        Uses CREATE TABLE IF NOT EXISTS for safe repeated calls.\n    \"\"\"\n    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n    logger.debug(f\"Ensuring 'parameters' table exists in {db_path}\")\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS parameters (\n                    name TEXT PRIMARY KEY,\n                    type TEXT,\n                    default_value TEXT,\n                    sweep_values TEXT,\n                    description TEXT,\n                    dimensions TEXT\n                )\n            \"\"\"\n            )\n            conn.commit()\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while creating table: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.get_parameters_from_db","title":"<code>get_parameters_from_db(db_path)</code>","text":"<p>Retrieves parameter details from the database.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> \u5fc5\u9700 <p>\u8fd4\u56de\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>List[Dict[str, Any]]</code> <p>A list of parameter dictionaries, each containing the name, default_value,</p> <code>List[Dict[str, Any]]</code> <p>description, and sweep_values.</p> Note <p>JSON-decodes stored values. Returns empty string for sweep_values if None. Result dict keys: name, default_value, description, sweep_values.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/sqlite_utils.py</code> <pre><code>def get_parameters_from_db(db_path: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"Retrieves parameter details from the database.\n\n    Args:\n        db_path: The path to the SQLite database file.\n\n    Returns:\n        A list of parameter dictionaries, each containing the name, default_value,\n        description, and sweep_values.\n\n    Note:\n        JSON-decodes stored values. Returns empty string for sweep_values if None.\n        Result dict keys: name, default_value, description, sweep_values.\n    \"\"\"\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(\n            \"SELECT name, default_value, description, sweep_values FROM parameters\"\n        )\n        params = []\n        for name, default_value, description, sweep_values in cursor.fetchall():\n            params.append(\n                {\n                    \"name\": name,\n                    \"default_value\": json.loads(default_value),\n                    \"description\": description,\n                    \"sweep_values\": json.loads(sweep_values) if sweep_values else \"\",\n                }\n            )\n    return params\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.store_parameters_in_db","title":"<code>store_parameters_in_db(db_path, params_data)</code>","text":"<p>Stores or replaces a list of parameter details in the database.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> \u5fc5\u9700 <code>params_data</code> <code>List[Dict[str, Any]]</code> <p>A list of dictionaries, where each dictionary contains details for a single parameter.</p> \u5fc5\u9700 <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Error</code> <p>If a database error occurs during insertion.</p> Note <p>Uses INSERT OR REPLACE for upsert behavior. JSON-encodes defaultValue and stores dimensions with '()' default. Skips parameters without names. Expected param dict keys: name, type, defaultValue, comment, dimensions.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/sqlite_utils.py</code> <pre><code>def store_parameters_in_db(db_path: str, params_data: List[Dict[str, Any]]) -&gt; None:\n    \"\"\"Stores or replaces a list of parameter details in the database.\n\n    Args:\n        db_path: The path to the SQLite database file.\n        params_data: A list of dictionaries, where each dictionary contains\n            details for a single parameter.\n\n    Raises:\n        sqlite3.Error: If a database error occurs during insertion.\n\n    Note:\n        Uses INSERT OR REPLACE for upsert behavior. JSON-encodes defaultValue\n        and stores dimensions with '()' default. Skips parameters without names.\n        Expected param dict keys: name, type, defaultValue, comment, dimensions.\n    \"\"\"\n    logger.info(f\"Storing {len(params_data)} parameters into '{db_path}'\")\n    if not params_data:\n        logger.warning(\"Parameter data is empty, nothing to store.\")\n        return\n\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            for param in params_data:\n                name = param.get(\"name\")\n                if not name:\n                    continue\n\n                value_json = json.dumps(param.get(\"defaultValue\"))\n                dimensions = param.get(\n                    \"dimensions\", \"()\"\n                )  # Default to '()' if not present\n\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO parameters (name, type, default_value, sweep_values, description, dimensions)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        name,\n                        param.get(\"type\", \"Real\"),\n                        value_json,\n                        None,\n                        param.get(\"comment\", \"\"),\n                        dimensions,\n                    ),\n                )\n            conn.commit()\n        logger.info(\"Successfully stored/updated parameters in the database.\")\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while storing parameters: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.update_sweep_values_in_db","title":"<code>update_sweep_values_in_db(db_path, param_sweep)</code>","text":"<p>Updates the 'sweep_values' for specified parameters in the database.</p> <p>\u53c2\u6570\uff1a</p> \u540d\u79f0 \u7c7b\u578b \u63cf\u8ff0 \u9ed8\u8ba4 <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> \u5fc5\u9700 <code>param_sweep</code> <code>Dict[str, Any]</code> <p>A dictionary where keys are parameter names and values are the corresponding sweep values (e.g., a list).</p> \u5fc5\u9700 <p>\u5f15\u53d1\uff1a</p> \u7c7b\u578b \u63cf\u8ff0 <code>Error</code> <p>If a database error occurs during the update.</p> Note <p>Converts numpy arrays to lists before JSON encoding. Warns if parameter not found in database. Uses UPDATE statement so parameters must exist before calling this function.</p> \u6e90\u4ee3\u7801\u4f4d\u4e8e\uff1a <code>tricys/utils/sqlite_utils.py</code> <pre><code>def update_sweep_values_in_db(db_path: str, param_sweep: Dict[str, Any]) -&gt; None:\n    \"\"\"Updates the 'sweep_values' for specified parameters in the database.\n\n    Args:\n        db_path: The path to the SQLite database file.\n        param_sweep: A dictionary where keys are parameter names and values are\n            the corresponding sweep values (e.g., a list).\n\n    Raises:\n        sqlite3.Error: If a database error occurs during the update.\n\n    Note:\n        Converts numpy arrays to lists before JSON encoding. Warns if parameter\n        not found in database. Uses UPDATE statement so parameters must exist\n        before calling this function.\n    \"\"\"\n    logger.info(f\"Updating sweep values in '{db_path}'\")\n    if not param_sweep:\n        logger.warning(\"param_sweep dictionary is empty. No values to update.\")\n        return\n\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            for param_name, sweep_values in param_sweep.items():\n                if isinstance(sweep_values, np.ndarray):\n                    sweep_values = sweep_values.tolist()\n\n                sweep_values_json = json.dumps(sweep_values)\n\n                cursor.execute(\n                    \"\"\"\n                    UPDATE parameters SET sweep_values = ? WHERE name = ?\n                \"\"\",\n                    (sweep_values_json, param_name),\n                )\n\n                if cursor.rowcount == 0:\n                    logger.warning(\n                        f\"Parameter '{param_name}' not found in database. No sweep value updated.\"\n                    )\n            conn.commit()\n        logger.info(\"Sweep values updated successfully.\")\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while updating sweep values: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"explanation/architecture.html","title":"\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1","text":""},{"location":"explanation/architecture.html#1","title":"1. \u6574\u4f53\u67b6\u6784","text":"<p>TRICYS \u91c7\u7528\u5206\u5c42\u67b6\u6784\u8bbe\u8ba1\uff0c\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u51e0\u5c42\uff1a</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u7528\u6237\u754c\u9762\u5c42             \n\u2502 tricys basic, tricys analysis, tricys gui       \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u4eff\u771f\u6267\u884c\u5c42                     \n\u2502     simulation, simulation_analysis    \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u6838\u5fc3\u529f\u80fd\u5c42                     \n\u2502      Jobs, Modelica, Interceptor            \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             \u5206\u6790\u4e0e\u540e\u5904\u7406\u5c42                   \n\u2502       Metric, Plot, Report, SALib           \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u5de5\u5177\u51fd\u6570\u5c42                     \n\u2502      Config, File, Log, SQLite Utils        \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                \u5916\u90e8\u4f9d\u8d56\u5c42                    \n\u2502     OpenModelica, Pandas, NumPy, SALib      \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"explanation/architecture.html#2","title":"2. \u7a0b\u5e8f\u5206\u5c42","text":""},{"location":"explanation/architecture.html#21","title":"2.1. \u7528\u6237\u754c\u9762\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/main.py</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u63d0\u4f9b\u547d\u4ee4\u884c\u63a5\u53e3\uff08CLI\uff09\u548c\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u4e24\u79cd\u4ea4\u4e92\u65b9\u5f0f</li> <li>\u89e3\u6790\u7528\u6237\u8f93\u5165\u7684\u547d\u4ee4\u884c\u53c2\u6570\u548c\u5b50\u547d\u4ee4\uff08<code>basic</code>, <code>analysis</code>, <code>gui</code>, <code>example</code>, <code>archive</code>, <code>unarchive</code>\uff09</li> <li>\u8def\u7531\u8bf7\u6c42\u5230\u76f8\u5e94\u7684\u4eff\u771f\u6267\u884c\u5c42\u6a21\u5757</li> <li>\u7ba1\u7406\u7528\u6237\u4f1a\u8bdd\u548c\u914d\u7f6e\u6587\u4ef6\u52a0\u8f7d</li> </ul> <p>\u5173\u952e\u529f\u80fd\uff1a</p> <ul> <li>CLI \u547d\u4ee4\u5206\u53d1\uff1a\u6839\u636e\u5b50\u547d\u4ee4\u6216\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9\u81ea\u52a8\u8bc6\u522b\u8fd0\u884c\u6a21\u5f0f</li> <li>GUI \u4ea4\u4e92\u754c\u9762\uff1a\u63d0\u4f9b\u53ef\u89c6\u5316\u7684\u53c2\u6570\u8bbe\u7f6e\u3001\u4eff\u771f\u542f\u52a8\u548c\u7ed3\u679c\u67e5\u770b\u529f\u80fd</li> <li>\u793a\u4f8b\u8fd0\u884c\u5668\uff1a\u96c6\u6210\u4ea4\u4e92\u5f0f\u793a\u4f8b\u9009\u62e9\u548c\u8fd0\u884c\u529f\u80fd</li> </ul>"},{"location":"explanation/architecture.html#22","title":"2.2. \u4eff\u771f\u6267\u884c\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/simulation/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u57fa\u7840\u4eff\u771f\u6a21\u5f0f (<code>simulation.py</code>)\uff1a\u6267\u884c\u5355\u6b21\u6216\u53c2\u6570\u626b\u63cf\u4eff\u771f\u4efb\u52a1</li> <li>\u7075\u654f\u5ea6\u5206\u6790\u6a21\u5f0f (<code>simulation_analysis.py</code>)\uff1a\u6267\u884c\u591a\u79cd\u654f\u611f\u6027\u5206\u6790\u5de5\u4f5c\u6d41</li> <li>\u7ba1\u7406\u4eff\u771f\u4efb\u52a1\u7684\u5b8c\u6574\u751f\u547d\u5468\u671f\uff08\u521d\u59cb\u5316\u3001\u6267\u884c\u3001\u540e\u5904\u7406\uff09</li> <li>\u534f\u8c03\u6838\u5fc3\u529f\u80fd\u5c42\u3001\u5206\u6790\u5c42\u548c\u540e\u5904\u7406\u5c42\u7684\u8c03\u7528</li> </ul> <p>\u8be6\u89c1\uff1a\u4eff\u771f\u6267\u884c\u6d41\u7a0b \u548c \u81ea\u52a8\u5206\u6790\u6d41\u7a0b</p>"},{"location":"explanation/architecture.html#23","title":"2.3. \u6838\u5fc3\u529f\u80fd\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/core/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>Modelica \u4ea4\u4e92 (<code>modelica.py</code>)\uff1a\u901a\u8fc7 OMPython \u4e0e OpenModelica \u5f15\u64ce\u901a\u4fe1</li> <li>\u4efb\u52a1\u751f\u6210 (<code>jobs.py</code>)\uff1a\u6839\u636e\u914d\u7f6e\u751f\u6210\u53c2\u6570\u626b\u63cf\u4efb\u52a1\u548c\u4eff\u771f\u4f5c\u4e1a</li> <li>\u62e6\u622a\u5668\u673a\u5236 (<code>interceptor.py</code>)\uff1a\u751f\u6210\u548c\u96c6\u6210\u62e6\u622a\u5668\u6a21\u578b\uff0c\u5b9e\u73b0\u534f\u540c\u4eff\u771f</li> </ul> <p>\u8be6\u89c1\uff1aAPI \u53c2\u8003 - \u6838\u5fc3\u6a21\u5757 (Core)</p>"},{"location":"explanation/architecture.html#24","title":"2.4. \u5206\u6790\u4e0e\u540e\u5904\u7406\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/analysis/</code>, <code>tricys/postprocess/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u6027\u80fd\u6307\u6807\u8ba1\u7b97 (<code>analysis/metric.py</code>)\uff1a\u8ba1\u7b97\u542f\u52a8\u76d8\u5b58\u3001\u500d\u589e\u65f6\u95f4\u3001\u8f6c\u6298\u70b9\u7b49\u5173\u952e\u6307\u6807</li> <li>\u6570\u636e\u53ef\u89c6\u5316 (<code>analysis/plot.py</code>)\uff1a\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u56fe\u3001\u53c2\u6570\u626b\u63cf\u56fe\u3001\u5bf9\u6bd4\u56fe\u7b49</li> <li>\u7075\u654f\u5ea6\u5206\u6790 (<code>analysis/salib.py</code>)\uff1a\u96c6\u6210 SALib \u5e93\u6267\u884c\u591a\u79cd\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5</li> <li>\u5206\u6790\u62a5\u544a\u751f\u6210 (<code>analysis/report.py</code>)\uff1a\u81ea\u52a8\u751f\u6210 Markdown \u683c\u5f0f\u7684\u5206\u6790\u62a5\u544a\uff0c\u652f\u6301 AI \u589e\u5f3a</li> <li>\u540e\u5904\u7406\u6a21\u5757 (<code>postprocess/</code>)\uff1a\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6570\u636e\u540e\u5904\u7406\u529f\u80fd</li> </ul> <p>\u8be6\u89c1\uff1aAPI \u53c2\u8003 - \u5206\u6790\u6a21\u5757 (Analysis)</p>"},{"location":"explanation/architecture.html#25","title":"2.5. \u5de5\u5177\u51fd\u6570\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/utils/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u914d\u7f6e\u7ba1\u7406 (<code>config_utils.py</code>)\uff1a\u914d\u7f6e\u6587\u4ef6\u52a0\u8f7d\u3001\u9a8c\u8bc1\u548c\u9884\u5904\u7406</li> <li>\u6587\u4ef6\u64cd\u4f5c (<code>file_utils.py</code>)\uff1a\u6587\u4ef6\u8def\u5f84\u5904\u7406\u3001\u552f\u4e00\u6587\u4ef6\u540d\u751f\u6210\u3001\u5f52\u6863\u7ba1\u7406</li> <li>\u65e5\u5fd7\u7cfb\u7edf (<code>log_utils.py</code>)\uff1a\u7ed3\u6784\u5316\u65e5\u5fd7\u8bb0\u5f55\u548c\u914d\u7f6e\u6062\u590d</li> <li>\u6570\u636e\u5e93\u64cd\u4f5c (<code>sqlite_utils.py</code>)\uff1aSQLite \u6570\u636e\u5b58\u50a8\u548c\u67e5\u8be2</li> </ul> <p>\u8be6\u89c1\uff1aAPI \u53c2\u8003 - \u5de5\u5177\u51fd\u6570 (Utilities)</p>"},{"location":"explanation/architecture.html#26","title":"2.6. \u5916\u90e8\u4f9d\u8d56\u5c42","text":"<p>\u4e3b\u8981\u4f9d\u8d56\uff1a</p> <ul> <li>OpenModelica\uff1aModelica \u6a21\u578b\u7f16\u8bd1\u548c\u4eff\u771f\u6267\u884c\u5f15\u64ce</li> <li>OMPython\uff1aPython \u4e0e OpenModelica \u7684\u63a5\u53e3\u5e93</li> <li>SALib\uff1a\u654f\u611f\u6027\u5206\u6790\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5e93</li> <li>Pandas/NumPy\uff1a\u6570\u636e\u5904\u7406\u548c\u6570\u503c\u8ba1\u7b97</li> <li>Matplotlib/Seaborn\uff1a\u6570\u636e\u53ef\u89c6\u5316</li> <li>OpenAI\uff08\u53ef\u9009\uff09\uff1aAI \u589e\u5f3a\u7684\u5206\u6790\u62a5\u544a\u751f\u6210</li> </ul> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u63d0\u4f9b\u5e95\u5c42\u7684\u4eff\u771f\u5f15\u64ce\u3001\u6570\u503c\u8ba1\u7b97\u548c\u79d1\u5b66\u8ba1\u7b97\u652f\u6301</li> <li>\u786e\u4fdd\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u80fd\u529b</li> </ul>"},{"location":"explanation/architecture.html#3","title":"3. \u8bbe\u8ba1\u539f\u5219","text":"<ol> <li>\u6a21\u5757\u5316\uff1a\u6bcf\u4e2a\u529f\u80fd\u6a21\u5757\u804c\u8d23\u5355\u4e00\uff0c\u76f8\u4e92\u72ec\u7acb</li> <li>\u53ef\u6269\u5c55\uff1a\u6613\u4e8e\u6dfb\u52a0\u65b0\u7684\u540e\u5904\u7406\u6a21\u5757\u3001\u6027\u80fd\u6307\u6807\u548c\u534f\u540c\u4eff\u771f\u5904\u7406\u5668</li> <li>\u914d\u7f6e\u9a71\u52a8\uff1a\u6240\u6709\u4eff\u771f\u4efb\u52a1\u901a\u8fc7 JSON \u914d\u7f6e\u6587\u4ef6\u5b9a\u4e49</li> <li>\u81ea\u52a8\u5316\uff1a\u4ece\u4eff\u771f\u5230\u5206\u6790\u62a5\u544a\u751f\u6210\u7684\u5168\u6d41\u7a0b\u81ea\u52a8\u5316</li> <li>\u5f00\u653e\u6027\uff1a\u5f00\u6e90\u8bbe\u8ba1\uff0c\u652f\u6301\u793e\u533a\u8d21\u732e</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_flow.html","title":"\u81ea\u52a8\u5206\u6790\u6d41\u7a0b","text":"<p><code>tricys</code> \u7684\u5206\u6790\u5de5\u4f5c\u6d41 (<code>simulation_analysis.py</code>) \u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u4ee5\u5206\u6790\u4e3a\u5bfc\u5411\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002\u5b83\u5728\u6838\u5fc3\u4eff\u771f\u529f\u80fd\u4e4b\u4e0a\uff0c\u6784\u5efa\u4e86\u590d\u6742\u7684\u591a\u6a21\u5f0f\u8c03\u5ea6\u3001\u76ee\u6807\u5bfb\u4f18\u548c\u62a5\u544a\u751f\u6210\u80fd\u529b\u3002\u672c\u7bc7\u6587\u6863\u5c06\u8be6\u7ec6\u89e3\u6790\u5176\u5185\u90e8\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_flow.html#1","title":"1. \u6838\u5fc3\u6d41\u7a0b\u56fe","text":"<p>\u4e0b\u9762\u662f <code>tricys</code> \u5206\u6790\u5de5\u4f5c\u6d41\u7684\u5b8c\u6574\u6d41\u7a0b\u56fe\u3002\u5b83\u4ece\u8bfb\u53d6\u914d\u7f6e\u5f00\u59cb\uff0c\u667a\u80fd\u5730\u9009\u62e9\u4e09\u79cd\u4e3b\u8981\u64cd\u4f5c\u6a21\u5f0f\u4e4b\u4e00\uff0c\u5e76\u6267\u884c\u76f8\u5e94\u7684\u4efb\u52a1\u76f4\u5230\u7ed3\u675f\u3002</p> <pre><code>graph TD\n    %% === 1. \u542f\u52a8\u9636\u6bb5 ===\n    subgraph Sub_A [\"A. \u542f\u52a8\u4e0e\u6a21\u5f0f\u9009\u62e9\"]\n        A1[\u5f00\u59cb: main config.json] --&gt; A2[\"\u51c6\u5907\u914d\u7f6e\u4e0e\u65e5\u5fd7&lt;br&gt;analysis_prepare_config()\"]\n        A2 --&gt; A3{\"&lt;font size=4&gt;&lt;b&gt;\u8fd0\u884c\u6a21\u5f0f\u5224\u65ad&lt;/b&gt;&lt;/font&gt;&lt;br&gt;\u5728 run_simulation() \u5185\u90e8\"}\n    end\n\n    %% \u6a21\u5f0f\u5224\u5b9a\u903b\u8f91\n    A3 --&gt; B_GROUP{analysis_cases \u662f\u5426\u5b58\u5728?}\n    B_GROUP -- \u662f --&gt; C1\n    B_GROUP -- \u5426 --&gt; D_GROUP{\u662f\u5426\u4e3a SALib \u5206\u6790?}\n\n    D_GROUP -- \u662f --&gt; E1\n    D_GROUP -- \u5426 --&gt; F1\n\n    %% === 2. \u6a21\u5f0f\u4e00 ===\n    subgraph Sub_C [\"C. \u6a21\u5f0f\u4e00: \u591a\u6848\u4f8b\u5206\u6790\"]\n        direction TB\n        C1[\"&lt;b&gt;\u6a21\u5f0f\u4e00: \u591a\u6848\u4f8b\u5206\u6790&lt;/b&gt;\"]\n        C1 --&gt; C2[\u4e3a\u6bcf\u4e2a\u6848\u4f8b\u521b\u5efa&lt;br&gt;\u72ec\u7acb\u5de5\u4f5c\u76ee\u5f55\u548c\u914d\u7f6e]\n        C2 --&gt; C3{\u5e76\u884c\u6267\u884c\u6848\u4f8b?&lt;br&gt;concurrent_cases}\n\n        C3 -- \u662f --&gt; C4[\u4f7f\u7528 &lt;b&gt;ProcessPoolExecutor&lt;/b&gt;&lt;br&gt;\u5e76\u884c\u8c03\u7528 _execute_analysis_case]\n        C3 -- \u5426 --&gt; C5[\u4e32\u884c\u5faa\u73af&lt;br&gt;\u9010\u4e2a\u8c03\u7528 _execute_analysis_case]\n\n        %% \u5b50\u56fe\uff1a\u5355\u4e2a\u6848\u4f8b\u6267\u884c\n        subgraph Sub_C6 [\"C6. \u5355\u4e2a\u6848\u4f8b\u7684\u6267\u884c _execute_analysis_case\"]\n            direction TB\n            C6_1[\u8fdb\u5165\u72ec\u7acb\u5de5\u4f5c\u76ee\u5f55] --&gt; C6_2[\"&lt;b&gt;\u9012\u5f52\u8c03\u7528 run_simulation&lt;br&gt;(\u7981\u7528\u5185\u90e8\u5e76\u53d1)&lt;/b&gt;\"] \n            C6_2 --&gt; C6_3[\u6267\u884c\u6a21\u5f0f\u4e09\u7684\u5b8c\u6574\u6d41\u7a0b]\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u7684\u7b2c\u4e00\u4e2a\u8282\u70b9 C6_1\uff0c\u800c\u4e0d\u662f\u5b50\u56fe\u672c\u8eab\n        C4 --&gt; C6_1\n        C5 --&gt; C6_1\n\n        C6_3 --&gt; C7[\u6240\u6709\u6848\u4f8b\u6267\u884c\u5b8c\u6bd5]\n        C7 --&gt; C8[\"\u6c47\u603b\u6240\u6709\u6848\u4f8b\u7684\u62a5\u544a&lt;br&gt;consolidate_reports()\"]\n        C8 --&gt; Z1[\u7ed3\u675f]\n    end\n\n    %% === 3. \u6a21\u5f0f\u4e8c ===\n    subgraph Sub_E [\"E. \u6a21\u5f0f\u4e8c: SALib \u5206\u6790\"]\n        direction TB\n        E1[\"&lt;b&gt;\u6a21\u5f0f\u4e8c: SALib \u5206\u6790&lt;/b&gt;\"] --&gt; E2[\u8c03\u7528 run_salib_analysis]\n\n        %% \u5b50\u56fe\uff1aSALib \u6d41\u7a0b\n        subgraph Sub_E3 [\"E3. SALib \u5185\u90e8\u6d41\u7a0b\"]\n            direction TB\n            E3_1[1. \u4f7f\u7528 SALib \u751f\u6210\u53c2\u6570\u6837\u672c] --&gt; E3_2[2. \u4e3a\u6bcf\u4e2a\u6837\u672c\u8fd0\u884c\u4eff\u771f] \n            E3_2 --&gt; E3_3[3. \u6536\u96c6\u7ed3\u679c\u5e76\u8ba1\u7b97\u654f\u611f\u5ea6\u6307\u6570]\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u8282\u70b9 E3_1\n        E2 --&gt; E3_1\n        E3_3 --&gt; Z2[\u7ed3\u675f]\n    end\n\n    %% === 4. \u6a21\u5f0f\u4e09 ===\n    subgraph Sub_F [\"F. \u6a21\u5f0f\u4e09: \u6807\u51c6\u626b\u63cf\u4e0e\u5206\u6790\"]\n        direction TB\n        F1[\"&lt;b&gt;\u6a21\u5f0f\u4e09: \u6807\u51c6\u626b\u63cf\u4e0e\u5206\u6790&lt;/b&gt;\"] --&gt; F2[\u751f\u6210\u4eff\u771f\u4efb\u52a1\u5217\u8868 jobs]\n        F2 --&gt; F3{\u5e76\u884c\u6267\u884c\u4efb\u52a1?&lt;br&gt;concurrent}\n\n        F3 -- \u662f --&gt; F4[\"\u4f7f\u7528 &lt;b&gt;ThreadPoolExecutor (\u6807\u51c6)&lt;/b&gt;&lt;br&gt;\u6216 &lt;b&gt;ProcessPoolExecutor (\u534f\u540c)&lt;/b&gt;&lt;br&gt;\u5e76\u884c\u6267\u884c\u6bcf\u4e2a\u4efb\u52a1\"]\n        F3 -- \u5426 --&gt; F5[\"\u4e32\u884c\u6267\u884c&lt;br&gt;_run_sequential_sweep()\"]\n\n        %% \u5b50\u56fe\uff1a\u5355\u4e2a\u4efb\u52a1\u6267\u884c\n        subgraph Sub_F6 [\"F6. \u5355\u4e2a\u4efb\u52a1\u7684\u6267\u884c _run_..._job\"]\n            direction TB\n            F6_1[1. \u5728\u9694\u79bb\u76ee\u5f55\u4e2d\u8fd0\u884c\u4eff\u771f] --&gt; F6_2{2. \u662f\u5426\u914d\u7f6e\u4e86\u4f18\u5316\u76ee\u6807?&lt;br&gt;Required_...}\n\n            F6_2 -- \u662f --&gt; F6_3[\"&lt;b&gt;\u4f18\u5316\u5b50\u6d41\u7a0b&lt;/b&gt;&lt;br&gt;\u8c03\u7528 _run_bisection_search_for_job\"]\n\n            %% \u5d4c\u5957\u5b50\u56fe\uff1a\u4e8c\u5206\u641c\u7d22\n            subgraph Sub_F6_4 [\"F6_4. \u4e8c\u5206\u641c\u7d22\u5faa\u73af\"]\n                F6_4_1[a. \u5728\u641c\u7d22\u8303\u56f4\u5185&lt;br&gt;\u8fed\u4ee3\u6267\u884c\u4eff\u771f] --&gt; F6_4_2[b. \u68c0\u67e5\u6307\u6807\u662f\u5426\u6ee1\u8db3\u6761\u4ef6] \n                F6_4_2 --&gt; F6_4_3[c. \u7f29\u5c0f\u641c\u7d22\u8303\u56f4]\n                F6_4_3 --&gt; F6_4_1\n            end\n\n            F6_3 --&gt; F6_4_1\n            F6_4_2 -- \u6ee1\u8db3\u6216\u7ed3\u675f --&gt; F6_5\n\n            F6_5[\"3. \u8fd4\u56de\u4eff\u771f\u7ed3\u679c\u8def\u5f84&lt;br&gt;\u548c&lt;b&gt;\u4f18\u5316\u7ed3\u679c&lt;/b&gt;\"]\n            F6_2 -- \u5426 --&gt; F6_5\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u8282\u70b9 F6_1\n        F4 --&gt; F6_1\n        F5 --&gt; F6_1\n\n        F6_5 --&gt; F7[\u6240\u6709\u4efb\u52a1\u6267\u884c\u5b8c\u6bd5]\n        F7 --&gt; F8[\"&lt;b&gt;\u7ed3\u679c\u805a\u5408\u4e0e\u540e\u5904\u7406&lt;/b&gt;\"]\n\n        %% \u5b50\u56fe\uff1a\u540e\u7eed\u6b65\u9aa4\n        subgraph Sub_F9 [\"F9. \u540e\u7eed\u6b65\u9aa4\"]\n            direction TB\n            F9_1[a. \u5408\u5e76\u4eff\u771f\u7ed3\u679c\u5230 sweep_results.csv] --&gt; F9_2[b. \u5408\u5e76\u4f18\u5316\u7ed3\u679c\u5230 requierd_tbr_summary.csv]\n            F9_2 --&gt; F9_3[\"c. \u6267\u884c\u654f\u611f\u6027\u5206\u6790&lt;br&gt;_run_sensitivity_analysis()&lt;br&gt;(\u63d0\u53d6\u6307\u6807\u3001\u751f\u6210\u56fe\u8868)\"]\n            F9_3 --&gt; F9_4[\"d. \u6267\u884c\u81ea\u5b9a\u4e49\u540e\u5904\u7406&lt;br&gt;_run_post_processing()\"]\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u8282\u70b9 F9_1\n        F8 --&gt; F9_1\n        F9_4 --&gt; Z3[\u7ed3\u675f]\n    end\n\n    %% \u6837\u5f0f\u5b9a\u4e49\n    style C1 fill:#e3f2fd,stroke:#333,stroke-width:2px\n    style E1 fill:#e8f5e9,stroke:#333,stroke-width:2px\n    style F1 fill:#fbe9e7,stroke:#333,stroke-width:2px</code></pre>"},{"location":"explanation/tricys_analysis/analysis_flow.html#2","title":"2. \u6d41\u7a0b\u6b65\u9aa4\u8be6\u89e3","text":""},{"location":"explanation/tricys_analysis/analysis_flow.html#21","title":"2.1. \u542f\u52a8\u4e0e\u6a21\u5f0f\u9009\u62e9","text":"<p>\u6574\u4e2a\u6d41\u7a0b\u59cb\u4e8e <code>main</code> \u51fd\u6570\uff0c\u5b83\u8d1f\u8d23\u52a0\u8f7d\u548c\u9884\u5904\u7406\u914d\u7f6e\u6587\u4ef6 (<code>analysis_prepare_config</code>) \u5e76\u8bbe\u7f6e\u65e5\u5fd7\u7cfb\u7edf\u3002\u6838\u5fc3\u903b\u8f91\u4f4d\u4e8e <code>run_simulation</code> \u51fd\u6570\u4e2d\uff0c\u5b83\u9996\u5148\u4f1a\u8fdb\u884c\u6a21\u5f0f\u5224\u65ad\uff0c\u4ee5\u51b3\u5b9a\u63a5\u4e0b\u6765\u6267\u884c\u54ea\u4e2a\u6838\u5fc3\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_flow.html#22","title":"2.2. \u6a21\u5f0f\u4e00\uff1a\u591a\u6848\u4f8b\u5206\u6790","text":"<p>\u5f53\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u4e86 <code>analysis_cases</code> \u65f6\uff0c\u6b64\u6a21\u5f0f\u88ab\u6fc0\u6d3b\u3002\u5b83\u7528\u4e8e\u6267\u884c\u4e00\u7cfb\u5217\u72ec\u7acb\u7684\u3001\u53ef\u5bf9\u6bd4\u7684\u5206\u6790\u7814\u7a76\u3002</p> <ol> <li>\u73af\u5883\u8bbe\u7f6e\uff1a\u6846\u67b6\u4f1a\u4e3a <code>analysis_cases</code> \u4e2d\u7684\u6bcf\u4e00\u4e2a\u6848\u4f8b\u521b\u5efa\u4e00\u4e2a\u5b8c\u5168\u72ec\u7acb\u7684\u5b50\u5de5\u4f5c\u76ee\u5f55\uff0c\u5e76\u4e3a\u5176\u751f\u6210\u4e00\u4efd\u5b9a\u5236\u5316\u7684\u914d\u7f6e\u6587\u4ef6\u3002\u8fd9\u786e\u4fdd\u4e86\u6bcf\u4e2a\u6848\u4f8b\u7684\u8fd0\u884c\u73af\u5883\uff08\u5305\u62ec\u6a21\u578b\u4fee\u6539\u3001\u4e34\u65f6\u6587\u4ef6\u548c\u7ed3\u679c\uff09\u90fd\u662f\u9694\u79bb\u7684\u3002</li> <li>\u5e76\u53d1\u6267\u884c\uff1a\u5982\u679c\u914d\u7f6e\u4e86 <code>\"concurrent_cases\": true</code>\uff0c<code>tricys</code> \u4f1a\u542f\u52a8\u4e00\u4e2a\u8fdb\u7a0b\u6c60 (<code>ProcessPoolExecutor</code>) \u6765\u5e76\u884c\u6267\u884c\u6240\u6709\u6848\u4f8b\u3002\u4f7f\u7528\u8fdb\u7a0b\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6848\u4f8b\u90fd\u662f\u4e00\u4e2a\u5b8c\u6574\u7684 <code>tricys</code> \u8fd0\u884c\u5b9e\u4f8b\uff0c\u9700\u8981\u72ec\u7acb\u7684\u5185\u5b58\u7a7a\u95f4\u548c\u6587\u4ef6\u7cfb\u7edf\u6743\u9650\u4ee5\u907f\u514d\u51b2\u7a81\u3002</li> <li>\u9012\u5f52\u8c03\u7528\uff1a\u6bcf\u4e2a\u6848\u4f8b\u7684\u6267\u884c\u7531 <code>_execute_analysis_case</code> \u51fd\u6570\u5305\u88f9\uff0c\u8be5\u51fd\u6570\u4f1a\u9012\u5f52\u5730\u8c03\u7528 <code>run_simulation</code>\uff0c\u5e76\u5f3a\u5236\u7981\u7528\u5185\u90e8\u7684\u5e76\u53d1\u6267\u884c\uff08\u9632\u6b62\u8fdb\u7a0b\u6c60\u5d4c\u5957\uff09\u3002\u8fd9\u610f\u5473\u7740\u6bcf\u4e2a\u6848\u4f8b\u5185\u90e8\u4f1a\u5b8c\u6574\u5730\u6267\u884c\u4e00\u904d\u201c\u6a21\u5f0f\u4e09\u201d\u7684\u6d41\u7a0b\u3002</li> <li>\u62a5\u544a\u6c47\u603b\uff1a\u6240\u6709\u6848\u4f8b\u6267\u884c\u5b8c\u6bd5\u540e\uff0c\u6846\u67b6\u4f1a\u8c03\u7528 <code>consolidate_reports</code> \u7b49\u51fd\u6570\uff0c\u4ece\u6240\u6709\u5b50\u5de5\u4f5c\u76ee\u5f55\u4e2d\u6536\u96c6\u5206\u6790\u7ed3\u679c\u548c\u62a5\u544a\uff0c\u5e76\u751f\u6210\u4e00\u4efd\u9876\u5c42\u7684\u6c47\u603b\u62a5\u544a\uff0c\u65b9\u4fbf\u7528\u6237\u8fdb\u884c\u8de8\u6848\u4f8b\u7684\u6bd4\u8f83\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_flow.html#23-salib","title":"2.3. \u6a21\u5f0f\u4e8c\uff1aSALib \u5168\u5c40\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5982\u679c\u914d\u7f6e\u6307\u5411\u4e00\u4e2a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff08GSA\uff09\u4efb\u52a1\uff08\u901a\u8fc7 <code>independent_variable_sampling</code> \u548c <code>analyzer</code> \u7b49\u5173\u952e\u5b57\u8bc6\u522b\uff09\uff0c<code>tricys</code> \u4f1a\u5c06\u63a7\u5236\u6743\u79fb\u4ea4\u7ed9\u4e13\u95e8\u7684 SALib \u5de5\u4f5c\u6d41\u3002</p> <ol> <li>\u8c03\u7528 <code>run_salib_analysis</code>\uff1a\u8fd9\u662f SALib \u6d41\u7a0b\u7684\u5165\u53e3\u3002</li> <li>\u53c2\u6570\u91c7\u6837\uff1a\u4f7f\u7528 SALib \u5e93\uff08\u5982 <code>saltelli.sample</code>\uff09\u6839\u636e\u914d\u7f6e\u7684\u53c2\u6570\u5206\u5e03\u751f\u6210\u5927\u91cf\u7684\u53c2\u6570\u6837\u672c\u96c6\u3002</li> <li>\u6279\u91cf\u4eff\u771f\uff1a\u4e3a\u6bcf\u4e00\u4e2a\u53c2\u6570\u6837\u672c\u8fd0\u884c\u4e00\u6b21 Modelica \u4eff\u771f\u3002</li> <li>\u7ed3\u679c\u5206\u6790\uff1a\u6536\u96c6\u6240\u6709\u4eff\u771f\u7ed3\u679c\uff0c\u5e76\u4f7f\u7528 SALib \u7684\u5206\u6790\u5668\uff08\u5982 <code>sobol.analyze</code>\uff09\u8ba1\u7b97\u6bcf\u4e2a\u53c2\u6570\u7684\u4e00\u9636\u3001\u4e8c\u9636\u548c\u603b\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1, S2, ST\uff09\u3002</li> <li>\u8f93\u51fa\u62a5\u544a\uff1a\u5c06\u654f\u611f\u6027\u6307\u6570\u548c\u76f8\u5173\u56fe\u8868\u8f93\u51fa\u4e3a\u6700\u7ec8\u7684\u5206\u6790\u62a5\u544a\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_flow.html#24","title":"2.4. \u6a21\u5f0f\u4e09\uff1a\u6807\u51c6\u626b\u63cf\u4e0e\u5206\u6790","text":"<p>\u8fd9\u662f\u6700\u57fa\u7840\u4e5f\u662f\u6700\u6838\u5fc3\u7684\u5de5\u4f5c\u6d41\uff0c\u5f53\u4ee5\u4e0a\u4e24\u79cd\u6a21\u5f0f\u7684\u6761\u4ef6\u90fd\u4e0d\u6ee1\u8db3\u65f6\uff0c\u5c31\u4f1a\u6267\u884c\u6b64\u6d41\u7a0b\u3002</p> <ol> <li>\u751f\u6210\u4efb\u52a1\uff1a\u6839\u636e <code>simulation_parameters</code> \u751f\u6210\u4eff\u771f\u4efb\u52a1\u5217\u8868 <code>jobs</code>\u3002</li> <li>\u6267\u884c\u4eff\u771f\u4efb\u52a1\uff1a<ul> <li>\u6839\u636e <code>concurrent</code> \u914d\u7f6e\uff0c\u9009\u62e9\u5e76\u884c\u6216\u4e32\u884c\u6267\u884c\u6240\u6709 <code>jobs</code>\u3002</li> <li>\u6bcf\u4e2a\u4efb\u52a1\u7684\u6267\u884c\u7531 <code>_run_single_job</code> \u6216 <code>_run_co_simulation</code> \u7b49\u51fd\u6570\u5904\u7406\u3002</li> </ul> </li> <li>\u4f18\u5316\u5b50\u6d41\u7a0b\uff08\u6838\u5fc3\u7279\u8272\uff09\uff1a\u5728\u5355\u6b21\u4eff\u771f\u4efb\u52a1\u6267\u884c\u5b8c\u6bd5\u540e\uff0c\u7cfb\u7edf\u4f1a\u68c0\u67e5\u662f\u5426\u914d\u7f6e\u4e86\u4f18\u5316\u76ee\u6807\uff08\u4ee5 <code>Required_</code> \u4e3a\u524d\u7f00\u7684\u6307\u6807\uff09\u3002<ul> <li>\u5982\u679c\u5b58\u5728\uff0c\u7cfb\u7edf\u4f1a\u7acb\u5373\u8c03\u7528 <code>_run_bisection_search_for_job</code>\uff0c\u542f\u52a8\u4e00\u4e2a\u4e8c\u5206\u641c\u7d22\u5faa\u73af\u3002</li> <li>\u8be5\u5faa\u73af\u4f1a\u4e3a\u4e86\u5bfb\u627e\u4e00\u4e2a\u80fd\u6ee1\u8db3\u9884\u8bbe\u6307\u6807\uff08\u4f8b\u5982\uff0c\u6c1a\u589e\u6b96\u6bd4TBR &gt; 1.05\uff09\u7684\u6700\u4f18\u53c2\u6570\u503c\uff0c\u800c\u8fed\u4ee3\u5730\u8fd0\u884c\u591a\u6b21\u4eff\u771f\uff0c\u5e76\u6839\u636e\u6bcf\u6b21\u7684\u7ed3\u679c\u52a8\u6001\u8c03\u6574\u53c2\u6570\uff0c\u76f4\u5230\u627e\u5230\u89e3\u6216\u8fbe\u5230\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002</li> </ul> </li> <li>\u7ed3\u679c\u805a\u5408\uff1a<ul> <li>\u6240\u6709\u4efb\u52a1\uff08\u5305\u62ec\u4f18\u5316\u5b50\u6d41\u7a0b\u4e2d\u7684\u6240\u6709\u4eff\u771f\uff09\u5b8c\u6210\u540e\uff0c\u6846\u67b6\u4f1a\u805a\u5408\u4e24\u7c7b\u6570\u636e\uff1a<ul> <li>\u6240\u6709\u4eff\u771f\u7684\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5408\u5e76\u5230 <code>sweep_results.csv</code>\u3002</li> <li>\u6240\u6709\u4f18\u5316\u4efb\u52a1\u7684\u6700\u7ec8\u7ed3\u679c\uff08\u4f8b\u5982\uff0c<code>TBR&gt;1.05</code> \u5bf9\u5e94\u7684\u6700\u4f18 <code>enrichment</code> \u662f <code>0.85</code>\uff09\uff0c\u5408\u5e76\u5230 <code>requierd_tbr_summary.csv</code>\u3002</li> </ul> </li> </ul> </li> <li>\u6700\u7ec8\u5206\u6790\u4e0e\u540e\u5904\u7406\uff1a<ul> <li>\u8c03\u7528 <code>_run_sensitivity_analysis</code>\uff0c\u5b83\u4f1a\u52a0\u8f7d\u805a\u5408\u540e\u7684\u6570\u636e\uff0c\u8ba1\u7b97\u6700\u7ec8\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPI\uff09\uff0c\u5e76\u751f\u6210\u5206\u6790\u56fe\u8868\u548c\u6458\u8981\u3002</li> <li>\u8c03\u7528 <code>_run_post_processing</code>\uff0c\u6267\u884c\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u4efb\u4f55\u6700\u7ec8\u5904\u7406\u811a\u672c\uff08\u4f8b\u5982\uff0c\u751f\u6210\u7279\u5b9a\u7684\u62a5\u544a\u683c\u5f0f\uff09\u3002</li> </ul> </li> </ol>"},{"location":"explanation/tricys_analysis/analysis_report.html","title":"\u751f\u6210\u5206\u6790\u62a5\u544a","text":"<p>TRICYS \u4e0d\u4ec5\u662f\u4e00\u4e2a\u4eff\u771f\u6267\u884c\u6846\u67b6\uff0c\u66f4\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u81ea\u52a8\u5316\u5206\u6790\u4e0e\u62a5\u544a\u5e73\u53f0\u3002\u5b83\u80fd\u591f\u5c06\u590d\u6742\u7684\u4eff\u771f\u7ed3\u679c\u81ea\u52a8\u5904\u7406\u6210\u7ed3\u6784\u6e05\u6670\u3001\u5185\u5bb9\u4e30\u5bcc\u3001\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u7684\u5206\u6790\u62a5\u544a\u3002\u5176\u62a5\u544a\u751f\u6210\u6d41\u7a0b\u91c7\u7528\u521b\u65b0\u7684\u5206\u5c42\u8bbe\u8ba1\uff0c\u4ece\u6570\u636e\u9a71\u52a8\u7684\u56fe\u8868\u751f\u6210\uff0c\u5230\u53ef\u9009\u7684\u3001\u7531\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u6df1\u5ea6\u5206\u6790\u4e0e\u5b66\u672f\u7ea7\u62a5\u544a\u64b0\u5199\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#1","title":"1. \u4e13\u4e1a\u672f\u8bed\u4e0e\u56fd\u9645\u5316\u56fe\u8868","text":"<p>\u4e3a\u4e86\u4f7f\u751f\u6210\u7684\u56fe\u8868\u5177\u6709\u4e13\u4e1a\u6027\u548c\u53ef\u8bfb\u6027\uff0cTRICYS \u5f15\u5165\u4e86\u4e00\u5957\u57fa\u4e8e\u5916\u90e8\u672f\u8bed\u8868\u7684\u6807\u7b7e\u6620\u5c04\u673a\u5236\uff0c\u5e76\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u5207\u6362\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#11","title":"1.1 \u5de5\u4f5c\u539f\u7406","text":"<p>\u8be5\u529f\u80fd\u7531 <code>tricys/analysis/plot.py</code> \u6a21\u5757\u5b9e\u73b0\u3002</p> <ol> <li>\u52a0\u8f7d\u672f\u8bed\u8868\uff1a\u7a0b\u5e8f\u542f\u52a8\u65f6\uff0c<code>load_glossary()</code> \u51fd\u6570\u4f1a\u8bfb\u53d6\u4e00\u4e2a\u7528\u6237\u6307\u5b9a\u7684 CSV \u6587\u4ef6\uff08<code>glossary_path</code>\uff09\u3002\u8be5 CSV \u6587\u4ef6\u5b9a\u4e49\u4e86\u5185\u90e8\u6a21\u578b\u53d8\u91cf\u540d\u4e0e\u5176\u4e2d\u82f1\u6587\u4e13\u4e1a\u672f\u8bed\u7684\u5bf9\u5e94\u5173\u7cfb\u3002</li> <li>\u8bbe\u7f6e\u8bed\u8a00\uff1a\u901a\u8fc7\u8c03\u7528 <code>set_plot_language('cn')</code> \u6216 <code>set_plot_language('en')</code>\uff0c\u53ef\u4ee5\u5168\u5c40\u5207\u6362\u56fe\u8868\u7684\u663e\u793a\u8bed\u8a00\u3002\u5207\u6362\u81f3\u4e2d\u6587\u65f6\uff0c\u4f1a\u81ea\u52a8\u542f\u7528\u652f\u6301\u4e2d\u6587\u7684\u5b57\u4f53\uff08\u5982\u201cSimHei\u201d\uff09\u3002</li> <li>\u6807\u7b7e\u683c\u5f0f\u5316\uff1a\u5728\u7ed8\u5236\u56fe\u8868\u65f6\uff0c\u6240\u6709\u539f\u59cb\u7684\u53d8\u91cf\u540d\uff08\u5982 <code>Startup_Inventory</code>, <code>sds.I[1]</code>\uff09\u90fd\u4f1a\u7ecf\u8fc7 <code>_format_label()</code> \u51fd\u6570\u5904\u7406\u3002\u8be5\u51fd\u6570\u4f1a\uff1a<ul> <li>\u9996\u5148\uff0c\u6839\u636e\u5f53\u524d\u8bbe\u7f6e\u7684\u8bed\u8a00\uff0c\u5728\u52a0\u8f7d\u7684\u672f\u8bed\u8868\u4e2d\u67e5\u627e\u5bf9\u5e94\u7684\u4e2d\u6587\u6216\u82f1\u6587\u4e13\u4e1a\u672f\u8bed\u3002</li> <li>\u5982\u679c\u67e5\u627e\u5230\uff0c\u5219\u4f7f\u7528\u8be5\u4e13\u4e1a\u672f\u8bed\u4f5c\u4e3a\u56fe\u8868\u6807\u7b7e\uff08\u4f8b\u5982\uff0c\u56fe\u4f8b\u3001\u5750\u6807\u8f74\u6807\u9898\uff09\u3002</li> <li>\u5982\u679c\u672a\u627e\u5230\uff0c\u5219\u6267\u884c\u9ed8\u8ba4\u7684\u683c\u5f0f\u5316\uff08\u4f8b\u5982\uff0c\u5c06\u4e0b\u5212\u7ebf\u66ff\u6362\u4e3a\u7a7a\u683c\uff09\uff0c\u4fdd\u8bc1\u6807\u7b7e\u7684\u57fa\u672c\u53ef\u8bfb\u6027\u3002</li> </ul> </li> <li>\u5355\u4f4d\u6620\u5c04\uff1a\u9664\u4e86\u672f\u8bed\uff0c\u5750\u6807\u8f74\u7684\u5355\u4f4d\u4e5f\u652f\u6301\u901a\u8fc7 <code>unit_map</code> \u914d\u7f6e\u8fdb\u884c\u8f6c\u6362\u548c\u663e\u793a\uff0c\u5e76\u540c\u6837\u652f\u6301\u56fd\u9645\u5316\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_report.html#12","title":"1.2 \u672f\u8bed\u8868\u683c\u5f0f\u793a\u4f8b","text":"<p>\u8be5 CSV \u6587\u4ef6\u5fc5\u987b\u5305\u542b\u4ee5\u4e0b\u4e09\u5217\uff1a</p> \u6a21\u578b\u53c2\u6570 (Model Parameter) \u82f1\u6587\u672f\u8bed (English Term) \u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation) <code>Startup_Inventory</code> Startup Inventory \u542f\u52a8\u5e93\u5b58 <code>Doubling_Time</code> Doubling Time \u500d\u589e\u65f6\u95f4 <code>sds.I[1]</code> Tritium Inventory in SDS \u8d2e\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf\u6c1a\u5e93\u5b58 <p>\u901a\u8fc7\u8fd9\u79cd\u673a\u5236\uff0cTRICYS \u80fd\u591f\u5c06\u5185\u90e8\u53d8\u91cf <code>Startup_Inventory</code> \u5728\u751f\u6210\u56fe\u8868\u65f6\u81ea\u52a8\u7f8e\u5316\u4e3a\u201cStartup Inventory (kg)\u201d\u6216\u201c\u542f\u52a8\u5e93\u5b58 (\u5343\u514b)\u201d\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#2","title":"2. \u6838\u5fc3\u56fe\u8868\u7c7b\u578b","text":"<p><code>tricys/analysis/plot.py</code> \u4e2d\u7684 <code>generate_analysis_plots()</code> \u51fd\u6570\u662f\u6240\u6709\u5206\u6790\u56fe\u8868\u7684\u603b\u5165\u53e3\uff0c\u5b83\u4f1a\u6839\u636e\u5206\u6790\u4efb\u52a1\u7684\u7c7b\u578b\u751f\u6210\u4ee5\u4e0b\u51e0\u7c7b\u6838\u5fc3\u56fe\u8868\uff1a</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#21","title":"2.1 \u4e3b\u8d8b\u52bf\u56fe","text":"<ul> <li>\u7528\u9014\uff1a\u5c55\u793a\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u56e0\u53d8\u91cf\uff09\u5982\u4f55\u968f\u72ec\u7acb\u626b\u63cf\u53d8\u91cf\u7684\u53d8\u5316\u800c\u53d8\u5316\u3002</li> <li>\u7279\u70b9\uff1a<ul> <li>\u5f53\u5b58\u5728\u591a\u4e2a\u80cc\u666f\u626b\u63cf\u53c2\u6570\uff08<code>simulation_parameters</code>\uff09\u65f6\uff0c\u4f1a\u81ea\u52a8\u4f7f\u7528\u4e0d\u540c\u7684\u989c\u8272\u3001\u7ebf\u578b\u548c\u6807\u8bb0\u6765\u7ed8\u5236\u591a\u6761\u66f2\u7ebf\uff0c\u5e76\u751f\u6210\u56fe\u4f8b\u3002</li> <li>\u5982\u679c\u66f2\u7ebf\u6570\u91cf\u4e0d\u591a\uff0c\u4f1a\u81ea\u52a8\u5728\u6570\u636e\u70b9\u4e0a\u6807\u6ce8\u6570\u503c\uff0c\u65b9\u4fbf\u7cbe\u786e\u8bfb\u6570\u3002</li> <li>\u652f\u6301\u5c06\u591a\u4e2a\u6307\u6807\u7ed8\u5236\u5728\u540c\u4e00\u5f20\u56fe\u7684\u591a\u4e2a\u5b50\u56fe\u4e2d\uff08<code>_generate_combined_plots</code>\uff09\uff0c\u6216\u4e3a\u6bcf\u4e2a\u6307\u6807\u751f\u6210\u72ec\u7acb\u7684\u56fe\u8868\u6587\u4ef6\uff08<code>_generate_individual_plots</code>\uff09\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_analysis/analysis_report.html#22","title":"2.2 \u7ea6\u675f\u6c42\u89e3\u5206\u6790\u56fe","text":"<ul> <li>\u7528\u9014\uff1a\u4e13\u95e8\u7528\u4e8e\u53ef\u89c6\u5316\u201c\u76ee\u6807\u5bfb\u4f18\u201d\u4efb\u52a1\u7684\u7ed3\u679c\uff08\u5373 <code>Required_</code> \u5f00\u5934\u7684\u6307\u6807\uff09\u3002</li> <li>\u7279\u70b9\uff1a<ul> <li>\u7531 <code>_generate_multi_required_plot()</code> \u51fd\u6570\u751f\u6210\uff0c\u901a\u5e38\u91c7\u7528\u591a\u5b50\u56fe\u5e03\u5c40\u3002</li> <li>\u6bcf\u4e2a\u5b50\u56fe\u4ee3\u8868\u4e00\u7ec4\u7279\u5b9a\u7684\u80cc\u666f\u53c2\u6570\u7ec4\u5408\uff0c\u6e05\u6670\u5730\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u573a\u666f\u4e0b\uff0c\u4e3a\u4e86\u8fbe\u6210\u67d0\u4e2a\u7ea6\u675f\u6761\u4ef6\uff08\u4f8b\u5982\uff0c\u500d\u589e\u65f6\u95f4\u5c0f\u4e8e10\u5e74\uff09\uff0c\u9700\u8981\u4ed8\u51fa\u7684\u201c\u4ee3\u4ef7\u201d\uff08\u5373\u88ab\u4f18\u5316\u7684\u53c2\u6570\u503c\uff09\u3002</li> <li>\u8fd9\u79cd\u56fe\u5bf9\u4e8e\u7406\u89e3\u591a\u53d8\u91cf\u6743\u8861\uff08Trade-offs\uff09\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_analysis/analysis_report.html#23","title":"2.3 \u626b\u63cf\u8fc7\u7a0b\u65f6\u5e8f\u56fe","text":"<ul> <li>\u7528\u9014\uff1a\u5f53\u9700\u8981\u89c2\u5bdf\u67d0\u4e2a\u52a8\u6001\u53d8\u91cf\u5728\u4e0d\u540c\u53c2\u6570\u626b\u63cf\u4e0b\u7684\u5b8c\u6574\u65f6\u95f4\u6f14\u5316\u8fc7\u7a0b\u65f6\uff0c\u751f\u6210\u6b64\u56fe\u3002</li> <li>\u7279\u70b9\uff1a<ul> <li>\u7531 <code>plot_sweep_time_series()</code> \u51fd\u6570\u751f\u6210\uff0c\u5305\u542b\u4e24\u4e2a\u5b50\u56fe\uff1a<ol> <li>\u5168\u5c40\u89c6\u56fe (Overall View)\uff1a\u5c55\u793a\u4ece <code>t=0</code> \u5230\u4eff\u771f\u7ed3\u675f\u7684\u5b8c\u6574\u65f6\u95f4\u66f2\u7ebf\u3002\u4e3a\u4e86\u7a81\u51fa\u65e9\u671f\u5173\u952e\u884c\u4e3a\uff0c\u6b64\u89c6\u56fe\u4f1a\u81ea\u52a8\u9690\u85cf\u8d85\u8fc7\u521d\u59cb\u503c\u4e24\u500d\u7684\u6570\u636e\u70b9\u3002</li> <li>\u7ec6\u8282\u89c6\u56fe (Detailed View)\uff1a\u81ea\u52a8\u805a\u7126\u4e8e\u6240\u6709\u66f2\u7ebf\u4e2d\u9996\u6b21\u8fbe\u5230\u6700\u5c0f\u503c\u7684\u533a\u57df\uff0c\u5e76\u653e\u5927\u663e\u793a\u3002\u8fd9\u5bf9\u4e8e\u89c2\u5bdf\u7cfb\u7edf\u542f\u52a8\u521d\u671f\u7684\u52a8\u6001\u7279\u6027\uff08\u5982\u5e93\u5b58\u7684\u201c\u4e0b\u8dcc-\u56de\u5347\u201d\u8f6c\u6298\u70b9\uff09\u975e\u5e38\u6709\u7528\u3002</li> </ol> </li> <li>\u4e00\u4e2a\u7ea2\u8272\u7684\u865a\u7ebf\u6846\u4f1a\u81ea\u52a8\u7ed8\u5236\u5728\u201c\u5168\u5c40\u89c6\u56fe\u201d\u4e0a\uff0c\u4ee5\u6807\u793a\u201c\u7ec6\u8282\u89c6\u56fe\u201d\u6240\u5bf9\u5e94\u7684\u533a\u57df\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_analysis/analysis_report.html#3","title":"3. \u591a\u9636\u6bb5\u62a5\u544a\u751f\u6210\u903b\u8f91","text":"<p>TRICYS \u7684\u62a5\u544a\u751f\u6210\u5206\u4e3a\u4e24\u4e2a\u6838\u5fc3\u9636\u6bb5\uff0c\u7531 <code>tricys/analysis/report.py</code> \u6a21\u5757\u8c03\u5ea6\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5c06\u539f\u59cb\u6570\u636e\u4e0e AI \u89e3\u8bfb\u5206\u79bb\uff0c\u4fdd\u8bc1\u4e86\u7ed3\u679c\u7684\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u3002</p> <pre><code>graph TD\n    A[\u5f00\u59cb] --&gt; B[\u6267\u884c\u6240\u6709\u4eff\u771f\u4e0e\u5206\u6790\u4efb\u52a1];\n    B --&gt; C[\"&lt;b&gt;\u9636\u6bb5\u4e00\uff1a\u751f\u6210\u57fa\u7840\u6570\u636e\u62a5\u544a&lt;/b&gt;&lt;br&gt;`generate_prompt_templates()`\"];\n    C --&gt; D{AI \u5206\u6790\u662f\u5426\u542f\u7528?};\n    D -- \u5426 --&gt; E[\u7ed3\u675f: \u4ec5\u5305\u542b\u6570\u636e\u548c\u56fe\u8868\u7684\u57fa\u7840\u62a5\u544a];\n    D -- \u662f --&gt; F[\"&lt;b&gt;\u9636\u6bb5\u4e8c\uff1a\u751f\u6210 AI \u589e\u5f3a\u62a5\u544a&lt;/b&gt;\"];\n\n    subgraph F\n        direction LR\n        F1[\"\u7b2c\u4e00\u6b21\u8c03\u7528 LLM:&lt;br&gt;\u539f\u59cb\u6570\u636e\u5206\u6790&lt;br&gt;`call_openai_analysis_api`\"] --&gt; F2[\"\u7b2c\u4e8c\u6b21\u8c03\u7528 LLM:&lt;br&gt;\u5b66\u672f\u62a5\u544a\u64b0\u5199&lt;br&gt;`generate_sensitivity_academic_report`\"];\n    end\n    F --&gt; G[\u7ed3\u675f: \u751f\u6210\u5305\u542b\u6df1\u5ea6\u5206\u6790\u7684\u5b66\u672f\u7ea7\u62a5\u544a];</code></pre>"},{"location":"explanation/tricys_analysis/analysis_report.html#31","title":"3.1. \u9636\u6bb5\u4e00\uff1a\u57fa\u7840\u6570\u636e\u62a5\u544a","text":"<p>\u6b64\u9636\u6bb5\u7531 <code>generate_prompt_templates()</code> \u51fd\u6570\u6267\u884c\uff0c\u5176\u6838\u5fc3\u804c\u8d23\u662f\u521b\u5efa\u4e00\u4e2a\u5185\u5bb9\u8be6\u5c3d\u3001\u7eaf\u6570\u636e\u9a71\u52a8\u7684 Markdown \u6587\u4ef6\u3002\u8fd9\u4efd\u6587\u4ef6\u662f\u540e\u7eed\u6240\u6709\u5206\u6790\u7684\u201c\u4e8b\u5b9e\u6839\u57fa\u201d\uff0c\u5305\u542b\uff1a</p> <ol> <li>\u914d\u7f6e\u8be6\u60c5\uff1a\u672c\u6b21\u5206\u6790\u7684\u6240\u6709\u914d\u7f6e\u53c2\u6570\uff0c\u5982\u72ec\u7acb/\u56e0\u53d8\u91cf\u3001\u626b\u63cf\u8303\u56f4\u3001\u4f18\u5316\u8bbe\u7f6e\u7b49\u3002</li> <li>\u6570\u636e\u8868\u683c\uff1a\u5c06 <code>sensitivity_analysis_summary.csv</code> \u548c <code>requierd_tbr_summary.csv</code> \u4e2d\u7684\u6570\u636e\u683c\u5f0f\u5316\u4e3a\u7f8e\u89c2\u7684 Markdown \u8868\u683c\u3002</li> <li>\u56fe\u8868\u5d4c\u5165\uff1a\u5c06 <code>plot.py</code> \u751f\u6210\u7684\u6240\u6709 <code>.svg</code> \u56fe\u8868\u6587\u4ef6\u901a\u8fc7 <code>![\u6807\u9898](\u6587\u4ef6\u540d.svg)</code> \u7684\u8bed\u6cd5\u5d4c\u5165\u62a5\u544a\u4e2d\u3002</li> <li>\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u5982\u679c\u9002\u7528\uff0c\u8fd8\u4f1a\u4ece <code>sweep_results.csv</code> \u4e2d\u63d0\u53d6\u5173\u952e\u52a8\u6001\u8fc7\u7a0b\uff08\u5982\u521d\u59cb\u3001\u8f6c\u6298\u70b9\u3001\u7ed3\u675f\u9636\u6bb5\uff09\u7684\u6570\u636e\u5207\u7247\uff0c\u4ee5\u8868\u683c\u5f62\u5f0f\u5448\u73b0\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_report.html#32","title":"3.2. \u9636\u6bb5\u4e8c\uff1a\u539f\u59cb\u6570\u636e\u5206\u6790","text":"<ul> <li>\u6267\u884c\u8005\uff1a<code>call_openai_analysis_api()</code></li> <li>\u76ee\u7684\uff1a\u5bf9\u7eaf\u6570\u636e\u8868\u683c\u8fdb\u884c\u6df1\u5ea6\u91cf\u5316\u5206\u6790\uff0c\u53d1\u6398\u6570\u636e\u80cc\u540e\u7684\u8d8b\u52bf\u4e0e\u5173\u8054\u3002</li> <li>\u8fc7\u7a0b\uff1a<ol> <li>\u5c06\u9636\u6bb5\u4e00\u751f\u6210\u7684\u57fa\u7840\u62a5\u544a\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u5e76\u9644\u52a0\u4e0a\u4e00\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5206\u6790\u6307\u4ee4\uff08\u89c1\u4e0b\u4e00\u8282\uff09\u3002</li> <li>\u4e00\u4e2a\u5173\u952e\u6307\u4ee4\u662f\u5ffd\u7565\u56fe\u8868\uff0c\u53ea\u5206\u6790\u8868\u683c\uff0c\u8fd9\u5f3a\u5236\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u800c\u975e\u5b9a\u6027\u7684\u5206\u6790\u3002</li> <li>LLM \u8fd4\u56de\u7684\u5206\u6790\u7ed3\u679c\u4f1a\u88ab\u8ffd\u52a0\u5230\u57fa\u7840\u62a5\u544a\u7684\u672b\u5c3e\uff0c\u5f62\u6210\u4e00\u4efd\u5305\u542b\u201c\u539f\u59cb\u6570\u636e+AI\u521d\u6b65\u89e3\u8bfb\u201d\u7684\u5b8c\u6574\u62a5\u544a\u3002</li> </ol> </li> </ul> \u6570\u636e\u5206\u6790\u5e08\u63d0\u793a\u8bcd <pre><code>**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u805a\u53d8\u53cd\u5e94\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u7684\u4e13\u5bb6\u3002\n**\u4efb\u52a1\uff1a** \u8bf7**\u5b8c\u5168\u57fa\u4e8e**\u4e0b\u65b9\u63d0\u4f9b\u7684**\u4e24\u7c7b\u6570\u636e\u8868\u683c**\uff0c\u5bf9\u805a\u53d8\u5806\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684**\u654f\u611f\u6027\u5206\u6790**\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\u3002\n**\u5206\u6790\u8981\u70b9 (\u5fc5\u987b\u4e25\u683c\u4f9d\u636e\u6570\u636e\u8868\u683c\u4f5c\u7b54)\uff1a**\n1.  **\u5168\u5c40\u654f\u611f\u6027\u5206\u6790:**\n    *   \u5206\u6790\u6027\u80fd\u6307\u6807\u603b\u8868\u5448\u73b0\u51fa\u600e\u6837\u7684**\u603b\u4f53\u8d8b\u52bf**\uff1f\n    *   \u54ea\u4e2a\u6027\u80fd\u6307\u6807\u5bf9\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u7684\u53d8\u5316\u6700\u4e3a\u654f\u611f\uff1f\n2.  **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a**\n    *   \u5206\u6790\u72ec\u7acb\u53d8\u91cf\u4e0e\u80cc\u666f\u626b\u63cf\u53c2\u6570\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\u3002\n3.  **\u52a8\u6001\u8fc7\u7a0b\u5206\u6790:**\n    *   \u89c2\u5bdf\u8fc7\u7a0b\u6570\u636e\u5207\u7247\uff1a\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u9636\u6bb5\u201d\u548c\u201c\u7ed3\u675f\u9636\u6bb5\u201d\u7684\u884c\u4e3a\u6709\u4f55\u4e0d\u540c\uff1f\n    *   \u8f6c\u6298\u70b9\u9636\u6bb5\u7684\u6570\u636e\u63ed\u793a\u4e86\u4ec0\u4e48\u7269\u7406\u8fc7\u7a0b\uff1f\n4.  **\u7efc\u5408\u7ed3\u8bba\uff1a**\n    *   \u603b\u7ed3\u8c03\u6574 `{independent_variable}` \u5bf9\u7cfb\u7edf\u7684\u7efc\u5408\u5f71\u54cd\u548c\u5229\u5f0a\u6743\u8861\u3002\n    *   \u53ef\u4ee5\u5f97\u51fa\u54ea\u4e9b\u5173\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\u6216\u8fd0\u884c\u4f18\u5316\u7684\u521d\u6b65\u5efa\u8bae\uff1f\n</code></pre>"},{"location":"explanation/tricys_analysis/analysis_report.html#33","title":"3.3. \u9636\u6bb5\u4e09\uff1a\u5b66\u672f\u62a5\u544a\u64b0\u5199","text":"<ul> <li>\u6267\u884c\u8005\uff1a<code>generate_sensitivity_academic_report()</code></li> <li>\u76ee\u7684\uff1a\u5c06\u4e00\u4efd\u5305\u542b\u6570\u636e\u3001\u56fe\u8868\u548c\u521d\u6b65\u5206\u6790\u7684\u6df7\u5408\u62a5\u544a\uff0c\u201c\u5347\u683c\u201d\u4e3a\u4e00\u7bc7\u7ed3\u6784\u4e25\u8c28\u3001\u8bed\u8a00\u4e13\u4e1a\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</li> <li>\u8fc7\u7a0b\uff1a<ol> <li>\u5c06\u66f4\u65b0\u540e\u7684\u62a5\u544a\uff08\u5df2\u5305\u542b\u7b2c\u4e00\u6b21AI\u5206\u6790\uff09\u548c\u672f\u8bed\u8868 (<code>glossary.csv</code>) \u4e00\u540c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u3002</li> <li>\u9644\u52a0\u4e0a\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u6307\u4ee4\uff0c\u8981\u6c42\u6a21\u578b\u626e\u6f14\u201c\u8d44\u6df1\u79d1\u5b66\u5bb6\u201d\u89d2\u8272\uff0c\u5e76\u4e25\u683c\u9075\u5faa\u5b66\u672f\u89c4\u8303\u3002</li> <li>LLM \u4f1a\u5229\u7528\u672f\u8bed\u8868\u5c06\u62a5\u544a\u4e2d\u7684\u5185\u90e8\u53d8\u91cf\u66ff\u6362\u4e3a\u4e13\u4e1a\u672f\u8bed\uff0c\u5e76\u6309\u7167\u6807\u51c6\u7684\u5b66\u672f\u7ed3\u6784\uff08\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\uff09\u91cd\u65b0\u7ec4\u7ec7\u548c\u64b0\u5199\u6240\u6709\u5185\u5bb9\u3002</li> <li>\u6700\u7ec8\u7ed3\u679c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5168\u65b0\u7684\u3001\u53ef\u76f4\u63a5\u4f7f\u7528\u7684\u5b66\u672f\u62a5\u544a\u6587\u4ef6 (<code>academic_report_....md</code>)\u3002</li> </ol> </li> </ul> \u8d44\u6df1\u79d1\u5b66\u5bb6\u63d0\u793a\u8bcd <pre><code>**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n**\u6307\u4ee4\uff1a**\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u4e13\u4e1a\u672f\u8bed\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u60a8**\u5fc5\u987b**\u4f7f\u7528 Markdown \u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6807\u9898 (Title):** ...\n    *   **\u6458\u8981 (Abstract):** ...\n    *   **\u5f15\u8a00 (Introduction):** ...\n    *   **\u65b9\u6cd5 (Methodology):** ...\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** ...\n    *   **\u7ed3\u8bba (Conclusion):** ...\n</code></pre>"},{"location":"explanation/tricys_analysis/performance_metrics.html","title":"\u6838\u5fc3\u6027\u80fd\u6307\u6807","text":"<p>\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u7684\u6a21\u62df\u4e0e\u5206\u6790\u4e2d\uff0c\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ecf\u6d4e\u6027\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\u3002<code>tricys</code> \u5185\u7f6e\u4e86\u4e00\u7cfb\u5217\u6838\u5fc3\u6027\u80fd\u6307\u6807\uff08Key Performance Indicators, KPIs\uff09\uff0c\u7528\u4e8e\u4ece\u52a8\u6001\u4eff\u771f\u7ed3\u679c\u4e2d\u91cf\u5316\u8bc4\u4f30\u7cfb\u7edf\u7684\u5173\u952e\u7279\u6027\u3002</p>"},{"location":"explanation/tricys_analysis/performance_metrics.html#1","title":"1. \u542f\u52a8\u5e93\u5b58","text":"<ul> <li>\u8ba1\u7b97\u51fd\u6570: <code>calculate_startup_inventory</code></li> <li>\u7269\u7406\u610f\u4e49: \u542f\u52a8\u5e93\u5b58\u662f\u6307\u5728\u53cd\u5e94\u5806\u542f\u52a8\u521d\u671f\uff0c\u4e3a\u4e86\u7ef4\u6301\u8fde\u7eed\u8fd0\u884c\u76f4\u81f3\u7cfb\u7edf\u8fbe\u5230\u6c1a\u81ea\u6301\uff08\u5373\u6c1a\u7684\u589e\u6b96\u901f\u7387\u7b49\u4e8e\u6216\u8d85\u8fc7\u5176\u6d88\u8017\u901f\u7387\uff09\u800c\u5fc5\u987b\u9884\u5148\u6295\u5165\u7684\u6c1a\u91cf\u3002\u5728\u6c1a\u5e93\u5b58\u968f\u65f6\u95f4\u53d8\u5316\u7684\u66f2\u7ebf\u4e0a\uff0c\u8fd9\u8868\u73b0\u4e3a\u4ece\u521d\u59cb\u5e93\u5b58\u4e0b\u964d\u5230\u6700\u4f4e\u70b9\uff08\u62d0\u70b9\uff09\u7684\u5782\u76f4\u8ddd\u79bb\u3002</li> <li> <p>\u8ba1\u7b97\u65b9\u6cd5:</p> <ol> <li>\u5728\u4eff\u771f\u65f6\u95f4\u5e8f\u5217\u4e2d\uff0c\u627e\u5230\u6c1a\u5e93\u5b58\u7684\u6700\u4f4e\u70b9\uff08Turning Point\uff09\uff0c\u8fd9\u4e2a\u70b9\u901a\u5e38\u4ee3\u8868\u7cfb\u7edf\u4ece\u51c0\u6d88\u8017\u8f6c\u4e3a\u51c0\u589e\u6b96\u7684\u65f6\u523b\u3002</li> <li>\u542f\u52a8\u5e93\u5b58\u88ab\u8ba1\u7b97\u4e3a \u521d\u59cb\u5e93\u5b58 \u4e0e \u6700\u4f4e\u5e93\u5b58 \u4e4b\u95f4\u7684\u5dee\u503c\u3002</li> </ol> <p><code>Startup Inventory = Initial Inventory - Minimum Inventory</code> - \u89e3\u8bfb: \u542f\u52a8\u5e93\u5b58\u662f\u4e00\u4e2a\u5173\u952e\u7684\u7ecf\u6d4e\u6027\u6307\u6807\u3002\u8f83\u4f4e\u7684\u542f\u52a8\u5e93\u5b58\u610f\u5473\u7740\u7cfb\u7edf\u80fd\u66f4\u5feb\u5730\u8fbe\u5230\u81ea\u6301\uff0c\u51cf\u5c11\u4e86\u5bf9\u5916\u90e8\u6c1a\u6e90\u7684\u4f9d\u8d56\u548c\u524d\u671f\u6295\u5165\u6210\u672c\uff0c\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u8bbe\u8ba1\u7684\u4f18\u5316\u76ee\u6807\u4e4b\u4e00\u3002</p> </li> </ul>"},{"location":"explanation/tricys_analysis/performance_metrics.html#2","title":"2. \u81ea\u6301\u65f6\u95f4","text":"<ul> <li>\u8ba1\u7b97\u51fd\u6570: <code>time_of_turning_point</code></li> <li>\u7269\u7406\u610f\u4e49: \u81ea\u6301\u65f6\u95f4\u662f\u6307\u7cfb\u7edf\u4ece\u542f\u52a8\u5f00\u59cb\uff0c\u5230\u5176\u603b\u6c1a\u5e93\u5b58\u91cf\u8fbe\u5230\u6700\u4f4e\u70b9\u5e76\u5f00\u59cb\u56de\u5347\u7684\u65f6\u523b\u3002\u8fd9\u4e2a\u65f6\u95f4\u70b9\u6807\u5fd7\u7740\u7cfb\u7edf\u5185\u90e8\u7684\u6c1a\u589e\u6b96\u901f\u7387\u5f00\u59cb\u8d85\u8fc7\u6d88\u8017\u548c\u635f\u5931\u901f\u7387\uff0c\u7cfb\u7edf\u5728\u7406\u8bba\u4e0a\u5b9e\u73b0\u4e86\u201c\u81ea\u7ed9\u81ea\u8db3\u201d\u3002</li> <li>\u8ba1\u7b97\u65b9\u6cd5:<ol> <li>\u8be5\u51fd\u6570\u9996\u5148\u5bf9\u5e93\u5b58\u6570\u636e\u8fdb\u884c\u5e73\u6ed1\u5904\u7406\uff0c\u4ee5\u6d88\u9664\u566a\u58f0\u5e72\u6270\uff0c\u5224\u65ad\u662f\u5426\u5b58\u5728\u4e00\u4e2a\u771f\u5b9e\u7684\u201c\u62d0\u70b9\u201d\u3002</li> <li>\u5982\u679c\u5e93\u5b58\u66f2\u7ebf\u662f\u5355\u8c03\u4e0b\u964d\u7684\uff08\u610f\u5473\u7740\u5728\u6574\u4e2a\u4eff\u771f\u65f6\u95f4\u5185\u90fd\u672a\u8fbe\u5230\u81ea\u6301\uff09\uff0c\u5219\u8fd4\u56de <code>NaN</code> (Not a Number)\u3002</li> <li>\u5426\u5219\uff0c\u5b83\u4f1a\u8fd4\u56de\u539f\u59cb\uff08\u672a\u5e73\u6ed1\u7684\uff09\u6570\u636e\u4e2d\u5e93\u5b58\u91cf\u8fbe\u5230\u6700\u5c0f\u503c\u7684\u7cbe\u786e\u65f6\u95f4\u70b9\u3002</li> </ol> </li> <li>\u89e3\u8bfb: \u81ea\u6301\u65f6\u95f4\u76f4\u63a5\u53cd\u6620\u4e86\u7cfb\u7edf\u8fbe\u5230\u6c1a\u5e73\u8861\u7684\u901f\u5ea6\u3002\u66f4\u77ed\u7684\u81ea\u6301\u65f6\u95f4\u662f\u7406\u60f3\u7684\uff0c\u56e0\u4e3a\u5b83\u8868\u660e\u7cfb\u7edf\u80fd\u66f4\u5feb\u5730\u6446\u8131\u5bf9\u542f\u52a8\u5e93\u5b58\u7684\u6d88\u8017\uff0c\u5e76\u5f00\u59cb\u79ef\u7d2f\u6c1a\uff0c\u8fd9\u5bf9\u5feb\u901f\u542f\u52a8\u5546\u4e1a\u805a\u53d8\u7535\u7ad9\u81f3\u5173\u91cd\u8981\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/performance_metrics.html#3","title":"3. \u500d\u589e\u65f6\u95f4","text":"<ul> <li>\u8ba1\u7b97\u51fd\u6570: <code>calculate_doubling_time</code></li> <li>\u7269\u7406\u610f\u4e49: \u500d\u589e\u65f6\u95f4\u662f\u6307\u5728\u8fbe\u5230\u6c1a\u81ea\u6301\u4e4b\u540e\uff0c\u7cfb\u7edf\u5185\u603b\u6c1a\u5e93\u5b58\u91cf\u7ffb\u500d\uff08\u5373\u8fbe\u5230\u521d\u59cb\u5e93\u5b58\u91cf\u7684\u4e24\u500d\uff09\u6240\u9700\u7684\u65f6\u95f4\u3002</li> <li>\u8ba1\u7b97\u65b9\u6cd5:<ol> <li>\u9996\u5148\uff0c\u786e\u5b9a\u7cfb\u7edf\u7684\u201c\u62d0\u70b9\u201d\uff08\u5e93\u5b58\u6700\u4f4e\u70b9\uff09\u3002</li> <li>\u7136\u540e\uff0c\u5728\u62d0\u70b9\u4e4b\u540e\u7684\u5e93\u5b58\u6570\u636e\u4e2d\uff0c\u5bfb\u627e\u7b2c\u4e00\u4e2a\u65f6\u95f4\u70b9\uff0c\u8be5\u70b9\u5e93\u5b58\u91cf\u5927\u4e8e\u6216\u7b49\u4e8e \u521d\u59cb\u5e93\u5b58\u7684\u4e24\u500d\u3002</li> <li>\u500d\u589e\u65f6\u95f4\u5c31\u662f\u8fd9\u4e2a\u65f6\u95f4\u70b9\u4e0e\u4eff\u771f\u5f00\u59cb\u65f6\u95f4\u4e4b\u5dee\u3002\u5982\u679c\u5e93\u5b58\u4ece\u672a\u8fbe\u5230\u521d\u59cb\u503c\u7684\u4e24\u500d\uff0c\u5219\u8fd4\u56de <code>NaN</code>\u3002</li> </ol> </li> <li>\u89e3\u8bfb: \u500d\u589e\u65f6\u95f4\u662f\u8861\u91cf\u6c1a\u589e\u6b96\u7cfb\u7edf\u201c\u76c8\u5229\u80fd\u529b\u201d\u7684\u6838\u5fc3\u6307\u6807\u3002\u4e00\u4e2a\u6709\u9650\u4e14\u5408\u7406\u7684\u500d\u589e\u65f6\u95f4\uff0c\u610f\u5473\u7740\u8be5\u805a\u53d8\u7535\u7ad9\u4e0d\u4ec5\u80fd\u81ea\u6211\u7ef4\u6301\uff0c\u8fd8\u80fd\u4e3a\u542f\u52a8\u65b0\u7684\u7535\u7ad9\u63d0\u4f9b\u989d\u5916\u7684\u6c1a\u71c3\u6599\u3002\u8fd9\u662f\u5b9e\u73b0\u805a\u53d8\u80fd\u6e90\u89c4\u6a21\u5316\u53d1\u5c55\u7684\u5173\u952e\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/performance_metrics.html#4","title":"4. \u7ea6\u675f\u6c42\u89e3\u6307\u6807","text":"<ul> <li>\u8ba1\u7b97\u65b9\u6cd5: <code>bisection_search</code> (\u5728 <code>tricys.simulation.simulation_analysis</code> \u4e2d\u5b9e\u73b0)</li> <li>\u7269\u7406\u610f\u4e49: \u5728\u8bb8\u591a\u8bbe\u8ba1\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5173\u5fc3\u7684\u4e0d\u662f\u5728\u56fa\u5b9a\u7684\u6c1a\u589e\u6b96\u6bd4\uff08Tritium Breeding Ratio, TBR\uff09\u4e0b\u7cfb\u7edf\u7684\u6027\u80fd\u5982\u4f55\uff0c\u800c\u662f\u53cd\u8fc7\u6765\uff1a\u4e3a\u4e86\u8fbe\u5230\u67d0\u4e2a\u7279\u5b9a\u7684\u5de5\u7a0b\u76ee\u6807\uff08\u4f8b\u5982\uff0c\u500d\u589e\u65f6\u95f4\u5c0f\u4e8e10\u5e74\uff09\uff0c\u6211\u4eec\u6240\u9700\u8981\u7684\u6700\u4f4eTBR\u662f\u591a\u5c11\uff1f</li> <li>\u7ea6\u675f\u6c42\u89e3\u4efb\u52a1\u3002<ul> <li>\u5f53\u60a8\u5728 <code>dependent_variables</code> \u4e2d\u5305\u542b\u5b83\u65f6\uff0c<code>tricys</code> \u4f1a\u542f\u7528\u4e00\u4e2a\u4f18\u5316\u7b97\u6cd5\uff08\u5982\u4e8c\u5206\u67e5\u627e <code>bisection_search</code>\uff09\u3002</li> <li>\u8be5\u7b97\u6cd5\u4f1a\u4ee5 <code>parameter_to_optimize</code>\uff08\u901a\u5e38\u662f\u6a21\u578b\u4e2d\u7684 <code>TBR</code> \u53c2\u6570\uff09\u4e3a\u53d8\u91cf\uff0c\u5728\u7ed9\u5b9a\u7684 <code>search_range</code> \u5185\u53cd\u590d\u8fed\u4ee3\u8fd0\u884c\u4eff\u771f\u3002</li> <li>\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u5b83\u4f1a\u68c0\u67e5\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u4f8b\u5982 <code>Doubling_Time</code>\uff09\u662f\u5426\u6ee1\u8db3\u9884\u8bbe\u7684\u7ea6\u675f\u6761\u4ef6\uff08\u4f8b\u5982\u5c0f\u4e8e\u67d0\u4e2a <code>metric_max_value</code>\uff09\u3002</li> <li>\u6700\u7ec8\uff0c\u7b97\u6cd5\u4f1a\u6536\u655b\u5e76\u8f93\u51fa\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u7684\u6700\u5c0fTBR\u503c\u3002</li> </ul> </li> <li>\u89e3\u8bfb: \u8fd9\u4e2a\u201c\u53cd\u5411\u201d\u6c42\u89e3\u7684\u80fd\u529b\u975e\u5e38\u5f3a\u5927\u3002\u5b83\u5c06\u8bbe\u8ba1\u95ee\u9898\u4ece\u201c\u6b63\u5411\u9a8c\u8bc1\u201d\u8f6c\u53d8\u4e3a\u201c\u9006\u5411\u5bfb\u4f18\u201d\uff0c\u5e2e\u52a9\u5de5\u7a0b\u5e08\u5feb\u901f\u786e\u5b9a\u5b9e\u73b0\u5173\u952e\u6027\u80fd\u76ee\u6807\u6240\u9700\u7684\u6700\u4f4e\u8bbe\u8ba1\u8981\u6c42\uff0c\u6781\u5927\u5730\u52a0\u901f\u4e86\u8bbe\u8ba1\u8fed\u4ee3\u8fc7\u7a0b\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html","title":"SALIB\u96c6\u6210\u65b9\u6cd5","text":"<p>TRICYS \u6df1\u5ea6\u96c6\u6210\u4e86\u4e1a\u754c\u9886\u5148\u7684\u654f\u611f\u6027\u5206\u6790\u5e93 SALib\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u5957\u5f3a\u5927\u3001\u81ea\u52a8\u5316\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff08Global Sensitivity Analysis, GSA\uff09\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08Uncertainty Quantification, UQ\uff09\u5de5\u4f5c\u6d41\u3002\u672c\u7bc7\u6587\u6863\u5c06\u4ecb\u7ecd SALib \u53ca\u5176\u6838\u5fc3\u65b9\u6cd5\uff0c\u5e76\u8be6\u7ec6\u89e3\u6790 TRICYS \u662f\u5982\u4f55\u901a\u8fc7\u4e00\u4e2a\u4e09\u6b65\u6d41\u7a0b\u4e0e SALib \u534f\u540c\u5de5\u4f5c\u7684\u3002</p>"},{"location":"explanation/tricys_analysis/salib_integration.html#1-salib","title":"1. SALib \u5e93\u53ca\u5176\u5206\u6790\u65b9\u6cd5\u7b80\u4ecb","text":""},{"location":"explanation/tricys_analysis/salib_integration.html#11-salib","title":"1.1. \u4ec0\u4e48\u662f SALib\uff1f","text":"<p>SALib \u662f\u4e00\u4e2a\u7528 Python \u7f16\u5199\u7684\u5f00\u6e90\u5e93\uff0c\u4e13\u95e8\u7528\u4e8e\u6267\u884c\u654f\u611f\u6027\u5206\u6790\u3002\u654f\u611f\u6027\u5206\u6790\u65e8\u5728\u7814\u7a76\u4e00\u4e2a\u6a21\u578b\u7684\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u5f52\u56e0\u4e8e\u5176\u4e0d\u540c\u8f93\u5165\u6e90\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7b80\u5355\u6765\u8bf4\uff0c\u5b83\u5e2e\u52a9\u6211\u4eec\u56de\u7b54\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u201c\u6a21\u578b\u4e2d\u7684\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u5bf9\u8f93\u51fa\u7ed3\u679c\u7684\u5f71\u54cd\u6700\u5927\uff1f\u201d</p> <p>\u5bf9\u4e8e\u50cf TRICYS \u8fd9\u6837\u7684\u590d\u6742\u4eff\u771f\u6a21\u578b\uff0cGSA \u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\uff1a</p> <ul> <li>\u8bc6\u522b\u5173\u952e\u53c2\u6570\uff1a\u5728\u4f17\u591a\u53c2\u6570\u4e2d\uff0c\u627e\u5230\u5bf9\u7cfb\u7edf\u6027\u80fd\uff08\u5982\u542f\u52a8\u5e93\u5b58\u3001\u500d\u589e\u65f6\u95f4\uff09\u5f71\u54cd\u6700\u5927\u7684\u5c11\u6570\u51e0\u4e2a\u3002</li> <li>\u7406\u89e3\u53c2\u6570\u4ea4\u4e92\uff1a\u63ed\u793a\u53c2\u6570\u4e4b\u95f4\u662f\u5426\u5b58\u5728\u590d\u6742\u7684\u975e\u7ebf\u6027\u6216\u4ea4\u4e92\u6548\u5e94\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#12-salib","title":"1.2. \u6838\u5fc3 SALib \u65b9\u6cd5","text":"<p>TRICYS \u7684 <code>TricysSALibAnalyzer</code> \u7c7b\u96c6\u6210\u4e86 SALib \u4e2d\u51e0\u79cd\u6700\u5e38\u7528\u548c\u6700\u5f3a\u5927\u7684\u5206\u6790\u65b9\u6cd5\uff1a</p>"},{"location":"explanation/tricys_analysis/salib_integration.html#sobol","title":"Sobol \u5206\u6790 (\u65b9\u5dee\u5206\u6790\u6cd5)","text":"<ul> <li>\u7c7b\u578b\uff1a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (GSA)\uff0c\u57fa\u4e8e\u65b9\u5dee\u5206\u89e3\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a<ul> <li>\u4e00\u9636\u6307\u6570 (S1)\uff1a\u8861\u91cf\u5355\u4e2a\u53c2\u6570\u53d8\u5316\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u76f4\u63a5\u8d21\u732e\uff0c\u5373\u201c\u4e3b\u6548\u5e94\u201d\u3002S1 \u503c\u8d8a\u9ad8\uff0c\u8be5\u53c2\u6570\u7684\u72ec\u7acb\u5f71\u54cd\u8d8a\u5927\u3002</li> <li>\u603b\u9636\u6307\u6570 (ST)\uff1a\u8861\u91cf\u5355\u4e2a\u53c2\u6570\u672c\u8eab\u53ca\u5176\u4e0e\u5176\u4ed6\u53c2\u6570\u6240\u6709\u4ea4\u4e92\u6548\u5e94\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u603b\u8d21\u732e\u3002</li> </ul> </li> <li>\u89e3\u8bfb\uff1a\u5982\u679c\u4e00\u4e2a\u53c2\u6570\u7684 <code>ST</code> \u503c\u8fdc\u5927\u4e8e\u5176 <code>S1</code> \u503c\uff0c\u5219\u8868\u660e\u8be5\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u975e\u7ebf\u6027\u6548\u5e94\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u6709\u663e\u8457\u7684\u4ea4\u4e92\u4f5c\u7528\u3002</li> <li>\u7279\u70b9\uff1a\u7ed3\u679c\u975e\u5e38\u53ef\u9760\u548c\u5168\u9762\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u7684\u6837\u672c\u91cf\u901a\u5e38\u5f88\u5927\uff08<code>N * (2D + 2)</code>\uff0c\u5176\u4e2d D \u662f\u53c2\u6570\u6570\u91cf\uff09\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#morris","title":"Morris \u5206\u6790 (\u7b5b\u9009\u6cd5)","text":"<ul> <li>\u7c7b\u578b\uff1a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff0c\u57fa\u4e8e\u8f68\u8ff9\u7684\u7b5b\u9009\u65b9\u6cd5\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a<ul> <li>\u03bc* (mu_star)\uff1a\u8861\u91cf\u53c2\u6570\u5bf9\u8f93\u51fa\u5f71\u54cd\u7684\u603b\u4f53\u5927\u5c0f\uff0c\u662f\u6548\u5e94\u7684\u7edd\u5bf9\u503c\u7684\u5747\u503c\u3002\u03bc* \u8d8a\u9ad8\uff0c\u53c2\u6570\u8d8a\u91cd\u8981\u3002</li> <li>\u03c3 (sigma)\uff1a\u8861\u91cf\u53c2\u6570\u6548\u5e94\u7684\u6807\u51c6\u5dee\u3002\u03c3 \u8d8a\u9ad8\uff0c\u8868\u660e\u53c2\u6570\u7684\u5f71\u54cd\u662f\u975e\u7ebf\u6027\u7684\uff0c\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u4ea4\u4e92\u3002</li> </ul> </li> <li>\u7279\u70b9\uff1a\u8ba1\u7b97\u6548\u7387\u975e\u5e38\u9ad8\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6709\u5927\u91cf\u8f93\u5165\u53c2\u6570\uff08\u9ad8\u7ef4\u6a21\u578b\uff09\u7684\u65e9\u671f\u63a2\u7d22\u9636\u6bb5\uff0c\u7528\u4e8e\u5feb\u901f\u7b5b\u9009\u51fa\u5c11\u6570\u51e0\u4e2a\u6700\u91cd\u8981\u7684\u53c2\u6570\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#fast","title":"FAST \u5206\u6790 (\u5085\u91cc\u53f6\u5e45\u5ea6\u654f\u611f\u6027\u68c0\u9a8c)","text":"<ul> <li>\u7c7b\u578b\uff1a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff0c\u57fa\u4e8e\u9891\u7387\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a\u4e0e Sobol \u7c7b\u4f3c\uff0c\u8ba1\u7b97\u4e00\u9636\u6307\u6570 (S1) \u548c\u603b\u9636\u6307\u6570 (ST)\u3002</li> <li>\u7279\u70b9\uff1a\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5b83\u6bd4 Sobol \u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0c\u4f46\u5bf9\u6a21\u578b\u7684\u9002\u7528\u6027\u6709\u4e00\u5b9a\u8981\u6c42\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#lhs","title":"\u62c9\u4e01\u8d85\u7acb\u65b9\u62bd\u6837 (LHS) \u4e0e\u4e0d\u786e\u5b9a\u6027\u5206\u6790","text":"<ul> <li>\u7c7b\u578b\uff1a\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (UQ)\u3002</li> <li>\u76ee\u7684\uff1aLHS \u672c\u8eab\u662f\u4e00\u79cd\u5148\u8fdb\u7684\u53c2\u6570\u91c7\u6837\u65b9\u6cd5\uff0c\u65e8\u5728\u9ad8\u6548\u5730\u8986\u76d6\u6574\u4e2a\u53c2\u6570\u7a7a\u95f4\u3002\u5f53\u4e0e TRICYS \u7ed3\u5408\u7528\u4e8e\u5206\u6790\u65f6\uff0c\u5176\u76ee\u7684\u4e0d\u662f\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\uff0c\u800c\u662f\u7814\u7a76\u5f53\u8f93\u5165\u53c2\u6570\u5728\u7ed9\u5b9a\u8303\u56f4\u5185\u4e0d\u786e\u5b9a\u65f6\uff0c\u8f93\u51fa\u6307\u6807\u7684\u7edf\u8ba1\u5206\u5e03\u7279\u6027\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a<ul> <li>\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5927/\u6700\u5c0f\u503c\u3002</li> <li>\u767e\u5206\u4f4d\u6570\uff08\u5982 5% \u548c 95%\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u8f93\u51fa\u7ed3\u679c\u7684\u7f6e\u4fe1\u533a\u95f4\u3002</li> </ul> </li> <li>\u89e3\u8bfb\uff1a\u901a\u8fc7 LHS \u5206\u6790\uff0c\u6211\u4eec\u53ef\u4ee5\u4e86\u89e3\u6a21\u578b\u8f93\u51fa\u7684\u7a33\u5b9a\u6027\u548c\u6ce2\u52a8\u8303\u56f4\uff0c\u8bc4\u4f30\u5176\u5728\u9762\u5bf9\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u65f6\u7684\u98ce\u9669\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#2","title":"2. \u4e09\u6b65\u96c6\u6210\u6d41\u7a0b","text":"<p>TRICYS \u5c06\u590d\u6742\u7684 GSA \u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e00\u4e2a\u6e05\u6670\u3001\u81ea\u52a8\u5316\u7684\u4e09\u6b65\u5de5\u4f5c\u6d41\u3002<code>TricysSALibAnalyzer</code> \u7c7b\u8d1f\u8d23\u8c03\u5ea6\u6574\u4e2a\u6d41\u7a0b\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u201cSALib \u8d1f\u8d23\u62bd\u6837\u4e0e\u5206\u6790\uff0cTRICYS \u8d1f\u8d23\u6267\u884c\u8ba1\u7b97\u201d\uff0c\u4e24\u8005\u901a\u8fc7 CSV \u6587\u4ef6\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u3002</p> <pre><code>graph TD\n    subgraph \"A. SALib \u7aef\"\n        A1[\"&lt;b&gt;\u6b65\u9aa4\u4e00\uff1a\u53c2\u6570\u91c7\u6837&lt;/b&gt;&lt;br&gt;\u5728 salib.py \u4e2d\u6267\u884c\"]\n        A1 --&gt; B1[\"1. \u5b9a\u4e49\u95ee\u9898 (`define_problem`)&lt;br&gt;\u6307\u5b9a\u53c2\u6570\u53ca\u5176\u8303\u56f4\"]\n        B1 --&gt; B2[\"2. \u751f\u6210\u6837\u672c (`generate_samples`)&lt;br&gt;\u9009\u62e9 Sobol/Morris \u7b49\u65b9\u6cd5\"]\n        B2 --&gt; B3[\"3. \u5bfc\u51fa\u6837\u672c (`run_tricys_simulations`)&lt;br&gt;\u751f\u6210 &lt;b&gt;salib_sampling.csv&lt;/b&gt; \u6587\u4ef6\"]\n    end\n\n    subgraph \"B. TRICYS \u7aef\"\n        C1[\"&lt;b&gt;\u6b65\u9aa4\u4e8c\uff1a\u6279\u91cf\u4eff\u771f&lt;/b&gt;&lt;br&gt;\u5728 simulation_analysis.py \u4e2d\u6267\u884c\"]\n        C1 --&gt; D1[\"1. \u751f\u6210\u7279\u5b9a\u914d\u7f6e\u6587\u4ef6&lt;br&gt;\u8ba9 TRICYS \u8bfb\u53d6 CSV\"]\n        D1 --&gt; D2[\"2. TRICYS \u542f\u52a8&lt;br&gt;\u5c06 CSV \u6bcf\u4e00\u884c\u4f5c\u4e3a\u72ec\u7acb\u7684\u4eff\u771f\u4efb\u52a1\"]\n        D2 --&gt; D3[\"3. \u6267\u884c\u6240\u6709\u4eff\u771f&lt;br&gt;\u5e76\u5c06\u6240\u6709\u4efb\u52a1\u7684\u7ed3\u679c\u6307\u6807&lt;br&gt;\u6c47\u603b\u5230 &lt;b&gt;sensitivity_analysis_summary.csv&lt;/b&gt;\"]\n    end\n\n    subgraph \"C. SALib \u7aef (\u518d\u6b21)\"\n        E1[\"&lt;b&gt;\u6b65\u9aa4\u4e09\uff1a\u7ed3\u679c\u5206\u6790&lt;/b&gt;&lt;br&gt;\u8fd4\u56de salib.py \u4e2d\u6267\u884c\"]\n        E1 --&gt; F1[\"1. \u52a0\u8f7d\u7ed3\u679c (`load_tricys_results`)&lt;br&gt;\u8bfb\u53d6 &lt;b&gt;sensitivity_analysis_summary.csv&lt;/b&gt;\"]\n        F1 --&gt; F2[\"2. \u8ba1\u7b97\u6307\u6570 (`analyze_sobol`\u7b49)&lt;br&gt;SALib \u5206\u6790\u4eff\u771f\u7ed3\u679c\"]\n        F2 --&gt; F3[\"3. \u751f\u6210\u62a5\u544a (`plot_results`, `save_report`)&lt;br&gt;\u8f93\u51fa\u56fe\u8868\u3001\u8868\u683c\u548c\u6700\u7ec8\u5206\u6790\u62a5\u544a\"]\n    end\n\n    B3 -- \"\u4f5c\u4e3a\u8f93\u5165\" --&gt; C1\n    D3 -- \"\u4f5c\u4e3a\u8f93\u5165\" --&gt; E1\n</code></pre>"},{"location":"explanation/tricys_analysis/salib_integration.html#salib-csv","title":"\u6b65\u9aa4\u4e00\uff1a\u53c2\u6570\u91c7\u6837 (SALib -&gt; CSV)","text":"<p>\u6b64\u9636\u6bb5\u5b8c\u5168\u5728 <code>salib.py</code> \u7684 <code>TricysSALibAnalyzer</code> \u7c7b\u4e2d\u5b8c\u6210\uff0c\u76ee\u6807\u662f\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6240\u6709\u53c2\u6570\u7ec4\u5408\u7684 CSV \u6587\u4ef6\u3002</p> <ol> <li>\u5b9a\u4e49\u95ee\u9898\uff1a\u901a\u8fc7\u8c03\u7528 <code>define_problem()</code>\uff0c\u7528\u6237\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u5305\u542b\u6240\u6709\u5f85\u5206\u6790\u53c2\u6570\u53ca\u5176\u53d6\u503c\u8303\u56f4\uff08bounds\uff09\u7684\u5b57\u5178\u3002</li> <li>\u751f\u6210\u6837\u672c\uff1a\u8c03\u7528 <code>generate_samples()</code>\uff0c\u5e76\u6307\u5b9a\u91c7\u6837\u65b9\u6cd5\uff08\u5982 <code>'sobol'</code>\uff09\u548c\u6837\u672c\u6570\u91cf <code>N</code>\u3002SALib \u4f1a\u6839\u636e\u6240\u9009\u65b9\u6cd5\u5728\u5b9a\u4e49\u7684\u53c2\u6570\u7a7a\u95f4\u4e2d\u751f\u6210\u4e00\u7cfb\u5217\u53c2\u6570\u70b9\u3002</li> <li>\u5bfc\u51fa\u6587\u4ef6\uff1a\u8c03\u7528 <code>run_tricys_simulations()</code> \u51fd\u6570\uff08\u6ce8\u610f\uff1a\u6b64\u51fd\u6570\u540d\u867d\u6709\u201csimulation\u201d\uff0c\u4f46\u5b83\u4e0d\u6267\u884c\u4eff\u771f\uff09\uff0c\u8be5\u51fd\u6570\u4f1a\u5c06\u4e0a\u4e00\u6b65\u751f\u6210\u7684\u6240\u6709\u53c2\u6570\u6837\u672c\u5199\u5165\u4e00\u4e2a\u540d\u4e3a <code>salib_sampling.csv</code> \u7684\u6587\u4ef6\u4e2d\u3002\u8fd9\u4e2a\u6587\u4ef6\u662f\u8fde\u63a5 SALib \u548c TRICYS \u7684\u6865\u6881\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/salib_integration.html#tricys-csv","title":"\u6b65\u9aa4\u4e8c\uff1a\u6279\u91cf\u4eff\u771f (TRICYS \u8bfb\u53d6 CSV)","text":"<p>\u6b64\u9636\u6bb5\u7531 <code>simulation_analysis.py</code> \u4e2d\u7684 <code>run_salib_analysis()</code> \u51fd\u6570\u8c03\u5ea6\uff0c\u5b83\u4f1a\u8c03\u7528 TRICYS \u7684\u6838\u5fc3\u4eff\u771f\u5f15\u64ce\u6765\u6267\u884c\u8ba1\u7b97\u3002</p> <ol> <li>\u751f\u6210\u7279\u5b9a\u914d\u7f6e\uff1a<code>salib.py</code> \u4e2d\u7684 <code>generate_tricys_config()</code> \u4f1a\u521b\u5efa\u4e00\u4e2a\u4e34\u65f6\u7684 TRICYS \u914d\u7f6e\u6587\u4ef6\u3002\u8fd9\u4e2a\u914d\u7f6e\u6587\u4ef6\u7684\u5173\u952e\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u5c06 <code>simulation_parameters</code> \u6307\u5411\u4e86\u4e0a\u4e00\u6b65\u751f\u6210\u7684 <code>salib_sampling.csv</code> \u6587\u4ef6\u3002     <pre><code>\"simulation_parameters\": {\n  \"file\": \"/path/to/salib_sampling.csv\"\n}\n</code></pre></li> <li>TRICYS \u542f\u52a8\u4e0e\u6267\u884c\uff1a\u5f53 <code>simulation_analysis.py</code> \u4f7f\u7528\u8fd9\u4e2a\u7279\u6b8a\u914d\u7f6e\u542f\u52a8\u65f6\uff0c\u5b83\u4f1a\u8bc6\u522b\u51fa\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u6587\u4ef6\u7684\u4efb\u52a1\u3002TRICYS \u4f1a\u9010\u884c\u8bfb\u53d6 <code>salib_sampling.csv</code>\uff0c\u5e76\u5c06\u6bcf\u4e00\u884c\uff08\u5373\u4e00\u7ec4\u5b8c\u6574\u7684\u53c2\u6570\uff09\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u4eff\u771f\u4efb\u52a1\u6765\u6267\u884c\u3002</li> <li>\u6c47\u603b\u7ed3\u679c\uff1aTRICYS \u4f1a\uff08\u5e76\u884c\u6216\u4e32\u884c\u5730\uff09\u6267\u884c\u6240\u6709\u4eff\u771f\u4efb\u52a1\u3002\u5f85\u6240\u6709\u4efb\u52a1\u5b8c\u6210\u540e\uff0c\u5b83\u4f1a\u5c06\u6bcf\u4e2a\u4efb\u52a1\u8ba1\u7b97\u51fa\u7684\u6027\u80fd\u6307\u6807\uff08\u5982 <code>Startup_Inventory</code>\uff09\u6c47\u603b\u8d77\u6765\uff0c\u5e76\u751f\u6210\u4e00\u4e2a\u540d\u4e3a <code>sensitivity_analysis_summary.csv</code> \u7684\u7ed3\u679c\u6587\u4ef6\u3002\u6b64\u6587\u4ef6\u7684\u6bcf\u4e00\u884c\u5bf9\u5e94 <code>salib_sampling.csv</code> \u4e2d\u7684\u4e00\u884c\u8f93\u5165\uff0c\u4ece\u800c\u5b8c\u7f8e\u5730\u5c06\u8f93\u5165\u53c2\u6570\u4e0e\u8f93\u51fa\u7ed3\u679c\u5bf9\u5e94\u8d77\u6765\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/salib_integration.html#salib","title":"\u6b65\u9aa4\u4e09\uff1a\u7ed3\u679c\u5206\u6790\u4e0e\u62a5\u544a (SALib \u8bfb\u53d6\u7ed3\u679c)","text":"<p>\u4eff\u771f\u5b8c\u6210\u540e\uff0c\u63a7\u5236\u6743\u518d\u6b21\u56de\u5230 <code>salib.py</code>\uff0c\u8fdb\u884c\u6700\u540e\u7684\u5206\u6790\u548c\u62a5\u544a\u751f\u6210\u3002</p> <ol> <li>\u52a0\u8f7d\u7ed3\u679c\uff1a<code>load_tricys_results()</code> \u51fd\u6570\u4f1a\u8bfb\u53d6 <code>sensitivity_analysis_summary.csv</code>\uff0c\u5c06 TRICYS \u7684\u8ba1\u7b97\u7ed3\u679c\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u3002</li> <li>\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\uff1a\u6839\u636e\u7528\u6237\u9009\u62e9\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u8c03\u7528\u5bf9\u5e94\u7684\u5206\u6790\u51fd\u6570\uff0c\u5982 <code>analyze_sobol()</code>\u3002\u8be5\u51fd\u6570\u4f1a\u5c06\u53c2\u6570\u6837\u672c\u548c\u4eff\u771f\u7ed3\u679c\u4e00\u540c\u9001\u5165 SALib \u7684\u5206\u6790\u5f15\u64ce\uff0c\u8ba1\u7b97\u51fa S1\u3001ST \u7b49\u654f\u611f\u6027\u6307\u6570\u3002</li> <li>\u751f\u6210\u62a5\u544a\uff1a\u6700\u540e\uff0c<code>plot_*_results()</code> \u548c <code>_save_sensitivity_report()</code> \u7b49\u51fd\u6570\u4f1a\u5229\u7528\u8ba1\u7b97\u51fa\u7684\u6307\u6570\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u53ef\u89c6\u5316\u7684\u56fe\u8868\uff08\u5982\u6761\u5f62\u56fe\u3001\u03bc*-\u03c3 \u56fe\uff09\u3001\u6570\u636e\u8868\u683c\u548c\u4e00\u4efd\u5b8c\u6574\u7684 Markdown \u5206\u6790\u62a5\u544a\uff08\u540c\u6837\u652f\u6301 AI \u589e\u5f3a\u7684\u6df1\u5ea6\u89e3\u8bfb\uff09\u3002</li> </ol> <p>\u901a\u8fc7\u8fd9\u4e09\u4e2a\u6e05\u6670\u7684\u6b65\u9aa4\uff0cTRICYS \u6210\u529f\u5730\u5c06 SALib \u5f3a\u5927\u7684\u91c7\u6837\u548c\u5206\u6790\u80fd\u529b\u4e0e\u81ea\u8eab\u9ad8\u6548\u7684\u4eff\u771f\u6267\u884c\u80fd\u529b\u89e3\u8026\u5e76\u96c6\u6210\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u95ee\u9898\u5b9a\u4e49\u5230\u6700\u7ec8\u62a5\u544a\u7684\u5168\u81ea\u52a8\u5316 GSA \u5de5\u4f5c\u6d41\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html","title":"\u534f\u540c\u4eff\u771f\u539f\u7406","text":"<p>\u5728\u534f\u540c\u4eff\u771f\u4e2d\uff0cTRICYS \u63d0\u4f9b\u4e86\u4e24\u79cd\u5c06\u5916\u90e8\u6570\u636e\u6ce8\u5165 Modelica \u6a21\u578b\u7684\u65b9\u6cd5\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#1","title":"1. \u62e6\u622a\u5668\u6a21\u5f0f","text":""},{"location":"explanation/tricys_basic/co_simulation.html#11","title":"1.1. \u5de5\u4f5c\u539f\u7406","text":"<p>\u62e6\u622a\u5668\u6a21\u5f0f\u662f\u4e00\u79cd\u975e\u4fb5\u5165\u5f0f\u7684\u6570\u636e\u6ce8\u5165\u65b9\u6cd5\u3002\u5b83\u4e0d\u4f1a\u4fee\u6539\u4efb\u4f55\u539f\u59cb\u7684\u6a21\u578b\u6587\u4ef6\uff0c\u800c\u662f\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u65b0\u6a21\u578b\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u3002</p> <p>\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5728\u539f\u59cb\u5b50\u6a21\u578b\u548c\u4e0b\u6e38\u7ec4\u4ef6\u4e4b\u95f4\u52a8\u6001\u63d2\u5165\u4e00\u4e2a\u65b0\u5efa\u7684\u201c\u62e6\u622a\u5668\u201d\u6a21\u578b\u3002\u6b64\u62e6\u622a\u5668\u50cf\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u5f00\u5173\uff0c\u5b83\u540c\u65f6\u63a5\u6536\u6765\u81ea\u539f\u59cb\u5b50\u6a21\u578b\u7684\u5b9e\u65f6\u8f93\u51fa\u4fe1\u53f7\u548c\u6765\u81ea CSV \u6587\u4ef6\u7684\u9884\u5b9a\u4e49\u6570\u636e\u3002\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u8bbe\u7f6e\u6a21\u578b\u53c2\u6570\uff0c\u60a8\u53ef\u4ee5\u7cbe\u786e\u63a7\u5236\u6bcf\u4e2a\u8f93\u51fa\u4fe1\u53f7\u662f\u9009\u62e9\u201c\u76f4\u901a\u201d\uff08Passthrough\uff09\u4e0a\u6e38\u7684\u5b9e\u65f6\u4fe1\u53f7\uff0c\u8fd8\u662f\u201c\u8986\u76d6\u201d\uff08Override\uff09\u4e3a\u4f7f\u7528 CSV \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u3002</p> <p>\u8fd9\u79cd\u6a21\u5f0f\u7684\u4f18\u52bf\u5728\u4e8e\u5b83\u7684\u5b89\u5168\u6027\u548c\u7075\u6d3b\u6027\uff0c\u6240\u6709\u4fee\u6539\u90fd\u662f\u5728\u81ea\u52a8\u751f\u6210\u7684\u526f\u672c\u4e0a\u8fdb\u884c\u7684\uff08\u4f8b\u5982 <code>_Intercepted.mo</code>\uff09\uff0c\u539f\u59cb\u6a21\u578b\u548c\u7cfb\u7edf\u8bbe\u8ba1\u4fdd\u6301\u4e0d\u53d8\uff0c\u975e\u5e38\u9002\u5408\u7528\u4e8e\u201cwhat-if\u201d\u5206\u6790\u3001\u6545\u969c\u6ce8\u5165\u6216\u4e34\u65f6\u66ff\u6362\u90e8\u5206\u7cfb\u7edf\u884c\u4e3a\u7684\u573a\u666f\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#12","title":"1.2. \u67b6\u6784\u56fe","text":"<pre><code>\u539f\u7cfb\u7edf\u7ed3\u6784\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n\n\u62e6\u622a\u5668\u6a21\u5f0f\u7ed3\u6784\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b] --&gt; [\u62e6\u622a\u5668] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n                               \u2191\n                           [CSV \u6570\u636e]\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#13","title":"1.3. \u5b9e\u73b0\u6b65\u9aa4","text":"<p><code>tricys</code> \u4f1a\u81ea\u52a8\u5b8c\u6210\u4ee5\u4e0b\u6b65\u9aa4\u6765\u5b9e\u73b0\u62e6\u622a\u5668\u6a21\u5f0f\uff1a</p> <pre><code>graph TD\n    A[\u5f00\u59cb] --&gt; B{\u8bfb\u53d6\u534f\u540c\u4eff\u771f\u914d\u7f6e};\n    B --&gt; C[\u901a\u8fc7 OMCSession \u5206\u6790&lt;br&gt;\u76ee\u6807\u5b50\u6a21\u578b\u4ee5\u83b7\u53d6\u6240\u6709\u8f93\u51fa\u7aef\u53e3];\n    C --&gt; D[\u4e3a\u5b50\u6a21\u578b\u52a8\u6001\u751f\u6210\u4e00\u4e2a&lt;br&gt;\u5bf9\u5e94\u7684 '..._Interceptor.mo' \u6a21\u578b\u6587\u4ef6];\n    D --&gt; E[\u8bfb\u53d6\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u7684\u4ee3\u7801];\n    E --&gt; F{\u5728\u7cfb\u7edf\u6a21\u578b\u4e2d&lt;br&gt;\u91cd\u6784\u8fde\u63a5\u5173\u7cfb};\n    F --&gt; G[1. \u58f0\u660e\u5e76\u5b9e\u4f8b\u5316\u62e6\u622a\u5668\u6a21\u578b];\n    F --&gt; H[2. \u4fee\u6539 connect \u8bed\u53e5&lt;br&gt;\u5c06\u539f\u8fde\u63a5\u91cd\u5b9a\u5411\u81f3\u62e6\u622a\u5668];\n    G &amp; H --&gt; I[\u5c06\u4fee\u6539\u540e\u7684\u7cfb\u7edf\u6a21\u578b&lt;br&gt;\u53e6\u5b58\u4e3a '..._Intercepted.mo' \u6587\u4ef6];\n    I --&gt; J[\u7ed3\u675f];\n\n    style C fill:#f9f,stroke:#333,stroke-width:2px;\n    style D fill:#ccf,stroke:#333,stroke-width:2px;\n    style F fill:#f9f,stroke:#333,stroke-width:2px;\n    style I fill:#ccf,stroke:#333,stroke-width:2px;</code></pre> <p>\u5177\u4f53\u6b65\u9aa4\u5206\u89e3\u5982\u4e0b\uff1a 1.  \u5206\u6790\u6a21\u578b\uff1a<code>tricys</code> \u9996\u5148\u4f7f\u7528 OpenModelica (OMC) \u5de5\u5177\u94fe\u5206\u6790\u76ee\u6807\u5b50\u6a21\u578b\uff0c\u81ea\u52a8\u8bc6\u522b\u51fa\u5176\u6240\u6709\u7684\u8f93\u51fa\u7aef\u53e3\u3001\u7ef4\u5ea6\u7b49\u5143\u4fe1\u606f\u3002 2.  \u751f\u6210\u62e6\u622a\u5668\uff1a\u6839\u636e\u4e0a\u4e00\u6b65\u83b7\u53d6\u7684\u7aef\u53e3\u4fe1\u606f\uff0c\u52a8\u6001\u751f\u6210\u4e00\u4e2a\u65b0\u7684 Modelica \u6a21\u578b\uff08<code>..._Interceptor.mo</code>\uff09\u3002\u8be5\u6a21\u578b\u5185\u90e8\u5305\u542b\u4e86 <code>CombiTimeTable</code> \u7ec4\u4ef6\uff08\u7528\u4e8e\u8bfb\u53d6CSV\uff09\u548c\u6570\u636e\u9009\u62e9\u903b\u8f91\u3002 3.  \u4fee\u6539\u7cfb\u7edf\uff1a<code>tricys</code> \u8bfb\u53d6\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u7684\u4ee3\u7801\uff0c\u5e76\u6267\u884c\u4ee5\u4e0b\u4fee\u6539\uff1a     *   \u5b9e\u4f8b\u5316\u62e6\u622a\u5668\uff1a\u5728 <code>equation</code> \u90e8\u5206\u4e4b\u524d\u6dfb\u52a0\u5bf9\u65b0\u751f\u6210\u7684\u62e6\u622a\u5668\u6a21\u578b\u7684\u5b9e\u4f8b\u58f0\u660e\u3002     *   \u91cd\u5b9a\u5411\u8fde\u63a5\uff1a\u901a\u8fc7\u6b63\u5219\u8868\u8fbe\u5f0f\u81ea\u52a8\u67e5\u627e\u5e76\u4fee\u6539 <code>connect</code> \u8bed\u53e5\u3002\u539f\u672c\u4ece\u5b50\u6a21\u578b\u8f93\u51fa\u7aef\u53e3\u5230\u4e0b\u6e38\u7ec4\u4ef6\u7684\u8fde\u63a5\u88ab\u65ad\u5f00\uff0c\u8f6c\u800c\u901a\u8fc7\u62e6\u622a\u5668\u8fdb\u884c\u8def\u7531\uff1a         *   <code>\u5b50\u6a21\u578b.\u8f93\u51fa\u7aef\u53e3</code> -&gt; <code>\u62e6\u622a\u5668.\u7269\u7406\u8f93\u5165\u7aef\u53e3</code>         *   <code>\u62e6\u622a\u5668.\u6700\u7ec8\u8f93\u51fa\u7aef\u53e3</code> -&gt; <code>\u4e0b\u6e38\u7ec4\u4ef6.\u8f93\u5165\u7aef\u53e3</code> 4.  \u4fdd\u5b58\u65b0\u7cfb\u7edf\uff1a\u5c06\u4fee\u6539\u540e\u7684\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u5185\u5bb9\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\uff0c\u5e76\u6dfb\u52a0 <code>_Intercepted</code> \u540e\u7f00\uff0c\u786e\u4fdd\u539f\u59cb\u7cfb\u7edf\u6a21\u578b\u6587\u4ef6\u4e0d\u53d7\u5f71\u54cd\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#14","title":"1.4. \u62e6\u622a\u5668\u6a21\u578b\u793a\u4f8b","text":"<pre><code>within example_model;\n\nmodel Plasma_Interceptor\n  // \u63a5\u6536\u539f\u6a21\u578b\u8f93\u51fa\n  Modelica.Blocks.Interfaces.RealInput physical_to_Pump[5];\n\n  // \u6700\u7ec8\u8f93\u51fa\n  Modelica.Blocks.Interfaces.RealOutput final_to_Pump[5];\n\n  protected\n    parameter String fileName = \"plasma_data.csv\";\n\n    // \u5217\u6620\u5c04\u53c2\u6570\uff1a[time, y1, y2, y3, y4, y5]\n    // \u5982\u679c\u67d0\u5217\u8bbe\u4e3a 1\uff0c\u8868\u793a\u4f7f\u7528\u7269\u7406\u6570\u636e\u800c\u975e CSV\n    parameter Integer columns_to_Pump[6] = {1, 2, 3, 4, 5, 6};\n\n    // CSV \u8bfb\u53d6\u5668\n    Modelica.Blocks.Sources.CombiTimeTable table_to_Pump(\n      tableName=\"csv_data_to_Pump\",\n      fileName=fileName,\n      columns=columns_to_Pump,\n      tableOnFile=true\n    );\n\n  equation\n    // \u9010\u5143\u7d20\u9009\u62e9\u6570\u636e\u6e90\n    for i in 1:5 loop\n      final_to_Pump[i] = if columns_to_Pump[i+1] &lt;&gt; 1 \n                         then table_to_Pump.y[i]   // \u4f7f\u7528 CSV\n                         else physical_to_Pump[i]; // \u4f7f\u7528\u7269\u7406\u6570\u636e\n    end for;\n\nend Plasma_Interceptor;\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#2","title":"2. \u76f4\u63a5\u66ff\u6362\u6a21\u5f0f","text":""},{"location":"explanation/tricys_basic/co_simulation.html#21","title":"2.1. \u5de5\u4f5c\u539f\u7406","text":"<p>\u76f4\u63a5\u66ff\u6362\u6a21\u5f0f\u662f\u4e00\u79cd\u4fb5\u5165\u5f0f\u4f46\u9ad8\u6548\u7684\u65b9\u6cd5\u3002\u5b83\u4f1a\u76f4\u63a5\u4fee\u6539\u76ee\u6807\u5b50\u6a21\u578b\u7684\u6587\u4ef6\uff0c\u7528\u4e00\u4e2a\u201c\u6570\u636e\u64ad\u653e\u5668\u201d\u6765\u5b8c\u5168\u66ff\u4ee3\u5176\u539f\u6709\u7684\u5185\u90e8\u903b\u8f91\u3002</p> <p>\u5de5\u4f5c\u6d41\u7a0b\u662f\uff0c<code>tricys</code> \u9996\u5148\u4f1a\u4e3a\u76ee\u6807\u5b50\u6a21\u578b\u521b\u5efa\u4e00\u4e2a\u5907\u4efd\u6587\u4ef6\uff08<code>.bak</code>\uff09\u3002\u7136\u540e\uff0c\u5b83\u4f1a\u201c\u6e05\u7a7a\u201d\u539f\u59cb\u6a21\u578b\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u5185\u90e8\u65b9\u7a0b\u548c\u53d8\u91cf\uff0c\u4ec5\u4fdd\u7559\u5176\u8f93\u5165/\u8f93\u51fa\u7aef\u53e3\u7684\u58f0\u660e\u3002\u63a5\u7740\uff0c\u5b83\u5411\u8be5\u6a21\u578b\u4e2d\u6dfb\u52a0 <code>CombiTimeTable</code> \u7ec4\u4ef6\uff0c\u5e76\u5c06\u8f93\u51fa\u7aef\u53e3\u76f4\u63a5\u8fde\u63a5\u5230\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u6570\u636e\u8f93\u51fa\u4e0a\u3002</p> <p>\u6700\u7ec8\uff0c\u8be5\u5b50\u6a21\u578b\u53d8\u6210\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u6570\u636e\u6e90\uff0c\u5176\u884c\u4e3a\u5b8c\u5168\u7531\u5916\u90e8 CSV \u6587\u4ef6\u5b9a\u4e49\u3002\u8fd9\u79cd\u6a21\u5f0f\u9002\u7528\u4e8e\u5f53\u4f60\u9700\u8981\u7528\u4e00\u4e2a\u56fa\u5b9a\u7684\u6570\u636e\u96c6\uff08\u4f8b\u5982\uff0c\u6765\u81ea\u9ad8\u7cbe\u5ea6\u4eff\u771f\u7684\u7ed3\u679c\u6216\u5b9e\u9a8c\u6570\u636e\uff09\u6765\u6c38\u4e45\u6216\u534a\u6c38\u4e45\u5730\u66ff\u6362\u4e00\u4e2a\u8ba1\u7b97\u6602\u8d35\u6216\u6682\u4e0d\u53ef\u7528\u7684\u5b50\u6a21\u578b\u65f6\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#22","title":"2.2. \u67b6\u6784\u56fe","text":"<pre><code>\u539f\u7cfb\u7edf\u7ed3\u6784\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n\n\u76f4\u63a5\u66ff\u6362\u6a21\u5f0f\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b(CSV\u7248)] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n                     \u2191\n                 [CSV \u6570\u636e]\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#23","title":"2.3. \u5b9e\u73b0\u6b65\u9aa4","text":"<p><code>tricys</code> \u901a\u8fc7\u4ee5\u4e0b\u81ea\u52a8\u5316\u6d41\u7a0b\u5b9e\u73b0\u76f4\u63a5\u66ff\u6362\uff1a</p> <pre><code>graph TD\n    A[\u5f00\u59cb] --&gt; B{\u8bfb\u53d6\u534f\u540c\u4eff\u771f\u914d\u7f6e};\n    B --&gt; C[\u5b9a\u4f4d\u5230\u76ee\u6807\u5b50\u6a21\u578b\u7684 '.mo' \u6587\u4ef6];\n    C --&gt; D[\u521b\u5efa\u8be5\u6587\u4ef6\u7684\u5907\u4efd&lt;br&gt;\u4f8b\u5982 'SubModel.mo' -&gt; 'SubModel.bak'];\n    D --&gt; E[\u8bfb\u53d6\u6a21\u578b\u4ee3\u7801&lt;br&gt;\u4ec5\u4fdd\u7559\u7aef\u53e3\u58f0\u660e\u548c\u6a21\u578b\u6846\u67b6];\n    E --&gt; F[\u751f\u6210\u65b0\u7684\u6a21\u578b\u5185\u5bb9];\n    F --&gt; G[1. \u6dfb\u52a0 CombiTimeTable \u7ec4\u4ef6&lt;br&gt;\u7528\u4e8e\u8bfb\u53d6 CSV \u6570\u636e];\n    F --&gt; H[2. \u521b\u5efa\u65b0\u7684 equation&lt;br&gt;\u5c06\u8f93\u51fa\u7aef\u53e3\u76f4\u63a5\u8fde\u63a5\u5230 Table \u7684\u8f93\u51fa];\n    G &amp; H --&gt; I[\u4f7f\u7528\u65b0\u751f\u6210\u7684\u4ee3\u7801&lt;br&gt;\u8986\u76d6\u539f\u59cb\u7684 '.mo' \u6587\u4ef6];\n    I --&gt; J[\u7ed3\u675f];\n\n    style D fill:#f9f,stroke:#333,stroke-width:2px;\n    style F fill:#f9f,stroke:#333,stroke-width:2px;\n    style I fill:#ccf,stroke:#333,stroke-width:2px;</code></pre> <p>\u5177\u4f53\u6b65\u9aa4\u5206\u89e3\u5982\u4e0b\uff1a 1.  \u5b9a\u4f4d\u4e0e\u5907\u4efd\uff1a<code>tricys</code> \u6839\u636e <code>submodel_name</code> \u5728\u9879\u76ee\u76ee\u5f55\u4e2d\u627e\u5230\u5bf9\u5e94\u7684 <code>.mo</code> \u6587\u4ef6\uff0c\u5e76\u7acb\u5373\u521b\u5efa\u4e00\u4e2a <code>.bak</code> \u540e\u7f00\u7684\u5907\u4efd\u6587\u4ef6\u4ee5\u9632\u6570\u636e\u4e22\u5931\u3002 2.  \u89e3\u6790\u4e0e\u6e05\u7a7a\uff1a\u7a0b\u5e8f\u8bfb\u53d6\u539f\u59cb\u6a21\u578b\u4ee3\u7801\uff0c\u5e76\u89e3\u6790\u51fa\u5176\u5b8c\u6574\u7684\u8f93\u5165/\u8f93\u51fa\u7aef\u53e3\u58f0\u660e\u3002\u7136\u540e\uff0c\u5b83\u4f1a\u4e22\u5f03\u6a21\u578b\u4e2d\u6240\u6709\u5176\u4ed6\u5185\u5bb9\uff0c\u5982 <code>parameter</code>, <code>protected</code> \u90e8\u5206\u7684\u53d8\u91cf\u4ee5\u53ca <code>equation</code> \u90e8\u5206\u7684\u6240\u6709\u65b9\u7a0b\u3002 3.  \u751f\u6210\u65b0\u4ee3\u7801\uff1a<code>tricys</code> \u57fa\u4e8e\u89e3\u6790\u51fa\u7684\u7aef\u53e3\u4fe1\u606f\u751f\u6210\u5168\u65b0\u7684\u6a21\u578b\u4ee3\u7801\uff1a     *   \u4fdd\u7559\u539f\u59cb\u7684\u7aef\u53e3\u58f0\u660e\uff0c\u786e\u4fdd\u5176\u5bf9\u5916\u63a5\u53e3\u4e0d\u53d8\u3002     *   \u4e3a\u6bcf\u4e2a\u9700\u8981\u88ab CSV \u6570\u636e\u9a71\u52a8\u7684\u8f93\u51fa\u7aef\u53e3\uff0c\u6dfb\u52a0\u4e00\u4e2a <code>CombiTimeTable</code> \u5b9e\u4f8b\uff0c\u5e76\u914d\u7f6e\u597d <code>fileName</code> \u548c <code>columns</code> \u7b49\u53c2\u6570\u3002     *   \u521b\u5efa\u4e00\u4e2a\u65b0\u7684 <code>equation</code> \u90e8\u5206\uff0c\u7528\u7b80\u5355\u7684\u6620\u5c04\u8bed\u53e5 <code>output_port = table.y</code> \u5c06\u8f93\u51fa\u7aef\u53e3\u76f4\u63a5\u8fde\u63a5\u5230 <code>CombiTimeTable</code> \u7684\u6570\u636e\u8f93\u51fa\u4e0a\u3002 4.  \u8986\u76d6\u6587\u4ef6\uff1a\u6700\u540e\uff0c<code>tricys</code> \u7528\u65b0\u751f\u6210\u7684\u4ee3\u7801\u5b8c\u5168\u8986\u76d6\u539f\u59cb\u7684 <code>.mo</code> \u6587\u4ef6\uff0c\u5b8c\u6210\u66ff\u6362\u8fc7\u7a0b\u3002\u7531\u4e8e\u5b50\u6a21\u578b\u7684\u63a5\u53e3\uff08\u7aef\u53e3\uff09\u6ca1\u6709\u6539\u53d8\uff0c\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u65e0\u9700\u4efb\u4f55\u4fee\u6539\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#24","title":"2.4. \u66ff\u6362\u540e\u6a21\u578b\u793a\u4f8b","text":"<pre><code>within example_model;\n\nmodel Plasma\n  // \u539f\u6709\u7aef\u53e3\u58f0\u660e\u4fdd\u6301\u4e0d\u53d8\n  Modelica.Blocks.Interfaces.RealInput pulseInput;\n  Modelica.Blocks.Interfaces.RealOutput from_Fueling_System[5];\n  Modelica.Blocks.Interfaces.RealOutput to_FW[5];\n  Modelica.Blocks.Interfaces.RealOutput to_Div[5];\n  Modelica.Blocks.Interfaces.RealOutput to_Pump[5];\n\nprotected\n  parameter String fileName = \"plasma_data.csv\";\n\n  // CSV \u6570\u636e\u6e90\n  Modelica.Blocks.Sources.CombiTimeTable table_to_Pump(\n    tableName=\"csv_data_to_Pump\",\n    fileName=fileName,\n    columns={1, 2, 3, 4, 5, 6},  // time + 5 data columns\n    tableOnFile=true\n  );\n\n  Modelica.Blocks.Sources.CombiTimeTable table_to_FW(\n    tableName=\"csv_data_to_FW\",\n    fileName=fileName,\n    columns={1, 7, 8, 9, 10, 11},\n    tableOnFile=true\n  );\n\n  // ... \u5176\u4ed6\u7aef\u53e3\u7684 table \u5b9a\u4e49 ...\n\nequation\n  // \u76f4\u63a5\u6620\u5c04 CSV \u5230\u8f93\u51fa\uff08\u5ffd\u7565\u8f93\u5165\uff09\n  for i in 1:5 loop\n    to_Pump[i] = table_to_Pump.y[i];\n    to_FW[i] = table_to_FW.y[i];\n    to_Div[i] = table_to_Div.y[i];\n    from_Fueling_System[i] = table_from_Fueling_System.y[i];\n  end for;\n\nend Plasma;\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#3","title":"3. \u7f16\u5199\u60a8\u81ea\u5df1\u7684\u5904\u7406\u5668","text":"<p>\u9664\u4e86\u4f7f\u7528\u5185\u7f6e\u7684\u5904\u7406\u5668\uff0c<code>tricys</code> \u534f\u540c\u4eff\u771f\u6846\u67b6\u6700\u5f3a\u5927\u7684\u529f\u80fd\u662f\u5141\u8bb8\u60a8\u7f16\u5199\u81ea\u5df1\u7684 Python \u51fd\u6570\uff08\u5904\u7406\u5668\uff09\u6765\u52a8\u6001\u751f\u6210\u6ce8\u5165\u5230 Modelica \u6a21\u578b\u4e2d\u7684\u6570\u636e\u3002\u8fd9\u610f\u5473\u7740\u60a8\u53ef\u4ee5\u96c6\u6210\u4efb\u4f55\u590d\u6742\u7684\u5916\u90e8\u6a21\u578b\u3001\u7b97\u6cd5\u6216\u6570\u636e\u6e90\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#31","title":"3.1. \u5904\u7406\u5668\u914d\u7f6e","text":"<p>\u5728 <code>config.json</code> \u7684 <code>co_simulation.handlers</code> \u5217\u8868\u4e2d\uff0c\u6bcf\u4e00\u4e2a\u5904\u7406\u5668\u5bf9\u8c61\u90fd\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u6765\u5b9a\u4e49\u5176\u884c\u4e3a\uff1a</p> <ul> <li> <p><code>handler_module</code> \u6216 <code>handler_script_path</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b\u4e4b\u4e00):</p> <ul> <li><code>handler_module</code>: \u6307\u5b9a\u5904\u7406\u5668\u51fd\u6570\u6240\u5728\u7684 Python \u6a21\u5757 \u7684\u5b8c\u6574\u8def\u5f84\u3002\u9002\u7528\u4e8e\u4ee3\u7801\u662f\u6807\u51c6 Python \u5305\u4e00\u90e8\u5206\u7684\u573a\u666f\u3002</li> <li><code>handler_script_path</code>: \u6307\u5b9a\u5305\u542b\u5904\u7406\u5668\u51fd\u6570\u7684 Python \u811a\u672c\u6587\u4ef6 \u7684\u8def\u5f84\u3002\u8fd9\u66f4\u52a0\u7075\u6d3b\uff0c\u9002\u7528\u4e8e\u72ec\u7acb\u7684\u811a\u672c\u6587\u4ef6\u3002</li> </ul> </li> <li> <p><code>handler_function</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</p> <ul> <li>\u63cf\u8ff0: \u8981\u5728\u6307\u5b9a\u6a21\u5757\u6216\u811a\u672c\u4e2d\u8c03\u7528\u7684\u51fd\u6570\u540d\u3002</li> </ul> </li> <li> <p><code>params</code> (\u5b57\u5178, \u9009\u586b):</p> <ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5305\u542b\u8981\u4f20\u9012\u7ed9\u5904\u7406\u5668\u51fd\u6570\u7684\u4efb\u610f\u5173\u952e\u5b57\u53c2\u6570\u7684\u5b57\u5178\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_basic/co_simulation.html#32","title":"3.2. \u51fd\u6570\u7b7e\u540d\u4e0e\u804c\u8d23","text":"<p>\u4e3a\u4e86\u80fd\u88ab <code>tricys</code> \u6846\u67b6\u6b63\u786e\u8c03\u7528\uff0c\u60a8\u7684\u5904\u7406\u5668\u51fd\u6570\u5fc5\u987b\u9075\u5faa\u7279\u5b9a\u7684\u7b7e\u540d\u3002\u6846\u67b6\u4f1a\u81ea\u52a8\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570\u4f20\u5165\u4e24\u4e2a\u6838\u5fc3\u8def\u5f84\uff0c\u60a8\u7684\u51fd\u6570\u9700\u8981\u5b9a\u4e49\u5e76\u63a5\u6536\u5b83\u4eec\uff1a</p> <pre><code>def my_handler(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"\n    \u4e00\u4e2a\u6807\u51c6\u7684\u5904\u7406\u5668\u51fd\u6570\u7b7e\u540d\u3002\n\n    Args:\n        temp_input_csv (str): \u4e00\u4e2a CSV \u6587\u4ef6\u7684\u8def\u5f84\uff0c\u5305\u542b\u4e0a\u6e38\u6a21\u578b\u7684\u8f93\u51fa\u7ed3\u679c\u3002\n                              \u60a8\u53ef\u4ee5\u8bfb\u53d6\u6b64\u6587\u4ef6\u6765\u83b7\u53d6\u9a71\u52a8\u60a8\u8ba1\u7b97\u7684\u8f93\u5165\u3002\n        temp_output_csv (str): \u4e00\u4e2a\u76ee\u6807 CSV \u6587\u4ef6\u7684\u8def\u5f84\uff0c\u60a8\u9700\u8981\u5c06\u8ba1\u7b97\u7ed3\u679c\u5199\u5165\u6b64\u6587\u4ef6\u3002\n                               tricys \u4f1a\u5c06\u6b64\u6587\u4ef6\u63d0\u4f9b\u7ed9 Modelica \u7684 CombiTimeTable\u3002\n        **kwargs: \u7528\u4e8e\u63a5\u6536\u6765\u81ea JSON \u914d\u7f6e\u4e2d \"params\" \u7684\u6240\u6709\u81ea\u5b9a\u4e49\u53c2\u6570\u3002\n\n    Returns:\n        dict: \u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u4e8e\u914d\u7f6e Modelica CombiTimeTable \u7684\u5217\u6620\u5c04\u3002\n    \"\"\"\n    # ... \u60a8\u7684\u4ee3\u7801\u903b\u8f91 ...\n</code></pre> <p>\u6838\u5fc3\u804c\u8d23: 1.  \u8bfb\u53d6\u8f93\u5165 (\u53ef\u9009): \u4f7f\u7528 Pandas \u6216\u5176\u4ed6\u5e93\u8bfb\u53d6 <code>temp_input_csv</code> \u6587\u4ef6\uff0c\u83b7\u53d6\u4e0a\u6e38\u6a21\u578b\u7684\u52a8\u6001\u8f93\u51fa\u3002 2.  \u6267\u884c\u8ba1\u7b97: \u8fd0\u884c\u60a8\u7684\u6a21\u578b\u3001\u7b97\u6cd5\u6216\u4efb\u4f55\u5176\u4ed6\u903b\u8f91\u3002 3.  \u5199\u5165\u8f93\u51fa: \u5c06\u60a8\u7684\u8ba1\u7b97\u7ed3\u679c\uff08\u5fc5\u987b\u5305\u542b <code>time</code> \u5217\uff09\u4fdd\u5b58\u4e3a CSV \u683c\u5f0f\u5230 <code>temp_output_csv</code> \u6307\u5b9a\u7684\u8def\u5f84\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#33","title":"3.3. \u8fd4\u56de\u503c","text":"<p>\u5904\u7406\u5668\u51fd\u6570\u5fc5\u987b\u8fd4\u56de\u4e00\u4e2a\u5b57\u5178\u3002\u8fd9\u4e2a\u5b57\u5178\u7684\u952e\u5bf9\u5e94 Modelica \u5b50\u6a21\u578b\u7684\u8f93\u51fa\u7aef\u53e3\u540d\uff0c\u503c\u662f\u4e00\u4e2a\u5b57\u7b26\u4e32\uff0c\u7528\u4e8e\u914d\u7f6e <code>CombiTimeTable</code> \u7684 <code>columns</code> \u53c2\u6570\uff0c\u5b9a\u4e49\u4e86\u5982\u4f55\u4ece\u60a8\u751f\u6210\u7684 CSV \u6587\u4ef6\u4e2d\u8bfb\u53d6\u6570\u636e\u5217\u3002</p> <ul> <li>\u793a\u4f8b: <code>return {\"to_CL\": \"{1,2,3,4,5,6}\"}</code></li> <li>\u8fd9\u544a\u8bc9 <code>tricys</code>\uff0c\u5bf9\u4e8e\u540d\u4e3a <code>to_CL</code> \u7684\u8f93\u51fa\u7aef\u53e3\uff0c\u751f\u6210\u7684 <code>CombiTimeTable</code> \u5e94\u8be5\u4f7f\u7528\u60a8\u5728 <code>temp_output_csv</code> \u4e2d\u5199\u5165\u7684\u7b2c 1 \u5230\u7b2c 6 \u5217\u6570\u636e\uff08\u5176\u4e2d\u7b2c 1 \u5217\u901a\u5e38\u662f <code>time</code>\uff09\u3002</li> </ul>"},{"location":"explanation/tricys_basic/co_simulation.html#34","title":"3.4. \u5b8c\u6574\u793a\u4f8b","text":"<p>\u4ee5\u5185\u7f6e\u7684 <code>div_handler.py</code> \u4e3a\u4f8b\uff0c\u5b83\u6a21\u62df\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u5916\u90e8\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4e0d\u4f9d\u8d56\u4e0a\u6e38\u8f93\u5165\uff0c\u800c\u662f\u81ea\u5df1\u751f\u6210\u6570\u636e\u3002</p> <p>\u6b65\u9aa4 1: \u521b\u5efa\u5904\u7406\u5668\u811a\u672c</p> <pre><code># tricys/handlers/div_handler.py\n\nimport os\nimport pandas as pd\n\ndef run_div_simulation(temp_input_csv, temp_output_csv, **kwargs):\n    \"\"\"\n    \u4e00\u4e2a\u7b80\u5355\u7684\u5904\u7406\u5668\uff0c\u5b83\u8bfb\u53d6\u4e00\u4e2a\u9884\u5b9a\u4e49\u7684 CSV \u6587\u4ef6\u5e76\u5c06\u5176\u5185\u5bb9\n    \u5199\u5165\u5230\u6846\u67b6\u6307\u5b9a\u7684\u76ee\u6807\u8f93\u51fa\u8def\u5f84\u3002\n    \"\"\"\n    # \u83b7\u53d6\u5f53\u524d\u6587\u4ef6\u6240\u5728\u76ee\u5f55\uff0c\u4ee5\u5b9a\u4f4d\u6570\u636e\u6587\u4ef6\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"div_handler.csv\")\n\n    # \u8bfb\u53d6\u6e90\u6570\u636e\n    source_df = pd.read_csv(source_csv_path)\n\n    # \u5b9a\u4e49\u9700\u8981\u8f93\u51fa\u5230 Modelica \u7684\u5217\n    columns_to_select = [\n        \"time\",\n        \"div.to_CL[1]\", \"div.to_CL[2]\", \"div.to_CL[3]\",\n        \"div.to_CL[4]\", \"div.to_CL[5]\",\n    ]\n    output_df = source_df[columns_to_select].copy()\n\n    # \u5c06\u5904\u7406\u540e\u7684\u6570\u636e\u5199\u5165\u6846\u67b6\u6307\u5b9a\u7684\u76ee\u6807 CSV \u6587\u4ef6\n    output_df.to_csv(temp_output_csv, index=False)\n\n    # \u8fd4\u56de\u7aef\u53e3\u4e0e\u5217\u7684\u6620\u5c04\u5173\u7cfb\n    output_placeholder = {\"to_CL\": \"{1,2,3,4,5,6}\"}\n    return output_placeholder\n</code></pre> <p>\u6b65\u9aa4 2: \u5728 <code>config.json</code> \u4e2d\u914d\u7f6e</p> <pre><code>\"co_simulation\": {\n    \"mode\": \"interceptor\",\n    \"handlers\": [\n        {\n            \"submodel_name\": \"example_model.DIV\",\n            \"instance_name\": \"div\",\n            \"handler_module\": \"tricys.handlers.div_handler\",\n            \"handler_function\": \"run_div_simulation\",\n            \"params\": {}\n        }\n    ]\n}\n</code></pre> <p>\u5728\u8fd9\u4e2a\u914d\u7f6e\u4e2d\uff0c<code>tricys</code> \u4f1a: 1.  \u5bfc\u5165 <code>tricys.handlers.div_handler</code> \u6a21\u5757\u3002 2.  \u8c03\u7528 <code>run_div_simulation</code> \u51fd\u6570\u3002 3.  \u51fd\u6570\u6267\u884c\u540e\uff0c\u751f\u6210\u4e00\u4e2a\u65b0\u7684 CSV \u6587\u4ef6\u3002 4.  \u4f7f\u7528\u51fd\u6570\u8fd4\u56de\u7684 <code>{\"to_CL\": \"{1,2,3,4,5,6}\"}</code> \u6765\u914d\u7f6e\u6ce8\u5165\u5230 Modelica \u4eff\u771f\u4e2d\u7684 <code>CombiTimeTable</code>\u3002</p>"},{"location":"explanation/tricys_basic/concurrency.html","title":"TRICYS \u5e76\u53d1\u6267\u884c","text":"<p>TRICYS \u65e8\u5728\u5145\u5206\u5229\u7528\u73b0\u4ee3\u591a\u6838\u5904\u7406\u5668\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u901a\u8fc7\u5e76\u53d1\u6267\u884c\u6765\u663e\u8457\u7f29\u77ed\u53c2\u6570\u626b\u63cf\u548c\u6279\u91cf\u4eff\u771f\u7684\u603b\u8017\u65f6\u3002\u6839\u636e\u4eff\u771f\u7c7b\u578b\u7684\u4e0d\u540c\uff0cTRICYS \u4f1a\u667a\u80fd\u5730\u91c7\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u5e76\u53d1\u7b56\u7565\uff1a\u591a\u7ebf\u7a0b\uff08\u7528\u4e8e\u6807\u51c6\u4eff\u771f\uff09\u548c\u591a\u8fdb\u7a0b\uff08\u7528\u4e8e\u534f\u540c\u4eff\u771f\uff09\u3002</p> <p>\u60a8\u53ef\u4ee5\u5728 <code>config.json</code> \u4e2d\u901a\u8fc7\u4ee5\u4e0b\u53c2\u6570\u6765\u63a7\u5236\u5e76\u53d1\u884c\u4e3a\uff1a</p> <pre><code>\"simulation\": {\n  \"concurrent\": true,  // \u8bbe\u7f6e\u4e3a true \u6765\u5f00\u542f\u5e76\u53d1\u6a21\u5f0f\n  \"max_workers\": 8     // \u8bbe\u7f6e\u6700\u5927\u5e76\u53d1\u5de5\u4f5c\u5355\u5143\u6570\uff0c\u9ed8\u8ba4\u4e3a CPU \u6838\u5fc3\u6570\n}\n</code></pre>"},{"location":"explanation/tricys_basic/concurrency.html#1","title":"1. \u6807\u51c6\u4eff\u771f\uff1a\u591a\u7ebf\u7a0b\u5e76\u53d1","text":"<p>\u5bf9\u4e8e\u4e0d\u6d89\u53ca\u534f\u540c\u4eff\u771f\u7684\u6807\u51c6\u53c2\u6570\u626b\u63cf\u4efb\u52a1\uff0cTRICYS \u9ed8\u8ba4\u4f7f\u7528\u591a\u7ebf\u7a0b\u6a21\u578b\u3002</p>"},{"location":"explanation/tricys_basic/concurrency.html#11","title":"1.1. \u5de5\u4f5c\u539f\u7406","text":"<p>TRICYS \u4f7f\u7528 Python \u7684 <code>concurrent.futures.ThreadPoolExecutor</code> \u6765\u7ba1\u7406\u4e00\u4e2a\u5de5\u4f5c\u7ebf\u7a0b\u6c60\u3002\u6bcf\u4e2a\u4eff\u771f\u4efb\u52a1\uff08\u5373\u4e00\u7ec4\u7279\u5b9a\u7684\u53c2\u6570\uff09\u4f1a\u88ab\u63d0\u4ea4\u5230\u7ebf\u7a0b\u6c60\u4e2d\uff0c\u7531\u4e00\u4e2a\u7a7a\u95f2\u7684\u7ebf\u7a0b\u6765\u6267\u884c\u3002</p> <pre><code># \u7b80\u5316\u7248\u539f\u7406\u4ee3\u7801\nfrom concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=8) as executor:\n    # _run_single_job \u662f\u6bcf\u4e2a\u7ebf\u7a0b\u8981\u6267\u884c\u7684\u4efb\u52a1\n    futures = [executor.submit(_run_single_job, config, params, i) for i, params in enumerate(jobs)]\n    # ... \u7b49\u5f85\u5e76\u6536\u96c6\u7ed3\u679c ...\n</code></pre>"},{"location":"explanation/tricys_basic/concurrency.html#12","title":"1.2. \u4e3a\u4f55\u4f7f\u7528\u591a\u7ebf\u7a0b\uff1f","text":"<p>\u867d\u7136 Python \u5b58\u5728\u5168\u5c40\u89e3\u91ca\u5668\u9501\uff08GIL\uff09\uff0c\u4f7f\u5f97\u5728\u5355\u4e2a\u8fdb\u7a0b\u4e2d\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684 CPU \u5bc6\u96c6\u578b\u4ee3\u7801\u5e76\u884c\uff0c\u4f46\u5bf9\u4e8e\u6807\u51c6 Modelica \u4eff\u771f\u573a\u666f\uff0c\u591a\u7ebf\u7a0b\u4ecd\u7136\u662f\u9ad8\u6548\u7684\u9009\u62e9\u3002\u539f\u56e0\u5982\u4e0b\uff1a</p> <ul> <li>I/O \u5bc6\u96c6\u578b\uff1a\u8c03\u7528 <code>OMPython</code> \u8fd0\u884c\u4eff\u771f\u672c\u8d28\u4e0a\u662f\u542f\u52a8\u4e00\u4e2a\u5916\u90e8\u7684 <code>simulate.exe</code> \u53ef\u6267\u884c\u6587\u4ef6\u3002Python \u7ebf\u7a0b\u5728\u6b64\u671f\u95f4\u4e3b\u8981\u5904\u4e8e\u7b49\u5f85\u72b6\u6001\uff08I/O-bound\uff09\uff0c\u7b49\u5f85\u5916\u90e8\u8fdb\u7a0b\u5b8c\u6210\u8ba1\u7b97\u5e76\u5199\u56de\u7ed3\u679c\u6587\u4ef6\u3002GIL \u5728\u6b64\u671f\u95f4\u4f1a\u88ab\u91ca\u653e\uff0c\u5141\u8bb8\u5176\u4ed6\u7ebf\u7a0b\u8fd0\u884c\u3002</li> <li>\u4f4e\u5f00\u9500\uff1a\u7ebf\u7a0b\u6bd4\u8fdb\u7a0b\u66f4\u8f7b\u91cf\uff0c\u521b\u5efa\u548c\u9500\u6bc1\u7684\u901f\u5ea6\u66f4\u5feb\uff0c\u5360\u7528\u7684\u7cfb\u7edf\u8d44\u6e90\u4e5f\u66f4\u5c11\u3002\u5bf9\u4e8e\u6570\u91cf\u4f17\u591a\u4f46\u6bcf\u6b21\u4eff\u771f\u8017\u65f6\u4e0d\u662f\u7279\u522b\u957f\u7684\u4efb\u52a1\uff0c\u4f7f\u7528\u7ebf\u7a0b\u53ef\u4ee5\u51cf\u5c11\u4efb\u52a1\u8c03\u5ea6\u7684\u989d\u5916\u5f00\u9500\u3002</li> </ul>"},{"location":"explanation/tricys_basic/concurrency.html#2","title":"2. \u534f\u540c\u4eff\u771f\uff1a\u591a\u8fdb\u7a0b\u5e76\u53d1","text":"<p>\u5bf9\u4e8e\u590d\u6742\u7684\u534f\u540c\u4eff\u771f\u4efb\u52a1\uff0cTRICYS \u5219\u5207\u6362\u5230\u66f4\u5065\u58ee\u7684\u591a\u8fdb\u7a0b\u6a21\u578b\u3002</p>"},{"location":"explanation/tricys_basic/concurrency.html#21","title":"2.1. \u5de5\u4f5c\u539f\u7406","text":"<p>TRICYS \u4f7f\u7528 <code>concurrent.futures.ProcessPoolExecutor</code> \u6765\u521b\u5efa\u4e00\u4e2a\u8fdb\u7a0b\u6c60\u3002\u6bcf\u4e2a\u534f\u540c\u4eff\u771f\u4efb\u52a1\uff08<code>_run_co_simulation</code>\uff09\u90fd\u5728\u4e00\u4e2a\u5b8c\u5168\u72ec\u7acb\u7684\u5b50\u8fdb\u7a0b\u4e2d\u8fd0\u884c\u3002</p> <pre><code># \u7b80\u5316\u7248\u539f\u7406\u4ee3\u7801\nfrom concurrent.futures import ProcessPoolExecutor\n\nwith ProcessPoolExecutor(max_workers=8) as executor:\n    # _run_co_simulation \u5728\u4e00\u4e2a\u72ec\u7acb\u7684\u8fdb\u7a0b\u4e2d\u6267\u884c\n    futures = [executor.submit(_run_co_simulation, config, params, i) for i, params in enumerate(jobs)]\n    # ... \u7b49\u5f85\u5e76\u6536\u96c6\u7ed3\u679c ...\n</code></pre>"},{"location":"explanation/tricys_basic/concurrency.html#22","title":"2.2. \u4e3a\u4f55\u5fc5\u987b\u4f7f\u7528\u591a\u8fdb\u7a0b\uff1f","text":"<p>\u534f\u540c\u4eff\u771f\u7684\u5de5\u4f5c\u6d41\u7a0b\u6d89\u53ca\u5230\u5bf9\u6587\u4ef6\u7cfb\u7edf\u7684\u5927\u91cf\u8bfb\u5199\u548c\u4fee\u6539\uff0c\u8fd9\u662f\u5176\u5fc5\u987b\u4f7f\u7528\u591a\u8fdb\u7a0b\u7684\u6838\u5fc3\u539f\u56e0\uff1a</p> <ul> <li>\u73af\u5883\u9694\u79bb\uff1a\u6bcf\u4e2a\u534f\u540c\u4eff\u771f\u4efb\u52a1\u90fd\u9700\u8981\u4e00\u4e2a\u7eaf\u51c0\u3001\u72ec\u7acb\u7684\u8fd0\u884c\u73af\u5883\u3002\u5b83\u4f1a\u5c06\u539f\u59cb Modelica \u6a21\u578b\u5305\u590d\u5236\u5230\u4e00\u4e2a\u4e34\u65f6\u76ee\u5f55\uff0c\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u4fee\u6539\uff08\u4f8b\u5982\uff0c\u751f\u6210\u62e6\u622a\u5668\u6216\u76f4\u63a5\u66ff\u6362\u6a21\u578b\uff09\u3002\u5982\u679c\u4f7f\u7528\u591a\u7ebf\u7a0b\uff0c\u591a\u4e2a\u4efb\u52a1\u4f1a\u540c\u65f6\u4fee\u6539\u5171\u4eab\u7684\u6a21\u578b\u6587\u4ef6\uff0c\u5bfc\u81f4\u6587\u4ef6\u635f\u574f\u548c\u7ed3\u679c\u9519\u4e71\u3002</li> <li>\u65e0\u72b6\u6001\u51b2\u7a81\uff1a\u8fdb\u7a0b\u62e5\u6709\u72ec\u7acb\u7684\u5185\u5b58\u7a7a\u95f4\u548c\u6587\u4ef6\u53e5\u67c4\u3002\u8fd9\u786e\u4fdd\u4e86\u4e00\u4e2a\u4efb\u52a1\u5bf9\u6a21\u578b\u4ee3\u7801\u7684\u4fee\u6539\u3001\u5916\u90e8 Python \u5904\u7406\u5668\uff08handler\uff09\u7684\u8fd0\u884c\u4ee5\u53ca\u751f\u6210\u7684\u6240\u6709\u4e2d\u95f4\u6587\u4ef6\uff0c\u90fd\u4e0d\u4f1a\u5bf9\u5176\u4ed6\u5e76\u884c\u4efb\u52a1\u4ea7\u751f\u4efb\u4f55\u5e72\u6270\u3002</li> <li>\u89c4\u907f GIL\uff1a\u534f\u540c\u4eff\u771f\u4e2d\u7684 Python \u5904\u7406\u5668\uff08handler\uff09\u672c\u8eab\u53ef\u80fd\u662f\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684\u3002\u5728\u591a\u8fdb\u7a0b\u6a21\u578b\u4e0b\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u6709\u81ea\u5df1\u7684 Python \u89e3\u91ca\u5668\u548c GIL\uff0c\u53ef\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u5e76\u884c\u8ba1\u7b97\uff0c\u5145\u5206\u5229\u7528\u6240\u6709 CPU \u6838\u5fc3\u3002</li> </ul>"},{"location":"explanation/tricys_basic/concurrency.html#3","title":"3. \u6027\u80fd\u4e0e\u5b9e\u8df5\u5efa\u8bae","text":"<ul> <li> <p>\u5408\u7406\u8bbe\u7f6e <code>max_workers</code>\uff1a</p> <ul> <li>\u5bf9\u4e8e I/O \u5bc6\u96c6\u578b\u7684\u6807\u51c6\u4eff\u771f\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u6bd4 CPU \u6838\u5fc3\u6570\u7a0d\u591a\u7684 <code>max_workers</code>\uff08\u4f8b\u5982\uff0c\u6838\u5fc3\u6570 * 1.5\uff09\u3002</li> <li>\u5bf9\u4e8e CPU \u5bc6\u96c6\u578b\u7684\u534f\u540c\u4eff\u771f\uff0c<code>max_workers</code> \u901a\u5e38\u8bbe\u7f6e\u4e3a\u7b49\u4e8e\u6216\u7565\u5c0f\u4e8e\u60a8\u7684 CPU \u6838\u5fc3\u6570\uff0c\u4ee5\u907f\u514d\u8fc7\u5ea6\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\u3002</li> <li>\u59cb\u7ec8\u8981\u8003\u8651\u5185\u5b58\u9650\u5236\u3002\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u4f1a\u6d88\u8017\u76f8\u5f53\u6570\u91cf\u7684\u5185\u5b58\uff0c\u5982\u679c <code>max_workers</code> \u8bbe\u7f6e\u5f97\u592a\u9ad8\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u5185\u5b58\u8017\u5c3d\u3002</li> </ul> </li> <li> <p>\u4efb\u52a1\u7c92\u5ea6\uff1a</p> <ul> <li>\u5e76\u53d1\u6267\u884c\u672c\u8eab\u6709\u5f00\u9500\u3002\u5982\u679c\u5355\u6b21\u4eff\u771f\u8017\u65f6\u975e\u5e38\u77ed\uff08\u4f8b\u5982\uff0c\u5c11\u4e8e 1 \u79d2\uff09\uff0c\u5e76\u53d1\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u53ef\u80fd\u8fd8\u4e0d\u8db3\u4ee5\u62b5\u6d88\u4efb\u52a1\u8c03\u5ea6\u7684\u5f00\u9500\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e32\u884c\u6267\u884c (<code>\"concurrent\": false</code>) \u53ef\u80fd\u66f4\u5feb\u3002</li> </ul> </li> <li> <p>\u76d1\u63a7\u7cfb\u7edf\u8d44\u6e90\uff1a</p> <ul> <li>\u5728\u8fd0\u884c\u5927\u89c4\u6a21\u5e76\u53d1\u4efb\u52a1\u65f6\uff0c\u5efa\u8bae\u4f7f\u7528\u7cfb\u7edf\u76d1\u63a7\u5de5\u5177\uff08\u5982\u4efb\u52a1\u7ba1\u7406\u5668\u6216 <code>htop</code>\uff09\u6765\u89c2\u5bdf CPU \u548c\u5185\u5b58\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u4ee5\u4fbf\u8c03\u6574 <code>max_workers</code> \u5230\u6700\u4f73\u503c\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html","title":"\u4eff\u771f\u6267\u884c\u6d41\u7a0b","text":""},{"location":"explanation/tricys_basic/simulation_flow.html#1","title":"1. \u4eff\u771f\u6267\u884c\u6d41\u7a0b","text":"<p><code>tricys</code> \u7684\u6838\u5fc3\u4eff\u771f\u6d41\u7a0b\u7531 <code>tricys/simulation/simulation.py</code> \u811a\u672c\u9a71\u52a8\u3002\u5b83\u88ab\u8bbe\u8ba1\u4e3a\u4e00\u4e2a\u9ad8\u5ea6\u53ef\u914d\u7f6e\u7684\u3001\u5065\u58ee\u7684\u4eff\u771f\u4e1a\u52a1\u6d41\u7a0b\u534f\u8c03\u7a0b\u5e8f\uff0c\u80fd\u591f\u5904\u7406\u4ece\u7b80\u5355\u7684\u5355\u6b21\u8fd0\u884c\u5230\u590d\u6742\u7684\u591a\u53c2\u6570\u3001\u591a\u6a21\u5f0f\uff08\u6807\u51c6/\u534f\u540c\uff09\u4eff\u771f\u3002</p> <p>\u4ee5\u4e0b\u662f\u5b8c\u6574\u7684\u6267\u884c\u6d41\u7a0b\u56fe\u548c\u8be6\u7ec6\u6b65\u9aa4\u89e3\u91ca\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#2","title":"2. \u8be6\u7ec6\u6d41\u7a0b\u56fe","text":"<pre><code>graph TD\n    %% 1. \u521d\u59cb\u5316\u9636\u6bb5\n    subgraph S1 [\"1. \u521d\u59cb\u5316\"]\n        A[\u5f00\u59cb: \u63d0\u4f9b\u914d\u7f6e\u6587\u4ef6] --&gt; B[\u8bfb\u53d6\u548c\u51c6\u5907\u914d\u7f6e]\n        B --&gt; C[\u8bbe\u7f6e\u65e5\u5fd7\u8bb0\u5f55]\n    end\n\n    %% 2. \u4f5c\u4e1a\u751f\u6210\u9636\u6bb5\n    subgraph S2 [\"2. \u4f5c\u4e1a\u751f\u6210\"]\n        C --&gt; D[\u6839\u636e simulation_parameters \u751f\u6210\u4eff\u771f\u4f5c\u4e1a]\n    end\n\n    %% 3. \u51b3\u7b56\u9636\u6bb5\n    subgraph S3 [\"3. \u6267\u884c\u6a21\u5f0f\u51b3\u7b56\"]\n        D --&gt; E{\u68c0\u6d4b\u5230 co_simulation \u914d\u7f6e?}\n        E -- \u662f --&gt; F[\u534f\u540c\u4eff\u771f\u6d41\u7a0b]\n        E -- \u5426 --&gt; G[\u6807\u51c6\u4eff\u771f\u6d41\u7a0b]\n\n        G --&gt; H{\u4f7f\u7528 concurrent \u5e76\u884c\u6a21\u5f0f?}\n        H -- \u662f --&gt; I[\u5e76\u884c\u6267\u884c\u591a\u4e2a _run_single_job]\n        H -- \u5426 --&gt; J[\u987a\u5e8f\u6267\u884c _run_sequential_sweep]\n\n        F --&gt; K{\u4f7f\u7528 concurrent \u5e76\u884c\u6a21\u5f0f?}\n        K -- \u662f --&gt; L[\u5e76\u884c\u6267\u884c\u591a\u4e2a _run_co_simulation]\n        K -- \u5426 --&gt; M[\u987a\u5e8f\u6267\u884c\u591a\u4e2a _run_co_simulation]\n    end\n\n    %% 4. \u5faa\u73af\u8282\u70b9 (\u8fde\u63a5\u70b9)\n    subgraph S4 [\"4. \u4f5c\u4e1a\u6267\u884c\u5165\u53e3\"]\n        J --&gt; N((\u6807\u51c6\u4eff\u771f\u5faa\u73af))\n        I --&gt; N\n\n        M --&gt; O((\u534f\u540c\u4eff\u771f\u5faa\u73af))\n        L --&gt; O\n    end\n\n    %% \u8be6\u7ec6\u6d41\u7a0b - \u6807\u51c6\u4eff\u771f\n    subgraph S5 [\"\u6807\u51c6\u4eff\u771f (_run_single_job / _run_sequential_sweep)\"]\n        N --&gt; N1[\u521b\u5efa\u72ec\u7acb\u5de5\u4f5c\u533a - \u5e76\u884c\u6a21\u5f0f]\n        N1 --&gt; N2[\u83b7\u53d6OMPython\u4f1a\u8bdd]\n        N2 --&gt; N3[\u52a0\u8f7dModelica\u6a21\u578b]\n        N3 --&gt; N4[\u8bbe\u7f6e\u4eff\u771f\u53c2\u6570]\n        N4 --&gt; N5[\u6267\u884c simulate]\n        N5 --&gt; N6[\u6e05\u7406\u5e76\u4fdd\u5b58\u7ed3\u679cCSV]\n        N6 --&gt; P[\u8fd4\u56de\u7ed3\u679c\u6587\u4ef6\u8def\u5f84]\n    end\n\n    %% \u8be6\u7ec6\u6d41\u7a0b - \u534f\u540c\u4eff\u771f\n    subgraph S6 [\"\u534f\u540c\u4eff\u771f (_run_co_simulation)\"]\n        O --&gt; O1[1. \u521b\u5efa\u72ec\u7acb\u5de5\u4f5c\u533a]\n        O1 --&gt; O2[2. \u590d\u5236\u6a21\u578b\u548c\u8d44\u4ea7\u6587\u4ef6]\n        O2 --&gt; O3[3. \u9636\u6bb5\u4e00: \u8fd0\u884c\u521d\u6b65\u4eff\u771f\u4ee5\u751f\u6210\u5904\u7406\u5668\u8f93\u5165]\n        O3 --&gt; O4[4. \u52a8\u6001\u52a0\u8f7dPython\u5904\u7406\u5668 Handler \u51fd\u6570]\n        O4 --&gt; O5[5. \u6267\u884c\u5904\u7406\u5668, \u751f\u6210\u5916\u90e8\u6570\u636eCSV]\n        O5 --&gt; O6[6. \u521b\u5efa\u5e76\u96c6\u6210\u62e6\u622a\u5668 Interceptor \u6a21\u578b]\n        O6 --&gt; O7[7. \u9636\u6bb5\u4e8c: \u4f7f\u7528\u62e6\u622a\u5668\u6a21\u578b\u8fd0\u884c\u6700\u7ec8\u4eff\u771f]\n        O7 --&gt; O8[8. \u6e05\u7406\u5e76\u4fdd\u5b58\u6700\u7ec8\u7ed3\u679cCSV]\n        O8 --&gt; P\n    end\n\n    %% 5. \u7ed3\u679c\u805a\u5408\n    subgraph S7 [\"5. \u7ed3\u679c\u805a\u5408\"]\n        P --&gt; Q{\u6536\u96c6\u6240\u6709\u4f5c\u4e1a\u7684\u7ed3\u679c\u8def\u5f84}\n        Q --&gt; R[\u8bfb\u53d6\u6bcf\u4e2a\u7ed3\u679cCSV]\n        R --&gt; S[\"\u4e3a\u53d8\u91cf\u5217\u540d\u9644\u52a0\u53c2\u6570 (e.g., 'var&amp;p1=v1')\"]\n        S --&gt; T[\u5408\u5e76\u6240\u6709\u7ed3\u679c\u4e3a\u4e00\u4e2aDataFrame]\n        T --&gt; U[\u4fdd\u5b58\u4e3a 'sweep_results.csv']\n    end\n\n    %% 6. \u540e\u5904\u7406\n    subgraph S8 [\"6. \u540e\u5904\u7406\"]\n        U --&gt; V{\u68c0\u6d4b\u5230 post_processing \u914d\u7f6e?}\n        V -- \u662f --&gt; W[\u52a8\u6001\u52a0\u8f7d\u5e76\u6267\u884c\u540e\u5904\u7406\u51fd\u6570]\n        V -- \u5426 --&gt; X[\u8df3\u8fc7\u540e\u5904\u7406]\n    end\n\n    %% 7. \u7ed3\u675f\n    subgraph S9 [\"7. \u6e05\u7406\u4e0e\u7ed3\u675f\"]\n        W --&gt; Y[\u6e05\u7406\u4e34\u65f6\u6587\u4ef6\u548c\u76ee\u5f55]\n        X --&gt; Y\n        Y --&gt; Z[\u7ed3\u675f]\n    end</code></pre>"},{"location":"explanation/tricys_basic/simulation_flow.html#3","title":"3. \u6d41\u7a0b\u6b65\u9aa4\u8be6\u89e3","text":""},{"location":"explanation/tricys_basic/simulation_flow.html#31","title":"3.1. \u521d\u59cb\u5316","text":"<ul> <li>\u8bfb\u53d6\u548c\u51c6\u5907\u914d\u7f6e: \u6d41\u7a0b\u4ece\u4e00\u4e2aJSON\u914d\u7f6e\u6587\u4ef6\u5f00\u59cb\u3002<code>tricys</code>\u4f1a\u8bfb\u53d6\u6b64\u6587\u4ef6\uff0c\u89e3\u6790\u6240\u6709\u8def\u5f84\u3001\u4eff\u771f\u8bbe\u7f6e\u548c\u53c2\u6570\uff0c\u5e76\u51c6\u5907\u4e00\u4e2a\u5185\u90e8\u4f7f\u7528\u7684\u914d\u7f6e\u5bf9\u8c61\u3002</li> <li>\u8bbe\u7f6e\u65e5\u5fd7\u8bb0\u5f55: \u6839\u636e\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u65e5\u5fd7\u8bbe\u7f6e\uff0c\u521d\u59cb\u5316\u5168\u5c40\u65e5\u5fd7\u8bb0\u5f55\u5668\uff0c\u4ee5\u4fbf\u5728\u6574\u4e2a\u6d41\u7a0b\u4e2d\u8bb0\u5f55\u8be6\u7ec6\u7684\u6b65\u9aa4\u3001\u8b66\u544a\u548c\u9519\u8bef\u3002</li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html#32","title":"3.2. \u4f5c\u4e1a\u751f\u6210","text":"<ul> <li><code>tricys</code>\u4f1a\u68c0\u67e5\u914d\u7f6e\u4e2d\u7684 <code>simulation_parameters</code> \u90e8\u5206\u3002\u5982\u679c\u5b9a\u4e49\u4e86\u53c2\u6570\u626b\u63cf\uff08\u4f8b\u5982\uff0c\u4e00\u4e2a\u53c2\u6570\u6709\u591a\u4e2a\u503c\uff09\uff0c\u5b83\u4f1a\u4e3a\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u751f\u6210\u4e00\u4e2a\u72ec\u7acb\u7684\u201c\u4f5c\u4e1a\u201d\u3002\u5982\u679c\u672a\u5b9a\u4e49\u53c2\u6570\u626b\u63cf\uff0c\u5219\u53ea\u4f1a\u751f\u6210\u4e00\u4e2a\u9ed8\u8ba4\u4f5c\u4e1a\u3002</li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html#33","title":"3.3. \u6267\u884c\u6a21\u5f0f\u51b3\u7b56","text":"<p>\u8fd9\u662f\u6d41\u7a0b\u7684\u4e00\u4e2a\u5173\u952e\u5206\u652f\u70b9\uff0c<code>tricys</code>\u4f1a\u6839\u636e\u914d\u7f6e\u51b3\u5b9a\u5982\u4f55\u6267\u884c\u751f\u6210\u7684\u4f5c\u4e1a\uff1a - \u6807\u51c6\u4eff\u771f vs \u534f\u540c\u4eff\u771f: \u9996\u5148\u68c0\u67e5\u662f\u5426\u5b58\u5728 <code>co_simulation</code> \u914d\u7f6e\u5757\u3002\u5982\u679c\u5b58\u5728\uff0c\u5c06\u8fdb\u5165\u534f\u540c\u4eff\u771f\u6d41\u7a0b\uff1b\u5426\u5219\uff0c\u8fdb\u5165\u6807\u51c6\u4eff\u771f\u6d41\u7a0b\u3002 - \u5e76\u884c vs \u987a\u5e8f: \u63a5\u7740\uff0c\u68c0\u67e5 <code>simulation.concurrent</code> \u6807\u5fd7\u3002\u5982\u679c\u4e3a <code>true</code>\uff0c<code>tricys</code>\u4f1a\u4f7f\u7528\u5e76\u53d1\u6a21\u5f0f\uff08\u591a\u7ebf\u7a0b\u6216\u591a\u8fdb\u7a0b\uff09\u540c\u65f6\u6267\u884c\u591a\u4e2a\u4f5c\u4e1a\u3002\u5982\u679c\u4e3a <code>false</code>\uff0c\u5219\u4f1a\u6309\u987a\u5e8f\u9010\u4e2a\u6267\u884c\u4f5c\u4e1a\u3002</p> <p>\u8fd9\u56db\u4e2a\u7ec4\u5408\uff08\u6807\u51c6/\u987a\u5e8f, \u6807\u51c6/\u5e76\u884c, \u534f\u540c/\u987a\u5e8f, \u534f\u540c/\u5e76\u884c\uff09\u5206\u522b\u5bf9\u5e94\u4e0d\u540c\u7684\u6267\u884c\u51fd\u6570\uff0c\u4ee5\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u548c\u9694\u79bb\u6027\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#34","title":"3.4. \u4f5c\u4e1a\u6267\u884c","text":"<p>\u6bcf\u4e2a\u4f5c\u4e1a\u90fd\u5728\u4e00\u4e2a\u72ec\u7acb\u7684\u3001\u9694\u79bb\u7684\u5de5\u4f5c\u533a\u4e2d\u6267\u884c\uff0c\u4ee5\u9632\u6b62\u6587\u4ef6\u51b2\u7a81\u3002</p> <ul> <li>\u6807\u51c6\u4eff\u771f\u6d41\u7a0b (<code>_run_single_job</code> / <code>_run_sequential_sweep</code>):</li> <li>\u83b7\u53d6\u4e00\u4e2a <code>OMPython</code> \u4f1a\u8bdd\u3002</li> <li>\u52a0\u8f7d\u6307\u5b9a\u7684 Modelica \u6a21\u578b\u5305\u3002</li> <li>\u5c06\u5f53\u524d\u4f5c\u4e1a\u7684\u53c2\u6570\u5e94\u7528\u5230\u6a21\u578b\u4e2d\u3002   4.\u8c03\u7528 <code>simulate()</code> \u6267\u884c\u4eff\u771f\u3002</li> <li> <p>\u5bf9\u751f\u6210\u7684 <code>_res.csv</code> \u7ed3\u679c\u6587\u4ef6\u8fdb\u884c\u6e05\u7406\uff08\u4f8b\u5982\uff0c\u53bb\u9664\u91cd\u590d\u7684\u65f6\u95f4\u70b9\uff09\uff0c\u5e76\u8fd4\u56de\u5176\u8def\u5f84\u3002</p> </li> <li> <p>\u534f\u540c\u4eff\u771f\u6d41\u7a0b (<code>_run_co_simulation</code>):   \u8fd9\u662f\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u591a\u9636\u6bb5\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5c06 Modelica \u6a21\u578b\u4e0e\u5916\u90e8 Python \u903b\u8f91\uff08\u79f0\u4e3a\"Handler\"\uff09\u96c6\u6210\uff1a</p> </li> <li>\u521b\u5efa\u5de5\u4f5c\u533a: \u4e3a\u4f5c\u4e1a\u521b\u5efa\u4e00\u4e2a\u5b8c\u5168\u9694\u79bb\u7684\u4e34\u65f6\u76ee\u5f55\u3002</li> <li>\u590d\u5236\u8d44\u4ea7: \u5c06\u6a21\u578b\u6587\u4ef6\uff08<code>.mo</code>\uff09\u4ee5\u53caHandler\u53ef\u80fd\u9700\u8981\u7684\u4efb\u4f55\u5916\u90e8\u6587\u4ef6\uff08\u5982CSV\u3001\u67e5\u627e\u8868\u7b49\uff09\u590d\u5236\u5230\u5de5\u4f5c\u533a\u3002</li> <li>\u9636\u6bb5\u4e00\uff1a\u521d\u6b65\u4eff\u771f: \u8fd0\u884c\u4e00\u6b21\u521d\u6b65\u4eff\u771f\u3002\u8fd9\u6b21\u4eff\u771f\u7684\u76ee\u7684\u4e0d\u662f\u5f97\u5230\u6700\u7ec8\u7ed3\u679c\uff0c\u800c\u662f\u4e3a\u4e86\u751f\u6210Handler\u6240\u9700\u8981\u7684\u8f93\u5165\u4fe1\u53f7\u3002\u4f8b\u5982\uff0c\u4e00\u4e2a\u5916\u90e8\u63a7\u5236\u5668\u9700\u8981\u77e5\u9053\u5f53\u524d\u7cfb\u7edf\u7684\u6e29\u5ea6\u548c\u538b\u529b\uff0c\u8fd9\u6b21\u4eff\u771f\u5c31\u4f1a\u628a\u8fd9\u4e9b\u53d8\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u5bfc\u51fa\u5230 <code>primary_inputs.csv</code>\u3002</li> <li>\u6267\u884cHandler: <code>tricys</code>\u52a8\u6001\u52a0\u8f7d\u914d\u7f6e\u6587\u4ef6\u4e2d\u6307\u5b9a\u7684Python Handler\u51fd\u6570\u3002</li> <li>\u751f\u6210\u5916\u90e8\u6570\u636e: \u8c03\u7528Handler\u51fd\u6570\uff0c\u5b83\u4f1a\u8bfb\u53d6 <code>primary_inputs.csv</code>\uff0c\u6267\u884c\u5176\u5185\u90e8\u903b\u8f91\uff08\u4f8b\u5982\uff0c\u4e00\u4e2aPID\u7b97\u6cd5\u6216\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff09\uff0c\u7136\u540e\u751f\u6210\u4e00\u4efd\u8f93\u51faCSV\u6587\u4ef6\uff08\u4f8b\u5982 <code>handler_outputs.csv</code>\uff09\u3002</li> <li>\u96c6\u6210\u62e6\u622a\u5668: <code>tricys</code>\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684Modelica\u6a21\u578b\uff08\u79f0\u4e3a\u62e6\u622a\u5668\u6a21\u578b\uff09\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u8bfb\u53d6 <code>handler_outputs.csv</code> \u7684\u6570\u636e\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8f93\u5165\u6ce8\u5165\u5230\u4e3b\u6a21\u578b\u4e2d\uff0c\u4ece\u800c\u53d6\u4ee3\u6216\"\u62e6\u622a\"\u539f\u59cb\u6a21\u578b\u7684\u67d0\u4e2a\u90e8\u5206\u3002</li> <li>\u9636\u6bb5\u4e8c\uff1a\u6700\u7ec8\u4eff\u771f: \u4f7f\u7528\u8fd9\u4e2a\u88ab\u4fee\u6539\u548c\u62e6\u622a\u8fc7\u7684\u65b0\u6a21\u578b\u8fd0\u884c\u6700\u7ec8\u7684\u3001\u5b8c\u6574\u7684\u4eff\u771f\u3002</li> <li>\u4fdd\u5b58\u7ed3\u679c: \u6e05\u7406\u6700\u7ec8\u7684\u4eff\u771f\u7ed3\u679c\u5e76\u8fd4\u56de\u5176\u8def\u5f84\u3002</li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html#35","title":"3.5. \u7ed3\u679c\u805a\u5408","text":"<p>\u6240\u6709\u4f5c\u4e1a\u6267\u884c\u5b8c\u6bd5\u540e\uff1a 1. <code>tricys</code>\u6536\u96c6\u6bcf\u4e2a\u6210\u529f\u4f5c\u4e1a\u7684\u7ed3\u679c\u6587\u4ef6\u8def\u5f84\u3002 2. \u5b83\u9010\u4e2a\u8bfb\u53d6\u8fd9\u4e9bCSV\u6587\u4ef6\uff0c\u5e76\u5c06\u5b83\u4eec\u5408\u5e76\u6210\u4e00\u4e2a\u5927\u7684 Pandas DataFrame\u3002 3. \u4e3a\u4e86\u533a\u5206\u6765\u81ea\u4e0d\u540c\u4f5c\u4e1a\u7684\u6570\u636e\uff0c\u5b83\u4f1a\u5c06\u53d8\u91cf\u5217\u91cd\u547d\u540d\uff0c\u9644\u52a0\u4ea7\u751f\u8be5\u6570\u636e\u7684\u53c2\u6570\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4e00\u4e2a\u4f5c\u4e1a\u7684\u53c2\u6570\u662f <code>{\"freq\": 10}</code>\uff0c\u90a3\u4e48\u539f\u59cb\u7684 <code>voltage</code> \u5217\u4f1a\u53d8\u4e3a <code>voltage&amp;freq=10</code>\u3002 4. \u6700\u7ec8\uff0c\u8fd9\u4e2a\u5408\u5e76\u540e\u7684 DataFrame \u88ab\u4fdd\u5b58\u4e3a <code>sweep_results.csv</code>\uff08\u7528\u4e8e\u53c2\u6570\u626b\u63cf\uff09\u6216 <code>simulation_result.csv</code>\uff08\u7528\u4e8e\u5355\u6b21\u8fd0\u884c\uff09\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#36","title":"3.6. \u540e\u5904\u7406","text":"<p>\u5982\u679c\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u4e86 <code>post_processing</code> \u4efb\u52a1\uff0c<code>tricys</code>\u4f1a\u5728\u6b64\u65f6\u6267\u884c\u5b83\u4eec\u3002\u5b83\u4f1a\u52a8\u6001\u52a0\u8f7d\u6307\u5b9a\u7684Python\u51fd\u6570\uff0c\u5e76\u5c06\u4e0a\u4e00\u6b65\u751f\u6210\u7684\u5408\u5e76\u7ed3\u679cDataFrame\u4f5c\u4e3a\u8f93\u5165\u4f20\u9012\u7ed9\u5b83\u3002\u8fd9\u5141\u8bb8\u7528\u6237\u65e0\u7f1d\u5730\u5bf9\u63a5\u81ea\u5b9a\u4e49\u7684\u5206\u6790\u3001\u7ed8\u56fe\u6216\u62a5\u544a\u751f\u6210\u811a\u672c\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#37","title":"3.7. \u6e05\u7406\u4e0e\u7ed3\u675f","text":"<ul> <li>\u9664\u975e\u5728\u914d\u7f6e\u4e2d\u8bbe\u7f6e\u4e86 <code>keep_temp_files: true</code>\uff0c\u5426\u5219 <code>tricys</code> \u4f1a\u81ea\u52a8\u5220\u9664\u6240\u6709\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u521b\u5efa\u7684\u4e34\u65f6\u5de5\u4f5c\u533a\u548c\u6587\u4ef6\u3002</li> <li>\u6d41\u7a0b\u7ed3\u675f\u3002</li> </ul>"},{"location":"guides/quickstart.html","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u672c\u6307\u5357\u5c06\u5f15\u5bfc\u60a8\u5b8c\u6210 Windows \u73af\u5883\u4e0b <code>tricys</code> \u7684\u5b89\u88c5\u8fc7\u7a0b\uff0c\u5e76\u8fd0\u884c\u4e00\u4e2a\u57fa\u672c\u7684\u547d\u4ee4\u884c\u4eff\u771f\u3002</p>"},{"location":"guides/quickstart.html#1","title":"1. \u73af\u5883\u8981\u6c42","text":"<p>\u5728\u5f00\u59cb\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u60a8\u7684\u7cfb\u7edf\u6ee1\u8db3\u4ee5\u4e0b\u8981\u6c42\uff1a</p> <ul> <li>Python: \u7248\u672c 3.8 \u6216\u66f4\u9ad8\u3002</li> <li>Git: \u7528\u4e8e\u514b\u9686\u9879\u76ee\u4ed3\u5e93\u3002</li> <li>OpenModelica: \u9700\u8981\u5b89\u88c5 OpenModelica\uff0c\u5e76\u786e\u4fdd\u5176\u547d\u4ee4\u884c\u5de5\u5177 (<code>omc.exe</code>) \u5df2\u6dfb\u52a0\u5230\u7cfb\u7edf\u7684 <code>PATH</code> \u73af\u5883\u53d8\u91cf\u4e2d\u3002</li> </ul> <p>\u63d0\u793a</p> <p>\u5728 Windows \u4e0a\u5b89\u88c5 Python \u65f6\uff0c\u8bf7\u52a1\u5fc5\u52fe\u9009 \"Add Python to PATH\" \u9009\u9879\uff0c\u4ee5\u786e\u4fdd <code>python</code> \u548c <code>pip</code> \u547d\u4ee4\u5728\u7ec8\u7aef\u4e2d\u53ef\u7528\u3002</p>"},{"location":"guides/quickstart.html#2","title":"2. \u5b89\u88c5\u6b65\u9aa4","text":""},{"location":"guides/quickstart.html#a","title":"a. \u514b\u9686\u9879\u76ee\u4ed3\u5e93","text":"<p>\u6253\u5f00\u60a8\u7684\u7ec8\u7aef\uff08\u5982 PowerShell \u6216 Cmd\uff09\uff0c\u4f7f\u7528 <code>git</code> \u514b\u9686 <code>tricys</code> \u7684\u6e90\u4ee3\u7801\u3002</p> <pre><code>git clone https://github.com/asipp-neutronics/tricys.git\ncd tricys\n</code></pre>"},{"location":"guides/quickstart.html#b","title":"b. \u521b\u5efa\u5e76\u6fc0\u6d3b\u865a\u62df\u73af\u5883","text":"<p>\u5728\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\uff0c\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684 Python \u865a\u62df\u73af\u5883\uff0c\u4ee5\u9694\u79bb\u9879\u76ee\u4f9d\u8d56\u3002</p> <pre><code># \u521b\u5efa\u865a\u62df\u73af\u5883\npython -m venv venv\n\n# \u6fc0\u6d3b\u865a\u62df\u73af\u5883\n.\\venv\\Scripts\\activate\n</code></pre> <p>\u6fc0\u6d3b\u540e\uff0c\u60a8\u4f1a\u770b\u5230\u7ec8\u7aef\u63d0\u793a\u7b26\u524d\u51fa\u73b0 <code>(venv)</code> \u5b57\u6837\u3002</p>"},{"location":"guides/quickstart.html#c","title":"c. \u5b89\u88c5\u9879\u76ee\u4f9d\u8d56","text":"<p>\u4f7f\u7528 <code>pip</code> \u5b89\u88c5 <code>tricys</code> \u53ca\u5176\u6240\u6709\u5f00\u53d1\u4f9d\u8d56\u9879\u3002<code>-e</code> \u53c2\u6570\u8868\u793a\u4ee5\u201c\u53ef\u7f16\u8f91\u201d\u6a21\u5f0f\u5b89\u88c5\uff0c\u8fd9\u610f\u5473\u7740\u60a8\u5bf9\u6e90\u4ee3\u7801\u7684\u4efb\u4f55\u4fee\u6539\u90fd\u4f1a\u7acb\u5373\u751f\u6548\u3002</p> <pre><code>pip install -e \".[win]\"\n\nor # \u6216\u4f7f\u7528Makefile.bat\u811a\u672c\u5b89\u88c5\u4f9d\u8d56\n\nMakefile.bat win-install\n</code></pre>"},{"location":"guides/quickstart.html#3","title":"3. \u8fd0\u884c\u793a\u4f8b","text":"<p><code>tricys</code> \u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7684\u793a\u4f8b\u8fd0\u884c\u5668\uff0c\u53ef\u4ee5\u5e2e\u52a9\u60a8\u5feb\u901f\u63a2\u7d22\u548c\u8fd0\u884c\u6240\u6709\u53ef\u7528\u7684\u793a\u4f8b\uff0c\u5305\u62ec\u57fa\u7840\u4eff\u771f\u548c\u9ad8\u7ea7\u5206\u6790\u4efb\u52a1\u3002\u8fd9\u662f\u9a8c\u8bc1\u5b89\u88c5\u5e76\u4e86\u89e3 <code>tricys</code> \u529f\u80fd\u7684\u6700\u7b80\u5355\u65b9\u6cd5\u3002</p>"},{"location":"guides/quickstart.html#a_1","title":"a. \u542f\u52a8\u793a\u4f8b\u8fd0\u884c\u5668","text":"<p>\u5728\u6fc0\u6d3b\u4e86\u865a\u62df\u73af\u5883\u7684\u7ec8\u7aef\u4e2d\uff0c\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8\u793a\u4f8b\u8fd0\u884c\u5668\uff1a</p> <pre><code>tricys example\n</code></pre>"},{"location":"guides/quickstart.html#b_1","title":"b. \u9009\u62e9\u5e76\u8fd0\u884c\u793a\u4f8b","text":"<p>\u8be5\u547d\u4ee4\u4f1a\u542f\u52a8\u4e00\u4e2a\u7edf\u4e00\u7684\u793a\u4f8b\u8fd0\u884c\u5668\uff0c\u626b\u63cf\u5e76\u5217\u51fa <code>example/basic</code> \u548c <code>example/analysis</code> \u76ee\u5f55\u4e0b\u7684\u6240\u6709\u53ef\u7528\u793a\u4f8b\u3002</p> <p>\u60a8\u4f1a\u770b\u5230\u4e00\u4e2a\u7c7b\u4f3c\u4e0b\u9762\u7684\u83dc\u5355\uff1a</p> <pre><code>============================================================\n         TRICYS \u7edf\u4e00\u793a\u4f8b\u8fd0\u884c\u5668\n============================================================\n\n  1. [BASIC] Basic Configuration\n     \u63cf\u8ff0: A basic simulation with a single run\n     \u914d\u7f6e: basic_configuration.json\n\n  2. [BASIC] Parameter Sweep\n     \u63cf\u8ff0: A multi-run simulation with parameter sweeps\n     \u914d\u7f6e: parameter_sweep.json\n\n  ...\n\n  6. [ANALYSIS] Baseline Condition Analysis\n     \u63cf\u8ff0: Baseline condition analysis for TBR search\n     \u914d\u7f6e: baseline_condition_analysis.json\n\n  ...\n\n  0. \u9000\u51fa\u7a0b\u5e8f\n  h. \u663e\u793a\u5e2e\u52a9\u4fe1\u606f\n  s. \u91cd\u65b0\u626b\u63cf\u793a\u4f8b\u76ee\u5f55\n\n============================================================\n</code></pre> <ul> <li>\u8f93\u5165\u6570\u5b57 (\u4f8b\u5982 <code>1</code>) \u5e76\u6309\u56de\u8f66\uff0c\u5373\u53ef\u8fd0\u884c\u5bf9\u5e94\u7684\u793a\u4f8b\u3002</li> <li>\u7a0b\u5e8f\u4f1a\u81ea\u52a8\u5c06\u793a\u4f8b\u6587\u4ef6\u590d\u5236\u5230\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u7684 <code>test_example</code> \u6587\u4ef6\u5939\u4e2d\uff0c\u5e76\u5728\u8be5\u76ee\u5f55\u4e2d\u6267\u884c\u4efb\u52a1\u3002</li> <li>\u8fd9\u79cd\u8bbe\u8ba1\u53ef\u4ee5\u786e\u4fdd\u539f\u59cb\u793a\u4f8b\u6587\u4ef6\u4e0d\u88ab\u4fee\u6539\uff0c\u5e76\u4fdd\u6301\u5de5\u4f5c\u533a\u6574\u6d01\u3002</li> </ul>"},{"location":"guides/quickstart.html#c_1","title":"c. \u67e5\u770b\u7ed3\u679c","text":"<p>\u4efb\u52a1\u5b8c\u6210\u540e\uff0c\u7ed3\u679c\u5c06\u4fdd\u5b58\u5728 <code>test_example</code> \u76ee\u5f55\u4e2d\uff0c\u4f4d\u4e8e\u76f8\u5e94\u793a\u4f8b\u7684\u5b50\u6587\u4ef6\u5939\u5185\u3002</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u8fd0\u884c\u4e86 <code>Basic Configuration</code> \u793a\u4f8b\uff0c\u7ed3\u679c\u5c06\u4f4d\u4e8e <code>test_example/basic/1_basic_configuration/</code> \u76ee\u5f55\u4e0b\u3002\u60a8\u53ef\u4ee5\u5728\u5176\u4e2d\u627e\u5230\uff1a</p> <ul> <li><code>simulation_result.csv</code>: \u5305\u542b\u6240\u6709\u8f93\u51fa\u53d8\u91cf\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6570\u636e\u3002</li> <li><code>simualtion_{timestamp}.log</code>: \u672c\u6b21\u8fd0\u884c\u7684\u8be6\u7ec6\u65e5\u5fd7\u6587\u4ef6\u3002</li> <li><code>basic_configuation.json</code>: \u672c\u6b21\u8fd0\u884c\u6240\u4f7f\u7528\u7684\u5b8c\u6574\u914d\u7f6e\u7684\u5907\u4efd\u3002</li> </ul>"},{"location":"guides/quickstart.html#4-gui","title":"4. \u8fd0\u884c\u56fe\u5f62\u7528\u6237\u754c\u9762 (GUI)","text":"<p>\u5982\u679c\u60a8\u66f4\u559c\u6b22\u56fe\u5f62\u5316\u64cd\u4f5c\uff0c\u53ef\u4ee5\u542f\u52a8 <code>tricys</code> \u7684 GUI\u3002</p> <pre><code>tricys gui\n</code></pre> <p>GUI \u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u754c\u9762\uff0c\u7528\u4e8e\u52a0\u8f7d\u6a21\u578b\u3001\u8bbe\u7f6e\u53c2\u6570\u3001\u5b9a\u4e49\u626b\u63cf\u8303\u56f4\u548c\u542f\u52a8\u4eff\u771f\u3002</p>"},{"location":"guides/quickstart.html#5-tricys","title":"5. TRICYS \u76f8\u5173\u547d\u4ee4","text":"<p>\u606d\u559c\uff01\u60a8\u5df2\u7ecf\u6210\u529f\u5b89\u88c5\u5e76\u8fd0\u884c\u4e86 <code>tricys</code>\u3002\u63a5\u4e0b\u6765\uff0c\u60a8\u53ef\u4ee5\u63a2\u7d22\u66f4\u9ad8\u7ea7\u7684\u529f\u80fd\uff0c\u4f8b\u5982\u53c2\u6570\u626b\u63cf\u6216\u534f\u540c\u4eff\u771f\u3002</p>"},{"location":"guides/models/cycle.html","title":"\u6c1a\u71c3\u6599\u5faa\u73af 0 \u7ef4\u7cfb\u7edf\u6a21\u578b","text":""},{"location":"guides/models/cycle.html#1","title":"1. \u6c1a\u5faa\u73af\u7cfb\u7edf\u4ecb\u7ecd","text":"<p>\u805a\u53d8\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u5728\u67b6\u6784\u4e0a\u5206\u4e3a\u4e24\u4e2a\u9ad8\u5ea6\u8026\u5408\u7684\u7cfb\u7edf\uff1a\u5185\u90e8\u71c3\u6599\u5faa\u73af\u548c\u5916\u90e8\u71c3\u6599\u5faa\u73af\u3002</p> <p></p>"},{"location":"guides/models/cycle.html#11","title":"1.1. \u5185\u90e8\u71c3\u6599\u5faa\u73af","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u5904\u7406\u672a\u71c3\u71c3\u6599\u7684\u9ad8\u901a\u91cf\u3001\u5feb\u901f\u95ed\u73af\u56de\u8def \u3002\u5176\u7269\u8d28\u6d41\u8def\u5f84\u5982\u4e0b\uff1a</p> <p>1)  \u6ce8\u5165 (Fuelling): \u5faa\u73af\u59cb\u4e8e\u71c3\u6599\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS)\u3002\u9ad8\u7eaf D-T \u71c3\u6599\u7ecf\u7531\u52a0\u6599\u7cfb\u7edf (FS) \u6ce8\u5165\u6258\u5361\u9a6c\u514b\u771f\u7a7a\u5ba4 (Plasma) \u3002</p> <p>2)  \u6392\u51fa (Exhaust): \u5728\u7b49\u79bb\u5b50\u4f53\u4e2d\uff0c\u4ec5\u6709\u5c11\u91cf\u71c3\u6599\u53d1\u751f\u805a\u53d8, \u5927\u90e8\u5206\u672a\u71c3\u71c3\u6599\u3001\u805a\u53d8\u4ea7\u7269\uff08\u6c26\u7070\uff09\u53ca\u6742\u8d28\u88ab\u5f15\u5bfc\u81f3\u504f\u6ee4\u5668 (Divertor) \u533a\u57df \u3002</p> <p>3)  \u6cf5\u9001 (Pumping): \u771f\u7a7a\u6cf5\u7cfb\u7edf (Pump_System) \u5c06\u8fd9\u4e9b\u6392\u51fa\u7684\u9ad8\u6e29\u5e9f\u6c14\u62bd\u51fa \u3002</p> <p>4)  \u51c0\u5316 (TEP): \u5e9f\u6c14\u88ab\u9001\u81f3\u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406\u7cfb\u7edf (TEP)\u3002TEP \u5728\u6b64\u8fdb\u884c\u5173\u952e\u7684\u5316\u5b66\u51c0\u5316\uff0c\u4ee5\u4ece\u6742\u8d28\uff08\u5982\u6c1a\u5316\u6c34 Q2O \u548c\u6c1a\u5316\u7532\u70f7 CQ4\uff09\u4e2d\u56de\u6536\u6c22\u540c\u4f4d\u7d20 \u3002</p> <p>5)  \u5206\u79bb (ISS): \u51c0\u5316\u540e\u7684\u6c22\u540c\u4f4d\u7d20 (Q2) \u6df7\u5408\u6c14\u6d41\u88ab\u9001\u81f3\u5185\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf (I-ISS)\uff0c\u901a\u5e38\u901a\u8fc7\u4f4e\u6e29\u7cbe\u998f\u6280\u672f\u8fdb\u884c\u540c\u4f4d\u7d20\u5206\u79bb \u3002</p> <p>6) \u56de\u6d41 (Return): \u6700\u7ec8\uff0c\u5206\u79bb\u51fa\u7684\u9ad8\u7eaf\u5ea6 D2 \u548c T2 \u71c3\u6599\u88ab\u9001\u56de SDS\uff0c\u5b9e\u73b0\u71c3\u6599\u7684\u518d\u5faa\u73af\uff0c\u5b8c\u6210\u5185\u90e8\u95ed\u73af \u3002</p>"},{"location":"guides/models/cycle.html#12","title":"1.2. \u5916\u90e8\u71c3\u6599\u5faa\u73af","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u8d1f\u8d23\u751f\u4ea7\u65b0\u71c3\u6599\u4ee5\u5b9e\u73b0\u6c1a\u81ea\u6301\u7684\u4f4e\u901a\u91cf\u3001\u6162\u901f\u56de\u8def \u3002\u5176\u7269\u8d28\u6d41\u8def\u5f84\u5982\u4e0b\uff1a</p> <p>1)  \u589e\u6b96 (Breeding): \u805a\u53d8\u4ea7\u751f\u7684\u9ad8\u80fd\u4e2d\u5b50\u8fdb\u5165\u589e\u6b96\u5305\u5c42 (Blanket)\uff0c\u4e0e\u5305\u5c42\u4e2d\u7684\u9502 (Li) \u53d1\u751f\u6838\u53cd\u5e94\u4ee5\u589e\u6b96\u65b0\u7684\u6c1a \u3002</p> <p>2)  \u63d0\u53d6 (Extraction): \u65b0\u751f\u7684\u6c1a\u901a\u8fc7\u589e\u6b96\u5242\u6c1a\u63d0\u53d6\u7cfb\u7edf (TES) \u4ece\u5305\u5c42\u6750\u6599\u4e2d\u79fb\u51fa \u3002</p> <p>3)  \u6cc4\u6f0f\u4e0e\u51c0\u5316 (Permeation &amp; Purification): \u4e0e\u6b64\u540c\u65f6\uff0c\u5c11\u91cf\u6c1a\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u6e17\u900f\u8fdb\u5165\u51b7\u5374\u5242\u56de\u8def (CL) \u3002\u51b7\u5374\u5242\u51c0\u5316\u7cfb\u7edf (CPS) \u8d1f\u8d23\u4ece\u51b7\u5374\u5242\u4e2d\u6355\u83b7\u5e76\u56de\u6536\u8fd9\u90e8\u5206\u6e17\u900f\u7684\u6c1a \u3002</p> <p>4)  \u6c47\u96c6\u4e0e\u5206\u79bb (Collection &amp; Separation): \u6765\u81ea TES \u7684\u5bcc\u6c1a\u6d41\uff08\u4f8b\u5982\uff0c\u56fa\u6001\u5305\u5c42\u7684\u6c26\u6c14\u5439\u626b\u6c14\u6216\u6db2\u6001\u5305\u5c42\u7684\u6e17\u900f\u5668\u4ea7\u6c14 \uff09\u4e0e\u6765\u81ea CPS \u7684\u56de\u6536\u6c1a\u6d41\u6c47\u5408\uff0c\u4e00\u540c\u88ab\u8f93\u9001\u81f3\u5916\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf (O-ISS) \u8fdb\u884c\u63d0\u7eaf\u3002</p> <p>5)  \u8865\u5145 (Replenish): O-ISS \u5c06\u6c26\u6c14\u53ca\u5176\u4ed6\u6742\u8d28\u53bb\u9664\u540e\uff0c\u628a\u9ad8\u7eaf\u5ea6\u6c1a\u9001\u5165 SDS\uff0c\u8865\u5145\u5230\u4e3b\u71c3\u6599\u5faa\u73af\u4e2d\uff0c\u5b8c\u6210\u5168\u5382\u7684\u71c3\u6599\u95ed\u73af \u3002</p>"},{"location":"guides/models/cycle.html#2-modelica","title":"2. Modelica\u793a\u4f8b\u6a21\u578b","text":"<p>TRICYS \u7684\u6838\u5fc3\u662f\u4e00\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af 0 \u7ef4\u7cfb\u7edf\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u805a\u53d8\u5806\u7684\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u62bd\u8c61\u4e3a\u4e00\u7cfb\u5217\u76f8\u4e92\u8fde\u63a5\u7684\u5b50\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u5b50\u7cfb\u7edf\u4ee3\u8868\u5b9e\u9645\u5de5\u5382\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u529f\u80fd\u6a21\u5757\u3002</p> <p>0 \u7ef4\u6a21\u578b\u610f\u5473\u7740\u6211\u4eec\u5173\u6ce8\u7684\u662f\u7cfb\u7edf\u7ea7\u7684\u7269\u8d28\u6d41\u52a8\u548c\u5e93\u5b58\u53d8\u5316\uff0c\u800c\u4e0d\u662f\u8be6\u7ec6\u7684\u7a7a\u95f4\u5206\u5e03\u3002\u8fd9\u79cd\u5efa\u6a21\u65b9\u6cd5\u7279\u522b\u9002\u5408\u7528\u4e8e\uff1a</p> <ul> <li>\u7cfb\u7edf\u7ea7\u7684\u6c1a\u5e93\u5b58\u5206\u6790</li> <li>\u71c3\u6599\u81ea\u6301\u65f6\u95f4\u8bc4\u4f30</li> <li>\u8bbe\u8ba1\u53c2\u6570\u4f18\u5316</li> <li>\u8fd0\u884c\u7b56\u7565\u7814\u7a76</li> <li>\u5b89\u5168\u6027\u8bc4\u4f30</li> </ul> <p></p> \u6a21\u578b\u7f29\u5199 (Abbreviation) \u4e2d\u6587\u5168\u79f0 (Chinese Full Name) \u82f1\u6587\u5168\u79f0 (English Full Name) <code>Plasma</code> \u7b49\u79bb\u5b50\u4f53 Plasma <code>Fueling_System</code> \u71c3\u6599\u6ce8\u5165\u7cfb\u7edf Fueling System <code>Pump_System</code> \u771f\u7a7a\u6cf5\u7cfb\u7edf Vacuum Pumping System <code>TEP_FEP</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u524d\u7aef Tokamak Exhaust Processing - Front-End Processing <code>TEP_IP</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u4e2d\u95f4\u5904\u7406 Tokamak Exhaust Processing - Intermediate Processing <code>TEP_FCU</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u6700\u7ec8\u51c0\u5316\u5355\u5143 Tokamak Exhaust Processing - Final Cleanup Unit <code>I_ISS</code> \u5185\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf Inner Isotope Separation System <code>SDS</code> \u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf Storage and Delivery System <code>Blanket</code> \u589e\u6b96\u5305\u5c42 Breeding Blanket <code>TES</code> \u6c1a\u63d0\u53d6\u7cfb\u7edf Tritium Extraction System <code>O_ISS</code> \u5916\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf Outer Isotope Separation System <code>FW</code> \u7b2c\u4e00\u58c1 First Wall <code>DIV</code> \u504f\u6ee4\u5668 Divertor <code>Coolant_Pipe</code> \u51b7\u5374\u5242\u56de\u8def Coolant Pipe <code>CPS</code> \u51b7\u5374\u5242\u51c0\u5316\u7cfb\u7edf Coolant Purification System <code>WDS</code> \u6c34\u53bb\u6c1a\u7cfb\u7edf Water Detritiation System"},{"location":"guides/models/cycle.html#3","title":"3. \u8fdb\u4e00\u6b65\u5b66\u4e60","text":"<ul> <li>\u5feb\u901f\u5f00\u59cb\uff1a\u8fd0\u884c\u60a8\u7684\u7b2c\u4e00\u4e2a\u4eff\u771f</li> <li>\u57fa\u7840\u914d\u7f6e\uff1a\u4e86\u89e3\u5982\u4f55\u914d\u7f6e\u6a21\u578b\u53c2\u6570</li> <li>\u53c2\u6570\u626b\u63cf\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u53c2\u6570\u7a7a\u95f4</li> <li>\u654f\u611f\u6027\u5206\u6790\uff1a\u8bc6\u522b\u5173\u952e\u53c2\u6570</li> </ul>"},{"location":"guides/tricys_analysis/index.html","title":"\u81ea\u52a8\u5206\u6790 (TRICYS ANALYSIS)","text":"<p><code>TRICYS ANALYSIS</code> \u662f <code>tricys</code> \u7684\u9ad8\u7ea7\u5206\u6790\u6a21\u5757\uff0c\u65e8\u5728\u5c06\u4e00\u7cfb\u5217\u590d\u6742\u7684\u4eff\u771f\u3001\u540e\u5904\u7406\u548c\u62a5\u544a\u751f\u6210\u4efb\u52a1\u81ea\u52a8\u5316\u3002\u4e0e\u6267\u884c\u5355\u6b21\u4eff\u771f\u7684 <code>TRICYS BASIC</code> \u4e0d\u540c\uff0c<code>ANALYSIS</code> \u6a21\u5757\u901a\u8fc7\u4e00\u4e2a\u7edf\u4e00\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u53ef\u4ee5\u6267\u884c\u4ece\u53c2\u6570\u626b\u63cf\u3001\u654f\u611f\u6027\u5206\u6790\u5230\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b49\u591a\u79cd\u9ad8\u7ea7\u5206\u6790\u4efb\u52a1\u3002</p> <p>\u672c\u7ae0\u8282\u5c06\u9996\u5148\u4ecb\u7ecd\u5404\u7c7b\u5206\u6790\u4efb\u52a1\u4e2d\u901a\u7528\u7684\u6838\u5fc3\u914d\u7f6e\u9879\uff0c\u7136\u540e\u5206\u8282\u8be6\u7ec6\u4ecb\u7ecd\u6bcf\u4e00\u79cd\u5177\u4f53\u7684\u5206\u6790\u6a21\u5f0f\u3002</p>"},{"location":"guides/tricys_analysis/index.html#1","title":"1. \u901a\u7528\u914d\u7f6e\u9879","text":"<p>\u5728 <code>tricys</code> \u7684\u5206\u6790\u914d\u7f6e\u6587\u4ef6\u4e2d\uff0c<code>sensitivity_analysis</code> \u5bf9\u8c61\u662f\u6240\u6709\u5206\u6790\u4efb\u52a1\u7684\u6838\u5fc3\u3002\u4ee5\u4e0b\u662f\u5176\u4e2d\u8de8\u591a\u79cd\u5206\u6790\u7c7b\u578b\u901a\u7528\u7684\u5173\u952e\u5b57\u6bb5\u3002</p>"},{"location":"guides/tricys_analysis/index.html#11","title":"1.1. \u591a\u6848\u4f8b\u5e76\u53d1\u6267\u884c","text":"<ul> <li> <p><code>analysis_cases</code> (\u5206\u6790\u6848\u4f8b\u5217\u8868)</p> <ul> <li>\u63cf\u8ff0: \u8fd9\u662f\u4e00\u4e2a\u6570\u7ec4\uff0c\u4e5f\u662f <code>TRICYS ANALYSIS</code> \u6a21\u5f0f\u7684\u6838\u5fc3\u3002\u5b83\u5141\u8bb8\u60a8\u5728\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u591a\u4e2a\u72ec\u7acb\u7684\u5206\u6790\u4efb\u52a1\u3002\u6bcf\u4e2a\u6570\u7ec4\u5143\u7d20\u90fd\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u5206\u6790\u6848\u4f8b\u5bf9\u8c61\uff0c\u53ef\u4ee5\u6709\u5404\u81ea\u72ec\u7acb\u7684 <code>name</code>\u3001<code>independent_variable</code>\u3001<code>dependent_variables</code> \u7b49\u3002<code>tricys</code> \u4f1a\u4f9d\u6b21\u6267\u884c\u8fd9\u4e2a\u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6848\u4f8b\u3002</li> <li>\u5e94\u7528: \u5f53\u60a8\u9700\u8981\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\u7248\u672c\u3001\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u6216\u4e0d\u540c\u5206\u6790\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c\u5728\u540c\u4e00\u6279\u6b21\u4e2d\u8fd0\u884c\u4e00\u4e2a\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u548c\u4e00\u4e2aSOBOL\u5206\u6790\uff09\u65f6\uff0c\u6b64\u529f\u80fd\u975e\u5e38\u6709\u7528\u3002</li> </ul> </li> <li> <p><code>concurrent_cases</code> (\u5e76\u53d1\u6267\u884c\u6848\u4f8b)</p> <ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5e03\u5c14\u503c (<code>true</code> \u6216 <code>false</code>)\uff0c\u9ed8\u8ba4\u4e3a <code>false</code>\u3002\u5f53\u8bbe\u7f6e\u4e3a <code>true</code> \u65f6\uff0c<code>tricys</code> \u4f1a\u542f\u7528\u591a\u8fdb\u7a0b\u5e76\u884c\u8ba1\u7b97\uff0c\u540c\u65f6\u6267\u884c <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u591a\u4e2a\u6848\u4f8b\u3002</li> <li>\u5e94\u7528: \u5bf9\u4e8e\u5305\u542b\u5927\u91cf\u72ec\u7acb\u5206\u6790\u6848\u4f8b\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u5f00\u542f\u6b64\u9009\u9879\u53ef\u4ee5\u5229\u7528\u591a\u6838CPU\u7684\u4f18\u52bf\uff0c\u663e\u8457\u7f29\u77ed\u603b\u5206\u6790\u65f6\u95f4\u3002</li> </ul> </li> <li> <p><code>max_case_workers</code> (\u6700\u5927\u5e76\u53d1\u8fdb\u7a0b\u6570)</p> <ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u6574\u6570\uff0c\u4ec5\u5728 <code>concurrent_cases</code> \u4e3a <code>true</code> \u65f6\u751f\u6548\u3002\u7528\u4e8e\u6307\u5b9a\u5e76\u884c\u6267\u884c\u7684\u6700\u5927\u8fdb\u7a0b\u6570\u3002</li> <li>\u9ed8\u8ba4\u503c: \u5982\u679c\u4e0d\u8bbe\u7f6e\uff0c<code>tricys</code> \u4f1a\u9ed8\u8ba4\u4f7f\u7528\u60a8\u673a\u5668\u4e0a\u7684CPU\u6838\u5fc3\u6570\u3002</li> <li>\u5efa\u8bae: \u5efa\u8bae\u8bbe\u7f6e\u4e3a\u4e0d\u8d85\u8fc7\u60a8\u8ba1\u7b97\u673a\u7684\u7269\u7406CPU\u6838\u5fc3\u6570\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/index.html#12-metrics_definition","title":"1.2. <code>metrics_definition</code> (\u6307\u6807\u5b9a\u4e49)","text":"<p>\u8fd9\u662f\u6700\u5173\u952e\u7684\u90e8\u5206\uff0c\u7528\u4e8e\u5b9a\u4e49\u60a8\u5173\u5fc3\u7684\u6027\u80fd\u6307\u6807 (KPIs)\uff0c\u4e5f\u5c31\u662f\u5206\u6790\u7ed3\u679c\u4e2d\u7684\u56e0\u53d8\u91cf\u3002</p> <ul> <li>\u7ed3\u6784: \u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u4e2d\u6bcf\u4e2a\u952e\u90fd\u662f\u60a8\u4e3a\u6307\u6807\u8d4b\u4e88\u7684\u552f\u4e00\u540d\u79f0\uff08\u5982 <code>Startup_Inventory</code>\uff09\u3002</li> <li>\u503c: \u4e00\u4e2a\u63cf\u8ff0\u5982\u4f55\u8ba1\u7b97\u8be5\u6307\u6807\u7684\u5bf9\u8c61\u3002<ul> <li><code>source_column</code>: \u7528\u4e8e\u8ba1\u7b97\u7684\u539f\u59cb\u6570\u636e\u6765\u6e90\uff0c\u5373\u4eff\u771f\u7ed3\u679c (<code>.csv</code>) \u4e2d\u7684\u5217\u540d\u3002</li> <li><code>method</code>: <code>tricys.analysis.metric</code> \u6a21\u5757\u4e2d\u7528\u4e8e\u8ba1\u7b97\u7684\u51fd\u6570\u540d\u3002</li> </ul> </li> <li>\u8be6\u89e3: <code>tricys</code> \u5185\u7f6e\u4e86\u591a\u79cd\u5e38\u7528\u6307\u6807\u8ba1\u7b97\u51fd\u6570\u3002\u5173\u4e8e\u5185\u7f6e\u6838\u5fc3\u6027\u80fd\u6307\u6807\uff08\u5982 <code>Startup_Inventory</code>, <code>Doubling_Time</code> \u7b49\uff09\u7684\u8be6\u7ec6\u7269\u7406\u610f\u4e49\u548c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605 \u6838\u5fc3\u6027\u80fd\u6307\u6807\u8be6\u89e3\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#13-glossary_path","title":"1.3. <code>glossary_path</code> (\u672f\u8bed\u8868)","text":"<ul> <li>\u63cf\u8ff0: \u6307\u5411\u4e00\u4e2a\u201c\u672f\u8bed\u8868\u201d CSV \u6587\u4ef6\u7684\u8def\u5f84\u3002\u63d0\u4f9b\u6b64\u6587\u4ef6\u53ef\u4ee5\u6781\u5927\u5730\u589e\u5f3a\u62a5\u544a\u7684\u53ef\u8bfb\u6027\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5c06\u4ee3\u7801\u4e2d\u7b80\u5199\u7684\u53d8\u91cf\u540d\uff08\u5982 <code>sds.I[1]</code>\uff09\u6620\u5c04\u4e3a\u6613\u4e8e\u7406\u89e3\u7684\u4e2d\u6587\u540d\u79f0\u548c\u63cf\u8ff0\u3002</li> <li>\u683c\u5f0f: \u8fd9\u662f\u4e00\u4e2a\u6807\u51c6\u7684 CSV \u6587\u4ef6\uff0c\u5176\u5217\u5934\u5e94\u5305\u542b <code>\u6a21\u578b\u53c2\u6570 (Model Parameter)</code> (\u5fc5\u586b), <code>\u82f1\u6587\u672f\u8bed (English Term)</code>, <code>\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)</code> \u7b49\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#14-unit_map","title":"1.4. <code>unit_map</code> (\u5355\u4f4d\u6620\u5c04)","text":"<ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u4e8e\u81ea\u5b9a\u4e49\u62a5\u544a\u56fe\u8868\u4e2d\u7684\u5355\u4f4d\uff0c\u4f7f\u7ed3\u679c\u66f4\u76f4\u89c2\u3002</li> <li>\u952e: \u53d8\u91cf\u540d\u6216\u6307\u6807\u540d\u3002</li> <li>\u503c: \u5305\u542b <code>unit</code> (\u5355\u4f4d\u5b57\u7b26\u4e32) \u548c <code>conversion_factor</code> (\u4ece\u539f\u59cb\u4eff\u771f\u5355\u4f4d\u5230\u76ee\u6807\u5355\u4f4d\u7684\u6362\u7b97\u7cfb\u6570) \u7684\u5bf9\u8c61\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4eff\u771f\u65f6\u95f4\u5355\u4f4d\u662f\u5c0f\u65f6\uff0c\u901a\u8fc7 <code>\"conversion_factor\": 24</code> \u53ef\u4ee5\u5c06 <code>Doubling_Time</code> \u7684\u5355\u4f4d\u6362\u7b97\u4e3a\u5929\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#15-ai-ai-true","title":"1.5. AI \u589e\u5f3a\u5206\u6790 (<code>\"ai\": true</code>)","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u5185\u7f6e\u4e86\u5f3a\u5927\u7684 AI \u5206\u6790\u529f\u80fd\u3002</p> <ul> <li>\u542f\u7528\u65b9\u5f0f: \u5728\u5177\u4f53\u5206\u6790\u6848\u4f8b\u7684\u914d\u7f6e\u4e2d\uff08\u4f8b\u5982 <code>analysis_cases</code> \u7684\u67d0\u4e2a\u5143\u7d20\u5185\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\u52a0\u5165 <code>\"ai\": true</code> \u5373\u53ef\u6fc0\u6d3b\u3002</li> <li>\u73af\u5883\u51c6\u5907: \u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09API \u51ed\u636e\u3002     <pre><code># .env file\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre></li> <li>\u529f\u80fd: \u542f\u7528\u540e\uff0c<code>tricys</code> \u4f1a\u5728\u751f\u6210\u6807\u51c6\u56fe\u8868\u548c\u6570\u636e\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u989d\u5916\u8c03\u7528 LLM\uff1a<ol> <li>\u5bf9\u5206\u6790\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\uff0c\u5e76\u5c06\u7ed3\u679c\u8ffd\u52a0\u5230\u6838\u5fc3\u7684 Markdown \u62a5\u544a\u4e2d\u3002</li> <li>\u751f\u6210\u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a (<code>academic_report.md</code>)\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u6c47\u62a5\u6216\u4f5c\u4e3a\u8bba\u6587\u521d\u7a3f\u3002</li> </ol> </li> </ul>"},{"location":"guides/tricys_analysis/index.html#16","title":"1.6. \u901a\u7528\u914d\u7f6e\u793a\u4f8b","text":"<p>\u4ee5\u4e0b JSON \u7247\u6bb5\u5c55\u793a\u4e86\u4e0a\u8ff0\u901a\u7528\u914d\u7f6e\u9879\u5728 <code>sensitivity_analysis</code> \u5bf9\u8c61\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002</p> <pre><code>\"sensitivity_analysis\": {\n    \"enabled\": true,\n    \"concurrent_cases\": true,\n    \"max_case_workers\": 4,\n    \"analysis_cases\": [\n        // ... \u6b64\u5904\u4e3a\u5177\u4f53\u5206\u6790\u6848\u4f8b\u7684\u5b9a\u4e49\uff0c\u8be6\u89c1\u5404\u5206\u6790\u7c7b\u578b\u6587\u6863 ...\n    ],\n    \"metrics_definition\": {\n        \"Startup_Inventory\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"calculate_startup_inventory\"\n        },\n        \"Doubling_Time\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"calculate_doubling_time\"\n        },\n        \"Required_TBR\": {\n            \"method\": \"bisection_search\",\n            \"parameter_to_optimize\": \"blanket.TBR\",\n            \"search_range\": [1, 1.5]\n        }\n    },\n    \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n    \"unit_map\": {\n        \"Doubling_Time\": {\n            \"unit\": \"days\",\n            \"conversion_factor\": 24\n        },\n        \"Startup_Inventory\": {\n            \"unit\": \"kg\",\n            \"conversion_factor\": 1000\n        }\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/index.html#2","title":"2. \u901a\u7528\u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u65e0\u8bba\u6267\u884c\u4f55\u79cd\u7c7b\u578b\u7684\u5206\u6790\uff0c<code>tricys</code> \u90fd\u4f1a\u5728\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u4ee5\u65f6\u95f4\u6233\u547d\u540d\u7684\u6587\u4ef6\u5939\uff0c\u7528\u4e8e\u5b58\u653e\u6240\u6709\u7ed3\u679c\u3002\u5bf9\u4e8e\u5728\u914d\u7f6e\u6587\u4ef6 <code>analysis_cases</code> \u4e2d\u5b9a\u4e49\u7684\u6bcf\u4e00\u4e2a\u5206\u6790\u6848\u4f8b\uff0c\u90fd\u4f1a\u5728\u65f6\u95f4\u6233\u6587\u4ef6\u5939\u5185\u521b\u5efa\u4e00\u4e2a\u4ee5\u6848\u4f8b <code>name</code> \u547d\u540d\u7684\u5b50\u6587\u4ef6\u5939\u3002</p> <p>\u4e00\u4e2a\u5178\u578b\u7684\u8f93\u51fa\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>&lt;run_timestamp&gt;/\n\u251c\u2500\u2500 Case_A_Name/\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u251c\u2500\u2500 analysis_report_Case_A_Name.md              # \u6838\u5fc3\u5206\u6790\u62a5\u544a\n\u2502   \u2502   \u251c\u2500\u2500 academic_report_Case_A_Name_gpt-4.md      # (\u53ef\u9009) AI \u5b66\u672f\u62a5\u544a\n\u2502   \u2502   \u251c\u2500\u2500 analysis_plot_1.svg                         # \u5206\u6790\u56fe\u88681\n\u2502   \u2502   \u2514\u2500\u2500 analysis_plot_2.svg                         # \u5206\u6790\u56fe\u88682\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u2514\u2500\u2500 ... (\u4e2d\u95f4\u6570\u636e\u6587\u4ef6)\n\u2502\n\u251c\u2500\u2500 Case_B_Name/\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u2514\u2500\u2500 ...\n\u2502\n\u2514\u2500\u2500 execution_report.md (\u5168\u5c40\u6267\u884c\u62a5\u544a)\n</code></pre> <p>\u6bcf\u4e2a\u6848\u4f8b\u5b50\u6587\u4ef6\u5939\u7684\u6838\u5fc3\u4ea7\u51fa\u90fd\u4f4d\u4e8e\u5176\u5185\u90e8\u7684 <code>report</code> \u6587\u4ef6\u5939\u4e2d\uff0c\u901a\u5e38\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p>"},{"location":"guides/tricys_analysis/index.html#21","title":"2.1. \u6838\u5fc3\u5206\u6790\u62a5\u544a","text":"<ul> <li>\u6587\u4ef6: <code>analysis_report_{case_name}.md</code></li> <li>\u683c\u5f0f: Markdown</li> <li>\u5185\u5bb9: \u8fd9\u662f\u5206\u6790\u7ed3\u679c\u7684\u6c47\u603b\uff0c\u4ee5\u7ed3\u6784\u5316\u7684\u65b9\u5f0f\u6574\u5408\u4e86\u914d\u7f6e\u3001\u56fe\u8868\u548c\u6570\u636e\u3002\u5176\u901a\u7528\u5185\u5bb9\u5305\u62ec\uff1a<ul> <li>\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u8be6\u60c5: \u8be6\u7ec6\u5217\u51fa\u7528\u4e8e\u672c\u6b21\u5206\u6790\u7684\u6240\u6709\u914d\u7f6e\u53c2\u6570\uff0c\u786e\u4fdd\u5206\u6790\u8fc7\u7a0b\u7684\u900f\u660e\u548c\u53ef\u590d\u73b0\u3002</li> <li>\u6027\u80fd\u6307\u6807\u603b\u8868: \u4e00\u4e2a\u6e05\u6670\u7684 Markdown \u8868\u683c\uff0c\u5217\u51fa\u4e86\u72ec\u7acb\u53d8\u91cf\u7684\u6bcf\u4e00\u6b21\u53d6\u503c\uff0c\u4ee5\u53ca\u5bf9\u5e94\u8ba1\u7b97\u51fa\u7684\u6240\u6709\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u7cbe\u786e\u6570\u503c\u3002\u8fd9\u662f\u6240\u6709\u5206\u6790\u56fe\u8868\u7684\u539f\u59cb\u6570\u636e\u6765\u6e90\u3002</li> <li>\u5206\u6790\u56fe\u8868: \u5d4c\u5165\u7684 SVG \u683c\u5f0f\u77e2\u91cf\u56fe\u3002\u56fe\u8868\u7684\u5177\u4f53\u7c7b\u578b\u548c\u5185\u5bb9\u53d6\u51b3\u4e8e\u5206\u6790\u6a21\u5f0f\uff08\u4f8b\u5982\uff0c\u5355\u53c2\u6570\u5206\u6790\u7684\u8d8b\u52bf\u7ebf\u56fe\u3001SOBOL\u5206\u6790\u7684\u654f\u611f\u6027\u6307\u6570\u6761\u5f62\u56fe\u7b49\uff09\uff0c\u5177\u4f53\u8bf7\u53c2\u9605\u5404\u5206\u6790\u7c7b\u578b\u7684\u6587\u6863\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/index.html#22-ai","title":"2.2. (\u53ef\u9009) AI \u589e\u5f3a\u62a5\u544a","text":"<p>\u5982\u679c\u914d\u7f6e\u4e86 <code>\"ai\": true</code>\uff0c<code>report</code> \u6587\u4ef6\u5939\u4e2d\u5c06\u989d\u5916\u51fa\u73b0\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u6c47\u62a5\u6216\u4f5c\u4e3a\u8bba\u6587\u521d\u7a3f\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#3","title":"3. \u5206\u6790\u7c7b\u578b\u5bfc\u822a","text":"<p>\u6839\u636e\u60a8\u7684\u7814\u7a76\u76ee\u7684\uff0c\u53ef\u4ee5\u9009\u62e9\u4ee5\u4e0b\u4e0d\u540c\u7684\u5206\u6790\u6a21\u5f0f\u3002\u8bf7\u70b9\u51fb\u94fe\u63a5\u67e5\u770b\u6bcf\u79cd\u6a21\u5f0f\u7684\u8be6\u7ec6\u914d\u7f6e\u65b9\u6cd5\u548c\u5e94\u7528\u573a\u666f\u3002</p> <ul> <li>\u57fa\u51c6\u5de5\u51b5\u5206\u6790: \u5bf9\u5355\u4e00\u3001\u786e\u5b9a\u7684\u53c2\u6570\u914d\u7f6e\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002</li> <li>\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790: \u7814\u7a76\u5355\u4e2a\u72ec\u7acb\u53c2\u6570\u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002</li> <li>\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790: \u5206\u6790\u591a\u4e2a\u53c2\u6570\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u8026\u5408\u6548\u5e94\uff0c\u6216\u8fdb\u884c\u201c\u76ee\u6807\u5bfb\u6c42\u201d\u5f0f\u5206\u6790\u3002</li> <li>SOBOL\u5168\u5c40\u654f\u611f\u6027\u5206\u6790: \u91cf\u5316\u591a\u4e2a\u8f93\u5165\u53c2\u6570\u53ca\u5176\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002</li> <li>Latin\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u6790: \u8bc4\u4f30\u8f93\u5165\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u4f20\u64ad\u5230\u6a21\u578b\u8f93\u51fa\u4e2d\uff0c\u5e76\u5206\u6790\u8f93\u51fa\u7684\u6982\u7387\u5206\u5e03\u3002</li> </ul>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html","title":"\u57fa\u51c6\u5de5\u51b5\u5206\u6790","text":"<p>\u57fa\u51c6\u5de5\u51b5\u5206\u6790\uff08Baseline Condition Analysis\uff09\u662f <code>tricys</code> \u5206\u6790\u5de5\u5177\u96c6\u4e2d\u7684\u4e00\u9879\u6838\u5fc3\u529f\u80fd\u3002\u5b83\u7528\u4e8e\u5bf9\u5355\u4e00\u3001\u786e\u5b9a\u7684\u53c2\u6570\u914d\u7f6e\uff08\u5373\u201c\u57fa\u51c6\u5de5\u51b5\u201d\uff09\u4e0b\u7684\u7cfb\u7edf\u884c\u4e3a\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u4e00\u4efd\u6807\u51c6\u5316\u7684 Markdown \u5206\u6790\u62a5\u544a\u3002</p> <p>\u8be5\u529f\u80fd\u672c\u8d28\u4e0a\u662f <code>tricys</code> \u7684\u540e\u5904\u7406\u6a21\u5757\uff0c\u5173\u4e8e\u540e\u5904\u7406\u6a21\u5757\u7684\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u540e\u5904\u7406\u6a21\u5757\u3002\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u8be5\u5206\u6790\u7684\u914d\u7f6e\u6587\u4ef6\u662f\u4e00\u6b21\u5355\u72ec\u7684\u4eff\u771f\uff0c\u7d27\u8ddf\u7740\u4e00\u4e2a\u7279\u5b9a\u7684\u540e\u5904\u7406\u6b65\u9aa4\u3002\u56e0\u6b64\uff0c\u914d\u7f6e\u6587\u4ef6\u4e2d\u4e0d\u5305\u542b <code>sensitivity_analysis</code> \u626b\u63cf\u90e8\u5206\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]|div.I[1]|cps.I[1]|tes.I[1]|blanket.I[1]|i_iss.I[1]|wds.I[1]|o_iss.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    },\n    \"post_processing\": [\n        {\n           \"module\": \"tricys.postprocess.baseline_analysis\",\n           \"function\": \"baseline_analysis\",\n           \"params\": {\n                \"detailed_var\": \"sds.I[1]\",\n                \"glossary_path\": \"../../example_glossary/example_glossary.csv\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<p>\u6838\u5fc3\u5728\u4e8e <code>post_processing</code> \u90e8\u5206\u7684\u914d\u7f6e\uff1a</p> <ul> <li><code>module</code>: \u56fa\u5b9a\u4e3a <code>tricys.postprocess.baseline_analysis</code>\u3002</li> <li><code>function</code>: \u56fa\u5b9a\u4e3a <code>baseline_analysis</code>\u3002</li> <li><code>params</code>:<ul> <li><code>detailed_var</code> (\u5b57\u7b26\u4e32, \u9009\u586b):<ul> <li>\u63cf\u8ff0: \u6307\u5b9a\u4e00\u4e2a\u6a21\u578b\u4e2d\u7684\u53d8\u91cf\uff0c\u62a5\u544a\u5c06\u4e3a\u8be5\u53d8\u91cf\u751f\u6210\u4e00\u5f20\u5305\u542b\u201c\u7ec6\u8282\u89c6\u56fe\u201d\u7684\u65f6\u95f4\u6f14\u5316\u66f2\u7ebf\u56fe\uff0c\u653e\u5927\u5176\u201c\u81ea\u6301\u70b9\u201d\u9644\u8fd1\u533a\u57df\u3002</li> </ul> </li> <li><code>glossary_path</code> (\u5b57\u7b26\u4e32, \u9009\u586b):<ul> <li>\u63cf\u8ff0: \u6307\u5411\u4e00\u4e2a\u201c\u672f\u8bed\u8868\u201d CSV \u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul> </li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u62a5\u544a\u7684\u7ed3\u6784\u4e0e\u901a\u7528\u8bf4\u660e\u4e2d\u63cf\u8ff0\u7684\u7c7b\u4f3c\uff0c\u4f46\u5176\u6838\u5fc3\u5185\u5bb9\u662f\u9488\u5bf9\u5355\u6b21\u8fd0\u884c\u7684\u5feb\u7167\u5206\u6790\uff0c\u5305\u542b\uff1a</p> <ol> <li>\u5173\u952e\u6027\u80fd\u6307\u6807 (Key Performance Indicators): \u57fa\u4e8e <code>detailed_var</code> \u8ba1\u7b97\u51fa\u7684 <code>Startup Inventory</code>, <code>Self-Sufficiency Time</code> \u548c <code>Doubling Time</code>\u3002</li> <li>\u6a21\u62df\u7ed3\u679c\u65f6\u5e8f\u56fe (Time-series Plot): \u5305\u542b\u5168\u5c40\u89c6\u56fe\u548c\u57fa\u4e8e <code>detailed_var</code> \u7684\u7ec6\u8282\u89c6\u56fe\u3002</li> <li>\u6a21\u62df\u7ed3\u675f\u65f6\u5404\u53d8\u91cf\u6700\u7ec8\u503c (Final Values Bar Chart): \u5404\u5b50\u7cfb\u7edf\u5728\u4eff\u771f\u7ed3\u675f\u65f6\u7684\u6c1a\u5e93\u5b58\u5206\u5e03\u6761\u5f62\u56fe\u3002</li> <li>\u6570\u636e\u8868\u683c: \u5305\u62ec\u6700\u7ec8\u503c\u6570\u636e\u8868\u548c\u5173\u952e\u9636\u6bb5\uff08\u521d\u59cb\u3001\u8f6c\u6298\u70b9\u3001\u7ed3\u675f\uff09\u7684\u6570\u636e\u5207\u7247\u3002</li> </ol>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#4-ai","title":"4. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#41","title":"4.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5bf9\u4e8e\u57fa\u51c6\u5de5\u51b5\u5206\u6790\uff0cAI \u529f\u80fd\u662f\u901a\u8fc7\u5728 <code>post_processing</code> \u4efb\u52a1\u7684 <code>params</code> \u5bf9\u8c61\u4e2d\u6dfb\u52a0 <code>\"ai\": true</code> \u6765\u6fc0\u6d3b\u7684\u3002</p> <pre><code>\"post_processing\": [\n    {\n       \"module\": \"tricys.postprocess.baseline_analysis\",\n       \"function\": \"baseline_analysis\",\n       \"params\": {\n            \"detailed_var\": \"sds.I[1]\",\n            \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n            \"ai\": true\n        }\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#42","title":"4.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#43","title":"4.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html","title":"Latin\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u6790","text":"<p>\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (Uncertainty Quantification, UQ) \u662f\u8bc4\u4f30\u6a21\u578b\u6216\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5173\u952e\u6b65\u9aa4\u3002\u5b83\u7684\u76ee\u7684\u4e0d\u662f\u627e\u51fa\u54ea\u4e2a\u53c2\u6570\u6700\u654f\u611f\uff0c\u800c\u662f\u56de\u7b54\u4e00\u4e2a\u66f4\u91cd\u8981\u7684\u95ee\u9898\uff1a\u201c\u5f53\u6211\u7684\u8f93\u5165\u53c2\u6570\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u4e0d\u786e\u5b9a\u65f6\uff0c\u6211\u7684\u8f93\u51fa\u7ed3\u679c\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u53ef\u80fd\u8303\u56f4\u662f\u591a\u5927\uff1f\u5176\u6982\u7387\u5206\u5e03\u662f\u600e\u6837\u7684\uff1f\u201d</p> <p><code>tricys</code> \u5229\u7528\u9ad8\u6548\u7684 Latin \u8d85\u7acb\u65b9\u91c7\u6837 (Latin Hypercube Sampling, LHS) \u6280\u672f\u6765\u8fdb\u884c UQ \u5206\u6790\u3002LHS \u662f\u4e00\u79cd\u5206\u5c42\u91c7\u6837\u65b9\u6cd5\uff0c\u5b83\u80fd\u7528\u76f8\u5bf9\u8f83\u5c11\u7684\u6837\u672c\u70b9\u5747\u5300\u5730\u63a2\u7d22\u6574\u4e2a\u591a\u7ef4\u53c2\u6570\u7a7a\u95f4\uff0c\u4ece\u800c\u9ad8\u6548\u5730\u8bc4\u4f30\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u4f20\u64ad\u5230\u6a21\u578b\u8f93\u51fa\u3002</p> <p>\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>LHS \u5206\u6790\u7684\u914d\u7f6e\u4e0e SOBOL \u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u975e\u5e38\u76f8\u4f3c\uff0c\u4e3b\u8981\u533a\u522b\u5728\u4e8e <code>analyzer.method</code> \u88ab\u8bbe\u7f6e\u4e3a <code>\"latin\"</code>\u3002</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_LATIN_Analysis\",\n                \"independent_variable\": [\"pulseSource.width\", \"plasma.nf\", \"plasma.fb\", \"tep_fep.to_SDS_Fraction[1]\", \"blanket.TBR\"],\n                \"independent_variable_sampling\": {\n                      \"pulseSource.width\": { \"bounds\": [50, 90], \"distribution\": \"unif\" },\n                      \"plasma.nf\": { \"bounds\": [0.1, 0.9], \"distribution\": \"unif\" },\n                      \"plasma.fb\": { \"bounds\": [0.03, 0.07], \"distribution\": \"unif\" },\n                      \"tep_fep.to_SDS_Fraction[1]\": { \"bounds\": [0.1, 0.8], \"distribution\": \"unif\" },\n                      \"blanket.TBR\": { \"bounds\": [1.05, 1.25], \"distribution\": \"unif\" }\n                },\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"analyzer\": {\n                    \"method\": \"latin\",\n                    \"sample_N\": 256\n                }\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li><code>independent_variable</code> (\u5217\u8868): \u4e00\u4e2a\u5305\u542b\u6240\u6709\u88ab\u89c6\u4e3a\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u7684\u8f93\u5165\u53c2\u6570\u7684\u5217\u8868\u3002</li> <li><code>independent_variable_sampling</code> (\u5bf9\u8c61): \u4e00\u4e2a\u5b57\u5178\uff0c\u4e3a\u6bcf\u4e2a\u4e0d\u786e\u5b9a\u53c2\u6570\u5b9a\u4e49\u5176\u91c7\u6837\u8303\u56f4\u548c\u6982\u7387\u5206\u5e03\u3002</li> <li><code>analyzer</code> (\u5bf9\u8c61): \u5b9a\u4e49\u8981\u4f7f\u7528\u7684\u5206\u6790\u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u3002</li> <li><code>method</code>: \u56fa\u5b9a\u4e3a <code>\"latin\"</code>\u3002</li> <li><code>sample_N</code>: Latin \u8d85\u7acb\u65b9\u91c7\u6837\u751f\u6210\u7684\u6837\u672c\u6570\u91cf\uff0c\u76f4\u63a5\u5bf9\u5e94\u4e8e\u5c06\u8981\u8fd0\u884c\u7684\u4eff\u771f\u603b\u6b21\u6570\u3002</li> </ul>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#3","title":"3. \u5de5\u4f5c\u6d41\u8be6\u89e3","text":"<p>\u5f53 <code>tricys</code> \u63a5\u6536\u5230\u4e00\u4e2a\u5305\u542b <code>analyzer</code> \u5b57\u6bb5\u7684\u5206\u6790\u4efb\u52a1\u65f6\uff08\u5982\u672c\u4f8b\u4e2d\u7684LHS\u5206\u6790\uff09\uff0c\u5b83\u4f1a\u542f\u52a8\u4e00\u4e2a\u57fa\u4e8e <code>SALib</code> \u5e93\u7684\u7279\u6b8a\u5de5\u4f5c\u6d41\u3002</p> <ol> <li>\u8bc6\u522b\u5206\u6790\u7c7b\u578b: \u5728 <code>tricys.simulation.simulation_analysis.py</code> \u7684\u4e3b\u6d41\u7a0b\u4e2d\uff0c\u7a0b\u5e8f\u9996\u5148\u68c0\u6d4b\u5230\u8fd9\u662f\u4e00\u4e2a SALib \u5206\u6790\u4efb\u52a1\u3002</li> <li>\u5b9a\u4e49\u95ee\u9898\u548c\u91c7\u6837: \u7a0b\u5e8f\u5c06\u4efb\u52a1\u59d4\u6258\u7ed9 <code>tricys.analysis.salib.py</code> \u6a21\u5757\uff0c\u8be5\u6a21\u5757\u6839\u636e\u914d\u7f6e\u5b9a\u4e49\u4e00\u4e2a <code>SALib</code> \u201c\u95ee\u9898\u7a7a\u95f4\u201d\uff0c\u5e76\u8c03\u7528 LHS \u91c7\u6837\u51fd\u6570\u751f\u6210 <code>N</code> \u4e2a\u53c2\u6570\u6837\u672c\u70b9\u3002</li> <li>\u6267\u884c\u6279\u91cf\u4eff\u771f: \u751f\u6210\u7684 <code>N</code> \u4e2a\u53c2\u6570\u6837\u672c\u88ab\u5199\u5165\u4e00\u4e2a\u4e34\u65f6\u7684 CSV \u6587\u4ef6\u4e2d\uff0c<code>tricys</code> \u968f\u540e\u4e3a\u6bcf\u4e2a\u6837\u672c\u70b9\u6267\u884c\u4e00\u6b21\u4eff\u771f\u3002</li> <li>\u6536\u96c6\u548c\u5206\u6790\u7ed3\u679c: \u6240\u6709\u4eff\u771f\u8fd0\u884c\u5b8c\u6bd5\u540e\uff0c\u7a0b\u5e8f\u4f1a\u8ba1\u7b97\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\u7684 <code>N</code> \u4e2a\u8f93\u51fa\u7ed3\u679c\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff08\u8ba1\u7b97\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u767e\u5206\u4f4d\u6570\u7b49\uff09\u3002</li> <li>\u751f\u6210\u62a5\u544a\u548c\u56fe\u8868: \u6700\u540e\uff0c\u7a0b\u5e8f\u6839\u636e\u7edf\u8ba1\u5206\u6790\u7ed3\u679c\u751f\u6210\u6700\u7ec8\u7684 Markdown \u62a5\u544a\uff0c\u5176\u4e2d\u5305\u542b\u8be6\u7ec6\u7684\u7edf\u8ba1\u6570\u636e\u8868\u683c\u548c\u8f93\u51fa\u5206\u5e03\u56fe\uff08\u76f4\u65b9\u56fe\u548c\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u56fe\uff09\u3002</li> </ol>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#4","title":"4. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u62a5\u544a\u7684\u6838\u5fc3\u5185\u5bb9\u662f\u9488\u5bf9\u6bcf\u4e00\u4e2a\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u72ec\u7acb\u7edf\u8ba1\u5206\u6790\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e <code>Startup_Inventory</code> \u6307\u6807\uff0c\u62a5\u544a\u4f1a\u5305\u542b\uff1a</p> <ol> <li>\u7edf\u8ba1\u6458\u8981 (Statistical Summary): \u63d0\u4f9b\u4e00\u7ec4\u6838\u5fc3\u7684\u7edf\u8ba1\u6570\u636e\uff0c\u5305\u62ec\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5c0f\u503c\u548c\u6700\u5927\u503c\u3002</li> <li>\u5206\u5e03\u5173\u952e\u70b9 (Key Distribution Points / CDF): \u63d0\u4f9b\u4e00\u7cfb\u5217\u767e\u5206\u4f4d\u6570\uff08\u59825%, 25%, 50% (\u4e2d\u4f4d\u6570), 75%, 95%\uff09\uff0c\u7528\u4e8e\u7cbe\u786e\u63cf\u8ff0\u8f93\u51fa\u6307\u6807\u7684\u7d2f\u79ef\u5206\u5e03\u60c5\u51b5\u3002</li> <li>\u8f93\u51fa\u5206\u5e03 (\u76f4\u65b9\u56fe\u6570\u636e): \u4e00\u4e2a\u8868\u683c\uff0c\u5c55\u793a\u4e86\u8f93\u51fa\u7ed3\u679c\u5728\u4e0d\u540c\u6570\u503c\u533a\u95f4\u7684\u9891\u6570\u5206\u5e03\u3002</li> <li>\u8f93\u51fa\u5206\u5e03\u56fe (Output Distribution Plot): \u5d4c\u5165\u7684 <code>.png</code> \u56fe\u8868\uff0c\u5305\u542b\u4e24\u4e2a\u5b50\u56fe\uff1a<ul> <li>\u76f4\u65b9\u56fe: \u76f4\u89c2\u5c55\u793a\u8f93\u51fa\u6307\u6807\u7684\u6982\u7387\u5bc6\u5ea6\u5206\u5e03\u5f62\u72b6\u3002</li> <li>\u7d2f\u79ef\u5206\u5e03\u51fd\u6570 (CDF): \u5c55\u793a\u4e86\u8f93\u51fa\u6307\u6807\u503c\u5c0f\u4e8e\u6216\u7b49\u4e8e\u67d0\u4e2a\u7279\u5b9a\u503c\u7684\u6982\u7387\u3002</li> </ul> </li> </ol>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#uq","title":"\u5982\u4f55\u89e3\u8bfbUQ\u7ed3\u679c","text":"<p>\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u6790\u7684\u91cd\u70b9\u662f\u7406\u89e3\u8f93\u51fa\u7684\u5206\u5e03\uff0c\u800c\u4e0d\u662f\u53c2\u6570\u7684\u654f\u611f\u5ea6\u6392\u5e8f\u3002</p> <ul> <li>\u770b\u4e2d\u5fc3\u8d8b\u52bf: \u5747\u503c (Mean) \u548c \u4e2d\u4f4d\u6570 (Median) \u544a\u8bc9\u60a8\u6027\u80fd\u6307\u6807\u6700\u53ef\u80fd\u843d\u5728\u54ea\u4e2a\u503c\u9644\u8fd1\u3002</li> <li>\u770b\u79bb\u6563\u7a0b\u5ea6: \u6807\u51c6\u5dee (Standard Deviation) \u548c 5%-95%\u767e\u5206\u4f4d\u6570\u7684\u8303\u56f4 \u63ed\u793a\u4e86\u8f93\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u6709\u591a\u5927\u3002\u8303\u56f4\u8d8a\u5bbd\uff0c\u8bf4\u660e\u8f93\u5165\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u7cfb\u7edf\u6027\u80fd\u9020\u6210\u7684\u5f71\u54cd\u8d8a\u5927\uff0c\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u53ef\u80fd\u8d8a\u5dee\u3002</li> <li>\u770b\u5206\u5e03\u5f62\u72b6: \u76f4\u65b9\u56fe\u7684\u5f62\u72b6\u5f88\u91cd\u8981\u3002\u4e00\u4e2a\u5bf9\u79f0\u7684\u3001\u7c7b\u4f3c\u6b63\u6001\u5206\u5e03\u7684\u949f\u5f62\u66f2\u7ebf\u662f\u6bd4\u8f83\u7406\u60f3\u7684\u3002\u5982\u679c\u5206\u5e03\u51fa\u73b0\u957f\u5c3e\u6216\u504f\u659c\uff0c\u53ef\u80fd\u610f\u5473\u7740\u7cfb\u7edf\u5728\u67d0\u4e9b\u53c2\u6570\u7ec4\u5408\u4e0b\u5bb9\u6613\u51fa\u73b0\u6781\u7aef\u7684\u597d\u6216\u574f\u7684\u7ed3\u679c\uff0c\u8fd9\u5bf9\u4e8e\u98ce\u9669\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002</li> </ul>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#5","title":"5. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/5_latin_uncertainty_analysis/latin_uncertainty_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"SALIB_LATIN_Analysis\",                 \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\",\"plasma.fb\",\"tep_fep.to_SDS_Fraction[1]\",\"blanket.TBR\"],                 \"independent_variable_sampling\":{                       \"pulseSource.width\": {                           \"bounds\": [50,90],                           \"distribution\": \"unif\"                       },                       \"plasma.nf\": {                           \"bounds\": [0.1,0.9],                           \"distribution\": \"unif\"                       },                       \"plasma.fb\": {                           \"bounds\": [0.03,0.07],                           \"distribution\": \"unif\"                       },                       \"tep_fep.to_SDS_Fraction[1]\": {                           \"bounds\": [0.1,0.8],                           \"distribution\": \"unif\"                       },                       \"blanket.TBR\": {                           \"bounds\": [1.05, 1.25],                           \"distribution\": \"unif\"                       }                 },                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Self_Sufficiency_Time\",                     \"Doubling_Time\"                 ],                 \"analyzer\": {                     \"method\": \"latin\",                     \"sample_N\": 256                 }             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#6-ai","title":"6. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#61","title":"6.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#62","title":"6.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#63","title":"6.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html","title":"\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5728\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u7684\u57fa\u7840\u4e0a\uff0c<code>tricys</code> \u63d0\u4f9b\u4e86\u529f\u80fd\u66f4\u5f3a\u5927\u7684\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002\u8be5\u529f\u80fd\u5141\u8bb8\u60a8\u5728\u7814\u7a76\u4e00\u4e2a\u4e3b\u72ec\u7acb\u53c2\u6570\uff08X\u8f74\uff09\u5bf9\u6027\u80fd\u6307\u6807\uff08Y\u8f74\uff09\u7684\u5f71\u54cd\u65f6\uff0c\u540c\u65f6\u626b\u63cf\u4e00\u4e2a\u6216\u591a\u4e2a\u80cc\u666f\u53c2\u6570\u3002</p> <p>\u8fd9\u4f7f\u5f97\u60a8\u53ef\u4ee5\u5728\u4e00\u5f20\u56fe\u4e0a\u751f\u6210\u4e00\u7ec4\u201c\u654f\u611f\u6027\u66f2\u7ebf\u65cf\u201d\uff0c\u5176\u4e2d\u6bcf\u4e00\u6761\u66f2\u7ebf\u4ee3\u8868\u4e00\u4e2a\u80cc\u666f\u53c2\u6570\u7684\u7279\u5b9a\u53d6\u503c\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u60a8\u53ef\u4ee5\u6df1\u5165\u5730\u7406\u89e3\u53c2\u6570\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u8026\u5408\u6548\u5e94\u3002\u6b64\u5916\uff0c\u8be5\u529f\u80fd\u8fd8\u652f\u6301\u4e00\u79cd\u5f3a\u5927\u7684\u201c\u76ee\u6807\u5bfb\u6c42\u201d\u5f0f\u5206\u6790\u3002</p> <p>\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#1","title":"1. \u6838\u5fc3\u6982\u5ff5\uff1a\u53c2\u6570\u4ea4\u4e92\u5206\u6790","text":"<p>\u8fd9\u662f\u591a\u53c2\u6570\u5206\u6790\u6700\u5e38\u89c1\u7684\u7528\u6cd5\uff0c\u5176\u6838\u5fc3\u662f\u5728 <code>analysis_cases</code> \u7684\u67d0\u4e2a\u6848\u4f8b\u5185\u90e8\uff0c\u5d4c\u5165\u4e00\u4e2a <code>simulation_parameters</code> \u5b57\u6bb5\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#11","title":"1.1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<pre><code>{\n    // ...\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"DIR_PLASMA_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\", // \u4e3b\u72ec\u7acb\u53c2\u6570 (X\u8f74)\n                \"independent_variable_sampling\": [0.1, 0.3, 0.6, 0.8],\n                \"dependent_variables\": [ \"Startup_Inventory\", \"Required_TBR\" ], // \u56e0\u53d8\u91cf (Y\u8f74)\n                \"simulation_parameters\": {\n                    \"plasma.fb\": [0.02, 0.04, 0.08, 0.09, 0.1], // \u80cc\u666f\u626b\u63cf\u53c2\u6570 (\u751f\u6210\u591a\u6761\u66f2\u7ebf)\n                    \"plasma.nf\": 0.5 // \u56fa\u5b9a\u7684\u80cc\u666f\u53c2\u6570\n                }\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#12","title":"1.2. \u5de5\u4f5c\u539f\u7406","text":"<ul> <li>\u4e3b\u72ec\u7acb\u53c2\u6570 (<code>independent_variable</code>): <code>tep_fep.to_SDS_Fraction[1]</code>\uff0c\u4f5c\u4e3a\u56fe\u8868\u7684 X\u8f74\u3002</li> <li>\u80cc\u666f\u626b\u63cf\u53c2\u6570 (<code>simulation_parameters</code>):<ul> <li><code>plasma.fb</code> \u7684\u503c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u5b83\u5c06\u6210\u4e3a\u56fe\u8868\u4e2d\u7684\u56fe\u4f8b (Legend)\uff0c\u6bcf\u4e00\u6761\u66f2\u7ebf\u5bf9\u5e94 <code>plasma.fb</code> \u7684\u4e00\u4e2a\u53d6\u503c\u3002</li> <li><code>plasma.nf</code> \u7684\u503c\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u5b83\u5c06\u5728\u6240\u6709\u4eff\u771f\u4e2d\u4fdd\u6301\u4e0d\u53d8\u3002</li> </ul> </li> <li>\u6267\u884c\u903b\u8f91: \u7a0b\u5e8f\u4f1a\u6267\u884c\u4e00\u4e2a\u201c\u5d4c\u5957\u5faa\u73af\u201d\u3002\u5bf9\u4e8e <code>independent_variable</code> \u7684\u6bcf\u4e00\u4e2a\u53d6\u503c\uff0c\u7a0b\u5e8f\u4f1a\u4e3a <code>plasma.fb</code> \u7684\u6bcf\u4e00\u4e2a\u503c\u90fd\u8fd0\u884c\u4e00\u6b21\u4eff\u771f\u3002\u603b\u8fd0\u884c\u6b21\u6570\u4e3a <code>len(independent_variable_sampling) * len(plasma.fb)</code>\u3002</li> </ul>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#2","title":"2. \u9ad8\u7ea7\u7528\u6cd5\uff1a\u76ee\u6807\u5bfb\u6c42\u5206\u6790","text":"<p>\u6b64\u529f\u80fd\u652f\u6301\u4e00\u79cd\u201c\u9006\u5411\u201d\u5206\u6790\u6a21\u5f0f\uff0c\u5373\u76ee\u6807\u5bfb\u6c42 (Goal-Seeking)\u3002\u60a8\u53ef\u4ee5\u6307\u5b9a\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u4f5c\u4e3a\u76ee\u6807\uff0c\u53cd\u5411\u6c42\u89e3\u4e3a\u4e86\u8fbe\u5230\u8fd9\u4e2a\u76ee\u6807\uff0c\u67d0\u4e2a\u8f93\u5165\u53c2\u6570\u9700\u8981\u88ab\u8bbe\u7f6e\u6210\u591a\u5c11\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#21","title":"2.1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u5173\u952e\u5728\u4e8e <code>simulation_parameters</code> \u4e2d\u5305\u542b\u4e86\u4e00\u4e2a\u4e0e <code>metrics_definition</code> \u4e2d\u4f18\u5316\u6307\u6807\u540c\u540d\u7684\u7279\u6b8a\u5bf9\u8c61\uff08\u672c\u4f8b\u4e2d\u4e3a <code>Required_TBR</code>\uff09\u3002</p> <pre><code>{\n    \"name\": \"DoubleTime_PLASMA_Analysis\",\n    \"independent_variable\": \"plasma.fb\", // \u4e3b\u72ec\u7acb\u53c2\u6570 (X\u8f74)\n    \"dependent_variables\": [ \"Startup_Inventory\", \"Required_TBR\" ], // \u56e0\u53d8\u91cf (Y\u8f74)\n    \"simulation_parameters\": {\n        \"plasma.nf\": 0.5,\n        \"Required_TBR\": { // \u7279\u6b8a\u7684\u76ee\u6807\u5bfb\u6c42\u914d\u7f6e\n            \"metric_name\": \"Doubling_Time\", // \u76ee\u6807\u6307\u6807\n            \"metric_max_value\": [4380, 8760, 13140, 17530] // \u76ee\u6807\u503c\u7684\u5217\u8868 (\u5355\u4f4d: \u5c0f\u65f6)\n        }\n    },\n    // ...\n    \"metrics_definition\": {\n        // ...\n        \"Required_TBR\": {\n            \"method\": \"bisection_search\",\n            \"parameter_to_optimize\": \"blanket.TBR\", // \u9700\u8981\u6c42\u89e3\u7684\u53c2\u6570\n            // ... (bisection_search \u7684\u5176\u4ed6\u914d\u7f6e)\n        }\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#22","title":"2.2. \u5de5\u4f5c\u539f\u7406","text":"<ul> <li>\u95ee\u9898\u63cf\u8ff0: \u6b64\u914d\u7f6e\u65e8\u5728\u56de\u7b54\uff1a\u201c\u5f53 <code>plasma.fb</code> \u53d8\u5316\u65f6\uff0c\u4e3a\u4e86\u5206\u522b\u5b9e\u73b0\u4e0d\u540c\u7684 <code>Doubling_Time</code> \u76ee\u6807\uff084380h, 8760h, ...\uff09\uff0c\u6211\u4eec\u9700\u8981\u7684 <code>blanket.TBR</code> \u662f\u591a\u5c11\uff1f\u201d</li> <li>\u6267\u884c\u903b\u8f91: \u5bf9\u4e8eX\u8f74\u4e0a\u7684\u6bcf\u4e00\u4e2a <code>plasma.fb</code> \u503c\uff0c\u7a0b\u5e8f\u4f1a\u9488\u5bf9 <code>metric_max_value</code> \u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u76ee\u6807\u503c\u542f\u52a8\u4e00\u6b21 <code>bisection_search</code> \u4f18\u5316\u5faa\u73af\uff0c\u4ee5\u6c42\u89e3\u51fa\u5bf9\u5e94\u7684 <code>blanket.TBR</code> \u503c\u3002</li> <li>\u7ed3\u679c\u89e3\u8bfb: \u6700\u7ec8\u7684\u56fe\u8868\u5c06\u5c55\u793a\uff0c\u5728\u4e0d\u540c\u7684\u500d\u589e\u65f6\u95f4\u76ee\u6807\u7ea6\u675f\u4e0b\uff0c\u6240\u9700\u7684TBR\u662f\u5982\u4f55\u968f\u7740<code>plasma.fb</code>\u53d8\u5316\u7684\u3002</li> </ul>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u4e0e\u5355\u53c2\u6570\u5206\u6790\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\uff1a</p> <ul> <li>\u5bf9\u4e8e\u53c2\u6570\u4ea4\u4e92\u5206\u6790\uff0c\u56fe\u8868\u5c06\u5305\u542b\u4e00\u7ec4\u66f2\u7ebf\uff0c\u56fe\u4f8b\u5bf9\u5e94\u80cc\u666f\u53c2\u6570\uff08\u5982 <code>plasma.fb</code>\uff09\u7684\u4e0d\u540c\u53d6\u503c\u3002</li> <li>\u5bf9\u4e8e\u76ee\u6807\u5bfb\u6c42\u5206\u6790\uff0c\u56fe\u8868\u540c\u6837\u5305\u542b\u591a\u6761\u66f2\u7ebf\uff0c\u4f46\u56fe\u4f8b\u5bf9\u5e94\u7684\u662f\u4e0d\u540c\u7684\u6027\u80fd\u76ee\u6807\u7ea6\u675f\uff08\u5982 <code>Doubling_Time = 4380h</code>\uff09\u3002</li> </ul> <p>\u8fd9\u4f7f\u5f97\u591a\u7ef4\u5ea6\u7684\u6570\u636e\u5173\u7cfb\u80fd\u591f\u88ab\u6e05\u6670\u5730\u5448\u73b0\u5728\u4e00\u5f20\u4e8c\u7ef4\u56fe\u8868\u4e2d\u3002\u62a5\u544a\u7684\u5176\u4ed6\u90e8\u5206\u4e0e\u901a\u7528\u7ed3\u6784\u4e00\u81f4\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#4","title":"4. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/3_multi_parameter_sensitivity_analysis/multi_parameter_sensitivity_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"DIR_PLASMA_Analysis\",                 \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",                 \"independent_variable_sampling\": [0.1,0.3,0.6,0.8],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1],                     \"plasma.nf\":0.5                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             },             {                 \"name\": \"Pulse_PLASMA_Analysis\",                 \"independent_variable\": \"pulseSource.width\",                 \"independent_variable_sampling\": [50,60,70,80,90,99],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1],                     \"plasma.nf\":0.5                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             },             {                 \"name\": \"DoubleTime_PLASMA_Analysis\",                 \"independent_variable\": \"plasma.fb\",                 \"independent_variable_sampling\": [0.02,0.05,0.08,0.1],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.nf\":0.5,                     \"Required_TBR\": {                         \"metric_name\":\"Doubling_Time\",                         \"metric_max_value\": [4380,8760,13140,17530]                     }                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#5-ai","title":"5. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#51","title":"5.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#52","title":"5.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#53","title":"5.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html","title":"\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u662f <code>tricys</code> \u7684\u6838\u5fc3\u529f\u80fd\u4e4b\u4e00\uff0c\u65e8\u5728\u7814\u7a76\u5355\u4e2a\u72ec\u7acb\u53c2\u6570\u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u4e00\u7cfb\u5217\u7528\u6237\u5b9a\u4e49\u7684\u5173\u952e\u6027\u80fd\u6307\u6807 (KPIs)\u3002</p> <p>\u8be5\u529f\u80fd\u4f1a\u81ea\u52a8\u8fd0\u884c\u4e00\u7cfb\u5217\u4eff\u771f\uff08\u6bcf\u6b21\u4eff\u771f\u5bf9\u5e94\u72ec\u7acb\u53c2\u6570\u7684\u4e00\u4e2a\u53d6\u503c\uff09\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u4eff\u771f\u7ed3\u679c\u7684\u6027\u80fd\u6307\u6807\uff0c\u5e76\u751f\u6210\u56fe\u8868\u6765\u76f4\u89c2\u5730\u5c55\u793a\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u7684\u6838\u5fc3\u914d\u7f6e\u4f4d\u4e8e <code>analysis_cases</code> \u5217\u8868\u4e2d\u3002\u6bcf\u4e2a\u5bf9\u8c61\u4ee3\u8868\u4e00\u4e2a\u72ec\u7acb\u7684\u5206\u6790\u6848\u4f8b\u3002</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e: metrics_definition, glossary_path, unit_map)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li><code>independent_variable</code> (\u5b57\u7b26\u4e32): \u8981\u8fdb\u884c\u626b\u63cf\u7684\u72ec\u7acb\u53c2\u6570\u7684\u5b8c\u6574\u6a21\u578b\u8def\u5f84\u3002\u8fd9\u5c06\u662f\u5206\u6790\u56fe\u8868\u7684X\u8f74\u3002</li> <li><code>independent_variable_sampling</code> (\u5217\u8868): \u4e3a\u72ec\u7acb\u53c2\u6570\u63d0\u4f9b\u7684\u4e00\u7ec4\u79bb\u6563\u7684\u626b\u63cf\u503c\u3002\u7a0b\u5e8f\u4f1a\u4e3a\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u503c\u8fd0\u884c\u4e00\u6b21\u4eff\u771f\u3002</li> <li><code>dependent_variables</code> (\u5217\u8868): \u8981\u5206\u6790\u7684\u56e0\u53d8\u91cf\u5217\u8868\uff08\u5373\u5728 <code>metrics_definition</code> \u4e2d\u5b9a\u4e49\u7684\u6307\u6807\u540d\u79f0\uff09\u3002\u8fd9\u5c06\u662f\u5206\u6790\u56fe\u8868\u7684Y\u8f74\u3002</li> <li><code>plot_type</code> (\u5b57\u7b26\u4e32): \u751f\u6210\u7684\u654f\u611f\u6027\u56fe\u8868\u7684\u7c7b\u578b\uff0c\u901a\u5e38\u4e3a <code>\"line\"</code> (\u7ebf\u56fe)\u3002</li> <li><code>combine_plots</code> (\u5e03\u5c14\u503c): \u662f\u5426\u5c06\u591a\u4e2a\u56e0\u53d8\u91cf\u7684\u5206\u6790\u7ed3\u679c\u7ed8\u5236\u5728\u540c\u4e00\u5f20\u56fe\u8868\u4e2d\u3002<code>true</code> \u4f1a\u751f\u6210\u4e00\u5f20\u5305\u542b\u591a\u4e2a\u5b50\u56fe\u7684\u7ec4\u5408\u56fe\uff0c<code>false</code> \u5219\u4e3a\u6bcf\u4e2a\u56e0\u53d8\u91cf\u751f\u6210\u4e00\u5f20\u72ec\u7acb\u7684\u56fe\u3002</li> <li><code>sweep_time</code> (\u5217\u8868): \u4e00\u4e2a\u5305\u542b\u539f\u59cb\u53d8\u91cf\u540d\u7684\u5217\u8868\u3002\u5bf9\u4e8e\u6b64\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\uff0c\u7a0b\u5e8f\u4f1a\u751f\u6210\u4e00\u5f20\u201c\u65cf\u8c31\u56fe\u201d\uff0c\u5373\u5c06\u6bcf\u6b21\u53c2\u6570\u626b\u63cf\u5f97\u5230\u7684\u65f6\u95f4\u6f14\u5316\u66f2\u7ebf\u7ed8\u5236\u5728\u540c\u4e00\u5f20\u56fe\u4e0a\uff0c\u4fbf\u4e8e\u6bd4\u8f83\u52a8\u6001\u884c\u4e3a\u7684\u5dee\u5f02\u3002</li> </ul>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u5206\u6790\u62a5\u544a\u7684\u7ed3\u6784\u4e0e\u901a\u7528\u8bf4\u660e\u4e2d\u63cf\u8ff0\u7684\u7c7b\u4f3c\uff0c\u4f46\u5176\u6838\u5fc3\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a</p> <ul> <li>\u56fe\u8868\u7684X\u8f74\u662f\u60a8\u5b9a\u4e49\u7684 <code>independent_variable</code>\u3002</li> <li>Y\u8f74\u662f <code>dependent_variables</code> \u4e2d\u5b9a\u4e49\u7684\u6027\u80fd\u6307\u6807\u3002</li> <li>\u5982\u679c <code>combine_plots</code> \u4e3a <code>true</code>\uff0c\u62a5\u544a\u5c06\u5305\u542b\u4e00\u5f20\u7ec4\u5408\u56fe\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5b50\u56fe\u5c55\u793a\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u968f\u72ec\u7acb\u53c2\u6570\u53d8\u5316\u7684\u8d8b\u52bf\u3002</li> <li>\u5982\u679c <code>sweep_time</code> \u88ab\u5b9a\u4e49\uff0c\u62a5\u544a\u8fd8\u4f1a\u5305\u542b\u4e00\u5f20\u201c\u65cf\u8c31\u56fe\u201d\uff0c\u5c55\u793a\u539f\u59cb\u53d8\u91cf\uff08\u5982 <code>sds.I[1]</code>\uff09\u5728\u4e0d\u540c\u72ec\u7acb\u53c2\u6570\u53d6\u503c\u4e0b\u7684\u65f6\u95f4\u6f14\u5316\u66f2\u7ebf\u3002</li> </ul>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#4","title":"4. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/2_single_parameter_sensitivity_analysis/single_parameter_sensitivity_analysis.json <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 12000.0,\n        \"step_size\": 0.5\n    },\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"Width_Analysis\",\n                \"independent_variable\": \"pulseSource.width\",\n                \"independent_variable_sampling\": [50,60,70,80,90,99],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"Fueling_Efficiency_Analysis\",\n                \"independent_variable\": \"plasma.nf\",\n                \"independent_variable_sampling\": [0.01,0.05,0.1,0.2,0.4,0.5,0.6,0.7,0.8,0.9],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"Burn_Fraction_Analysis\",\n                \"independent_variable\": \"plasma.fb\",\n                \"independent_variable_sampling\": [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"DIR_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",\n                \"independent_variable_sampling\": [0.1,0.15,0.2,0.3,0.4,0.6,0.8],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05,1.1,1.15,1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"I_ISS_Analysis\",\n                \"independent_variable\": \"i_iss.T\",\n                \"independent_variable_sampling\": [4,6,8,10],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            }\n        ],\n        \"metrics_definition\": {\n            \"Startup_Inventory\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_startup_inventory\"\n            },\n            \"Self_Sufficiency_Time\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"time_of_turning_point\"\n            },\n            \"Doubling_Time\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_doubling_time\"\n            },\n            \"Required_TBR\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"bisection_search\",\n                \"parameter_to_optimize\": \"blanket.TBR\",\n                \"search_range\": [1,1.5],\n                \"tolerance\": 0.005,\n                \"max_iterations\": 10\n            }\n        },\n        \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n        \"unit_map\": {\n            \"Doubling_Time\": {\n                \"unit\": \"days\",\n                \"conversion_factor\": 24\n            },\n            \"Startup_Inventory\": {\n                \"unit\": \"kg\",\n                \"conversion_factor\": 1000\n            },\n            \"Self_Sufficiency_Time\": {\n                \"unit\": \"days\",\n                \"conversion_factor\": 24\n            },\n            \"power\":{\n                \"unit\": \"MW\"\n            },\n            \"period\":{\n                \"unit\": \"hours\"\n            },\n            \"width\":{\n                \"unit\": \"%\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#5-ai","title":"5. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#51","title":"5.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#52","title":"5.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#53","title":"5.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html","title":"SOBOL\u5168\u5c40\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (Global Sensitivity Analysis, GSA) \u662f\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u91cf\u5316\u6a21\u578b\u8f93\u5165\u53c2\u6570\uff08\u4ee5\u53ca\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff09\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002\u4e0e\u4e00\u6b21\u53ea\u6539\u53d8\u4e00\u4e2a\u53c2\u6570\u7684\u5c40\u90e8\u654f\u611f\u6027\u5206\u6790\u4e0d\u540c\uff0cGSA \u4f1a\u540c\u65f6\u5728\u6574\u4e2a\u53c2\u6570\u7a7a\u95f4\u5185\u8fdb\u884c\u63a2\u7d22\u3002</p> <p><code>tricys</code> \u96c6\u6210\u4e86\u4e1a\u754c\u6807\u51c6\u7684 <code>SALib</code> \u5e93\uff0c\u63d0\u4f9b\u4e86\u5bf9 Sobol \u65b9\u6cd5\u7684\u76f4\u63a5\u652f\u6301\u3002Sobol \u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u7684 GSA \u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u9ad8\u6548\u5730\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u53c2\u6570\u5bf9\u6a21\u578b\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u8d21\u732e\u5ea6\uff0c\u5305\u62ec\u53c2\u6570\u7684\u72ec\u7acb\u5f71\u54cd\u548c\u53c2\u6570\u95f4\u7684\u4ea4\u4e92\u5f71\u54cd\u3002</p> <p>\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>SOBOL \u5206\u6790\u7684\u914d\u7f6e\u4e0e\u4e4b\u524d\u7684\u654f\u611f\u6027\u5206\u6790\u6709\u663e\u8457\u4e0d\u540c\uff0c\u4e3b\u8981\u4f53\u73b0\u5728 <code>independent_variable</code> \u53d8\u4e3a\u5217\u8868\uff0c<code>independent_variable_sampling</code> \u53d8\u4e3a\u5bf9\u8c61\uff0c\u5e76\u65b0\u589e\u4e86 <code>analyzer</code> \u5b57\u6bb5\u3002</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_SOBOL_Analysis\",\n                \"independent_variable\": [\"pulseSource.width\", \"plasma.nf\", \"plasma.fb\", \"tep_fep.to_SDS_Fraction[1]\", \"blanket.TBR\"],\n                \"independent_variable_sampling\": {\n                      \"pulseSource.width\": { \"bounds\": [50, 90], \"distribution\": \"unif\" },\n                      \"plasma.nf\": { \"bounds\": [0.1, 0.9], \"distribution\": \"unif\" },\n                      \"plasma.fb\": { \"bounds\": [0.03, 0.07], \"distribution\": \"unif\" },\n                      \"tep_fep.to_SDS_Fraction[1]\": { \"bounds\": [0.1, 0.8], \"distribution\": \"unif\" },\n                      \"blanket.TBR\": { \"bounds\": [1.05, 1.25], \"distribution\": \"unif\" }\n                },\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"analyzer\": {\n                    \"method\": \"sobol\",\n                    \"sample_N\": 256\n                }\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li><code>independent_variable</code> (\u5217\u8868): \u4e00\u4e2a\u5305\u542b\u6240\u6709\u8981\u8fdb\u884c\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u7684\u5217\u8868\u3002</li> <li><code>independent_variable_sampling</code> (\u5bf9\u8c61): \u4e00\u4e2a\u5b57\u5178\uff0c\u4e3a <code>independent_variable</code> \u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u53c2\u6570\u5b9a\u4e49\u5176\u91c7\u6837\u8303\u56f4\u548c\u6982\u7387\u5206\u5e03\u3002</li> <li>\u952e: \u53c2\u6570\u7684\u5b8c\u6574\u8def\u5f84\u3002</li> <li>\u503c: \u5305\u542b <code>bounds</code> (\u5217\u8868 <code>[min, max]</code>) \u548c <code>distribution</code> (\u5b57\u7b26\u4e32, \u5982 <code>\"unif\"</code>) \u7684\u5bf9\u8c61\u3002</li> <li><code>analyzer</code> (\u5bf9\u8c61): \u5b9a\u4e49\u8981\u4f7f\u7528\u7684 GSA \u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u3002</li> <li><code>method</code>: \u5bf9\u4e8e Sobol \u5206\u6790\uff0c\u56fa\u5b9a\u4e3a <code>\"sobol\"</code>\u3002</li> <li><code>sample_N</code>: Sobol \u91c7\u6837\u6240\u9700\u7684\u57fa\u6570 <code>N</code>\u3002<ul> <li>\u26a0\ufe0f \u91cd\u8981: \u5b9e\u9645\u8fd0\u884c\u7684\u4eff\u771f\u603b\u6b21\u6570\u5c06\u662f <code>N * (2D + 2)</code>\uff0c\u5176\u4e2d <code>D</code> \u662f <code>independent_variable</code> \u7684\u6570\u91cf\u3002\u4f8b\u5982\uff0c\u672c\u4f8b\u4e2d <code>D=5</code>, <code>N=256</code>\uff0c\u5219\u603b\u4eff\u771f\u6b21\u6570\u4e3a <code>256 * (2*5 + 2) = 3072</code> \u6b21\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u62a5\u544a\u7684\u6838\u5fc3\u5185\u5bb9\u662f\u9488\u5bf9\u6bcf\u4e00\u4e2a\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u72ec\u7acb\u5206\u6790\u7ed3\u679c\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e <code>Startup_Inventory</code> \u6307\u6807\uff0c\u62a5\u544a\u4f1a\u5305\u542b\uff1a</p> <ol> <li>Sobol\u654f\u611f\u6027\u6307\u6570\u8868: \u4e00\u4e2a Markdown \u8868\u683c\uff0c\u7cbe\u786e\u5217\u51fa\u6bcf\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\uff08S1\uff09\u3001\u603b\u9636\uff08ST\uff09\u654f\u611f\u6027\u6307\u6570\u53ca\u5176\u7f6e\u4fe1\u533a\u95f4\u3002</li> <li>\u654f\u611f\u6027\u6307\u6570\u56fe: \u5d4c\u5165\u7684\u6761\u5f62\u56fe\uff0c\u76f4\u89c2\u5730\u5bf9\u6bd4\u5404\u4e2a\u53c2\u6570\u7684 S1 \u548c ST \u6307\u6570\uff0c\u4fbf\u4e8e\u5feb\u901f\u8bc6\u522b\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002</li> </ol>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#sobol_1","title":"\u5982\u4f55\u89e3\u8bfbSobol\u6307\u6570","text":"<ul> <li>S1 (\u4e00\u9636\u6307\u6570): \u53c2\u6570\u7684\u72ec\u7acb\u8d21\u732e\u3002S1 \u503c\u8d8a\u9ad8\uff0c\u8868\u793a\u8be5\u53c2\u6570\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u76f4\u63a5\u5f71\u54cd\u8d8a\u5927\u3002</li> <li>ST (\u603b\u9636\u6307\u6570): \u53c2\u6570\u7684\u603b\u4f53\u8d21\u732e\uff0c\u5305\u62ec\u5176\u72ec\u7acb\u5f71\u54cd\u4ee5\u53ca\u5b83\u4e0e\u6240\u6709\u5176\u4ed6\u53c2\u6570\u7684\u4ea4\u4e92\u4f5c\u7528\u3002</li> <li>\u4ea4\u4e92\u4f5c\u7528 (Interaction): <code>ST - S1</code> \u7684\u5dee\u503c\u53ef\u4ee5\u8fd1\u4f3c\u8861\u91cf\u8be5\u53c2\u6570\u4e0e\u5176\u4ed6\u53c2\u6570\u7684\u4ea4\u4e92\u6548\u5e94\u5f3a\u5ea6\u3002\u5982\u679c\u4e00\u4e2a\u53c2\u6570\u7684 <code>ST</code> \u8fdc\u5927\u4e8e\u5176 <code>S1</code>\uff0c\u8bf4\u660e\u8be5\u53c2\u6570\u7684\u5f88\u591a\u5f71\u54cd\u662f\u901a\u8fc7\u4e0e\u5176\u4ed6\u53c2\u6570\u7684\u8026\u5408\u3001\u534f\u540c\u4f5c\u7528\u5b9e\u73b0\u7684\u3002</li> <li></li> </ul>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#4","title":"4. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/4_sobol_global_sensitivity_analysis/sobol_global_sensitivity_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"SALIB_SOBOL_Analysis\",                 \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\",\"plasma.fb\",\"tep_fep.to_SDS_Fraction[1]\",\"blanket.TBR\"],                 \"independent_variable_sampling\":{                       \"pulseSource.width\": {                           \"bounds\": [50,90],                           \"distribution\": \"unif\"                       },                       \"plasma.nf\": {                           \"bounds\": [0.1,0.9],                           \"distribution\": \"unif\"                       },                       \"plasma.fb\": {                           \"bounds\": [0.03,0.07],                           \"distribution\": \"unif\"                       },                       \"tep_fep.to_SDS_Fraction[1]\": {                           \"bounds\": [0.1,0.8],                           \"distribution\": \"unif\"                       },                       \"blanket.TBR\": {                           \"bounds\": [1.05, 1.25],                           \"distribution\": \"unif\"                       }                 },                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Self_Sufficiency_Time\",                     \"Doubling_Time\"                 ],                 \"analyzer\": {                     \"method\": \"sobol\",                     \"sample_N\": 256                 }             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#5-ai","title":"5. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#51","title":"5.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#52","title":"5.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#53","title":"5.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_basic/basic_configuration.html","title":"\u57fa\u7840\u914d\u7f6e","text":"<p>TRICYS \u7684\u6240\u6709\u4eff\u771f\u4efb\u52a1\u90fd\u7531\u4e00\u4e2a JSON \u914d\u7f6e\u6587\u4ef6\u9a71\u52a8\u3002\u8fd9\u4e2a\u6587\u4ef6\u8be6\u7ec6\u5b9a\u4e49\u4e86\u6a21\u578b\u8def\u5f84\u3001\u4eff\u771f\u53c2\u6570\u3001\u626b\u63cf\u53d8\u91cf\u4ee5\u53ca\u540e\u5904\u7406\u7b49\u6240\u6709\u73af\u8282\u3002</p> <p>\u672c\u8282\u5c06\u4ecb\u7ecd\u4e00\u4e2a\u6700\u57fa\u7840\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u7528\u4e8e\u8fd0\u884c\u5355\u6b21\u4eff\u771f\u3002\u638c\u63e1\u57fa\u7840\u914d\u7f6e\u662f\u4f7f\u7528 TRICYS \u7684\u7b2c\u4e00\u6b65\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u914d\u7f6e\u6587\u4ef6\u5982\u4e0b\u6240\u793a\uff0c\u5b83\u5b9a\u4e49\u4e86\u8981\u8fd0\u884c\u54ea\u4e2a\u6a21\u578b\u4ee5\u53ca\u5982\u4f55\u8fd0\u884c\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    }\n}\n</code></pre> <p>\u8fd9\u4e2a\u914d\u7f6e\u6587\u4ef6\u5c06\u8fd0\u884c\u4e00\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684\u4eff\u771f\uff0c\u65f6\u957f\u4e3a 2000 \u5c0f\u65f6\uff0c\u6bcf 0.5 \u5c0f\u65f6\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\uff0c\u53ea\u4fdd\u5b58\u65f6\u95f4\u548c SDS \u7cfb\u7edf\u6c1a\u5e93\u5b58\u4e24\u4e2a\u53d8\u91cf\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#2","title":"2. \u5fc5\u987b\u914d\u7f6e\u9879","text":""},{"location":"guides/tricys_basic/basic_configuration.html#21-paths","title":"2.1. <code>paths</code> (\u8def\u5f84\u914d\u7f6e)","text":"<p>\u8fd9\u4e2a\u90e8\u5206\u7528\u4e8e\u5b9a\u4e49\u6240\u6709\u4e0e\u6587\u4ef6\u8def\u5f84\u76f8\u5173\u7684\u8bbe\u7f6e\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#package_path","title":"<code>package_path</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u6307\u5411 Modelica \u6a21\u578b\u7684\u6839 <code>package.mo</code> \u6587\u4ef6\u3002TRICYS \u5c06\u4ece\u8fd9\u91cc\u52a0\u8f7d\u548c\u89e3\u6790\u60a8\u7684\u6a21\u578b\u3002</li> <li>\u8def\u5f84\u7c7b\u578b: \u53ef\u4ee5\u662f\u7edd\u5bf9\u8def\u5f84\uff0c\u4e5f\u53ef\u4ee5\u662f\u76f8\u5bf9\u4e8e\u8be5 JSON \u914d\u7f6e\u6587\u4ef6\u6240\u5728\u4f4d\u7f6e\u7684\u76f8\u5bf9\u8def\u5f84\u3002</li> <li>\u793a\u4f8b:   <pre><code>\"package_path\": \"C:/Models/example_model/package.mo\"  // \u7edd\u5bf9\u8def\u5f84 (Windows)\n\"package_path\": \"/home/user/models/package.mo\"         // \u7edd\u5bf9\u8def\u5f84 (Linux)\n\"package_path\": \"../models/package.mo\"                 // \u76f8\u5bf9\u8def\u5f84\n</code></pre></li> </ul> <p>\u8def\u5f84\u5206\u9694\u7b26</p> <p>\u5728 JSON \u6587\u4ef6\u4e2d\uff0cWindows \u8def\u5f84\u53ef\u4ee5\u4f7f\u7528\u6b63\u659c\u6760 <code>/</code> \u6216\u53cc\u53cd\u659c\u6760 <code>\\\\</code>\uff1a <pre><code>\"package_path\": \"C:/Models/package.mo\"      // \u63a8\u8350\n\"package_path\": \"C:\\\\Models\\\\package.mo\"    // \u4e5f\u53ef\u4ee5\n</code></pre></p>"},{"location":"guides/tricys_basic/basic_configuration.html#22-simulation","title":"2.2. <code>simulation</code> (\u4eff\u771f\u914d\u7f6e)","text":"<p>\u8fd9\u4e2a\u90e8\u5206\u5305\u542b\u4e86\u8fd0\u884c\u4eff\u771f\u6240\u9700\u7684\u6838\u5fc3\u53c2\u6570\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#model_name","title":"<code>model_name</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u8981\u4eff\u771f\u7684\u5b8c\u6574 Modelica \u6a21\u578b\u540d\u79f0\u3002\u5b83\u9075\u5faa <code>\u5305\u540d.\u6a21\u578b\u540d</code> \u7684\u683c\u5f0f\u3002</li> <li>\u683c\u5f0f: <code>&lt;PackageName&gt;.&lt;ModelName&gt;</code></li> <li>\u793a\u4f8b:   <pre><code>\"model_name\": \"example_model.Cycle\"\n</code></pre>   \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c<code>example_model</code> \u662f\u5305\u540d\uff08\u5bf9\u5e94 <code>package.mo</code>\uff09\uff0c<code>Cycle</code> \u662f\u5176\u4e2d\u5b9a\u4e49\u7684\u5177\u4f53\u6a21\u578b\u3002</li> </ul> <p>\u6a21\u578b\u540d\u79f0\u5fc5\u987b\u5b8c\u5168\u5339\u914d</p> <p>\u6a21\u578b\u540d\u79f0\u533a\u5206\u5927\u5c0f\u5199\uff0c\u5fc5\u987b\u4e0e Modelica \u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u540d\u79f0\u5b8c\u5168\u4e00\u81f4\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#variablefilter","title":"<code>variableFilter</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u7528\u4e8e\u7b5b\u9009\u8f93\u51fa\u7ed3\u679c\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u3002\u53ea\u6709\u540d\u79f0\u5339\u914d\u8be5\u8868\u8fbe\u5f0f\u7684\u53d8\u91cf\u624d\u4f1a\u88ab\u4fdd\u5b58\u5230\u6700\u7ec8\u7684 <code>.csv</code> \u7ed3\u679c\u6587\u4ef6\u4e2d\u3002</li> <li>\u683c\u5f0f: \u4f7f\u7528\u7ad6\u7ebf <code>|</code> \u5206\u9694\u591a\u4e2a\u53d8\u91cf\u540d\u6216\u6a21\u5f0f\u3002</li> <li>\u793a\u4f8b:   <pre><code>// \u53ea\u4fdd\u5b58\u65f6\u95f4\u548c\u4e00\u4e2a\u53d8\u91cf\n\"variableFilter\": \"time|sds.I[1]\"\n\n// \u4fdd\u5b58\u65f6\u95f4\u548c\u4e00\u4e2a\u6570\u7ec4\u53d8\u91cf\n\"variableFilter\": \"time|sds.I[1-5]\"\n\n// \u4fdd\u5b58\u591a\u4e2a\u7279\u5b9a\u53d8\u91cf\n\"variableFilter\": \"time|sds.I[1]|blanket.I[1-5]|div.I[1-5]\"\n</code></pre></li> </ul> <p>\u5efa\u8bae</p> <p>\u4e3a\u4e86\u51cf\u5c0f\u8f93\u51fa\u6587\u4ef6\u5927\u5c0f\u548c\u63d0\u9ad8\u6027\u80fd\uff0c\u5efa\u8bae\u53ea\u4fdd\u5b58\u60a8\u771f\u6b63\u9700\u8981\u5206\u6790\u7684\u53d8\u91cf\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#stop_time","title":"<code>stop_time</code> (\u6d6e\u70b9\u6570, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u4eff\u771f\u7684\u603b\u65f6\u957f\uff08\u5355\u4f4d\uff1a\u79d2\uff09\u3002\u4eff\u771f\u5c06\u4ece <code>0</code> \u65f6\u523b\u8fd0\u884c\u5230 <code>stop_time</code>\u3002</li> <li>\u5355\u4f4d: \u5c0f\u65f6</li> </ul>"},{"location":"guides/tricys_basic/basic_configuration.html#step_size","title":"<code>step_size</code> (\u6d6e\u70b9\u6570, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u4eff\u771f\u7684\u65f6\u95f4\u6b65\u957f\uff08\u5355\u4f4d\uff1a\u79d2\uff09\u3002\u8fd9\u4e5f\u662f\u7ed3\u679c\u8f93\u51fa\u7684\u65f6\u95f4\u95f4\u9694\u3002</li> <li>\u6743\u8861: </li> <li>\u8f83\u5c0f\u7684\u6b65\u957f\uff1a\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u4f46\u4eff\u771f\u65f6\u95f4\u66f4\u957f\uff0c\u8f93\u51fa\u6587\u4ef6\u66f4\u5927</li> <li>\u8f83\u5927\u7684\u6b65\u957f\uff1a\u901f\u5ea6\u66f4\u5feb\uff0c\u4f46\u53ef\u80fd\u4e22\u5931\u5feb\u901f\u53d8\u5316\u7684\u7ec6\u8282</li> </ul>"},{"location":"guides/tricys_basic/basic_configuration.html#3","title":"3. \u9ed8\u8ba4\u914d\u7f6e\u9879","text":"<p>\u9664\u4e86\u4e0a\u8ff0\u5fc5\u586b\u9879\uff0cTRICYS \u8fd8\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u53ef\u9009\u914d\u7f6e\uff0c\u5b83\u4eec\u62e5\u6709\u5408\u7406\u7684\u9ed8\u8ba4\u503c\u3002\u4e0d\u8bbe\u7f6e\u8fd9\u4e9b\u9009\u9879\u65f6\uff0c\u7cfb\u7edf\u5c06\u81ea\u52a8\u4f7f\u7528\u4ee5\u4e0b\u9ed8\u8ba4\u884c\u4e3a\uff1a</p>"},{"location":"guides/tricys_basic/basic_configuration.html#31-paths","title":"3.1. <code>paths</code> (\u8def\u5f84\u914d\u7f6e)","text":"\u53c2\u6570 (Parameter) \u63cf\u8ff0 (Description) \u9ed8\u8ba4\u503c (Default Value) <code>results_dir</code> \u7528\u4e8e\u5b58\u653e\u4eff\u771f\u7ed3\u679c\u7684\u76ee\u5f55\u540d\u3002 <code>\"results\"</code> <code>temp_dir</code> \u7528\u4e8e\u5b58\u653e\u4e34\u65f6\u6587\u4ef6\u7684\u76ee\u5f55\u540d\u3002 <code>\"temp\"</code> <code>log_dir</code> \u7528\u4e8e\u5b58\u653e\u65e5\u5fd7\u6587\u4ef6\u7684\u76ee\u5f55\u540d\u3002 <code>\"log\"</code> <code>db_path</code> \u7528\u4e8e\u5b58\u50a8\u548c\u8bfb\u53d6\u6a21\u578b\u53c2\u6570\u7684 SQLite \u6570\u636e\u5e93\u6587\u4ef6\u8def\u5f84\u3002 \u5728\u6bcf\u6b21\u8fd0\u884c\u65f6\u52a8\u6001\u521b\u5efa\u4e8e\u4e34\u65f6\u76ee\u5f55\u4e2d\u3002 <p>\u8f93\u51fa\u76ee\u5f55\u7ed3\u6784</p> <p>TRICYS \u4f1a\u5728\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u4ee5\u65f6\u95f4\u6233\u547d\u540d\u7684\u4e3b\u8fd0\u884c\u76ee\u5f55\uff08\u4f8b\u5982 <code>20250116_103000/</code>\uff09\u3002\u4e0a\u8ff0\u6240\u6709\u8f93\u51fa\u76ee\u5f55\uff08<code>results</code>, <code>temp</code>, <code>log</code>\uff09\u90fd\u5c06\u9ed8\u8ba4\u521b\u5efa\u5728\u8fd9\u4e2a\u65f6\u95f4\u6233\u76ee\u5f55\u5185\u90e8\uff0c\u4ee5\u786e\u4fdd\u6bcf\u6b21\u8fd0\u884c\u7684\u8f93\u51fa\u7ed3\u679c\u90fd\u76f8\u4e92\u9694\u79bb\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#32-simulation","title":"3.2. <code>simulation</code> (\u4eff\u771f\u914d\u7f6e)","text":"\u53c2\u6570 (Parameter) \u63cf\u8ff0 (Description) \u9ed8\u8ba4\u503c (Default Value) <code>concurrent</code> \u662f\u5426\u5f00\u542f\u5e76\u53d1\uff08\u5e76\u884c\uff09\u4eff\u771f\uff0c\u7528\u4e8e\u52a0\u901f\u53c2\u6570\u626b\u63cf\u4efb\u52a1\u3002 <code>false</code> <code>max_workers</code> \u5982\u679c\u5f00\u542f\u5e76\u53d1\uff0c\u6b64\u9009\u9879\u7528\u4e8e\u6307\u5b9a\u6700\u5927\u5e76\u884c\u5de5\u4f5c\u8fdb\u7a0b\u6570\u3002 \u7cfb\u7edf CPU \u6838\u5fc3\u6570\u7684\u4e00\u534a <code>keep_temp_files</code> \u662f\u5426\u5728\u4eff\u771f\u7ed3\u675f\u540e\u4fdd\u7559\u4e34\u65f6\u6587\u4ef6\uff08\u5982\u6a21\u578b\u7f16\u8bd1\u6587\u4ef6\uff09\u3002\u5bf9\u4e8e\u8c03\u8bd5\u975e\u5e38\u6709\u7528\u3002 <code>true</code>"},{"location":"guides/tricys_basic/basic_configuration.html#33-logging","title":"3.3. <code>logging</code> (\u65e5\u5fd7\u914d\u7f6e)","text":"\u53c2\u6570 (Parameter) \u63cf\u8ff0 (Description) \u9ed8\u8ba4\u503c (Default Value) <code>log_level</code> \u65e5\u5fd7\u8bb0\u5f55\u7684\u6700\u4f4e\u7ea7\u522b\u3002\u53ef\u9009\u503c\u5305\u62ec \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"\u3002 <code>\"INFO\"</code> <code>log_to_console</code> \u662f\u5426\u5c06\u65e5\u5fd7\u5b9e\u65f6\u8f93\u51fa\u5230\u63a7\u5236\u53f0\u3002 <code>true</code> <code>log_count</code> \u5728\u65e5\u5fd7\u76ee\u5f55\u4e0b\u4fdd\u7559\u7684\u65e7\u65e5\u5fd7\u6587\u4ef6\u7684\u6700\u5927\u6570\u91cf\u3002 <code>5</code>"},{"location":"guides/tricys_basic/basic_configuration.html#4","title":"4. \u914d\u7f6e\u6a21\u677f","text":"<p>\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u7528\u573a\u666f\u7684\u914d\u7f6e\u6a21\u677f\uff0c\u53ef\u4ee5\u76f4\u63a5\u590d\u5236\u4f7f\u7528\uff1a</p>"},{"location":"guides/tricys_basic/basic_configuration.html#41","title":"4.1 \u5feb\u901f\u6d4b\u8bd5\u6a21\u677f","text":"<p>\u6b64\u6a21\u677f\u9002\u7528\u4e8e\u5feb\u901f\u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u80fd\u6b63\u5e38\u8fd0\u884c\uff0c\u5b83\u4f1a\u4fdd\u5b58\u6240\u6709\u53d8\u91cf\uff0c\u5e76\u4ee5\u8f83\u77ed\u7684\u65f6\u957f\u8fd0\u884c\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"path/to/your/package.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"YourModel.Name\",\n        \"variableFilter\": \"time|.*\",\n        \"stop_time\": 100.0,\n        \"step_size\": 1.0\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#42","title":"4.2 \u751f\u4ea7\u73af\u5883\u6a21\u677f","text":"<p>\u6b64\u6a21\u677f\u9002\u7528\u4e8e\u6b63\u5f0f\u7684\u3001\u957f\u65f6\u95f4\u7684\u4eff\u771f\u3002\u5b83\u53ea\u4fdd\u5b58\u5173\u952e\u53d8\u91cf\uff0c\u5c06\u7ed3\u679c\u8f93\u51fa\u5230\u6307\u5b9a\u7684\u751f\u4ea7\u76ee\u5f55\uff0c\u5e76\u914d\u7f6e\u4e86\u66f4\u4e25\u683c\u7684\u65e5\u5fd7\u8bb0\u5f55\u548c\u8c03\u8bd5\u9009\u9879\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"path/to/your/package.mo\",\n        \"results_dir\": \"production_results\"\n    },\n    \"simulation\": {\n        \"model_name\": \"YourModel.Name\",\n        \"variableFilter\": \"time|key_var1|key_var2\",\n        \"stop_time\": 86400.0,\n        \"step_size\": 10.0,\n        \"keep_temp_files\": false\n    },\n    \"logging\": {\n        \"log_level\": \"INFO\",\n        \"log_to_console\": false,\n        \"log_count\": 10\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#5","title":"5. \u5982\u4f55\u8fd0\u884c","text":"<p>\u914d\u7f6e\u597d\u6587\u4ef6\u540e\uff0c\u6709\u4e24\u79cd\u65b9\u5f0f\u8fd0\u884c\u4eff\u771f\uff1a</p>"},{"location":"guides/tricys_basic/basic_configuration.html#51","title":"5.1. \u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\u6587\u4ef6","text":"<p>\u5c06\u914d\u7f6e\u6587\u4ef6\u4fdd\u5b58\u4e3a <code>config.json</code> \u5e76\u653e\u5728\u9879\u76ee\u6839\u76ee\u5f55\uff1a</p> <pre><code>tricys\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#52","title":"5.2. \u6307\u5b9a\u914d\u7f6e\u6587\u4ef6","text":"<pre><code>tricys -c my_config.json\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#6","title":"6. \u67e5\u770b\u7ed3\u679c","text":"<p>\u4eff\u771f\u5b8c\u6210\u540e\uff0c\u7ed3\u679c\u4fdd\u5b58\u5728\u65f6\u95f4\u6233\u5b50\u76ee\u5f55{timestamp}\u4e2d\uff1a</p> <pre><code>Working Directory/\n\u2514\u2500\u2500 {timestamp}/\n    \u251c\u2500\u2500 log/        \n        \u2514\u2500\u2500 simulation_{timestamp}.log  # \u8fd0\u884c\u65e5\u5fd7\n    \u251c\u2500\u2500 result/                 \n        \u2514\u2500\u2500 simulation_result.csv       # \u4eff\u771f\u7ed3\u679c\u6570\u636e\n    \u2514\u2500\u2500 temp/\n        \u2514\u2500\u2500 job_1/                      # \u4e34\u65f6\u4efb\u52a1\u6570\u636e\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#61-python","title":"6.1. \u4f7f\u7528 Python \u5206\u6790\u7ed3\u679c","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# \u8bfb\u53d6\u7ed3\u679c\ndf = pd.read_csv('results/20250116_103000/simulation_result.csv')\n\n# \u67e5\u770b\u6570\u636e\nprint(df.head())\nprint(f\"\u4eff\u771f\u65f6\u957f: {df['time'].max()} \u79d2\")\nprint(f\"\u6700\u7ec8\u6c1a\u5e93\u5b58: {df['sds.I[1]'].iloc[-1]:.2f} g\")\n\n# \u7ed8\u5236\u6c1a\u5e93\u5b58\u53d8\u5316\u66f2\u7ebf\nplt.figure(figsize=(10, 6))\nplt.plot(df['time'], df['sds.I[1]'], label='SDS \u6c1a\u5e93\u5b58')\nplt.xlabel('\u65f6\u95f4 (\u79d2)')\nplt.ylabel('\u6c1a\u5e93\u5b58 (g)')\nplt.title('\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf\u6c1a\u5e93\u5b58\u968f\u65f6\u95f4\u53d8\u5316')\nplt.legend()\nplt.grid(True)\nplt.savefig('inventory_plot.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#62-excel","title":"6.2. \u4f7f\u7528 Excel \u67e5\u770b","text":"<p>\u76f4\u63a5\u7528 Microsoft Excel \u6216 LibreOffice Calc \u6253\u5f00 <code>simulation_result.csv</code> \u6587\u4ef6\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#7","title":"7. \u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u4e86\u57fa\u7840\u914d\u7f6e\u540e\uff0c\u60a8\u53ef\u4ee5\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>\u53c2\u6570\u626b\u63cf\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u53c2\u6570\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd</li> <li>\u5e76\u53d1\u8fd0\u884c\uff1a\u52a0\u901f\u5927\u89c4\u6a21\u4eff\u771f</li> <li>\u540e\u5904\u7406\u6a21\u5757\uff1a\u81ea\u52a8\u5206\u6790\u548c\u62a5\u544a\u751f\u6210</li> <li>\u534f\u540c\u4eff\u771f\uff1a\u4e0e\u5916\u90e8\u8f6f\u4ef6\u96c6\u6210</li> </ul>"},{"location":"guides/tricys_basic/co_simulation_module.html","title":"\u534f\u540c\u4eff\u771f\u6a21\u5757","text":"<p>\u534f\u540c\u4eff\u771f\uff08Co-Simulation\uff09\u662f <code>tricys</code> \u4e2d\u4e00\u9879\u9ad8\u7ea7\u4e14\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u5b83\u5141\u8bb8 Modelica \u6a21\u578b\u4e0e\u5916\u90e8\u7a0b\u5e8f\uff08\u5982 Aspen Plus, MATLAB, \u6216\u81ea\u5b9a\u4e49\u7684 Python \u811a\u672c\uff09\u8fdb\u884c\u4ea4\u4e92\uff0c\u5b9e\u73b00\u7ef4\u7cfb\u7edf\u6a21\u578b\u4e0e3\u7ef4\u5b50\u6a21\u5757\u591a\u7269\u7406\u573a\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u96c6\u6210\u3002</p> <p>\u8fd9\u5bf9\u4e8e\u4ee5\u4e0b\u573a\u666f\u5c24\u5176\u6709\u7528\uff1a</p> <ul> <li>\u67d0\u4e2a\u5b50\u7cfb\u7edf\u7684\u6a21\u578b\u5728\u53e6\u4e00\u4e2a\u4e13\u4e1a\u8f6f\u4ef6\u4e2d\u5df2\u7ecf\u5b58\u5728\u4e14\u975e\u5e38\u6210\u719f\u3002</li> <li>\u5b50\u7cfb\u7edf\u7684\u884c\u4e3a\u975e\u5e38\u590d\u6742\uff0c\u96be\u4ee5\u7528 Modelica \u8bed\u8a00\u76f4\u63a5\u63cf\u8ff0\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u5916\u90e8\u8ba1\u7b97\u5f97\u5230\u3002</li> </ul>"},{"location":"guides/tricys_basic/co_simulation_module.html#1","title":"1. \u5de5\u4f5c\u6d41\u7a0b","text":"<p>\u534f\u540c\u4eff\u771f\u7684\u6838\u5fc3\u601d\u60f3\u662f\u201c\u8fd0\u884c-\u5904\u7406-\u518d\u8fd0\u884c\u201d (Run-Process-Rerun)\u3002</p> <pre><code>graph LR\n    A[1.\u521d\u6b65\u4eff\u771f] --&gt; B[(\u7ed3\u679c)];\n    B --&gt; C[2.\u5916\u90e8\u5904\u7406\u5668 Handler ];\n    C --&gt; D[(\u65b0\u6570\u636e)];\n    D --&gt; E[3.\u6ce8\u5165\u65b0\u6570\u636e];\n    E --&gt; F[4.\u6700\u7ec8\u5b8c\u6574\u4eff\u771f];\n\n    style A fill:#A6C8FF\n    style C fill:#FFDDA6\n    style F fill:#A6FFC8</code></pre> <ol> <li>\u521d\u6b65\u4eff\u771f (Primary Run): <code>tricys</code> \u9996\u5148\u8fd0\u884c\u4e00\u4e2a\u4e0d\u5305\u542b\u88ab\u66ff\u4ee3\u5b50\u7cfb\u7edf\u7684\u521d\u6b65\u4eff\u771f\u3002</li> <li>\u8c03\u7528\u5904\u7406\u5668 (Call Handlers): \u521d\u6b65\u4eff\u771f\u7684\u7ed3\u679c\u88ab\u4f20\u9012\u7ed9\u4e00\u4e2a\u6216\u591a\u4e2a\u7528\u6237\u5b9a\u4e49\u7684\u201c\u5904\u7406\u5668\u201d(Handler)\u3002</li> <li>\u5916\u90e8\u8ba1\u7b97: \u5904\u7406\u5668\u51fd\u6570\u63a5\u6536\u7ed3\u679c\uff0c\u5e76\u8c03\u7528\u5916\u90e8\u7a0b\u5e8f\uff08\u5982 Aspen\uff09\u6216\u6267\u884c\u5185\u90e8\u7b97\u6cd5\uff0c\u8ba1\u7b97\u51fa\u65b0\u7684\u6570\u636e\u3002</li> <li>\u6570\u636e\u6ce8\u5165 (Injection): \u5904\u7406\u5668\u8fd4\u56de\u4e00\u4e2a\u6570\u636e\u5b57\u5178\u3002<code>tricys</code> \u4f1a\u52a8\u6001\u5730\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u9876\u5c42\u6a21\u578b\uff0c\u7528 <code>CombiTimeTable</code> (\u6570\u636e\u8868) \u6a21\u5757\u66ff\u6362\u6389\u539f\u6765\u7684\u5b50\u7cfb\u7edf\uff0c\u5e76\u5c06\u5904\u7406\u5668\u8fd4\u56de\u7684\u6570\u636e\u4f5c\u4e3a\u8fd9\u4e2a\u6570\u636e\u8868\u7684\u5185\u5bb9\u3002</li> <li>\u6700\u7ec8\u4eff\u771f (Final Run): <code>tricys</code> \u8fd0\u884c\u8fd9\u4e2a\u88ab\u52a8\u6001\u4fee\u6539\u8fc7\u7684\u3001\u5305\u542b\u6ce8\u5165\u6570\u636e\u7684\u65b0\u6a21\u578b\uff0c\u4ece\u800c\u5b8c\u6210\u4e00\u6b21\u5b8c\u6574\u7684\u534f\u540c\u4eff\u771f\u3002</li> </ol>"},{"location":"guides/tricys_basic/co_simulation_module.html#2","title":"2. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u901a\u8fc7\u5728 <code>config.json</code> \u4e2d\u5b9a\u4e49 <code>co_simulation</code> \u5b57\u6bb5\u6765\u542f\u7528\u6b64\u529f\u80fd\u3002</p> <pre><code>{\n    \"paths\": { ... },\n    \"simulation\": { ... },\n    \"simulation_parameters\": { ... },\n    \"co_simulation\": {\n        \"mode\": \"replacement\",\n        \"handlers\":[\n            {\n                \"submodel_name\": \"example_model.I_ISS\",\n                \"instance_name\": \"i_iss\",\n                \"handler_module\": \"tricys.handlers.i_iss_handler\",\n                \"handler_function\": \"run_dummy_simulation\",\n                \"params\": {\n                    \"description\": \"This is a dummy handler for i_iss.\",\n                    \"dummy_value\": 123.45\n                }\n            },\n            {\n                \"submodel_name\": \"example_model.DIV\",\n                \"instance_name\": \"div\",\n                \"handler_module\": \"tricys.handlers.div_handler\",\n                \"handler_function\": \"run_div_simulation\",\n                \"params\": {\n                    \"description\": \"This is a dummy handler for i_iss.\",\n                    \"dummy_value\": 123.45\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/co_simulation_module.html#3","title":"3. \u914d\u7f6e\u9879\u8be6\u89e3","text":""},{"location":"guides/tricys_basic/co_simulation_module.html#31-co_simulation","title":"3.1. <code>co_simulation</code> (\u9876\u5c42\u5bf9\u8c61)","text":"\u53c2\u6570 (Parameter) \u7c7b\u578b\u4e0e\u8981\u6c42 \u63cf\u8ff0 <code>mode</code> \u5b57\u7b26\u4e32, \u9009\u586b \u5b9a\u4e49\u534f\u540c\u4eff\u771f\u7684\u96c6\u6210\u6a21\u5f0f\u3002\u9ed8\u8ba4\u4e3a <code>\"interceptor\"</code>\u3002 <code>handlers</code> \u5217\u8868, \u5fc5\u586b \u4e00\u4e2a\u6216\u591a\u4e2a\u201c\u5904\u7406\u5668\u914d\u7f6e\u5bf9\u8c61\u201d\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5bf9\u8c61\u5b9a\u4e49\u5982\u4f55\u5904\u7406\u4e00\u4e2a\u7279\u5b9a\u7684\u5b50\u6a21\u578b\u3002"},{"location":"guides/tricys_basic/co_simulation_module.html#32-mode","title":"3.2. <code>mode</code> (\u96c6\u6210\u6a21\u5f0f)","text":"<p><code>mode</code> \u5b57\u6bb5\u51b3\u5b9a\u4e86 <code>tricys</code> \u5982\u4f55\u5c06\u5916\u90e8\u8ba1\u7b97\u7ed3\u679c\u96c6\u6210\u56de Modelica \u6a21\u578b\u4e2d\u3002</p> <ul> <li> <p><code>\"interceptor\"</code> (\u9ed8\u8ba4\u6a21\u5f0f):</p> <ul> <li>\u975e\u4fb5\u5165\u5f0f\u3002\u5b83\u4f1a\u4e3a\u76ee\u6807\u5b50\u6a21\u578b\u751f\u6210\u4e00\u4e2a\u201c\u62e6\u622a\u5668\u201d\u5305\u88f9\u6a21\u578b\uff0c\u5e76\u5728\u4e00\u4e2a\u65b0\u7684\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u4e2d\u91cd\u5b9a\u5411\u8fde\u63a5\u3002</li> <li>\u4f18\u70b9: \u539f\u59cb\u6a21\u578b\u6587\u4ef6\uff08\u5305\u62ec\u5b50\u6a21\u578b\u548c\u9876\u5c42\u6a21\u578b\uff09\u90fd\u4fdd\u6301\u4e0d\u53d8\uff0c\u5b89\u5168\u6027\u9ad8\u3002</li> <li>\u9002\u7528\u573a\u666f: \u63a8\u8350\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f7f\u7528\uff0c\u5c24\u5176\u662f\u5f53\u60a8\u4e0d\u5e0c\u671b\u4fee\u6539\u539f\u59cb\u6a21\u578b\u5e93\u65f6\u3002</li> </ul> </li> <li> <p><code>\"replacement\"</code>:</p> <ul> <li>\u4fb5\u5165\u5f0f\u3002\u5b83\u4f1a\u76f4\u63a5\u4fee\u6539\u76ee\u6807\u5b50\u6a21\u578b\u7684 <code>.mo</code> \u6587\u4ef6\uff08\u4f1a\u521b\u5efa <code>.bak</code> \u5907\u4efd\uff09\uff0c\u5c06\u5176\u5185\u90e8\u903b\u8f91\u5b8c\u5168\u66ff\u6362\u4e3a\u4eceCSV\u6587\u4ef6\u8bfb\u53d6\u6570\u636e\u7684\u903b\u8f91\u3002</li> <li>\u4f18\u70b9: \u5b9e\u73b0\u66f4\u76f4\u63a5\uff0c\u4e0d\u9700\u8981\u751f\u6210\u65b0\u7684\u9876\u5c42\u6a21\u578b\u3002</li> <li>\u9002\u7528\u573a\u666f: \u5f53\u60a8\u5e0c\u671b\u5bf9\u5b50\u6a21\u578b\u8fdb\u884c\u6c38\u4e45\u6027\u6216\u534a\u6c38\u4e45\u6027\u7684\u884c\u4e3a\u66ff\u6362\uff0c\u6216\u8005\u5728\u67d0\u4e9b\u590d\u6742\u7684\u6a21\u578b\u7ed3\u6784\u4e2d\uff0c\u201c\u62e6\u622a\u5668\u201d\u6a21\u5f0f\u96be\u4ee5\u5b9e\u73b0\u8fde\u63a5\u91cd\u8def\u7531\u65f6\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_basic/co_simulation_module.html#33-handlers","title":"3.3. <code>handlers</code> (\u914d\u7f6e\u5bf9\u8c61\u5217\u8868)","text":"<p><code>handlers</code> \u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u66ff\u6362\u4efb\u52a1\u3002</p> \u53c2\u6570 (Parameter) \u7c7b\u578b\u4e0e\u8981\u6c42 \u63cf\u8ff0 <code>submodel_name</code> \u5b57\u7b26\u4e32, \u5fc5\u586b \u8981\u88ab\u5916\u90e8\u5904\u7406\u5668\u66ff\u4ee3\u7684\u5b50\u6a21\u578b\u7684\u5b8c\u6574 Modelica \u7c7b\u8def\u5f84\u3002\u4f8b\u5982 <code>example_model.DIV</code>\u3002 <code>instance_name</code> \u5b57\u7b26\u4e32, \u5fc5\u586b \u8be5\u5b50\u6a21\u578b\u5728\u9876\u5c42\u4eff\u771f\u6a21\u578b (<code>simulation.model_name</code>) \u4e2d\u7684\u5b9e\u4f8b\u540d\u3002\u4f8b\u5982\uff0c\u5982\u679c\u9876\u5c42\u6a21\u578b\u4e2d\u6709 <code>DIV div;</code>\uff0c\u90a3\u4e48\u8fd9\u91cc\u7684 <code>instance_name</code> \u5c31\u662f <code>div</code>\u3002 <code>handler_script_path</code> \u5b57\u7b26\u4e32, \u63a8\u8350 \u6307\u5411\u5305\u542b\u5904\u7406\u5668\u903b\u8f91\u7684 Python \u811a\u672c\u6587\u4ef6\u7684\u76f8\u5bf9\u6216\u7edd\u5bf9\u8def\u5f84\u3002\u8fd9\u662f\u6307\u5b9a\u5904\u7406\u5668\u7684\u9996\u9009\u65b9\u6cd5\u3002 <code>handler_module</code> \u5b57\u7b26\u4e32, \u517c\u5bb9 \u5305\u542b\u5904\u7406\u5668\u903b\u8f91\u7684 Python \u6a21\u5757\u7684\u8def\u5f84\uff08\u4f8b\u5982 <code>tricys.handlers.div_handler</code>\uff09\u3002\u7528\u4e8e\u5411\u540e\u517c\u5bb9\u3002\u5982\u679c\u540c\u65f6\u63d0\u4f9b\u4e86 <code>handler_script_path</code>\uff0c\u5219\u4f18\u5148\u4f7f\u7528\u811a\u672c\u8def\u5f84\u3002 <code>handler_function</code> \u5b57\u7b26\u4e32, \u5fc5\u586b \u5728\u5904\u7406\u5668\u811a\u672c\u6216\u6a21\u5757\u4e2d\u8981\u8c03\u7528\u7684\u51fd\u6570\u540d\u3002 <code>params</code> \u5b57\u5178, \u9009\u586b \u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u4e2d\u5305\u542b\u7684\u952e\u503c\u5bf9\u5c06\u4f5c\u4e3a\u5173\u952e\u5b57\u53c2\u6570\u4f20\u9012\u7ed9\u5904\u7406\u5668\u51fd\u6570\u3002"},{"location":"guides/tricys_basic/co_simulation_module.html#4","title":"4. \u7ed3\u679c\u8f93\u51fa","text":"<p>\u534f\u540c\u4eff\u771f\u7684\u6700\u7ec8\u8f93\u51fa\u4e0e\u6807\u51c6\u4eff\u771f\u7c7b\u4f3c\uff0c\u4f1a\u6839\u636e\u4efb\u52a1\u6570\u91cf\u5728\u7ed3\u679c\u76ee\u5f55 (<code>results_dir</code>) \u4e2d\u751f\u6210\u4e00\u4e2a\u5408\u5e76\u7684 CSV \u6587\u4ef6\uff1a</p> <ul> <li>\u5355\u6b21\u8fd0\u884c: <code>simulation_result.csv</code></li> <li>\u53c2\u6570\u626b\u63cf: <code>sweep_results.csv</code></li> </ul> <p>\u5728\u8fd9\u4e2a\u6587\u4ef6\u4e2d\uff0c\u88ab\u5916\u90e8\u5904\u7406\u5668\u66ff\u4ee3\u7684\u5b50\u6a21\u5757\u7684\u76f8\u5173\u53d8\u91cf\u5217\uff0c\u5176\u6570\u636e\u5c06\u6765\u6e90\u4e8e\u60a8\u7684\u5904\u7406\u5668\u51fd\u6570\u7684\u8ba1\u7b97\u7ed3\u679c\uff0c\u800c\u4e0d\u662f\u539f\u59cb Modelica \u6a21\u578b\u7684\u8ba1\u7b97\u7ed3\u679c\u3002</p>"},{"location":"guides/tricys_basic/co_simulation_module.html#5","title":"5. \u81ea\u5b9a\u4e49\u5904\u7406\u5668","text":"<p>\u8981\u771f\u6b63\u53d1\u6325\u534f\u540c\u4eff\u771f\u7684\u5a01\u529b\uff0c\u60a8\u9700\u8981\u521b\u5efa\u81ea\u5df1\u7684\u5904\u7406\u5668\u51fd\u6570\u3002</p>"},{"location":"guides/tricys_basic/co_simulation_module.html#51","title":"5.1. \u5904\u7406\u5668\u51fd\u6570\u89c4\u8303","text":"<p>\u60a8\u7684\u5904\u7406\u5668\u5fc5\u987b\u9075\u5faa\u4ee5\u4e0b\u89c4\u8303\uff1a</p> <ol> <li> <p>\u51fd\u6570\u7b7e\u540d:     <pre><code>def my_handler(temp_input_csv: str, temp_output_csv: str, **params) -&gt; dict:\n    # ... \u51fd\u6570\u4f53 ...\n</code></pre></p> <ul> <li><code>temp_input_csv</code>: <code>tricys</code> \u4f20\u5165\u7684 \u8f93\u5165\u6587\u4ef6\u8def\u5f84\u3002\u8be5 CSV \u6587\u4ef6\u5305\u542b\u4e86\u7b2c\u4e00\u9636\u6bb5\u4eff\u771f\u8bb0\u5f55\u7684\u3001\u5b50\u6a21\u5757\u6240\u9700\u7684\u6240\u6709\u8f93\u5165\u7aef\u53e3\u6570\u636e\u3002</li> <li><code>temp_output_csv</code>: \u60a8\u9700\u8981\u5c06\u8ba1\u7b97\u7ed3\u679c\u5199\u5165\u7684 \u8f93\u51fa\u6587\u4ef6\u8def\u5f84\u3002</li> <li><code>**params</code>: \u4e00\u4e2a\u5b57\u5178\uff0c\u5305\u542b\u4e86\u60a8\u5728 <code>config.json</code> \u4e2d\u4e3a\u8be5\u5904\u7406\u5668\u914d\u7f6e\u7684\u6240\u6709 <code>params</code>\u3002</li> </ul> </li> <li> <p>\u6838\u5fc3\u903b\u8f91:</p> <ul> <li>\u4f7f\u7528 <code>pandas</code> \u6216\u5176\u4ed6\u5e93\u8bfb\u53d6 <code>temp_input_csv</code> \u7684\u6570\u636e\u3002</li> <li>\u6267\u884c\u60a8\u7684\u6838\u5fc3\u8ba1\u7b97\u903b\u8f91\u3002</li> <li>\u5c06\u7ed3\u679c\uff08\u5fc5\u987b\u5305\u542b 'time' \u5217\uff09\u4fdd\u5b58\u5230 <code>temp_output_csv</code> \u8def\u5f84\u3002</li> </ul> </li> <li> <p>\u8fd4\u56de\u503c (\u91cd\u8981):</p> <ul> <li>\u51fd\u6570 \u5fc5\u987b \u8fd4\u56de\u4e00\u4e2a\u5b57\u5178\uff0c\u8be5\u5b57\u5178\u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u60a8\u8f93\u51fa\u7684 CSV \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5217\u6620\u5c04\u5230 Modelica \u5b50\u6a21\u5757\u7684\u8f93\u51fa\u7aef\u53e3\u3002</li> <li>\u952e (key): Modelica \u5b50\u6a21\u5757\u7684\u8f93\u51fa\u7aef\u53e3\u540d (\u5b57\u7b26\u4e32)\u3002</li> <li>\u503c (value): \u4e00\u4e2a\u8868\u793a Modelica \u6570\u7ec4\u7684\u5b57\u7b26\u4e32\uff0c\u683c\u5f0f\u4e3a <code>\"{t, y1, y2, ...}\"</code>\u3002\u5176\u4e2d <code>t</code> \u662f <code>time</code> \u5217\u7684\u7d22\u5f15\uff08\u901a\u5e38\u662f1\uff09\uff0c<code>y1</code>, <code>y2</code>... \u662f\u5bf9\u5e94\u7aef\u53e3\u5404\u7ef4\u5ea6\u6570\u636e\u5217\u7684\u7d22\u5f15\u3002</li> </ul> </li> </ol>"},{"location":"guides/tricys_basic/co_simulation_module.html#52","title":"5.2. \u5904\u7406\u5668\u793a\u4f8b","text":"<p>\u5047\u8bbe\u6211\u4eec\u8981\u66ff\u6362\u7684 Modelica \u5b50\u6a21\u5757 <code>MySubModel</code> \u6709\u4e00\u4e2a5\u7ef4\u8f93\u51fa\u7aef\u53e3 <code>to_O_ISS</code>\u3002</p> <p><code>my_div_handler.py</code>: <pre><code>import pandas as pd\n\ndef run_div_simulation(temp_input_csv: str, temp_output_csv: str, **params) -&gt; dict:\n    \"\"\"\n    \u4e00\u4e2a\u7b80\u5355\u7684\u5904\u7406\u5668\u793a\u4f8b\u3002\n    \u5b83\u8bfb\u53d6\u8f93\u5165\uff0c\u5c06\u6240\u6709\u8f93\u5165\u503c\u4e58\u4ee5\u4e00\u4e2a\u6765\u81ea\u914d\u7f6e\u7684\u56e0\u5b50\uff0c\u7136\u540e\u5199\u56de\u3002\n    \"\"\"\n    # \u6253\u5370\u4ece config.json \u4f20\u5165\u7684\u53c2\u6570\n    factor = params.get(\"factor\", 1.0)\n    print(f\"Running DIV handler with factor: {factor}\")\n\n    # 1. \u8bfb\u53d6\u8f93\u5165\u6570\u636e\n    input_df = pd.read_csv(temp_input_csv)\n\n    # 2. \u6267\u884c\u8ba1\u7b97 (\u793a\u4f8b\uff1a\u5c06\u6240\u6709\u8f93\u5165\u4e58\u4ee5\u56e0\u5b50)\n    # \u5047\u8bbe\u8f93\u5165\u7aef\u53e3\u540d\u4e3a 'div.from_plasma[1]' \u5230 '[5]'\n    output_df = pd.DataFrame()\n    output_df['time'] = input_df['time']\n    for i in range(1, 6):\n        input_col_name = f'div.from_plasma[{i}]'\n        output_col_name = f'to_O_ISS_{i}' # \u5728CSV\u4e2d\u81ea\u5b9a\u4e49\u5217\u540d\n        if input_col_name in input_df.columns:\n            output_df[output_col_name] = input_df[input_col_name] * factor\n        else:\n            output_df[output_col_name] = 0 # \u5982\u679c\u8f93\u5165\u4e0d\u5b58\u5728\uff0c\u5219\u8f93\u51fa0\n\n    # 3. \u5c06\u7ed3\u679c\u5199\u5165\u6307\u5b9a\u7684\u8f93\u51faCSV\u6587\u4ef6\n    output_df.to_csv(temp_output_csv, index=False)\n\n    # 4. \u8fd4\u56de\u7aef\u53e3\u5230CSV\u5217\u7684\u6620\u5c04\n    # CSV\u67096\u5217: time, to_O_ISS_1, ..., to_O_ISS_5\n    # Modelica\u7aef\u53e3 to_O_ISS \u662f5\u7ef4\u7684\n    # \u6620\u5c04\u5173\u7cfb:\n    # time -&gt; column 1\n    # to_O_ISS[1] -&gt; column 2 (to_O_ISS_1)\n    # to_O_ISS[2] -&gt; column 3 (to_O_ISS_2)\n    # ...\n    # to_O_ISS[5] -&gt; column 6 (to_O_ISS_5)\n    return {\n        \"to_O_ISS\": \"{1,2,3,4,5,6}\"\n    }\n</code></pre></p>"},{"location":"guides/tricys_basic/co_simulation_module.html#53","title":"5.3. \u66f4\u65b0\u914d\u7f6e\u6587\u4ef6","text":"<p>\u73b0\u5728\uff0c\u60a8\u53ef\u4ee5\u66f4\u65b0 <code>config.json</code> \u6765\u4f7f\u7528\u8fd9\u4e2a\u65b0\u7684\u672c\u5730\u5904\u7406\u5668\u811a\u672c\u3002\u6211\u4eec\u63a8\u8350\u4f7f\u7528 <code>handler_script_path</code>\uff0c\u56e0\u4e3a\u5b83\u6bd4 <code>handler_module</code> \u66f4\u76f4\u63a5\u3002</p> <p>\u540c\u65f6\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u660e\u786e\u6307\u5b9a\u534f\u540c\u4eff\u771f\u7684 <code>mode</code>\u3002</p> <pre><code>{\n    ...\n    \"co_simulation\": {\n        \"mode\": \"interceptor\", // \"interceptor\" (\u9ed8\u8ba4) \u6216 \"replacement\"\n        \"handlers\": [\n            {\n                \"submodel_name\": \"example_model.DIV\",\n                \"instance_name\": \"div\",\n                \"handler_script_path\": \"path/to/my_div_handler.py\", // \u4f7f\u7528\u811a\u672c\u8def\u5f84\n                \"handler_function\": \"run_div_simulation\",\n                \"params\": {\n                    \"factor\": 1.5 // \u4f20\u9012\u7ed9\u51fd\u6570\u7684\u81ea\u5b9a\u4e49\u53c2\u6570\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/co_simulation_module.html#6","title":"6. \u9ad8\u7ea7\uff1a\u539f\u7406\u89e3\u8bf4","text":"<ul> <li>\u534f\u540c\u4eff\u771f\uff1a\u534f\u540c\u4eff\u771f\u4e2d\u4e24\u79cd\u5c06\u5916\u90e8\u6570\u636e\u6ce8\u5165 Modelica \u6a21\u578b\u7684\u65b9\u6cd5\u3002</li> </ul>"},{"location":"guides/tricys_basic/concurrent_operation.html","title":"\u5e76\u53d1\u8fd0\u884c","text":"<p>\u5bf9\u4e8e\u5305\u542b\u5927\u91cf\u4eff\u771f\u4efb\u52a1\u7684\u53c2\u6570\u626b\u63cf\uff0c\u9010\u4e2a\u987a\u5e8f\u6267\u884c\u53ef\u80fd\u4f1a\u975e\u5e38\u8017\u65f6\u3002<code>tricys</code> \u652f\u6301\u5e76\u53d1\u8fd0\u884c\uff08\u5e76\u884c\u8ba1\u7b97\uff09\uff0c\u53ef\u4ee5\u5145\u5206\u5229\u7528\u60a8\u8ba1\u7b97\u673a\u7684\u591a\u4e2a CPU \u6838\u5fc3\uff0c\u663e\u8457\u7f29\u77ed\u603b\u4eff\u771f\u65f6\u95f4\u3002</p>"},{"location":"guides/tricys_basic/concurrent_operation.html#1","title":"1. \u5982\u4f55\u542f\u7528\u5e76\u53d1","text":"<p>\u542f\u7528\u5e76\u53d1\u975e\u5e38\u7b80\u5355\uff0c\u53ea\u9700\u5728\u914d\u7f6e\u6587\u4ef6\u7684 <code>simulation</code> \u90e8\u5206\u5c06 <code>concurrent</code> \u6807\u5fd7\u8bbe\u7f6e\u4e3a <code>true</code>\u3002</p> <pre><code>{\n    \"paths\": {\n        ...\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        ...\n        \"concurrent\": true,\n        \"max_workers\": 4\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/concurrent_operation.html#2","title":"2. \u914d\u7f6e\u9879\u8be6\u89e3","text":""},{"location":"guides/tricys_basic/concurrent_operation.html#21-simulationconcurrent","title":"2.1. <code>simulation.concurrent</code>","text":"<ul> <li>\u63cf\u8ff0: \u662f\u5426\u542f\u7528\u5e76\u53d1\u8fd0\u884c\u3002</li> <li>\u7c7b\u578b: \u5e03\u5c14\u503c (<code>true</code> \u6216 <code>false</code>)\u3002</li> <li>\u9ed8\u8ba4\u503c: <code>false</code>\u3002</li> <li>\u5de5\u4f5c\u539f\u7406: \u5f53\u8bbe\u7f6e\u4e3a <code>true</code> \u65f6\uff0c<code>tricys</code> \u4f1a\u542f\u52a8\u4e00\u4e2a\u8fdb\u7a0b\u6c60\uff0c\u5c06\u4eff\u771f\u4efb\u52a1\uff08\u4f8b\u5982\u53c2\u6570\u626b\u63cf\u4e2d\u7684\u6bcf\u4e00\u6b21\u8fd0\u884c\uff09\u5206\u914d\u7ed9\u4e0d\u540c\u7684\u8fdb\u7a0b\u5e76\u884c\u6267\u884c\u3002</li> </ul>"},{"location":"guides/tricys_basic/concurrent_operation.html#22-simulationmax_workers","title":"2.2. <code>simulation.max_workers</code>","text":"<ul> <li>\u63cf\u8ff0: \u63a7\u5236\u7528\u4e8e\u5e76\u53d1\u6267\u884c\u7684\u6700\u5927\u8fdb\u7a0b\u6570\uff08\u6216\u79f0\u201c\u5de5\u4f5c\u8fdb\u7a0b\u201d\u6570\u91cf\uff09\u3002</li> <li>\u7c7b\u578b: \u6574\u6570 (\u9009\u586b)\u3002</li> <li>\u9ed8\u8ba4\u503c: \u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c<code>tricys</code> \u5c06\u9ed8\u8ba4\u4f7f\u7528\u60a8\u8ba1\u7b97\u673a\u4e0a\u7684 \u6240\u6709\u53ef\u7528 CPU \u6838\u5fc3\u6570\u3002</li> <li>\u5efa\u8bae:<ul> <li>\u5bf9\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u5efa\u8bae\u5c06\u6b64\u503c\u8bbe\u7f6e\u4e3a\u4e0d\u8d85\u8fc7\u60a8\u8ba1\u7b97\u673a\u7684\u7269\u7406\u6838\u5fc3\u6570\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002</li> <li>\u5982\u679c\u5728\u4eff\u771f\u8fc7\u7a0b\u4e2d\u9047\u5230\u5185\u5b58\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u9002\u5f53\u8c03\u4f4e <code>max_workers</code> \u7684\u503c\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u4f1a\u72ec\u7acb\u52a0\u8f7d\u6a21\u578b\u5e76\u6d88\u8017\u4e00\u5b9a\u7684\u5185\u5b58\u3002</li> </ul> </li> </ul> <p>\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c<code>\"concurrent\": true</code> \u548c <code>\"max_workers\": 4</code> \u610f\u5473\u7740 <code>tricys</code> \u4f1a\u521b\u5efa\u4e00\u4e2a\u5305\u542b 4 \u4e2a\u5de5\u4f5c\u8fdb\u7a0b\u7684\u8fdb\u7a0b\u6c60\uff0c\u6765\u5e76\u884c\u5904\u7406\u7531\u53c2\u6570\u626b\u63cf\u751f\u6210\u7684 10 \u4e2a\u4eff\u771f\u4efb\u52a1\u3002</p> <p>\u9002\u7528\u573a\u666f</p> <p>\u5e76\u53d1\u8fd0\u884c\u4e0d\u4ec5\u9002\u7528\u4e8e\u6807\u51c6\u7684\u53c2\u6570\u626b\u63cf\uff0c\u4e5f\u540c\u6837\u9002\u7528\u4e8e\u534f\u540c\u4eff\u771f\u548c\u81ea\u52a8\u5206\u6790\u6d41\u7a0b\uff0c\u80fd\u591f\u5168\u9762\u63d0\u5347 <code>tricys</code> \u7684\u6267\u884c\u6548\u7387\u3002</p>"},{"location":"guides/tricys_basic/parameter_sweep.html","title":"\u53c2\u6570\u626b\u63cf","text":"<p>\u53c2\u6570\u626b\u63cf\u662f <code>tricys</code> \u7684\u6838\u5fc3\u529f\u80fd\u4e4b\u4e00\uff0c\u5b83\u5141\u8bb8\u60a8\u7cfb\u7edf\u5730\u7814\u7a76\u4e00\u4e2a\u6216\u591a\u4e2a\u6a21\u578b\u53c2\u6570\u7684\u53d8\u5316\u5bf9\u4eff\u771f\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u60a8\u53ea\u9700\u4e3a\u6bcf\u4e2a\u611f\u5174\u8da3\u7684\u53c2\u6570\u63d0\u4f9b\u4e00\u7ec4\u503c\uff0c<code>tricys</code> \u4f1a\u81ea\u52a8\u521b\u5efa\u5e76\u8fd0\u884c\u6240\u6709\u53ef\u80fd\u7684\u53c2\u6570\u7ec4\u5408\u3002</p>"},{"location":"guides/tricys_basic/parameter_sweep.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u5728\u57fa\u7840\u914d\u7f6e\u4e4b\u4e0a\uff0c\u6211\u4eec\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a <code>simulation_parameters</code> \u5b57\u6bb5\uff0c\u5373\u53ef\u5b9a\u4e49\u53c2\u6570\u626b\u63cf\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    },\n    \"simulation_parameters\": {\n        \"tep_fep.to_SDS_Fraction[1]\": [0.1, 0.15, 0.2, 0.3, 0.4, 0.6, 0.8],\n        \"blanket.TBR\": \"linspace:1.05:1.15:3\"\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/parameter_sweep.html#2","title":"2. \u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li>\u63cf\u8ff0: <code>simulation_parameters</code>\u914d\u7f6e\u9879 \u662f\u4e00\u4e2a\u5b57\u5178\uff08\u952e\u503c\u5bf9\u96c6\u5408\uff09\uff0c\u7528\u4e8e\u5b9a\u4e49\u8981\u626b\u63cf\u7684\u53c2\u6570\u53ca\u5176\u5bf9\u5e94\u7684\u503c\u3002</li> <li>\u952e (Key): \u5fc5\u987b\u662f Modelica \u6a21\u578b\u4e2d\u53d8\u91cf\u7684\u5b8c\u6574\u8def\u5f84\u3002\u4f8b\u5982 <code>blanket.TBR</code> \u6216 <code>tep_fep.to_SDS_Fraction[1]</code>\u3002</li> <li> <p>\u503c (Value): \u53ef\u4ee5\u662f\u4ee5\u4e0b\u51e0\u79cd\u683c\u5f0f\uff1a</p> <ol> <li> <p>\u79bb\u6563\u503c\u5217\u8868 (List):</p> <ul> <li>\u683c\u5f0f: <code>[v1, v2, v3, ...]</code></li> <li>\u793a\u4f8b: <code>[0.1, 0.15, 0.2]</code></li> <li>\u8bf4\u660e: \u7a0b\u5e8f\u5c06\u4f9d\u6b21\u4f7f\u7528\u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u503c\u8fdb\u884c\u4eff\u771f\u3002</li> </ul> </li> <li> <p>\u9ad8\u7ea7\u626b\u63cf\u683c\u5f0f (String):</p> <ul> <li>\u63cf\u8ff0: <code>tricys</code> \u652f\u6301\u591a\u79cd\u7d27\u51d1\u7684\u5b57\u7b26\u4e32\u683c\u5f0f\u6765\u751f\u6210\u6570\u503c\u5e8f\u5217\uff0c\u975e\u5e38\u9002\u5408\u5b9a\u4e49\u7ebf\u6027\u3001\u5bf9\u6570\u7b49\u5e8f\u5217\u3002</li> <li>\u793a\u4f8b: <code>\"linspace:1.05:1.15:3\"</code> \u8868\u793a\u5728 1.05 \u548c 1.15 \u4e4b\u95f4\u751f\u6210 3 \u4e2a\u7b49\u95f4\u8ddd\u7684\u6570\u503c\u3002</li> <li>\u652f\u6301\u7684\u683c\u5f0f:</li> </ul> </li> </ol> </li> </ul> \u683c\u5f0f \u8bed\u6cd5 \u63cf\u8ff0 \u7ebf\u6027\u5e8f\u5217 (Range) <code>\"start:stop:step\"</code> \u4ece <code>start</code> \u5230 <code>stop</code> \u751f\u6210\u4e00\u4e2a\u6b65\u957f\u4e3a <code>step</code> \u7684\u7b49\u5dee\u5e8f\u5217\u3002\u4f8b\u5982: <code>\"1:5:2\"</code> \u4f1a\u751f\u6210 <code>[1, 3, 5]</code>\u3002 \u7ebf\u6027\u95f4\u9694 (Linspace) <code>\"linspace:start:stop:num\"</code> \u5728 <code>start</code> \u548c <code>stop</code> \u4e4b\u95f4\u751f\u6210 <code>num</code> \u4e2a\u7b49\u95f4\u8ddd\u7684\u6570\u503c\u3002\u4f8b\u5982: <code>\"linspace:0:10:3\"</code> \u4f1a\u751f\u6210 <code>[0, 5, 10]</code>\u3002 \u5bf9\u6570\u95f4\u9694 (Logspace) <code>\"log:start:stop:num\"</code> \u5728 <code>start</code> \u548c <code>stop</code> \u4e4b\u95f4\u751f\u6210 <code>num</code> \u4e2a\u5bf9\u6570\u7b49\u8ddd\u7684\u6570\u503c\uff0c\u9002\u5408\u8de8\u6570\u91cf\u7ea7\u7684\u626b\u63cf\u3002\u4f8b\u5982: <code>\"log:1:100:3\"</code> \u4f1a\u751f\u6210 <code>[1, 10, 100]</code>\u3002 \u968f\u673a\u6570 (Random) <code>\"rand:min:max:count\"</code> \u5728 <code>min</code> \u548c <code>max</code> \u4e4b\u95f4\u751f\u6210 <code>count</code> \u4e2a\u5747\u5300\u5206\u5e03\u7684\u968f\u673a\u6570\u3002\u4f8b\u5982: <code>\"rand:0:1:2\"</code> \u53ef\u80fd\u4f1a\u751f\u6210 <code>[0.23, 0.87]</code>\u3002 \u4ece\u6587\u4ef6\u8bfb\u53d6 (From File) <code>\"file:path/to/data.csv:column_name\"</code> \u4ece\u6307\u5b9a\u7684 CSV \u6587\u4ef6\u4e2d\u7684 <code>column_name</code> \u5217\u8bfb\u53d6\u6570\u503c\u4f5c\u4e3a\u626b\u63cf\u5217\u8868\u3002 \u6570\u7ec4\u5c55\u5f00 (Array Expansion) <code>\"{val1, val2, ...}\"</code> \u7528\u4e8e\u4e00\u6b21\u6027\u8bbe\u7f6e Modelica \u6570\u7ec4\u4e2d\u591a\u4e2a\u5143\u7d20\u7684\u7279\u6b8a\u683c\u5f0f\u3002\u4f8b\u5982\uff0c\u4e3a\u53c2\u6570 <code>my_array</code> \u8bbe\u7f6e\u503c <code>\"{10, 25, 50}\"</code>\uff0c\u5c06\u4f1a\u88ab\u81ea\u52a8\u5c55\u5f00\u4e3a <code>my_array[1]=10</code>, <code>my_array[2]=25</code>, <code>my_array[3]=50</code>\u3002\u82b1\u62ec\u53f7\u5185\u7684\u503c\u672c\u8eab\u4e5f\u53ef\u4ee5\u662f\u5176\u4ed6\u9ad8\u7ea7\u683c\u5f0f\u7684\u5b57\u7b26\u4e32\u3002 <p>\u591a\u53c2\u6570\u626b\u63cf</p> <ul> <li>\u60a8\u53ef\u4ee5\u540c\u65f6\u5b9a\u4e49\u591a\u4e2a\u53c2\u6570\u8fdb\u884c\u626b\u63cf\uff0c<code>tricys</code> \u4f1a\u8ba1\u7b97\u6240\u6709\u53c2\u6570\u503c\u7684\u7b1b\u5361\u5c14\u79ef\uff0c\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6240\u6709\u53ef\u80fd\u7ec4\u5408\u7684\u4eff\u771f\u4efb\u52a1\u5217\u8868\u3002</li> <li>\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c<code>tep_fep.to_SDS_Fraction[1]</code> \u6709 7 \u4e2a\u503c\uff0c<code>blanket.TBR</code> \u6709 3 \u4e2a\u503c\uff0c\u56e0\u6b64\u7a0b\u5e8f\u603b\u5171\u4f1a\u8fd0\u884c <code>7 * 3 = 21</code> \u6b21\u4eff\u771f\u3002</li> </ul>"},{"location":"guides/tricys_basic/parameter_sweep.html#3","title":"3. \u7ed3\u679c\u8f93\u51fa","text":"<p>\u5bf9\u4e8e\u53c2\u6570\u626b\u63cf\u4efb\u52a1\uff0c\u9664\u4e86\u6bcf\u6b21\u5355\u72ec\u8fd0\u884c\u7684 <code>simulation_result.csv</code> \u6587\u4ef6\u5916\uff0c<code>tricys</code> \u8fd8\u4f1a\u751f\u6210\u4e00\u4e2a\u6c47\u603b\u6587\u4ef6 <code>sweep_results.csv</code>\uff0c\u5982\u4e0b\uff1a</p> <pre><code>Working Directory/\n\u2514\u2500\u2500 {timestamp}/\n    \u251c\u2500\u2500 log/        \n        \u2514\u2500\u2500 simulation_{timestamp}.log      # \u8fd0\u884c\u65e5\u5fd7\n    \u251c\u2500\u2500 result/                 \n        \u2514\u2500\u2500 sweep_results.csv               # \u4eff\u771f\u7ed3\u679c\u6c47\u603b\u6570\u636e\n    \u2514\u2500\u2500 temp/\n        \u251c\u2500\u2500 job_1/                      \n            \u2514\u2500\u2500 job_1_simulation_result.csv # \u4eff\u771f\u4efb\u52a1\u4e00\u6a21\u62df\u7ed3\u679c\n        \u251c\u2500\u2500 job_2/                      \n            \u2514\u2500\u2500 job_2_simulation_result.csv # \u4eff\u771f\u4efb\u52a1\u4e8c\u6a21\u62df\u7ed3\u679c\n        \u2514\u2500\u2500 ......\n</code></pre> <ul> <li><code>sweep_results.csv</code>:</li> <li>\u7b2c\u4e00\u5217: <code>time</code>\uff0c\u8868\u793a\u65f6\u95f4\u8f74\u3002</li> <li>\u5176\u4f59\u5217: \u6bcf\u4e00\u5217\u4ee3\u8868\u4e00\u6b21\u7279\u5b9a\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u4eff\u771f\u7ed3\u679c\u3002\u5217\u6807\u9898\u6e05\u6670\u5730\u6807\u660e\u4e86\u8be5\u6b21\u8fd0\u884c\u6240\u4f7f\u7528\u7684\u53c2\u6570\u53ca\u5176\u503c\uff0c\u4f8b\u5982 <code>sds.I[1]&amp;tep_fep.to_SDS_Fraction[1]=0.1&amp;blanket.TBR=1.05</code>\uff0c\u65b9\u4fbf\u60a8\u76f4\u63a5\u5728 CSV \u6587\u4ef6\u4e2d\u6bd4\u8f83\u4e0d\u540c\u5de5\u51b5\u4e0b\u7684\u7ed3\u679c\u3002</li> </ul>"},{"location":"guides/tricys_basic/parameter_sweep.html#4","title":"4. \u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u4e86\u53c2\u6570\u626b\u63cf\u540e\uff0c\u60a8\u53ef\u4ee5\u63a2\u7d22\u66f4\u9ad8\u7ea7\u7684\u529f\u80fd\u6765\u63d0\u5347\u6548\u7387\u548c\u5206\u6790\u6df1\u5ea6\uff1a</p> <ul> <li>\u5e76\u53d1\u8fd0\u884c\uff1a\u5b66\u4e60\u5982\u4f55\u5229\u7528\u591a\u6838\u5904\u7406\u5668\u5e76\u884c\u6267\u884c\u5927\u91cf\u626b\u63cf\u4efb\u52a1\uff0c\u5927\u5e45\u7f29\u77ed\u4eff\u771f\u65f6\u95f4\u3002</li> <li>\u540e\u5904\u7406\u6a21\u5757\uff1a\u4e86\u89e3\u5982\u4f55\u81ea\u52a8\u5206\u6790\u626b\u63cf\u7ed3\u679c\uff0c\u4f8b\u5982\u8ba1\u7b97\u6bcf\u4e2a\u5de5\u51b5\u4e0b\u7684\u6700\u5927\u503c\u3001\u5e73\u5747\u503c\u6216\u62a5\u8b66\u6b21\u6570\u3002</li> <li>\u654f\u611f\u6027\u5206\u6790\uff1a\u8fdb\u884c\u66f4\u7cfb\u7edf\u5316\u7684\u53c2\u6570\u5f71\u54cd\u7814\u7a76\uff0c\u4f8b\u5982 Sobol \u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html","title":"\u540e\u5904\u7406\u6a21\u5757","text":"<p><code>tricys</code> \u4e0d\u4ec5\u80fd\u8fd0\u884c\u4eff\u771f\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u540e\u5904\u7406\uff08Post-Processing\uff09\u6846\u67b6\uff0c\u5141\u8bb8\u60a8\u5728\u4eff\u771f\u4efb\u52a1\u5b8c\u6210\u540e\u81ea\u52a8\u5bf9\u7ed3\u679c\u8fdb\u884c\u5206\u6790\u3001\u751f\u6210\u62a5\u544a\u6216\u6267\u884c\u5176\u4ed6\u81ea\u5b9a\u4e49\u64cd\u4f5c\u3002</p> <p>\u540e\u5904\u7406\u529f\u80fd\u901a\u8fc7\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u6dfb\u52a0 <code>post_processing</code> \u5b57\u6bb5\u6765\u5b9e\u73b0\u3002</p>"},{"location":"guides/tricys_basic/post_processing_module.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u4ee5\u4e0b\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u5728\u53c2\u6570\u626b\u63cf\u5b8c\u6210\u540e\uff0c\u81ea\u52a8\u6267\u884c\u4e24\u4e2a\u5206\u6790\u4efb\u52a1\uff1a\u4e00\u4e2a\u4f7f\u7528\u5185\u7f6e\u7684 <code>module</code>\uff0c\u53e6\u4e00\u4e2a\u4f7f\u7528\u7528\u6237\u81ea\u5b9a\u4e49\u7684 <code>script_path</code>\u3002</p> <pre><code>{\n    \"paths\": {\n        ...\n    },\n    \"simulation\": {\n        ...\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    },\n    \"post_processing\": [\n        {\n            \"module\": \"tricys.postprocess.static_alarm\",\n            \"function\": \"check_thresholds\",\n            \"params\": {\n                \"rules\": [{\"columns\": [\"sds.I[1]\"], \"min\": 0.0}]\n            }\n        },\n        {\n            \"script_path\": \"scripts/my_custom_analyzer.py\",\n            \"function\": \"analyze_peak_value\",\n            \"params\": {\n                \"target_column_pattern\": \"sds.I[1]*\",\n                \"report_filename\": \"peak_values.json\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/tricys_basic/post_processing_module.html#2","title":"2. \u914d\u7f6e\u9879\u8be6\u89e3","text":""},{"location":"guides/tricys_basic/post_processing_module.html#21-post_processing","title":"2.1. <code>post_processing</code>","text":"<ul> <li>\u63cf\u8ff0: \u8fd9\u662f\u4e00\u4e2a\u5217\u8868\uff08Array\uff09\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2a\u72ec\u7acb\u7684\u540e\u5904\u7406\u6b65\u9aa4\u3002\u8fd9\u4e9b\u6b65\u9aa4\u4f1a\u6309\u7167\u5b83\u4eec\u5728\u5217\u8868\u4e2d\u7684\u987a\u5e8f\u4f9d\u6b21\u6267\u884c\u3002</li> <li>\u6267\u884c\u65f6\u673a: \u6240\u6709\u4eff\u771f\u4efb\u52a1\uff08\u4f8b\u5982\u53c2\u6570\u626b\u63cf\u4e2d\u7684\u6bcf\u4e00\u6b21\u8fd0\u884c\uff09\u5168\u90e8\u5b8c\u6210\u540e\uff0c<code>tricys</code> \u4f1a\u5c06\u6c47\u603b\u7684\u7ed3\u679c\uff08<code>sweep_results.csv</code>\uff09\u52a0\u8f7d\u5230\u4e00\u4e2a Pandas DataFrame \u4e2d\uff0c\u5e76\u5c06\u5176\u4f20\u9012\u7ed9\u60a8\u6307\u5b9a\u7684\u540e\u5904\u7406\u51fd\u6570\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#22","title":"2.2. \u540e\u5904\u7406\u51fd\u6570","text":"<p>\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u5b9a\u4e49\u4e86\u4e00\u4e2a\u8981\u6267\u884c\u7684 Python \u51fd\u6570\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u4e24\u79cd\u65b9\u5f0f\u4e4b\u4e00\u6765\u6307\u5b9a\u8981\u8c03\u7528\u7684\u4ee3\u7801\uff1a</p>"},{"location":"guides/tricys_basic/post_processing_module.html#module","title":"\u65b9\u5f0f\u4e00\uff1a<code>module</code> (\u6a21\u5757\u52a0\u8f7d)","text":"<ul> <li><code>module</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</li> <li>\u63cf\u8ff0: \u8981\u8c03\u7528\u7684 Python \u51fd\u6570\u6240\u5728\u7684\u6a21\u5757\u7684\u5b8c\u6574\u8def\u5f84\u3002\u8fd9\u8981\u6c42\u60a8\u7684\u4ee3\u7801\u662f\u4e00\u4e2a\u53ef\u4ee5\u901a\u8fc7 <code>import</code> \u8bed\u53e5\u52a0\u8f7d\u7684 Python \u5305\u6216\u6a21\u5757\uff08\u4f8b\u5982\uff0c\u5df2\u5b89\u88c5\u6216\u4f4d\u4e8e\u5e26\u6709 <code>__init__.py</code> \u7684\u76ee\u5f55\u4e2d\uff09\u3002</li> <li>\u793a\u4f8b: <code>tricys.postprocess.static_alarm</code></li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#script_path","title":"\u65b9\u5f0f\u4e8c\uff1a<code>script_path</code> (\u811a\u672c\u8def\u5f84\u52a0\u8f7d)","text":"<ul> <li><code>script_path</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</li> <li>\u63cf\u8ff0: \u6307\u5411\u5305\u542b\u8981\u8c03\u7528\u51fd\u6570\u7684\u5355\u4e2a Python \u811a\u672c\u6587\u4ef6\u7684\u8def\u5f84\u3002\u8fd9\u66f4\u52a0\u7075\u6d3b\uff0c\u4e0d\u9700\u8981\u60a8\u7684\u811a\u672c\u6210\u4e3a\u4e00\u4e2a\u6b63\u5f0f\u7684\u5305\u3002</li> <li>\u793a\u4f8b: <code>scripts/my_custom_analyzer.py</code></li> </ul> <p>\u65e0\u8bba\u4f7f\u7528\u54ea\u79cd\u65b9\u5f0f\uff0c\u60a8\u90fd\u9700\u8981\u63d0\u4f9b\u4ee5\u4e0b\u5b57\u6bb5\uff1a</p> <ul> <li><code>function</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</li> <li>\u63cf\u8ff0: \u8981\u5728\u6307\u5b9a\u6a21\u5757\u6216\u811a\u672c\u4e2d\u8c03\u7528\u7684\u51fd\u6570\u540d\u3002</li> <li> <p>\u793a\u4f8b: <code>check_thresholds</code></p> </li> <li> <p><code>params</code> (\u5b57\u5178, \u9009\u586b):</p> </li> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5305\u542b\u8981\u4f20\u9012\u7ed9\u76ee\u6807\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570\uff08keyword arguments\uff09\u7684\u5b57\u5178\u3002</li> <li>\u793a\u4f8b: \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c<code>params</code> \u4e3a <code>check_thresholds</code> \u51fd\u6570\u63d0\u4f9b\u4e86 <code>rules</code> \u53c2\u6570\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#3","title":"3. \u5185\u7f6e\u540e\u5904\u7406\u6a21\u5757","text":"<p><code>tricys</code> \u81ea\u5e26\u4e86\u4e00\u4e9b\u5e38\u7528\u7684\u540e\u5904\u7406\u6a21\u5757\uff0c\u4f4d\u4e8e <code>tricys/postprocess</code> \u76ee\u5f55\u4e0b\uff1a</p> <ul> <li><code>rise_analysis</code>: \u7528\u4e8e\u5206\u6790\u4fe1\u53f7\u7684\u4e0a\u5347\u65f6\u95f4\u3001\u4e0b\u964d\u65f6\u95f4\u3001\u5cf0\u503c\u7b49\u52a8\u6001\u7279\u6027\u3002</li> <li><code>static_alarm</code>: \u7528\u4e8e\u68c0\u67e5\u7ed3\u679c\u662f\u5426\u8d85\u51fa\u4e86\u9884\u8bbe\u7684\u9759\u6001\u9608\u503c\uff08\u4e0a\u9650\u6216\u4e0b\u9650\uff09\u3002</li> <li><code>baseline_analysis</code>: \u7528\u4e8e\u6267\u884c\u57fa\u51c6\u5de5\u51b5\u5206\u6790\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#4","title":"4. \u81ea\u5b9a\u4e49\u540e\u5904\u7406\u6a21\u5757","text":"<p>\u540e\u5904\u7406\u6846\u67b6\u6700\u5927\u7684\u4f18\u52bf\u5728\u4e8e\u5176\u6269\u5c55\u6027\u3002\u60a8\u53ef\u4ee5\u8f7b\u677e\u7f16\u5199\u81ea\u5df1\u7684 Python \u811a\u672c\u6765\u6267\u884c\u4efb\u4f55\u60f3\u8981\u7684\u5206\u6790\u3002</p>"},{"location":"guides/tricys_basic/post_processing_module.html#41","title":"4.1. \u51fd\u6570\u7b7e\u540d","text":"<p>\u4e3a\u4e86\u80fd\u88ab <code>tricys</code> \u6846\u67b6\u6b63\u786e\u8c03\u7528\uff0c\u60a8\u7684\u81ea\u5b9a\u4e49\u540e\u5904\u7406\u51fd\u6570\u5fc5\u987b\u9075\u5faa\u7279\u5b9a\u7684\u7b7e\u540d\u3002\u6846\u67b6\u4f1a\u81ea\u52a8\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570\u4f20\u5165\u4e24\u4e2a\u6838\u5fc3\u6570\u636e\uff1a</p> <ol> <li><code>results_df</code> (pd.DataFrame): \u5305\u542b\u6240\u6709\u4eff\u771f\u8fd0\u884c\u6c47\u603b\u7ed3\u679c\u7684 Pandas DataFrame\u3002</li> <li><code>output_dir</code> (str): \u4e00\u4e2a\u4e13\u5c5e\u7684\u8f93\u51fa\u76ee\u5f55\u8def\u5f84\uff0c\u4f9b\u60a8\u4fdd\u5b58\u62a5\u544a\u3001\u56fe\u8868\u7b49\u5206\u6790\u4ea7\u7269\u3002</li> </ol> <p>\u56e0\u6b64\uff0c\u60a8\u7684\u51fd\u6570\u7b7e\u540d\u5fc5\u987b\u80fd\u591f\u63a5\u6536\u8fd9\u4e24\u4e2a\u53c2\u6570\uff0c\u4ee5\u53ca\u60a8\u5728 <code>params</code> \u4e2d\u5b9a\u4e49\u7684\u4efb\u4f55\u5176\u4ed6\u81ea\u5b9a\u4e49\u53c2\u6570\u3002</p> <p>\u4e00\u4e2a\u6807\u51c6\u7684\u51fd\u6570\u7b7e\u540d\u5982\u4e0b\uff1a</p> <pre><code>import pandas as pd\n\ndef my_custom_function(results_df: pd.DataFrame, output_dir: str, **kwargs):\n    \"\"\"\n    \u4e00\u4e2a\u901a\u7528\u7684\u540e\u5904\u7406\u51fd\u6570\u7b7e\u540d\u3002\n\n    - results_df: \u7531 tricys \u4f20\u5165\u7684\u4eff\u771f\u7ed3\u679c\u3002\n    - output_dir: \u7531 tricys \u63d0\u4f9b\u7684\u7528\u4e8e\u4fdd\u5b58\u62a5\u544a\u7684\u76ee\u5f55\u3002\n    - **kwargs: \u7528\u4e8e\u63a5\u6536\u6765\u81ea JSON \u914d\u7f6e\u4e2d \"params\" \u7684\u6240\u6709\u81ea\u5b9a\u4e49\u53c2\u6570\u3002\n    \"\"\"\n    # \u4ece kwargs \u4e2d\u83b7\u53d6\u81ea\u5b9a\u4e49\u53c2\u6570\n    my_param = kwargs.get(\"my_param\", \"default_value\")\n\n    # \u5728\u8fd9\u91cc\u7f16\u5199\u60a8\u7684\u5206\u6790\u4ee3\u7801...\n    print(f\"\u5206\u6790\u62a5\u544a\u5c06\u4fdd\u5b58\u5728: {output_dir}\")\n    print(f\"\u6536\u5230\u7684\u81ea\u5b9a\u4e49\u53c2\u6570 my_param \u7684\u503c\u4e3a: {my_param}\")\n    print(\"\u7ed3\u679c\u6570\u636e\u9884\u89c8:\")\n    print(results_df.head())\n</code></pre>"},{"location":"guides/tricys_basic/post_processing_module.html#42","title":"4.2. \u5b8c\u6574\u793a\u4f8b","text":"<p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684\u81ea\u5b9a\u4e49\u540e\u5904\u7406\u811a\u672c\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u901a\u8fc7 <code>script_path</code> \u5728\u914d\u7f6e\u4e2d\u8c03\u7528\u5b83\u3002</p> <p>\u6b65\u9aa4 1: \u521b\u5efa\u5206\u6790\u811a\u672c</p> <p>\u5047\u8bbe\u6211\u4eec\u5728\u9879\u76ee\u4e0b\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a <code>scripts/my_custom_analyzer.py</code> \u7684\u6587\u4ef6\uff1a</p> <pre><code># scripts/my_custom_analyzer.py\nimport pandas as pd\nimport os\nimport json\n\ndef analyze_peak_value(results_df: pd.DataFrame, output_dir: str, target_column_pattern: str, report_filename: str = \"peak_report.json\"):\n    \"\"\"\n    \u5728\u6240\u6709\u5339\u914d\u7684\u5217\u4e2d\u67e5\u627e\u5cf0\u503c\uff0c\u5e76\u751f\u6210\u4e00\u4efd\u62a5\u544a\u3002\n    \"\"\"\n    # \u7b5b\u9009\u51fa\u7b26\u5408\u6a21\u5f0f\u7684\u5217\n    target_columns = [col for col in results_df.columns if target_column_pattern in col]\n\n    if not target_columns:\n        print(f\"\u8b66\u544a: \u672a\u627e\u5230\u5339\u914d '{target_column_pattern}' \u7684\u5217\u3002\")\n        return\n\n    # \u8ba1\u7b97\u6bcf\u4e00\u5217\u7684\u5cf0\u503c\n    peak_values = results_df[target_columns].max().to_dict()\n\n    # \u5b9a\u4e49\u62a5\u544a\u8f93\u51fa\u8def\u5f84\n    report_path = os.path.join(output_dir, report_filename)\n\n    # \u4fdd\u5b58\u62a5\u544a\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(peak_values, f, indent=4)\n\n    print(f\"\u5cf0\u503c\u5206\u6790\u62a5\u544a\u5df2\u4fdd\u5b58\u81f3: {report_path}\")\n</code></pre> <p>\u6b65\u9aa4 2: \u66f4\u65b0\u914d\u7f6e\u6587\u4ef6</p> <p>\u73b0\u5728\uff0c\u5728\u60a8\u7684 <code>config.json</code> \u4e2d\u914d\u7f6e <code>post_processing</code> \u90e8\u5206\u6765\u8c03\u7528\u8fd9\u4e2a\u811a\u672c\uff1a</p> <pre><code>{\n    ...\n    \"post_processing\": [\n        {\n            \"script_path\": \"scripts/my_custom_analyzer.py\",\n            \"function\": \"analyze_peak_value\",\n            \"params\": {\n                \"target_column_pattern\": \"sds.I[1]\",\n                \"report_filename\": \"sds_peak_values.json\"\n            }\n        }\n    ]\n}\n</code></pre> <p>\u5f53 <code>tricys</code> \u5b8c\u6210\u6240\u6709\u4eff\u771f\u540e\uff0c\u5b83\u4f1a\u81ea\u52a8\u6267\u884c <code>analyze_peak_value</code> \u51fd\u6570\uff0c\u5e76\u5c06\u4eff\u771f\u7ed3\u679c\u4e2d\u6240\u6709\u5305\u542b <code>sds.I[1]</code> \u7684\u5217\u7684\u5cf0\u503c\u8ba1\u7b97\u51fa\u6765\uff0c\u6700\u540e\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230 <code>post_processing/sds_peak_values.json</code> \u6587\u4ef6\u4e2d\u3002</p> <p>\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u60a8\u53ef\u4ee5\u5c06\u4efb\u610f\u590d\u6742\u7684\u6570\u636e\u5206\u6790\u6d41\u7a0b\u65e0\u7f1d\u96c6\u6210\u5230 <code>tricys</code> \u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\u3002</p>"},{"location":"guides/tricys_basic/post_processing_module.html#5","title":"5. \u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u4e86\u5982\u4f55\u521b\u5efa\u548c\u4f7f\u7528\u540e\u5904\u7406\u6a21\u5757\u540e\uff0c\u60a8\u53ef\u4ee5\u5c06\u5b83\u5e94\u7528\u5230\u66f4\u590d\u6742\u7684\u573a\u666f\u4e2d\uff1a</p> <ul> <li>\u654f\u611f\u6027\u5206\u6790\uff1a\u4e3a\u590d\u6742\u7684\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u7f16\u5199\u4e13\u7528\u7684\u540e\u5904\u7406\u811a\u672c\uff0c\u4ee5\u63d0\u53d6\u5173\u952e\u6307\u6807\u548c\u751f\u6210\u53ef\u89c6\u5316\u56fe\u8868\u3002</li> <li>\u534f\u540c\u4eff\u771f\uff1a\u5bf9\u5305\u542b\u5916\u90e8\u6a21\u5757\u7684\u534f\u540c\u4eff\u771f\u7ed3\u679c\u8fdb\u884c\u6574\u5408\u4e0e\u5206\u6790\u3002</li> </ul>"},{"location":"questions/advanced_features.html","title":"\ud83d\udd2c \u9ad8\u7ea7\u529f\u80fd","text":"\u95ee\uff1a\u4ec0\u4e48\u662f\u534f\u540c\u4eff\u771f\uff1f\u5982\u4f55\u4f7f\u7528\uff1f <p>\u534f\u540c\u4eff\u771f\u5141\u8bb8 TRICYS \u4e0e\u5916\u90e8\u8f6f\u4ef6\uff08\u5982 Aspen Plus\uff09\u4ea4\u4e92\uff1a</p> <p>\u5de5\u4f5c\u6d41\u7a0b\uff1a 1. \u8fd0\u884c\u521d\u6b65\u4eff\u771f 2. \u8c03\u7528\u5916\u90e8\u5904\u7406\u5668\uff08Handler\uff09 3. \u5916\u90e8\u8f6f\u4ef6\u8ba1\u7b97\u65b0\u6570\u636e 4. \u5c06\u6570\u636e\u6ce8\u5165\u56de Modelica \u6a21\u578b 5. \u8fd0\u884c\u6700\u7ec8\u5b8c\u6574\u4eff\u771f</p> <p>\u914d\u7f6e\u793a\u4f8b\uff1a <pre><code>{\n    \"co_simulation\": [\n        {\n            \"mode\": \"interceptor\",\n            \"submodel_name\": \"example_model.I_ISS\",\n            \"instance_name\": \"i_iss\",\n            \"handler_module\": \"tricys.handlers.i_iss_handler\",\n            \"handler_function\": \"run_aspen_simulation\",\n            \"params\": {\n                \"bkp_path\": \"path/to/aspen/file.bkp\"\n            }\n        }\n    ]\n}\n</code></pre></p> <ul> <li><code>mode</code>\uff1a<code>interceptor</code>\uff08\u9ed8\u8ba4\uff09\u6216<code>replacement</code>\u3002</li> <li><code>handler_module</code>\uff1a\u5904\u7406\u5668\u6240\u5728\u7684\u6a21\u5757\u3002</li> <li><code>handler_script_path</code>\uff1a\u6216\u8005\uff0c\u76f4\u63a5\u63d0\u4f9b\u5904\u7406\u5668\u811a\u672c\u7684\u8def\u5f84\u3002</li> </ul> <p>\u8be6\u89c1\uff1a\u534f\u540c\u4eff\u771f\u6a21\u5757</p> \u95ee\uff1a\u5982\u4f55\u521b\u5efa\u81ea\u5b9a\u4e49\u540e\u5904\u7406\u6a21\u5757\uff1f <p>\u540e\u5904\u7406\u6a21\u5757\u662f Python \u51fd\u6570\uff0c\u63a5\u6536\u4eff\u771f\u7ed3\u679c\u5e76\u6267\u884c\u5206\u6790\uff1a</p> <p>1. \u521b\u5efa\u5904\u7406\u51fd\u6570\uff1a <pre><code># my_postprocess.py\ndef analyze_results(df, output_filename=\"my_report.txt\"):\n    \"\"\"\n    \u81ea\u5b9a\u4e49\u540e\u5904\u7406\u51fd\u6570\n\n    Args:\n        df: Pandas DataFrame\uff0c\u5305\u542b\u4eff\u771f\u7ed3\u679c\n        output_filename: \u8f93\u51fa\u6587\u4ef6\u540d\n    \"\"\"\n    # \u6267\u884c\u5206\u6790\n    max_inventory = df['sds.I[1]'].max()\n\n    # \u4fdd\u5b58\u7ed3\u679c\n    with open(output_filename, 'w') as f:\n        f.write(f\"\u6700\u5927\u6c1a\u5e93\u5b58: {max_inventory} g\\n\")\n</code></pre> \u6ce8\u610f\uff1a\u8bf7\u5c06\u81ea\u5b9a\u4e49\u6a21\u5757\uff08\u5982<code>my_postprocess.py</code>\uff09\u653e\u7f6e\u5728 <code>tricys</code> \u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\uff0c\u6216\u786e\u4fdd\u5b83\u5728 Python \u7684\u53ef\u53ef\u5bfc\u5165\u8def\u5f84\u4e2d\u3002</p> <p>2. \u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u5f15\u7528\uff1a <pre><code>{\n    \"post_processing\": [\n        {\n            \"module\": \"my_postprocess\",\n            \"function\": \"analyze_results\",\n            \"params\": {\n                \"output_filename\": \"custom_report.txt\"\n            }\n        }\n    ]\n}\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff1f <p>TRICYS \u63d0\u4f9b\u591a\u79cd\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\uff1a</p> <p>1. \u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a <pre><code>tricys analysis -c single_param_analysis.json\n</code></pre></p> <p>\u7814\u7a76\u5355\u4e2a\u53c2\u6570\u5bf9 KPIs \u7684\u5f71\u54cd\u3002</p> <p>2. \u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a <pre><code>tricys analysis -c multi_param_analysis.json\n</code></pre></p> <p>\u7814\u7a76\u53c2\u6570\u95f4\u7684\u8026\u5408\u6548\u5e94\u3002</p> <p>3. SOBOL \u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff1a <pre><code>tricys analysis -c sobol_analysis.json\n</code></pre></p> <p>\u91cf\u5316\u53c2\u6570\u53ca\u5176\u4ea4\u4e92\u4f5c\u7528\u7684\u8d21\u732e\u3002</p> <p>4. Latin \u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff1a <pre><code>tricys analysis -c latin_analysis.json\n</code></pre></p> <p>\u8bc4\u4f30\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002</p> <p>\u8be6\u89c1\uff1a\u654f\u611f\u6027\u5206\u6790\u6559\u7a0b</p> \u95ee\uff1a\u5982\u4f55\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6027\u80fd\u6307\u6807\uff1f <p>\u6027\u80fd\u6307\u6807\uff08Metrics\uff09\u5728 <code>sensitivity_analysis.metrics_definition</code> \u4e2d\u5b9a\u4e49\uff1a</p> <p>\u4f7f\u7528\u5185\u7f6e\u6307\u6807\uff1a <pre><code>{\n    \"metrics_definition\": {\n        \"Max_Inventory\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"max_value\"\n        }\n    }\n}\n</code></pre></p> <p>\u5185\u7f6e\u6307\u6807\u65b9\u6cd5\uff1a * <code>get_final_value</code> * <code>max_value</code>, <code>min_value</code>, <code>mean_value</code> * <code>time_of_max</code>, <code>time_of_min</code> * <code>time_of_turning_point</code> * <code>calculate_startup_inventory</code> * <code>calculate_doubling_time</code> * <code>calculate_required_tbr</code>\uff08\u4e8c\u5206\u6cd5\u641c\u7d22\uff09</p> <p>\u5173\u4e8e\u5185\u7f6e\u6307\u6807\u7684\u8be6\u7ec6\u7269\u7406\u610f\u4e49\uff0c\u8bf7\u53c2\u8003 \u6838\u5fc3\u6027\u80fd\u6307\u6807\u8be6\u89e3\u3002</p> <p>\u521b\u5efa\u81ea\u5b9a\u4e49\u6307\u6807\uff1a <pre><code># my_metrics.py\ndef calculate_peak_to_peak(series):\n    \"\"\"\u8ba1\u7b97\u5cf0\u5cf0\u503c\"\"\"\n    return series.max() - series.min()\n</code></pre></p> <p>\u5728 <code>tricys/analysis/metric.py</code> \u4e2d\u6ce8\u518c\u60a8\u7684\u51fd\u6570\uff0c\u6216\u76f4\u63a5\u5728\u914d\u7f6e\u4e2d\u5f15\u7528\u3002</p>"},{"location":"questions/best_practices.html","title":"\ud83d\udca1 \u6700\u4f73\u5b9e\u8df5","text":"\u95ee\uff1a\u5982\u4f55\u7ec4\u7ec7\u5927\u578b\u4eff\u771f\u9879\u76ee\uff1f <p>\u63a8\u8350\u7684\u76ee\u5f55\u7ed3\u6784\uff1a</p> <pre><code>my_fusion_project/\n\u251c\u2500\u2500 models/                 # Modelica \u6a21\u578b\n\u2502   \u251c\u2500\u2500 package.mo\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 configs/                # \u914d\u7f6e\u6587\u4ef6\n\u2502   \u251c\u2500\u2500 baseline.json\n\u2502   \u251c\u2500\u2500 sensitivity.json\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 scripts/                # \u8f85\u52a9\u811a\u672c\n\u2502   \u251c\u2500\u2500 prepare_data.py\n\u2502   \u2514\u2500\u2500 post_analysis.py\n\u251c\u2500\u2500 data/                   # \u8f93\u5165\u6570\u636e\n\u2502   \u2514\u2500\u2500 external_data.csv\n\u251c\u2500\u2500 results/                # \u4eff\u771f\u7ed3\u679c\uff08\u81ea\u52a8\u751f\u6210\uff09\n\u2514\u2500\u2500 reports/                # \u6700\u7ec8\u62a5\u544a\n</code></pre> \u95ee\uff1a\u5982\u4f55\u7248\u672c\u7ba1\u7406\u914d\u7f6e\u6587\u4ef6\uff1f <p>\u4f7f\u7528 Git \u8fdb\u884c\u7248\u672c\u63a7\u5236\uff1a</p> <pre><code># \u521d\u59cb\u5316 Git \u4ed3\u5e93\ngit init\n\n# \u521b\u5efa .gitignore\necho \"results/\" &gt;&gt; .gitignore\necho \"*.log\" &gt;&gt; .gitignore\necho \"*.pyc\" &gt;&gt; .gitignore\necho \"__pycache__/\" &gt;&gt; .gitignore\n\n# \u63d0\u4ea4\u914d\u7f6e\u6587\u4ef6\ngit add configs/*.json\ngit commit -m \"feat: add baseline configuration\"\n</code></pre> \u95ee\uff1a\u5982\u4f55\u5728\u591a\u53f0\u673a\u5668\u4e0a\u5206\u5e03\u5f0f\u8fd0\u884c\uff1f <p>\u76ee\u524d TRICYS \u4e0d\u76f4\u63a5\u652f\u6301\u5206\u5e03\u5f0f\u8ba1\u7b97\uff0c\u4f46\u60a8\u53ef\u4ee5\uff1a</p> <ol> <li>\u624b\u52a8\u5206\u5272\u4efb\u52a1\uff1a</li> <li>\u5c06\u53c2\u6570\u626b\u63cf\u5206\u6210\u591a\u4e2a\u5b50\u96c6</li> <li>\u5728\u4e0d\u540c\u673a\u5668\u4e0a\u8fd0\u884c\u4e0d\u540c\u7684\u5b50\u96c6</li> <li> <p>\u624b\u52a8\u5408\u5e76\u7ed3\u679c</p> </li> <li> <p>\u4f7f\u7528\u96c6\u7fa4\u8c03\u5ea6\u5668\uff08\u5982 SLURM\uff09\uff1a</p> </li> <li>\u5c06\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u4f5c\u4e3a\u72ec\u7acb\u7684\u4f5c\u4e1a\u63d0\u4ea4</li> <li>\u4f7f\u7528\u540e\u5904\u7406\u811a\u672c\u6c47\u603b\u7ed3\u679c</li> </ol> \u95ee\uff1a\u5982\u4f55\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff1f <p>Modelica \u6a21\u578b\u5c42\u9762\uff1a 1. \u7b80\u5316\u6a21\u578b\u7ed3\u6784\uff0c\u907f\u514d\u8fc7\u5ea6\u590d\u6742\u7684\u65b9\u7a0b 2. \u4f7f\u7528\u9002\u5f53\u7684\u6570\u503c\u6c42\u89e3\u5668\u8bbe\u7f6e 3. \u907f\u514d\u4ee3\u6570\u73af\u548c\u4e8b\u4ef6\u8fc7\u591a</p> <p>TRICYS \u5c42\u9762\uff1a 1. \u542f\u7528\u5e76\u53d1\u8fd0\u884c 2. \u51cf\u5c11\u8f93\u51fa\u53d8\u91cf 3. \u4f7f\u7528\u534f\u540c\u4eff\u771f\u66ff\u4ee3\u590d\u6742\u5b50\u7cfb\u7edf</p>"},{"location":"questions/configuration.html","title":"\u2699\ufe0f \u914d\u7f6e\u8fd0\u884c","text":"\u95ee\uff1a\u5982\u4f55\u8fd0\u884c\u4eff\u771f\uff1f <p>TRICYS \u63d0\u4f9b\u591a\u79cd\u8fd0\u884c\u65b9\u5f0f\uff1a</p> <p>1. \u547d\u4ee4\u884c\uff08CLI\uff09\uff1a <pre><code># \u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\u6587\u4ef6 config.json\ntricys\n\n# \u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\ntricys -c my_config.json\n\n# \u8fd0\u884c\u5206\u6790\u4efb\u52a1\ntricys analysis -c analysis_config.json\n</code></pre></p> <p>2. \u56fe\u5f62\u754c\u9762\uff08GUI\uff09\uff1a <pre><code>tricys gui\n</code></pre></p> <p>3. \u4ea4\u4e92\u5f0f\u793a\u4f8b\uff1a <pre><code># \u8fd0\u884c\u6240\u6709\u793a\u4f8b\u7684\u4ea4\u4e92\u5f0f\u83dc\u5355\ntricys example\n\n# \u8fd0\u884c\u57fa\u7840\u4eff\u771f\u793a\u4f8b\ntricys basic example\n\n# \u8fd0\u884c\u5206\u6790\u793a\u4f8b\ntricys analysis example\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u7406\u89e3\u8f93\u51fa\u6587\u4ef6\uff1f <p>\u4eff\u771f\u5b8c\u6210\u540e\uff0c\u7ed3\u679c\u4fdd\u5b58\u5728 <code>results/</code> \u76ee\u5f55\u4e0b\u7684\u65f6\u95f4\u6233\u5b50\u76ee\u5f55\u4e2d\uff1a</p> \u6587\u4ef6\u540d \u8bf4\u660e <code>simulation_result.csv</code> \u5355\u53c2\u6570\u7ec4\u5408\u7684\u8be6\u7ec6\u7ed3\u679c\uff0c\u5305\u542b\u6240\u6709\u53d8\u91cf\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002 <code>sweep_results.csv</code> \u591a\u53c2\u6570\u7ec4\u5408\uff08\u53c2\u6570\u626b\u63cf\uff09\u7684\u6c47\u603b\u7ed3\u679c\u3002 <code>sensitivity_analysis_summary.csv</code> \u3010\u4ec5\u5206\u6790\u4efb\u52a1\u3011 \u654f\u611f\u6027\u5206\u6790\u7684\u6c47\u603b\u6307\u6807\uff0c\u6bcf\u884c\u662f\u4e00\u6b21\u8fd0\u884c\u7684KPI\u3002 <code>requierd_tbr_summary.csv</code> \u3010\u4ec5\u5206\u6790\u4efb\u52a1\u3011 \u5f53\u6267\u884c\u201cTBR\u9700\u6c42\u201d\u7b49\u76ee\u6807\u641c\u7d22\u4efb\u52a1\u65f6\u751f\u6210\u7684\u4f18\u5316\u7ed3\u679c\u3002 <code>simulation_*.log</code> \u8be6\u7ec6\u7684\u8fd0\u884c\u65e5\u5fd7\uff0c\u5305\u542b\u8c03\u8bd5\u4fe1\u606f\u3002 <code>config.json</code> \u672c\u6b21\u8fd0\u884c\u4f7f\u7528\u7684\u5b8c\u6574\u914d\u7f6e\u5907\u4efd\u3002 <code>*_report.md</code> \u3010\u4ec5\u5206\u6790\u4efb\u52a1\u3011 \u81ea\u52a8\u751f\u6210\u7684AI\u5206\u6790\u62a5\u544a\u3002 <code>*.png</code> / <code>*.csv</code> \u5404\u79cd\u56fe\u8868\u548c\u6570\u636e\u5bfc\u51fa\u3002 <p>\u7ed3\u679c\u6587\u4ef6CSV\u7ed3\u6784</p> <p>\u65e0\u8bba\u8fd0\u884c\u4e00\u4e2a\u8fd8\u662f\u591a\u4e2a\u53c2\u6570\u7ec4\u5408\uff0c\u6700\u7ec8\u7684CSV\u6587\u4ef6\u90fd\u9075\u5faa\u76f8\u4f3c\u7684\u5217\u547d\u540d\u89c4\u5219\u3002</p> <ul> <li> <p>\u57fa\u7840\u60c5\u51b5 (\u65e0\u626b\u63cf\u53c2\u6570):     \u5982\u679c <code>simulation_parameters</code> \u4e3a\u7a7a\uff0c\u5217\u540d\u5c31\u662f <code>variableFilter</code> \u4e2d\u5b9a\u4e49\u7684\u53d8\u91cf\u540d\u3002     <pre><code>time,sds.I[1],blanket.I[1],...\n0.0,10.5,2.3,...\n</code></pre></p> </li> <li> <p>\u53c2\u6570\u626b\u63cf\u60c5\u51b5:     \u5f53 <code>simulation_parameters</code> \u4e0d\u4e3a\u7a7a\u65f6\uff0c\u5217\u540d\u4f1a\u9644\u52a0\u53c2\u6570\u4fe1\u606f\u3002     <pre><code>time,sds.I[1]&amp;blanket.TBR=1.05,sds.I[1]&amp;blanket.TBR=1.1,...\n</code></pre></p> <ul> <li>\u5217\u540d\u683c\u5f0f: <code>&lt;\u53d8\u91cf\u540d&gt;&amp;&lt;\u53c2\u65701&gt;=&lt;\u503c1&gt;&amp;&lt;\u53c2\u65702&gt;=&lt;\u503c2&gt;...</code></li> <li><code>time</code> \u5217\u4fdd\u6301\u4e0d\u53d8\u3002</li> <li>\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u6bcf\u4e2a\u53d8\u91cf\u90fd\u6210\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u5217\u3002\u5217\u540d\u7531 \u53d8\u91cf\u540d \u548c \u53c2\u6570-\u503c \u5bf9\u62fc\u63a5\u800c\u6210\uff0c\u5e76\u7528 <code>&amp;</code> \u7b26\u53f7\u5206\u9694\u3002</li> </ul> </li> </ul> \u95ee\uff1a\u5982\u4f55\u5b9a\u4e49\u590d\u6742\u7684\u53c2\u6570\u626b\u63cf\uff1f <p>TRICYS \u652f\u6301\u591a\u79cd\u53c2\u6570\u626b\u63cf\u683c\u5f0f\uff1a</p> \u529f\u80fd \u683c\u5f0f \u793a\u4f8b \u8bf4\u660e \u79bb\u6563\u5217\u8868 <code>[v1, v2, ...]</code> <code>[6, 12, 18]</code> \u4e00\u7ec4\u79bb\u6563\u503c \u7b49\u5dee\u5e8f\u5217 <code>\"start:stop:step\"</code> <code>\"1.05:1.15:0.05\"</code> \u8d77\u59cb\u503c\u3001\u7ec8\u6b62\u503c\u3001\u6b65\u957f \u7ebf\u6027\u95f4\u9694 <code>\"linspace:start:stop:num\"</code> <code>\"linspace:10:20:5\"</code> \u751f\u6210 <code>num</code> \u4e2a\u7b49\u95f4\u8ddd\u70b9 \u5bf9\u6570\u95f4\u9694 <code>\"log:start:stop:num\"</code> <code>\"log:1:1000:4\"</code> \u751f\u6210 <code>num</code> \u4e2a\u5bf9\u6570\u5c3a\u5ea6\u7684\u70b9 \u4ece\u6587\u4ef6\u8bfb\u53d6 <code>\"file:path:column\"</code> <code>\"file:data.csv:voltage\"</code> \u4ece CSV \u6587\u4ef6\u7684\u6307\u5b9a\u5217\u8bfb\u53d6 <p>\u793a\u4f8b\u914d\u7f6e\uff1a <pre><code>{\n    \"simulation_parameters\": {\n        \"blanket.TBR\": [1.05, 1.1, 1.15, 1.2],\n        \"plasma.fb\": \"linspace:0.01:0.1:10\",\n        \"tep_fep.to_SDS_Fraction[1]\": \"log:0.1:1.0:5\"\n    }\n}\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u8fc7\u6ee4\u8f93\u51fa\u53d8\u91cf\uff1f <p>\u4f7f\u7528 <code>variableFilter</code> \u53c2\u6570\u6765\u9009\u62e9\u9700\u8981\u4fdd\u5b58\u7684\u53d8\u91cf\u3002\u8be5\u53c2\u6570\u652f\u6301\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u4f46\u8bf7\u6ce8\u610f\u5176\u8bed\u6cd5\u4ee5\u5339\u914dModelica\u53d8\u91cf\u547d\u540d\u89c4\u5219\u3002</p> <p>\u914d\u7f6e\u793a\u4f8b\uff1a</p> <pre><code>{\n    \"simulation\": {\n        \"variableFilter\": \"time|sds.I[1]|blanket.I[1-5]|div.I[1-5]\"\n    }\n}\n</code></pre> <p>\u5e38\u7528\u6a21\u5f0f\uff1a *   <code>time</code>\uff1a\u65f6\u95f4\u53d8\u91cf\uff08\u5fc5\u987b\u5305\u542b\uff09 *   <code>sds.I[1]</code>\uff1a\u7cbe\u786e\u5339\u914d\u5355\u4e2a\u53d8\u91cf *   <code>sds.I[1-5]</code>\uff1a\u5339\u914d\u6570\u7ec4\u53d8\u91cf <code>sds.I[1]</code> \u5230 <code>sds.I[5]</code> *   <code>blanket.I[1-5]|div.I[1-5]</code>\uff1a\u5339\u914d\u591a\u4e2a\u7279\u5b9a\u6570\u7ec4\u53d8\u91cf</p> \u95ee\uff1a\u4eff\u771f\u65f6\u95f4\u5f88\u957f\uff0c\u5982\u4f55\u52a0\u901f\uff1f <p>\u53ef\u4ee5\u91c7\u53d6\u4ee5\u4e0b\u4f18\u5316\u63aa\u65bd\uff1a</p> <p>1. \u542f\u7528\u5e76\u53d1\u8fd0\u884c\uff1a <pre><code>{\n    \"simulation\": {\n        \"concurrent\": true,\n        \"max_workers\": 4\n    }\n}\n</code></pre></p> <p>2. \u51cf\u5c11\u8f93\u51fa\u53d8\u91cf\uff1a <pre><code>{\n    \"simulation\": {\n        \"variableFilter\": \"time|sds.I[1]\"  # \u53ea\u4fdd\u5b58\u5173\u952e\u53d8\u91cf\n    }\n}\n</code></pre></p> <p>3. \u589e\u5927\u65f6\u95f4\u6b65\u957f\uff08\u6743\u8861\u7cbe\u5ea6\uff09\uff1a <pre><code>{\n    \"simulation\": {\n        \"step_size\": 1.0  # \u4ece 0.5 \u589e\u52a0\u5230 1.0\n    }\n}\n</code></pre></p> <p>4. \u51cf\u5c11\u626b\u63cf\u70b9\u6570\uff1a <pre><code>{\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1.05:1.15:5\"  # \u4ece 20 \u51cf\u5c11\u5230 5\n    }\n}\n</code></pre></p>"},{"location":"questions/installation.html","title":"\ud83d\ude80 \u5b89\u88c5\u73af\u5883","text":"\u95ee\uff1a\u652f\u6301\u54ea\u4e9b\u64cd\u4f5c\u7cfb\u7edf\uff1f <p>TRICYS \u652f\u6301\u4ee5\u4e0b\u64cd\u4f5c\u7cfb\u7edf\uff1a</p> <ul> <li>Windows 10/11\uff08\u63a8\u8350\u4f7f\u7528 WSL2 + Docker\uff09</li> <li>Ubuntu 20.04+</li> <li>CentOS/Rocky Linux 8+</li> <li>macOS\uff08\u901a\u8fc7 Docker\uff09</li> </ul> \u95ee\uff1a\u5fc5\u987b\u4f7f\u7528 Docker \u5417\uff1f <p>\u4e0d\u662f\u5fc5\u987b\u7684\u3002Docker \u63d0\u4f9b\u4e86\u6700\u7b80\u4fbf\u7684\u5b89\u88c5\u65b9\u5f0f\uff0c\u4f46\u60a8\u4e5f\u53ef\u4ee5\uff1a</p> <ul> <li>\u5728 Windows \u4e0a\u672c\u5730\u5b89\u88c5\uff08\u9700\u8981\u5b89\u88c5 OpenModelica \u548c Python\uff09</li> <li>\u5728 Linux \u4e0a\u672c\u5730\u5b89\u88c5</li> <li>\u4f7f\u7528 WSL2\uff08Windows Subsystem for Linux\uff09</li> </ul> <p>Docker \u7684\u4f18\u52bf\u662f\u73af\u5883\u9694\u79bb\u548c\u5f00\u7bb1\u5373\u7528\uff0c\u9002\u5408\u521d\u5b66\u8005\u3002</p> \u95ee\uff1a\u9700\u8981\u4ec0\u4e48\u7248\u672c\u7684 Python\uff1f <p>TRICYS \u8981\u6c42 Python 3.8 \u6216\u66f4\u9ad8\u7248\u672c\u3002\u63a8\u8350\u4f7f\u7528 Python 3.10 \u6216 3.11 \u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u548c\u517c\u5bb9\u6027\u3002</p> \u95ee\uff1aOpenModelica \u662f\u5fc5\u9700\u7684\u5417\uff1f <p>\u662f\u7684\u3002TRICYS \u4f7f\u7528 OpenModelica \u4f5c\u4e3a\u5efa\u6a21\u548c\u4eff\u771f\u540e\u7aef\u3002\u8bf7\u786e\u4fdd\uff1a</p> <ol> <li>\u5df2\u5b89\u88c5 OpenModelica</li> <li><code>omc</code> \u547d\u4ee4\u53ef\u5728\u547d\u4ee4\u884c\u4e2d\u8bbf\u95ee\uff08\u5df2\u6dfb\u52a0\u5230 PATH\uff09</li> </ol> <p>\u9a8c\u8bc1\u65b9\u6cd5\uff1a <pre><code>omc --version\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u89e3\u51b3\\\"\u627e\u4e0d\u5230 omc \u547d\u4ee4\\\"\u7684\u9519\u8bef\uff1f <p>Windows\uff1a 1. \u786e\u8ba4 OpenModelica \u5b89\u88c5\u8def\u5f84\uff08\u901a\u5e38\u662f <code>C:\\OpenModelica\\bin</code>\uff09 2. \u6dfb\u52a0\u5230\u7cfb\u7edf\u73af\u5883\u53d8\u91cf PATH 3. \u91cd\u542f\u7ec8\u7aef\u6216 VSCode</p> <p>Linux\uff1a <pre><code># \u68c0\u67e5 omc \u4f4d\u7f6e\nwhich omc\n\n# \u5982\u679c\u672a\u627e\u5230\uff0c\u6dfb\u52a0\u5230 PATH\nexport PATH=\"/opt/openmodelica/bin:$PATH\"\n\n# \u6216\u8005\u6c38\u4e45\u6dfb\u52a0\u5230 ~/.bashrc\necho 'export PATH=\"/opt/openmodelica/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> \u95ee\uff1aDocker \u955c\u50cf\u4e0b\u8f7d\u5f88\u6162\u600e\u4e48\u529e\uff1f <p>\u53ef\u4ee5\u4f7f\u7528\u56fd\u5185\u7684 Docker \u955c\u50cf\u52a0\u901f\u5668\uff1a</p> <pre><code># \u7f16\u8f91 Docker \u914d\u7f6e\uff08Linux\uff09\nsudo nano /etc/docker/daemon.json\n\n# \u6dfb\u52a0\u955c\u50cf\u52a0\u901f\u5730\u5740\n{\n  \"registry-mirrors\": [\n    \"https://docker.mirrors.ustc.edu.cn\",\n    \"https://hub-mirror.c.163.com\"\n  ]\n}\n\n# \u91cd\u542f Docker\nsudo systemctl restart docker\n</code></pre> \u95ee\uff1a\u9879\u76ee\u4e2d\u7684 <code>Makefile</code> \u548c <code>Makefile.bat</code> \u662f\u505a\u4ec0\u4e48\u7528\u7684\uff1f <p><code>Makefile</code> (\u9002\u7528\u4e8e Linux/macOS) \u548c <code>Makefile.bat</code> (\u9002\u7528\u4e8e Windows) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u5feb\u6377\u547d\u4ee4\u6765\u7b80\u5316\u5e38\u89c1\u7684\u5f00\u53d1\u4efb\u52a1\uff0c\u4f8b\u5982\u5b89\u88c5\u3001\u6e05\u7406\u548c\u6d4b\u8bd5\u3002</p> <p>\u5e38\u7528\u547d\u4ee4:</p> <ul> <li> <p>\u5b89\u88c5\u4f9d\u8d56:     <pre><code># (Linux/macOS)\nmake dev-install\n\n# (Windows)\nMakefile.bat dev-install\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u5b89\u88c5\u9879\u76ee\u7684\u6240\u6709\u5f00\u53d1\u4f9d\u8d56\u3002</p> </li> <li> <p>\u4ee3\u7801\u683c\u5f0f\u5316\u4e0e\u68c0\u67e5:     <pre><code># (Linux/macOS)\nmake check\n\n# (Windows)\nMakefile.bat check\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u81ea\u52a8\u683c\u5f0f\u5316\u4ee3\u7801\u5e76\u8fd0\u884c\u9759\u6001\u68c0\u67e5\u3002</p> </li> <li> <p>\u8fd0\u884c\u6d4b\u8bd5:     <pre><code># (Linux/macOS)\nmake test\n\n# (Windows)\nMakefile.bat test\n</code></pre></p> </li> <li> <p>\u6e05\u7406\u9879\u76ee:     <pre><code># (Linux/macOS)\nmake clean\n\n# (Windows)\nMakefile.bat clean\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u5220\u9664\u6240\u6709\u6784\u5efa\u7f13\u5b58\u548c\u4e34\u65f6\u6587\u4ef6\u3002</p> </li> </ul> <p>\u4f7f\u7528\u8fd9\u4e9b\u547d\u4ee4\u53ef\u4ee5\u5e2e\u52a9\u60a8\u4fdd\u6301\u5f00\u53d1\u73af\u5883\u7684\u4e00\u81f4\u6027\u3002\u66f4\u591a\u547d\u4ee4\u8bf7\u67e5\u770b\u6587\u4ef6\u5185\u5bb9\u6216\u4f7f\u7528 <code>make help</code> / <code>Makefile.bat help</code>\u3002</p> \u95ee\uff1a\u5982\u4f55\u624d\u80fd\u5728\u672c\u5730\u67e5\u770b\u548c\u6784\u5efa\u6587\u6863\uff1f <p>\u9879\u76ee\u4f7f\u7528 MkDocs \u548c Material for MkDocs \u4e3b\u9898\u6765\u751f\u6210\u6587\u6863\u3002\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7 <code>Makefile</code> \u548c <code>Makefile.bat</code> \u63d0\u4f9b\u4e86\u5feb\u6377\u547d\u4ee4\u3002</p> <p>\u6b65\u9aa4\u5982\u4e0b:</p> <ol> <li> <p>\u5b89\u88c5\u6587\u6863\u4f9d\u8d56:     <pre><code># (Linux/macOS)\nmake docs-install\n\n# (Windows)\nMakefile.bat docs-install\n</code></pre></p> </li> <li> <p>\u542f\u52a8\u672c\u5730\u9884\u89c8\u670d\u52a1\u5668:     <pre><code># (Linux/macOS)\nmake docs-serve\n\n# (Windows)\nMakefile.bat docs-serve\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u542f\u52a8\u4e00\u4e2a\u672c\u5730\u670d\u52a1\u5668\uff08\u901a\u5e38\u5728 <code>http://127.0.0.1:18000</code>\uff09\uff0c\u5e76\u4e14\u5f53\u60a8\u4fee\u6539\u6587\u6863\u6e90\u6587\u4ef6\u65f6\uff0c\u7f51\u9875\u4f1a\u81ea\u52a8\u5237\u65b0\u3002</p> </li> <li> <p>\u6784\u5efa\u9759\u6001\u7f51\u7ad9 (\u53ef\u9009):     <pre><code># (Linux/macOS)\nmake docs-build\n\n# (Windows)\nMakefile.bat docs-build\n</code></pre>     \u5982\u679c\u60a8\u60f3\u751f\u6210\u5b8c\u6574\u7684\u9759\u6001 HTML \u6587\u4ef6\uff08\u4f8b\u5982\u7528\u4e8e\u90e8\u7f72\uff09\uff0c\u53ef\u4ee5\u8fd0\u884c\u6b64\u547d\u4ee4\u3002\u751f\u6210\u7684\u6587\u4ef6\u4f4d\u4e8e <code>site/</code> \u76ee\u5f55\u4e0b\u3002</p> </li> </ol>"},{"location":"questions/troubleshooting.html","title":"\ud83d\udc1b \u6545\u969c\u6392\u9664","text":"\u95ee\uff1a\u4eff\u771f\u5931\u8d25\uff0c\u5982\u4f55\u8c03\u8bd5\uff1f <p>1. \u67e5\u770b\u65e5\u5fd7\u6587\u4ef6\uff1a <pre><code># \u67e5\u770b\u6700\u65b0\u8fd0\u884c\u7684\u65e5\u5fd7\ntail -f results/&lt;timestamp&gt;/simulation_*.log\n</code></pre></p> <p>2. \u5e38\u89c1\u9519\u8bef\u53ca\u89e3\u51b3\u65b9\u6cd5\uff1a</p> \u9519\u8bef\u4fe1\u606f \u53ef\u80fd\u539f\u56e0 \u89e3\u51b3\u65b9\u6cd5 <code>Model not found</code> \u6a21\u578b\u8def\u5f84\u9519\u8bef \u68c0\u67e5 <code>package_path</code> \u662f\u5426\u6b63\u786e <code>Failed to compile</code> Modelica \u8bed\u6cd5\u9519\u8bef \u5728 OMEdit \u4e2d\u6253\u5f00\u6a21\u578b\u68c0\u67e5\u9519\u8bef <code>Variable not found</code> <code>variableFilter</code> \u4e2d\u7684\u53d8\u91cf\u4e0d\u5b58\u5728 \u68c0\u67e5\u53d8\u91cf\u540d\u62fc\u5199\uff0c\u4f7f\u7528\u6b63\u786e\u7684\u8def\u5f84 <code>Out of memory</code> \u5e76\u53d1\u8fdb\u7a0b\u8fc7\u591a\u6216\u6a21\u578b\u592a\u5927 \u51cf\u5c11 <code>max_workers</code> \u6216\u589e\u52a0\u7cfb\u7edf\u5185\u5b58 <code>Permission denied</code> \u6587\u4ef6\u6743\u9650\u95ee\u9898 \u68c0\u67e5\u5de5\u4f5c\u76ee\u5f55\u7684\u8bfb\u5199\u6743\u9650 <p>3. \u542f\u7528\u8be6\u7ec6\u65e5\u5fd7\uff1a <pre><code>{\n    \"logging\": {\n        \"level\": \"DEBUG\"\n    }\n}\n</code></pre></p> \u95ee\uff1aGUI \u65e0\u6cd5\u542f\u52a8\u6216\u663e\u793a\u4e0d\u6b63\u5e38\uff1f <p>Windows/Linux \u672c\u5730\uff1a * \u786e\u4fdd\u5b89\u88c5\u4e86 Tkinter\uff1a<code>pip install tk</code> * \u68c0\u67e5\u663e\u793a\u73af\u5883\u53d8\u91cf\uff1a<code>echo $DISPLAY</code></p> <p>Docker \u5bb9\u5668\uff1a * Windows 11\uff1a\u786e\u4fdd WSL2 \u7684 WSLg \u529f\u80fd\u5df2\u542f\u7528 * Linux\uff1a\u8fd0\u884c <code>xhost +local:</code> \u5141\u8bb8\u5bb9\u5668\u8bbf\u95ee X11 * \u4f7f\u7528\u5305\u542b GUI \u652f\u6301\u7684\u955c\u50cf\uff1a<code>tricys_openmodelica_gui</code></p> \u95ee\uff1a\u53c2\u6570\u626b\u63cf\u7ed3\u679c\u4e0d\u5b8c\u6574\uff1f <p>\u53ef\u80fd\u7684\u539f\u56e0\uff1a</p> <ol> <li>\u67d0\u4e9b\u4eff\u771f\u5931\u8d25\uff1a</li> <li>\u67e5\u770b\u65e5\u5fd7\u6587\u4ef6\u4e2d\u7684\u9519\u8bef\u4fe1\u606f</li> <li> <p>\u68c0\u67e5\u53c2\u6570\u503c\u662f\u5426\u5408\u7406\uff08\u5982\u907f\u514d\u9664\u96f6\u3001\u8d1f\u503c\u7b49\uff09</p> </li> <li> <p>\u8f93\u51fa\u53d8\u91cf\u8fc7\u6ee4\u5668\u592a\u4e25\u683c\uff1a</p> </li> <li> <p>\u68c0\u67e5 <code>variableFilter</code> \u662f\u5426\u5339\u914d\u4e86\u6240\u9700\u53d8\u91cf</p> </li> <li> <p>\u5e76\u53d1\u95ee\u9898\uff1a</p> </li> <li>\u5c1d\u8bd5\u7981\u7528\u5e76\u53d1\uff1a<code>\"concurrent\": false</code></li> <li>\u67e5\u770b\u662f\u5426\u6709\u8fdb\u7a0b\u5d29\u6e83</li> </ol> \u95ee\uff1a\u5982\u4f55\u62a5\u544a Bug\uff1f <p>\u8bf7\u5728 GitHub Issues \u4e2d\u521b\u5efa\u65b0 Issue\uff0c\u5e76\u63d0\u4f9b\uff1a</p> <ol> <li>\u73af\u5883\u4fe1\u606f\uff1a</li> <li>\u64cd\u4f5c\u7cfb\u7edf\u548c\u7248\u672c</li> <li>Python \u7248\u672c</li> <li>OpenModelica \u7248\u672c</li> <li> <p>TRICYS \u7248\u672c</p> </li> <li> <p>\u91cd\u73b0\u6b65\u9aa4\uff1a</p> </li> <li>\u5b8c\u6574\u7684\u914d\u7f6e\u6587\u4ef6</li> <li>\u8fd0\u884c\u7684\u547d\u4ee4</li> <li> <p>\u4f7f\u7528\u7684\u6a21\u578b\uff08\u5982\u679c\u53ef\u80fd\uff09</p> </li> <li> <p>\u9519\u8bef\u4fe1\u606f\uff1a</p> </li> <li>\u5b8c\u6574\u7684\u9519\u8bef\u5806\u6808</li> <li> <p>\u76f8\u5173\u7684\u65e5\u5fd7\u7247\u6bb5</p> </li> <li> <p>\u9884\u671f\u884c\u4e3a\uff1a</p> </li> <li>\u60a8\u671f\u671b\u53d1\u751f\u4ec0\u4e48</li> <li>\u5b9e\u9645\u53d1\u751f\u4e86\u4ec0\u4e48</li> </ol>"},{"location":"en/index.html","title":"TRICYS: Tritium Integrated Cycle Simulation Platform","text":"<p>Welcome to TRICYS (TRitium Integrated CYcle Simulation), the Tritium Integrated Cycle Simulation platform. TRICYS is an open-source, modular, and multi-scale fusion reactor tritium fuel cycle simulator, designed to provide physics-based dynamic closed-loop analysis while strictly adhering to plant-wide mass balance principles.</p> <p>Our goal is to provide researchers and engineers with a flexible and powerful platform for exploring various tritium management strategies, optimizing system design, and deeply understanding the dynamics of tritium flow and inventory within a fusion reactor environment.</p> <p>We welcome community contributions! Whether you are a fusion scientist, a software engineer, or an enthusiast passionate about open-source projects, there are many ways to get involved in the development of TRICYS.</p> <p>Quick Start Report an Issue Example model of a 0-dimensional tritium fuel cycle system</p>"},{"location":"en/index.html#what-can-tricys-do","title":"\ud83d\udcda What can TRICYS do?","text":"<ul> <li>Parameter Scanning &amp; Concurrency: Systematically study the impact of multiple parameters on system performance, supporting concurrent execution and large-scale batch simulations.</li> <li>Sub-module Co-simulation: Supports data exchange with external tools (like Aspen Plus) to complete sub-module system integration.</li> <li>Automated Report Generation: Automatically generate standardized Markdown analysis reports, including charts, statistical data, and visualized results.</li> <li>Parameter Sensitivity Analysis: Supports custom sensitivity analysis of system parameters and integrates the SALib (Sensitivity Analysis Library in Python) library to quantify the impact of parameters on outputs.</li> </ul>"},{"location":"en/index.html#why-choose-tricys","title":"\ud83d\udd2c Why choose TRICYS?","text":"<ul> <li>Accuracy &amp; Flexibility: Combines detailed physical models with a highly configurable system architecture.</li> <li>Modular Design: Easy to integrate into existing workflows and automation systems.</li> <li>Industrial Applications: Suitable for fusion reactor design optimization, operational strategy evaluation, and safety analysis.</li> <li>Community-Driven: Benefits from collaborative development and transparent decision-making processes.</li> <li>Educational Tool: Provides an excellent resource for students and new researchers to understand fusion fuel cycle dynamics.</li> </ul>"},{"location":"en/changelog.html","title":"Changelog","text":"<p>TRICYS follows Semantic Versioning:</p> <ul> <li>Major: Incremented for incompatible API changes</li> <li>Minor: Incremented for adding new functionality in a backward-compatible manner</li> <li>Patch: Incremented for backward-compatible bug fixes</li> </ul>"},{"location":"en/changelog.html#100-2025-11-15","title":"1.0.0 ( 2025-11-15 )","text":"<p>TRICYS 1.0.0 is the first official stable release of the project, marking the completion of core functionalities and readiness for production environments.</p> <ul> <li>Parameter Scanning and Concurrency: Systematically study the impact of multiple parameters on system performance, supporting concurrent execution and large-scale batch simulations.</li> <li>Sub-module Co-simulation: Supports data exchange with external tools (e.g., Aspen Plus) to achieve sub-module system integration.</li> <li>Automated Report Generation: Automatically generates standardized Markdown analysis reports, including charts, statistical data, and visualization results.</li> <li>Parameter Sensitivity Analysis: Supports custom sensitivity analysis for system parameters and integrates the SALib (Sensitivity Analysis Library in Python) library to quantify the impact of parameters on the output.</li> </ul>"},{"location":"en/license.html","title":"License","text":"<pre><code>                                                              Apache License\n                                                        Version 2.0, January 2004\n                                                     http://www.apache.org/licenses/\n\n                                TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n                                1. Definitions.\n\n                                   \"License\" shall mean the terms and conditions for use, reproduction,\n                                   and distribution as defined by Sections 1 through 9 of this document.\n\n                                   \"Licensor\" shall mean the copyright owner or entity authorized by\n                                   the copyright owner that is granting the License.\n\n                                   \"Legal Entity\" shall mean the union of the acting entity and all\n                                   other entities that control, are controlled by, or are under common\n                                   control with that entity. For the purposes of this definition,\n                                   \"control\" means (i) the power, direct or indirect, to cause the\n                                   direction or management of such entity, whether by contract or\n                                   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n                                   outstanding shares, or (iii) beneficial ownership of such entity.\n\n                                   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n                                   exercising permissions granted by this License.\n\n                                   \"Source\" form shall mean the preferred form for making modifications,\n                                   including but not limited to software source code, documentation\n                                   source, and configuration files.\n\n                                   \"Object\" form shall mean any form resulting from mechanical\n                                   transformation or translation of a Source form, including but\n                                   not limited to compiled object code, generated documentation,\n                                   and conversions to other media types.\n\n                                   \"Work\" shall mean the work of authorship, whether in Source or\n                                   Object form, made available under the License, as indicated by a\n                                   copyright notice that is included in or attached to the work\n                                   (an example is provided in the Appendix below).\n\n                                   \"Derivative Works\" shall mean any work, whether in Source or Object\n                                   form, that is based on (or derived from) the Work and for which the\n                                   editorial revisions, annotations, elaborations, or other modifications\n                                   represent, as a whole, an original work of authorship. For the purposes\n                                   of this License, Derivative Works shall not include works that remain\n                                   separable from, or merely link (or bind by name) to the interfaces of,\n                                   the Work and Derivative Works thereof.\n\n                                   \"Contribution\" shall mean any work of authorship, including\n                                   the original version of the Work and any modifications or additions\n                                   to that Work or Derivative Works thereof, that is intentionally\n                                   submitted to Licensor for inclusion in the Work by the copyright owner\n                                   or by an individual or Legal Entity authorized to submit on behalf of\n                                   the copyright owner. For the purposes of this definition, \"submitted\"\n                                   means any form of electronic, verbal, or written communication sent\n                                   to the Licensor or its representatives, including but not limited to\n                                   communication on electronic mailing lists, source code control systems,\n                                   and issue tracking systems that are managed by, or on behalf of, the\n                                   Licensor for the purpose of discussing and improving the Work, but\n                                   excluding communication that is conspicuously marked or otherwise\n                                   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n                                   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n                                   on behalf of whom a Contribution has been received by Licensor and\n                                   subsequently incorporated within the Work.\n\n                                2. Grant of Copyright License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   copyright license to reproduce, prepare Derivative Works of,\n                                   publicly display, publicly perform, sublicense, and distribute the\n                                   Work and such Derivative Works in Source or Object form.\n\n                                3. Grant of Patent License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   (except as stated in this section) patent license to make, have made,\n                                   use, offer to sell, sell, import, and otherwise transfer the Work,\n                                   where such license applies only to those patent claims licensable\n                                   by such Contributor that are necessarily infringed by their\n                                   Contribution(s) alone or by combination of their Contribution(s)\n                                   with the Work to which such Contribution(s) was submitted. If You\n                                   institute patent litigation against any entity (including a\n                                   cross-claim or counterclaim in a lawsuit) alleging that the Work\n                                   or a Contribution incorporated within the Work constitutes direct\n                                   or contributory patent infringement, then any patent licenses\n                                   granted to You under this License for that Work shall terminate\n                                   as of the date such litigation is filed.\n\n                                4. Redistribution. You may reproduce and distribute copies of the\n                                   Work or Derivative Works thereof in any medium, with or without\n                                   modifications, and in Source or Object form, provided that You\n                                   meet the following conditions:\n\n                                   (a) You must give any other recipients of the Work or\n                                       Derivative Works a copy of this License; and\n\n                                   (b) You must cause any modified files to carry prominent notices\n                                       stating that You changed the files; and\n\n                                   (c) You must retain, in the Source form of any Derivative Works\n                                       that You distribute, all copyright, patent, trademark, and\n                                       attribution notices from the Source form of the Work,\n                                       excluding those notices that do not pertain to any part of\n                                       the Derivative Works; and\n\n                                   (d) If the Work includes a \"NOTICE\" text file as part of its\n                                       distribution, then any Derivative Works that You distribute must\n                                       include a readable copy of the attribution notices contained\n                                       within such NOTICE file, excluding those notices that do not\n                                       pertain to any part of the Derivative Works, in at least one\n                                       of the following places: within a NOTICE text file distributed\n                                       as part of the Derivative Works; within the Source form or\n                                       documentation, if provided along with the Derivative Works; or,\n                                       within a display generated by the Derivative Works, if and\n                                       wherever such third-party notices normally appear. The contents\n                                       of the NOTICE file are for informational purposes only and\n                                       do not modify the License. You may add Your own attribution\n                                       notices within Derivative Works that You distribute, alongside\n                                       or as an addendum to the NOTICE text from the Work, provided\n                                       that such additional attribution notices cannot be construed\n                                       as modifying the License.\n\n                                   You may add Your own copyright statement to Your modifications and\n                                   may provide additional or different license terms and conditions\n                                   for use, reproduction, or distribution of Your modifications, or\n                                   for any such Derivative Works as a whole, provided Your use,\n                                   reproduction, and distribution of the Work otherwise complies with\n                                   the conditions stated in this License.\n\n                                5. Submission of Contributions. Unless You explicitly state otherwise,\n                                   any Contribution intentionally submitted for inclusion in the Work\n                                   by You to the Licensor shall be under the terms and conditions of\n                                   this License, without any additional terms or conditions.\n                                   Notwithstanding the above, nothing herein shall supersede or modify\n                                   the terms of any separate license agreement you may have executed\n                                   with Licensor regarding such Contributions.\n\n                                6. Trademarks. This License does not grant permission to use the trade\n                                   names, trademarks, service marks, or product names of the Licensor,\n                                   except as required for reasonable and customary use in describing the\n                                   origin of the Work and reproducing the content of the NOTICE file.\n\n                                7. Disclaimer of Warranty. Unless required by applicable law or\n                                   agreed to in writing, Licensor provides the Work (and each\n                                   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n                                   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n                                   implied, including, without limitation, any warranties or conditions\n                                   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n                                   PARTICULAR PURPOSE. You are solely responsible for determining the\n                                   appropriateness of using or redistributing the Work and assume any\n                                   risks associated with Your exercise of permissions under this License.\n\n                                8. Limitation of Liability. In no event and under no legal theory,\n                                   whether in tort (including negligence), contract, or otherwise,\n                                   unless required by applicable law (such as deliberate and grossly\n                                   negligent acts) or agreed to in writing, shall any Contributor be\n                                   liable to You for damages, including any direct, indirect, special,\n                                   incidental, or consequential damages of any character arising as a\n                                   result of this License or out of the use or inability to use the\n                                   Work (including but not limited to damages for loss of goodwill,\n                                   work stoppage, computer failure or malfunction, or any and all\n                                   other commercial damages or losses), even if such Contributor\n                                   has been advised of the possibility of such damages.\n\n                                9. Accepting Warranty or Additional Liability. While redistributing\n                                   the Work or Derivative Works thereof, You may choose to offer,\n                                   and charge a fee for, acceptance of support, warranty, indemnity,\n                                   or other liability obligations and/or rights consistent with this\n                                   License. However, in accepting such obligations, You may act only\n                                   on Your own behalf and on Your sole responsibility, not on behalf\n                                   of any other Contributor, and only if You agree to indemnify,\n                                   defend, and hold each Contributor harmless for any liability\n                                   incurred by, or claims asserted against, such Contributor by reason\n                                   of your accepting any such warranty or additional liability.\n\n                                END OF TERMS AND CONDITIONS\n\n                                APPENDIX: How to apply the Apache License to your work.\n\n                                   To apply the Apache License to your work, attach the following\n                                   boilerplate notice, with the fields enclosed by brackets \"[]\"\n                                   replaced with your own identifying information. (Don't include\n                                   the brackets!)  The text should be enclosed in the appropriate\n                                   comment syntax for the file format. We also recommend that a\n                                   file or class name and description of purpose be included on the\n                                   same \"printed page\" as the copyright notice for easier\n                                   identification within third-party archives.\n\n                                Copyright [yyyy] [name of copyright owner]\n\n                                Licensed under the Apache License, Version 2.0 (the \"License\");\n                                you may not use this file except in compliance with the License.\n                                You may obtain a copy of the License at\n\n                                    http://www.apache.org/licenses/LICENSE-2.0\n\n                                Unless required by applicable law or agreed to in writing, software\n                                distributed under the License is distributed on an \"AS IS\" BASIS,\n                                WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n                                See the License for the specific language governing permissions and\n                                limitations under the License.\n</code></pre>"},{"location":"en/api/tricys_analysis.html","title":"API Reference - Analysis Modules","text":"<p>Analysis Modules</p> <p>The Analysis modules provide tools for processing, visualizing, and reporting TRICYS simulation results. Please select a specific module of interest from the tabs below.</p> MetricPlotReportSALib (Sensitivity) <p>Utility functions for plotting simulation results.</p> <p>This module provides functions to generate plots from the simulation output CSV files, such as visualizing startup tritium inventory or time-series data.</p>"},{"location":"en/api/tricys_core.html","title":"API Reference - Core Modules","text":"<p>Core Modules</p> <p>The Core modules contain the core functionalities of TRICYS, such as job management, Modelica interaction, and event interceptors. Please select a specific module of interest from the tabs below.</p> JobsModelicaInterceptor <p>Utilities for interacting with OpenModelica via OMPython.</p> <p>This module provides a set of functions to manage an OpenModelica session, load models, retrieve parameter details, and format parameter values for simulation.</p>"},{"location":"en/api/tricys_handlers.html","title":"API Reference - Co-simulation Handlers","text":"<p>Co-simulation Handlers</p> <p>The Co-simulation Handlers provide interfaces for data exchange and co-simulation with external simulation tools (like Aspen Plus). Please select a specific module of interest from the tabs below.</p> DIV HandlerI_ISS Handler"},{"location":"en/api/tricys_postprocess.html","title":"API Reference - Post-processing Modules","text":"<p>Post-processing Modules</p> <p>The Post-processing modules provide analysis and reporting functions that are automatically executed after a simulation run. Please select a specific module of interest from the tabs below.</p> Baseline AnalysisRise AnalysisStatic Alarm <p>This module provides functions for plotting simulation results.</p>"},{"location":"en/api/tricys_simulation.html","title":"API Reference - Main Simulation Entrypoints","text":"<p>Main Simulation Entrypoints</p> <p>The Main Simulation Entrypoints contain the main execution scripts for TRICYS, responsible for launching standard simulation and analysis workflows. Please select a specific module of interest from the tabs below.</p> Standard SimulationSimulation Analysis"},{"location":"en/api/tricys_utils.html","title":"API Reference - Utilities","text":"<p>Utilities</p> <p>The Utilities provide a series of helper functions for configuration processing, file operations, logging, and database interaction. Please select a specific module of interest from the tabs below.</p> Config UtilsFile UtilsLog UtilsSQLite Utils <p>Configuration utility functions for tricys.</p> <p>Utility functions for file and directory management.</p> <p>This module provides helper functions for creating unique filenames and managing log file rotation.</p> <p>Utilities for interacting with the simulation parameter SQLite database.</p> <p>This module provides functions to create, store, update, and retrieve simulation parameter data from a SQLite database file.</p>"},{"location":"en/explanation/architecture.html","title":"System Architecture","text":""},{"location":"en/explanation/architecture.html#1-overall-architecture","title":"1. Overall Architecture","text":"<p>TRICYS adopts a layered architectural design, primarily consisting of the following layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               User Interface Layer            \u2502\n\u2502  (tricys basic, tricys analysis, tricys gui)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             Simulation Execution Layer        \u2502\n\u2502    (simulation, simulation_analysis)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Core Function Layer           \u2502\n\u2502        (Jobs, Modelica, Interceptor)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Analysis &amp; Post-processing Layer    \u2502\n\u2502         (Metric, Plot, Report, SALib)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Utility Layer                \u2502\n\u2502     (Config, File, Log, SQLite Utils)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              External Dependency Layer        \u2502\n\u2502    (OpenModelica, Pandas, NumPy, SALib)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"en/explanation/architecture.html#2-program-layers","title":"2. Program Layers","text":""},{"location":"en/explanation/architecture.html#21-user-interface-layer","title":"2.1. User Interface Layer","text":"<p>Location: <code>tricys/main.py</code></p> <p>Responsibilities:</p> <ul> <li>Provides two interaction methods: Command-Line Interface (CLI) and Graphical User Interface (GUI).</li> <li>Parses user-input command-line arguments and subcommands (<code>basic</code>, <code>analysis</code>, <code>gui</code>, <code>example</code>, <code>archive</code>, <code>unarchive</code>).</li> <li>Routes requests to the appropriate modules in the Simulation Execution Layer.</li> <li>Manages user sessions and configuration file loading.</li> </ul> <p>Key Functions:</p> <ul> <li>CLI Command Dispatch: Automatically identifies the run mode based on subcommands or configuration file content.</li> <li>GUI Interaction: Provides a visual interface for parameter setting, simulation startup, and result viewing.</li> <li>Example Runner: Integrates interactive selection and execution of examples.</li> </ul>"},{"location":"en/explanation/architecture.html#22-simulation-execution-layer","title":"2.2. Simulation Execution Layer","text":"<p>Location: <code>tricys/simulation/</code></p> <p>Responsibilities:</p> <ul> <li>Basic Simulation Mode (<code>simulation.py</code>): Executes single or parameter-sweep simulation tasks.</li> <li>Sensitivity Analysis Mode (<code>simulation_analysis.py</code>): Executes various sensitivity analysis workflows.</li> <li>Manages the complete lifecycle of simulation tasks (initialization, execution, post-processing).</li> <li>Coordinates calls to the Core Function, Analysis, and Post-processing layers.</li> </ul> <p>See also: Simulation Flow and Analysis Flow</p>"},{"location":"en/explanation/architecture.html#23-core-function-layer","title":"2.3. Core Function Layer","text":"<p>Location: <code>tricys/core/</code></p> <p>Responsibilities:</p> <ul> <li>Modelica Interaction (<code>modelica.py</code>): Communicates with the OpenModelica engine via OMPython.</li> <li>Job Generation (<code>jobs.py</code>): Generates parameter sweep tasks and simulation jobs based on the configuration.</li> <li>Interceptor Mechanism (<code>interceptor.py</code>): Generates and integrates interceptor models to enable co-simulation.</li> </ul> <p>See also: API Reference - Core Module</p>"},{"location":"en/explanation/architecture.html#24-analysis-post-processing-layer","title":"2.4. Analysis &amp; Post-processing Layer","text":"<p>Location: <code>tricys/analysis/</code>, <code>tricys/postprocess/</code></p> <p>Responsibilities:</p> <ul> <li>Performance Metric Calculation (<code>analysis/metric.py</code>): Calculates key metrics such as startup inventory, doubling time, and turning points.</li> <li>Data Visualization (<code>analysis/plot.py</code>): Generates time-series plots, parameter sweep plots, comparison plots, etc.</li> <li>Sensitivity Analysis (<code>analysis/salib.py</code>): Integrates the SALib library to perform various sensitivity analysis methods.</li> <li>Analysis Report Generation (<code>analysis/report.py</code>): Automatically generates analysis reports in Markdown format, with optional AI enhancement.</li> <li>Post-processing Modules (<code>postprocess/</code>): Provides extensible data post-processing capabilities.</li> </ul> <p>See also: API Reference - Analysis Module</p>"},{"location":"en/explanation/architecture.html#25-utility-layer","title":"2.5. Utility Layer","text":"<p>Location: <code>tricys/utils/</code></p> <p>Responsibilities:</p> <ul> <li>Configuration Management (<code>config_utils.py</code>): Handles configuration file loading, validation, and preprocessing.</li> <li>File Operations (<code>file_utils.py</code>): Manages file paths, unique filename generation, and archiving.</li> <li>Logging System (<code>log_utils.py</code>): Provides structured logging and configuration recovery.</li> <li>Database Operations (<code>sqlite_utils.py</code>): Manages SQLite data storage and querying.</li> </ul> <p>See also: API Reference - Utilities</p>"},{"location":"en/explanation/architecture.html#26-external-dependency-layer","title":"2.6. External Dependency Layer","text":"<p>Key Dependencies:</p> <ul> <li>OpenModelica: The engine for compiling and executing Modelica models.</li> <li>OMPython: The interface library between Python and OpenModelica.</li> <li>SALib: A library for sensitivity analysis and uncertainty quantification.</li> <li>Pandas/NumPy: Used for data processing and numerical computation.</li> <li>Matplotlib/Seaborn: Used for data visualization.</li> <li>OpenAI (Optional): For generating AI-enhanced analysis reports.</li> </ul> <p>Responsibilities:</p> <ul> <li>Provides the underlying simulation engine, numerical computation, and scientific computing support.</li> <li>Ensures cross-platform compatibility and high-performance computation capabilities.</li> </ul>"},{"location":"en/explanation/architecture.html#3-design-principles","title":"3. Design Principles","text":"<ol> <li>Modularity: Each functional module has a single responsibility and is independent.</li> <li>Extensibility: Easy to add new post-processing modules, performance metrics, and co-simulation handlers.</li> <li>Configuration-Driven: All simulation tasks are defined through JSON configuration files.</li> <li>Automation: Fully automated workflow from simulation to analysis report generation.</li> <li>Openness: Open-source design that encourages community contributions.</li> </ol>"},{"location":"en/explanation/tricys_analysis/analysis_flow.html","title":"TRICYS Analysis Workflow","text":"<p>The analysis workflow of <code>tricys</code> (<code>simulation_analysis.py</code>) is a powerful, analysis-oriented automated process. Built upon the core simulation functionality, it incorporates complex multi-mode scheduling, goal-seeking optimization, and report generation capabilities. This document provides a detailed breakdown of its internal workflow.</p>"},{"location":"en/explanation/tricys_analysis/analysis_flow.html#1-core-workflow-diagram","title":"1. Core Workflow Diagram","text":"<p>Below is the complete workflow diagram for the <code>tricys</code> analysis process. It starts by reading the configuration, intelligently selects one of three primary operating modes, and executes the corresponding tasks until completion.</p> <pre><code>graph TD\n    %% === 1. Startup Phase ===\n    subgraph Sub_A [\"A. Startup &amp; Mode Selection\"]\n        A1[Start: main config.json] --&gt; A2[\"Prepare Config &amp; Logs&lt;br&gt;analysis_prepare_config()\"]\n        A2 --&gt; A3{\"&lt;font size=4&gt;&lt;b&gt;Execution Mode Dispatch&lt;/b&gt;&lt;/font&gt;&lt;br&gt;Inside run_simulation()\"}\n    end\n\n    %% Mode Dispatch Logic\n    A3 --&gt; B_GROUP{analysis_cases defined?}\n    B_GROUP -- Yes --&gt; C1\n    B_GROUP -- No --&gt; D_GROUP{Is it a SALib analysis?}\n\n    D_GROUP -- Yes --&gt; E1\n    D_GROUP -- No --&gt; F1\n\n    %% === 2. Mode One ===\n    subgraph Sub_C [\"C. Mode 1: Multi-Case Analysis\"]\n        direction TB\n        C1[\"&lt;b&gt;Mode 1: Multi-Case Analysis&lt;/b&gt;\"]\n        C1 --&gt; C2[Create isolated workspace&lt;br&gt;&amp; config for each case]\n        C2 --&gt; C3{Run cases in parallel?&lt;br&gt;concurrent_cases}\n\n        C3 -- Yes --&gt; C4[Use &lt;b&gt;ProcessPoolExecutor&lt;/b&gt;&lt;br&gt;to call _execute_analysis_case in parallel]\n        C3 -- No --&gt; C5[Loop sequentially&lt;br&gt;and call _execute_analysis_case]\n\n        %% Subgraph for single case execution\n        subgraph Sub_C6 [\"C6. Single Case Execution (_execute_analysis_case)\"]\n            direction TB\n            C6_1[Change to isolated workspace] --&gt; C6_2[\"&lt;b&gt;Recursively call run_simulation&lt;br&gt;(with inner concurrency disabled)&lt;/b&gt;\"] \n            C6_2 --&gt; C6_3[Execute the full flow of Mode 3]\n        end\n\n        C4 --&gt; C6_1\n        C5 --&gt; C6_1\n\n        C6_3 --&gt; C7[All cases completed]\n        C7 --&gt; C8[\"Consolidate reports&lt;br&gt;from all cases&lt;br&gt;consolidate_reports()\"]\n        C8 --&gt; Z1[End]\n    end\n\n    %% === 3. Mode Two ===\n    subgraph Sub_E [\"E. Mode 2: SALib Analysis\"]\n        direction TB\n        E1[\"&lt;b&gt;Mode 2: SALib Analysis&lt;/b&gt;\"] --&gt; E2[Call run_salib_analysis]\n\n        %% Subgraph for SALib flow\n        subgraph Sub_E3 [\"E3. SALib Internal Workflow\"]\n            direction TB\n            E3_1[1. Generate parameter samples using SALib] --&gt; E3_2[2. Run simulation for each sample] \n            E3_2 --&gt; E3_3[3. Collect results and compute sensitivity indices]\n        end\n\n        E2 --&gt; E3_1\n        E3_3 --&gt; Z2[End]\n    end\n\n    %% === 4. Mode Three ===\n    subgraph Sub_F [\"F. Mode 3: Standard Sweep &amp; Analysis\"]\n        direction TB\n        F1[\"&lt;b&gt;Mode 3: Standard Sweep &amp; Analysis&lt;/b&gt;\"] --&gt; F2[Generate list of simulation jobs]\n        F2 --&gt; F3{Run jobs in parallel?&lt;br&gt;concurrent}\n\n        F3 -- Yes --&gt; F4[\"Use &lt;b&gt;ThreadPoolExecutor (Standard Sim)&lt;/b&gt;&lt;br&gt;or &lt;b&gt;ProcessPoolExecutor (Co-Sim)&lt;/b&gt;&lt;br&gt;to run each job in parallel\"]\n        F3 -- No --&gt; F5[\"Execute sequentially&lt;br&gt;_run_sequential_sweep()\"]\n\n        %% Subgraph for single job execution\n        subgraph Sub_F6 [\"F6. Single Job Execution (_run_..._job)\"]\n            direction TB\n            F6_1[1. Run simulation in isolated workspace] --&gt; F6_2{2. Optimization goal configured?&lt;br&gt;(e.g., Required_...)}\n\n            F6_2 -- Yes --&gt; F6_3[\"&lt;b&gt;Optimization Sub-flow&lt;/b&gt;&lt;br&gt;Call _run_bisection_search_for_job\"]\n\n            %% Nested subgraph for bisection search\n            subgraph Sub_F6_4 [\"F6_4. Bisection Search Loop\"]\n                F6_4_1[a. Iteratively run simulations&lt;br&gt;within search range] --&gt; F6_4_2[b. Check if metric meets target] \n                F6_4_2 --&gt; F6_4_3[c. Narrow search range]\n                F6_4_3 --&gt; F6_4_1\n            end\n\n            F6_3 --&gt; F6_4_1\n            F6_4_2 -- Met or Finished --&gt; F6_5\n\n            F6_5[\"3. Return simulation result path&lt;br&gt;&amp; &lt;b&gt;optimization results&lt;/b&gt;\"]\n            F6_2 -- No --&gt; F6_5\n        end\n\n        F4 --&gt; F6_1\n        F5 --&gt; F6_1\n\n        F6_5 --&gt; F7[All jobs completed]\n        F7 --&gt; F8[\"&lt;b&gt;Result Aggregation &amp; Post-processing&lt;/b&gt;\"]\n\n        %% Subgraph for subsequent steps\n        subgraph Sub_F9 [\"F9. Subsequent Steps\"]\n            direction TB\n            F9_1[a. Merge simulation results to sweep_results.csv] --&gt; F9_2[b. Merge optimization results to requierd_tbr_summary.csv]\n            F9_2 --&gt; F9_3[\"c. Run sensitivity analysis&lt;br&gt;_run_sensitivity_analysis()&lt;br&gt;(Extract metrics, generate plots)\"]\n            F9_3 --&gt; F9_4[\"d. Execute custom post-processing&lt;br&gt;_run_post_processing()\"]\n        end\n\n        F8 --&gt; F9_1\n        F9_4 --&gt; Z3[End]\n    end\n\n    %% Style Definitions\n    style C1 fill:#e3f2fd,stroke:#333,stroke-width:2px\n    style E1 fill:#e8f5e9,stroke:#333,stroke-width:2px\n    style F1 fill:#fbe9e7,stroke:#333,stroke-width:2px</code></pre>"},{"location":"en/explanation/tricys_analysis/analysis_flow.html#2-detailed-workflow-steps","title":"2. Detailed Workflow Steps","text":""},{"location":"en/explanation/tricys_analysis/analysis_flow.html#21-startup-and-mode-selection","title":"2.1. Startup and Mode Selection","text":"<p>The entire process begins in the <code>main</code> function, which is responsible for loading and preprocessing the configuration file (<code>analysis_prepare_config</code>) and setting up the logging system. The core logic resides in the <code>run_simulation</code> function, which first performs mode dispatch to decide which core workflow to execute next.</p>"},{"location":"en/explanation/tricys_analysis/analysis_flow.html#22-mode-1-multi-case-analysis","title":"2.2. Mode 1: Multi-Case Analysis","text":"<p>This mode is activated when <code>analysis_cases</code> is defined in the configuration file. It is used to execute a series of independent, comparable analysis studies.</p> <ol> <li>Environment Setup: The framework creates a completely separate sub-workspace for each case defined in <code>analysis_cases</code> and generates a customized configuration file for each. This ensures that the execution environment for each case (including model modifications, temporary files, and results) is isolated.</li> <li>Concurrent Execution: If <code>\"concurrent_cases\": true</code> is configured, <code>tricys</code> starts a process pool (<code>ProcessPoolExecutor</code>) to execute all cases in parallel. Using processes is crucial here, as each case is a full <code>tricys</code> run instance that requires independent memory space and file system permissions to avoid conflicts.</li> <li>Recursive Call: The execution of each case is wrapped by the <code>_execute_analysis_case</code> function, which recursively calls <code>run_simulation</code> while forcing internal concurrency to be disabled (to prevent nested process pools). This means each case internally executes the complete workflow of \"Mode 3\".</li> <li>Report Consolidation: After all cases are completed, the framework calls functions like <code>consolidate_reports</code> to collect the analysis results and reports from all sub-workspaces and generate a top-level summary report, facilitating cross-case comparisons for the user.</li> </ol>"},{"location":"en/explanation/tricys_analysis/analysis_flow.html#23-mode-2-salib-global-sensitivity-analysis","title":"2.3. Mode 2: SALib Global Sensitivity Analysis","text":"<p>If the configuration points to a Global Sensitivity Analysis (GSA) task (identified by keywords like <code>independent_variable_sampling</code> and <code>analyzer</code>), <code>tricys</code> hands over control to a dedicated SALib workflow.</p> <ol> <li>Call <code>run_salib_analysis</code>: This is the entry point for the SALib process.</li> <li>Parameter Sampling: It uses the SALib library (e.g., <code>saltelli.sample</code>) to generate a large set of parameter samples based on the configured parameter distributions.</li> <li>Batch Simulation: It runs a Modelica simulation for each parameter sample.</li> <li>Result Analysis: It collects all simulation results and uses a SALib analyzer (e.g., <code>sobol.analyze</code>) to calculate the first-order, second-order, and total-order sensitivity indices (S1, S2, ST) for each parameter.</li> <li>Output Report: The sensitivity indices and related plots are outputted as the final analysis report.</li> </ol>"},{"location":"en/explanation/tricys_analysis/analysis_flow.html#24-mode-3-standard-sweep-and-analysis","title":"2.4. Mode 3: Standard Sweep and Analysis","text":"<p>This is the most fundamental and core workflow, executed when the conditions for the other two modes are not met.</p> <ol> <li>Job Generation: A list of simulation jobs is generated based on the <code>simulation_parameters</code>.</li> <li>Job Execution:<ul> <li>Based on the <code>concurrent</code> configuration, all <code>jobs</code> are executed either in parallel or sequentially.</li> <li>The execution of each job is handled by functions like <code>_run_single_job</code> or <code>_run_co_simulation</code>.</li> </ul> </li> <li>Optimization Sub-flow (Core Feature): After a single simulation job is completed, the system checks if an optimization goal is configured (metrics prefixed with <code>Required_</code>).<ul> <li>If yes, the system immediately calls <code>_run_bisection_search_for_job</code> to start a bisection search loop.</li> <li>This loop iteratively runs multiple simulations to find the optimal parameter value that satisfies a predefined metric (e.g., a TBR &gt; 1.05), adjusting the parameter based on the results of each iteration until a solution is found or the maximum number of iterations is reached.</li> </ul> </li> <li>Result Aggregation:<ul> <li>After all tasks (including all simulations within the optimization sub-flow) are complete, the framework aggregates two types of data:<ul> <li>The raw time-series data from all simulations is merged into <code>sweep_results.csv</code>.</li> <li>The final results of all optimization tasks (e.g., the optimal <code>enrichment</code> for <code>TBR&gt;1.05</code> is <code>0.85</code>) are merged into <code>requierd_tbr_summary.csv</code>.</li> </ul> </li> </ul> </li> <li>Final Analysis and Post-processing:<ul> <li><code>_run_sensitivity_analysis</code> is called to load the aggregated data, calculate final Key Performance Indicators (KPIs), and generate analysis plots and summaries.</li> <li><code>_run_post_processing</code> is called to execute any user-defined custom scripts (e.g., to generate reports in a specific format).</li> </ul> </li> </ol>"},{"location":"en/explanation/tricys_analysis/analysis_report.html","title":"TRICYS Automated Analysis Reports","text":"<p>TRICYS is more than just a simulation execution framework; it is also a powerful platform for automated analysis and reporting. It can automatically process complex simulation results into well-structured, content-rich analysis reports that support both English and Chinese. Its report generation process uses an innovative layered design, achieving end-to-end automation from data-driven chart generation to optional, Large Language Model (LLM)-driven in-depth analysis and academic-grade report writing.</p>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#1-glossary-and-internationalized-charts","title":"1. Glossary and Internationalized Charts","text":"<p>To make the generated charts professional and readable, TRICYS introduces a label mapping mechanism based on an external glossary, which also supports switching between English and Chinese.</p>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#11-how-it-works","title":"1.1 How It Works","text":"<p>This functionality is implemented by the <code>tricys/analysis/plot.py</code> module.</p> <ol> <li>Load Glossary: When the program starts, the <code>load_glossary()</code> function reads a user-specified CSV file (<code>glossary_path</code>). This CSV file defines the correspondence between internal model variable names and their professional terms in English and Chinese.</li> <li>Set Language: By calling <code>set_plot_language('cn')</code> or <code>set_plot_language('en')</code>, the display language of the charts can be switched globally. When switching to Chinese, a font that supports Chinese characters (e.g., \"SimHei\") is automatically enabled.</li> <li>Format Labels: When plotting, all raw variable names (e.g., <code>Startup_Inventory</code>, <code>sds.I[1]</code>) are processed by the <code>_format_label()</code> function. This function will:<ul> <li>First, look up the corresponding professional term in English or Chinese in the loaded glossary based on the current language setting.</li> <li>If found, it uses that professional term as the chart label (e.g., for legends, axis titles).</li> <li>If not found, it performs default formatting (e.g., replacing underscores with spaces) to ensure basic readability.</li> </ul> </li> <li>Unit Mapping: In addition to terms, the units on the axes can also be converted and displayed via the <code>unit_map</code> configuration, which also supports internationalization.</li> </ol>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#12-glossary-format-example","title":"1.2 Glossary Format Example","text":"<p>The CSV file must contain the following three columns:</p> Model Parameter English Term Chinese Translation <code>Startup_Inventory</code> Startup Inventory \u542f\u52a8\u5e93\u5b58 <code>Doubling_Time</code> Doubling Time \u500d\u589e\u65f6\u95f4 <code>sds.I[1]</code> Tritium Inventory in SDS \u8d2e\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf\u6c1a\u5e93\u5b58 <p>With this mechanism, TRICYS can automatically format the internal variable <code>Startup_Inventory</code> into \"Startup Inventory (kg)\" or \"\u542f\u52a8\u5e93\u5b58 (\u5343\u514b)\" when generating charts.</p>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#2-core-chart-types","title":"2. Core Chart Types","text":"<p>The <code>generate_analysis_plots()</code> function in <code>tricys/analysis/plot.py</code> serves as the main entry point for all analysis charts. It generates several core types of charts based on the analysis task.</p>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#21-main-trend-plots","title":"2.1 Main Trend Plots","text":"<ul> <li>Purpose: To show how key performance indicators (dependent variables) change in response to variations in the independent sweep variable.</li> <li>Features:<ul> <li>When multiple background sweep parameters (<code>simulation_parameters</code>) are present, it automatically plots multiple curves with different colors, line styles, and markers, and generates a legend.</li> <li>If the number of curves is small, it automatically annotates the data points with their values for precise reading.</li> <li>Supports plotting multiple metrics in subplots within a single figure (<code>_generate_combined_plots</code>) or generating separate chart files for each metric (<code>_generate_individual_plots</code>).</li> </ul> </li> </ul>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#22-constraint-solving-analysis-plots","title":"2.2 Constraint-Solving Analysis Plots","text":"<ul> <li>Purpose: Specifically designed to visualize the results of \"goal-seeking\" tasks (i.e., metrics prefixed with <code>Required_</code>).</li> <li>Features:<ul> <li>Generated by the <code>_generate_multi_required_plot()</code> function, usually in a multi-subplot layout.</li> <li>Each subplot represents a specific combination of background parameters, clearly showing the \"cost\" (the optimized parameter value) required to meet a certain constraint (e.g., doubling time less than 10 years) under different scenarios.</li> <li>This type of plot is crucial for understanding multi-variable trade-offs.</li> </ul> </li> </ul>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#23-sweep-process-time-series-plots","title":"2.3 Sweep Process Time-Series Plots","text":"<ul> <li>Purpose: Generated when it is necessary to observe the complete time evolution of a dynamic variable across different parameter sweeps.</li> <li>Features:<ul> <li>Generated by the <code>plot_sweep_time_series()</code> function, it contains two subplots:<ol> <li>Overall View: Shows the complete time curve from <code>t=0</code> to the end of the simulation. To highlight key early behaviors, this view automatically hides data points that exceed twice the initial value.</li> <li>Detailed View: Automatically focuses on and zooms into the region where the minimum value is first reached across all curves. This is very useful for observing the system's initial dynamic characteristics (like the \"dip-and-recover\" turning point of the inventory).</li> </ol> </li> <li>A red dashed box is automatically drawn on the \"Overall View\" to indicate the region corresponding to the \"Detailed View\".</li> </ul> </li> </ul>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#3-multi-stage-report-generation-logic","title":"3. Multi-Stage Report Generation Logic","text":"<p>TRICYS's report generation is divided into several core stages, orchestrated by the <code>tricys/analysis/report.py</code> module. This design separates raw data from AI interpretation, ensuring transparency and traceability of the results.</p> <pre><code>graph TD\n    A[Start] --&gt; B[Execute all simulation and analysis tasks];\n    B --&gt; C[\"&lt;b&gt;Stage 1: Generate Base Data Report&lt;/b&gt;&lt;br&gt;`generate_prompt_templates()`\"];\n    C --&gt; D{Is AI analysis enabled?};\n    D -- No --&gt; E[End: A base report with only data and charts];\n    D -- Yes --&gt; F[\"&lt;b&gt;Stage 2: Generate AI-Enhanced Report&lt;/b&gt;\"];\n\n    subgraph F\n        direction LR\n        F1[\"First LLM Call:&lt;br&gt;Raw Data Analysis&lt;br&gt;`call_openai_analysis_api`\"] --&gt; F2[\"Second LLM Call:&lt;br&gt;Academic Report Writing&lt;br&gt;`generate_sensitivity_academic_report`\"];\n    end\n    F --&gt; G[End: An academic-grade report with in-depth analysis];</code></pre>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#31-stage-1-base-data-report","title":"3.1. Stage 1: Base Data Report","text":"<p>This stage is executed by the <code>generate_prompt_templates()</code> function. Its core responsibility is to create a comprehensive, purely data-driven Markdown file. This file serves as the \"source of truth\" for all subsequent analysis and includes:</p> <ol> <li>Configuration Details: All configuration parameters for the analysis, such as independent/dependent variables, sweep ranges, and optimization settings.</li> <li>Data Tables: Data from <code>sensitivity_analysis_summary.csv</code> and <code>requierd_tbr_summary.csv</code> formatted into clean Markdown tables.</li> <li>Embedded Charts: All <code>.svg</code> chart files generated by <code>plot.py</code> are embedded into the report using <code>![Title](filename.svg)</code> syntax.</li> <li>Dynamic Data Slices: If applicable, it also extracts data slices of key dynamic processes (e.g., initial, turning point, and final stages) from <code>sweep_results.csv</code> and presents them in tabular form.</li> </ol>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#32-stage-2-raw-data-analysis","title":"3.2. Stage 2: Raw Data Analysis","text":"<ul> <li>Executor: <code>call_openai_analysis_api()</code></li> <li>Purpose: To perform a deep, quantitative analysis of the pure data tables to uncover underlying trends and correlations.</li> <li>Process:<ol> <li>The base report generated in Stage 1 is used as context, appended with a carefully designed analysis prompt (see next section).</li> <li>A key instruction is to ignore the charts and only analyze the tables, which forces the model to perform quantitative rather than qualitative analysis.</li> <li>The analysis result returned by the LLM is appended to the base report, creating a single report that contains \"raw data + initial AI interpretation\".</li> </ol> </li> </ul> Data Analyst Prompt <pre><code>**Role:** You are an expert in the field of tritium fuel cycles for fusion reactors.\n**Task:** Please provide a deep interpretation of the sensitivity analysis results for a fusion reactor fuel cycle model, **based solely** on the **two types of data tables** provided below.\n**Analysis Points (Must be answered strictly based on the data tables):**\n1.  **Global Sensitivity Analysis:**\n    *   What **overall trends** do the summary performance metrics tables exhibit?\n    *   Which performance metric is most sensitive to changes in the independent variable `{independent_variable}`?\n2.  **Interaction Effect Analysis:**\n    *   Analyze the interaction effects between the independent variable and the background sweep parameters on the performance metrics.\n3.  **Dynamic Process Analysis:**\n    *   Observing the process data slices: what are the differences in the system's behavior during the \"initial phase\" and the \"final phase\"?\n    *   What physical process does the data from the \"turning point phase\" reveal?\n4.  **Comprehensive Conclusion:**\n    *   Summarize the overall impact and potential trade-offs of adjusting `{independent_variable}` on the system.\n    *   What preliminary suggestions for system design or operational optimization can be derived from these findings?\n</code></pre>"},{"location":"en/explanation/tricys_analysis/analysis_report.html#33-stage-3-academic-report-writing","title":"3.3. Stage 3: Academic Report Writing","text":"<ul> <li>Executor: <code>generate_sensitivity_academic_report()</code></li> <li>Purpose: To \"upgrade\" a mixed report containing data, charts, and preliminary analysis into a well-structured, professionally-worded academic-style report.</li> <li>Process:<ol> <li>The updated report (now including the first AI analysis) and the glossary file (<code>glossary.csv</code>) are provided together as context.</li> <li>A more complex prompt is appended, instructing the model to act as a \"senior scientist\" and strictly follow academic conventions.</li> <li>The LLM will use the glossary to replace internal variable names with professional terms and rewrite all content according to a standard academic structure (Abstract, Introduction, Methodology, Results and Discussion, Conclusion).</li> <li>The final result is saved as a new, ready-to-use academic report file (<code>academic_report_....md</code>).</li> </ol> </li> </ul> Senior Scientist Prompt <pre><code>**Role:** You are a senior scientist with a deep academic background in nuclear fusion engineering, particularly in the tritium fuel cycle.\n**Task:** You have received a preliminary report and a glossary of professional terms from an automated analysis program. Based on these two documents, your task is to write a more professional, formal, and in-depth analysis summary report suitable for academic publication.\n**Instructions:**\n1.  **Professional Language:** Replace the model parameters/abbreviations in the preliminary report (e.g., `sds.I[1]`, `Startup_Inventory`) with their corresponding professional terms from the glossary.\n2.  **Academic Rewriting:** Reorganize and rephrase the findings from the preliminary report using rigorous and objective academic language.\n3.  **Presentation and Citation of Figures and Tables:**\n    *   **Display Figures:** In the \"Results and Discussion\" section, you **must** use Markdown syntax `![Figure Title](figure_filename.svg)` to **directly embed** and display all the charts included in the preliminary report.\n    *   **Cite Figures:** When analyzing and discussing the content of the figures in the text, please number and cite them using phrases like \"As shown in Figure 1...\".\n4.  **Structured Report:** Your report should be about a **sensitivity analysis** and include the following sections:\n    *   **Title:** ...\n    *   **Abstract:** ...\n    *   **Introduction:** ...\n    *   **Methodology:** ...\n    *   **Results and Discussion:** ...\n    *   **Conclusion:** ...\n</code></pre>"},{"location":"en/explanation/tricys_analysis/performance_metrics.html","title":"Core Performance Metrics","text":"<p>In the simulation and analysis of the tritium fuel cycle, evaluating the system's economic efficiency and sustainability is crucial. <code>tricys</code> has a built-in series of Key Performance Indicators (KPIs) used to quantitatively assess the key characteristics of the system from dynamic simulation results.</p>"},{"location":"en/explanation/tricys_analysis/performance_metrics.html#1-startup-inventory","title":"1. Startup Inventory","text":"<ul> <li>Calculation Function: <code>calculate_startup_inventory</code></li> <li>Physical Meaning: Startup inventory refers to the amount of tritium that must be pre-loaded at the beginning of a reactor's operation to sustain continuous operation until the system achieves tritium self-sufficiency (i.e., the tritium breeding rate equals or exceeds its consumption rate). On a time-varying curve of tritium inventory, this is represented by the vertical distance from the initial inventory down to its lowest point (the turning point).</li> <li> <p>Calculation Method:</p> <ol> <li>In the simulation time series, find the lowest point of the tritium inventory (the Turning Point), which typically represents the moment the system transitions from net consumption to net breeding.</li> <li>The startup inventory is calculated as the difference between the Initial Inventory and the Minimum Inventory.</li> </ol> <p><code>Startup Inventory = Initial Inventory - Minimum Inventory</code> - Interpretation: Startup inventory is a key economic indicator. A lower startup inventory means the system can achieve self-sufficiency faster, reducing reliance on external tritium sources and upfront investment costs, making it a primary optimization target in tritium fuel cycle system design.</p> </li> </ul>"},{"location":"en/explanation/tricys_analysis/performance_metrics.html#2-self-sufficiency-time","title":"2. Self-Sufficiency Time","text":"<ul> <li>Calculation Function: <code>time_of_turning_point</code></li> <li>Physical Meaning: Self-sufficiency time is the time from the start of the system's operation until its total tritium inventory reaches its lowest point and begins to increase. This point in time marks when the system's internal tritium breeding rate starts to exceed the rates of consumption and loss, and the system theoretically becomes \"self-sufficient.\"</li> <li>Calculation Method:<ol> <li>The function first smooths the inventory data to eliminate noise and determine if a true \"turning point\" exists.</li> <li>If the inventory curve is monotonically decreasing (meaning self-sufficiency is not achieved within the simulation time), it returns <code>NaN</code> (Not a Number).</li> <li>Otherwise, it returns the exact time point from the original (unsmoothed) data where the inventory reaches its minimum value.</li> </ol> </li> <li>Interpretation: The self-sufficiency time directly reflects the speed at which the system reaches tritium balance. A shorter self-sufficiency time is ideal as it indicates the system can more quickly move past consuming the startup inventory and begin accumulating tritium, which is crucial for the rapid commissioning of commercial fusion power plants.</li> </ul>"},{"location":"en/explanation/tricys_analysis/performance_metrics.html#3-doubling-time","title":"3. Doubling Time","text":"<ul> <li>Calculation Function: <code>calculate_doubling_time</code></li> <li>Physical Meaning: Doubling time is the time required for the total tritium inventory in the system to double (i.e., reach twice the initial inventory) after achieving tritium self-sufficiency.</li> <li>Calculation Method:<ol> <li>First, determine the system's \"turning point\" (the point of minimum inventory).</li> <li>Then, in the inventory data after the turning point, find the first time point where the inventory is greater than or equal to twice the initial inventory.</li> <li>The doubling time is the difference between this time point and the start of the simulation. If the inventory never reaches twice the initial value, it returns <code>NaN</code>.</li> </ol> </li> <li>Interpretation: Doubling time is a core metric for measuring the \"profitability\" of a tritium breeding system. A finite and reasonable doubling time means the fusion power plant can not only sustain itself but also provide additional tritium fuel to start new plants. This is key to achieving the large-scale development of fusion energy.</li> </ul>"},{"location":"en/explanation/tricys_analysis/performance_metrics.html#4-constraint-solving-metrics-eg-required_tbr","title":"4. Constraint-Solving Metrics (e.g., Required_TBR)","text":"<ul> <li>Calculation Method: <code>bisection_search</code> (implemented in <code>tricys.simulation.simulation_analysis</code>)</li> <li>Physical Meaning: In many design studies, the concern is not how the system performs at a fixed Tritium Breeding Ratio (TBR), but the reverse: to achieve a specific engineering goal (e.g., a doubling time of less than 10 years), what is the minimum required TBR?</li> <li>Implementation:<ul> <li><code>Required_TBR</code> is not a directly calculated metric but a constraint-solving task.</li> <li>When you include it in <code>dependent_variables</code>, <code>tricys</code> enables an optimization algorithm (like <code>bisection_search</code>).</li> <li>This algorithm iteratively runs simulations within a given <code>search_range</code>, using a <code>parameter_to_optimize</code> (usually the <code>TBR</code> parameter in the model) as the variable.</li> <li>In each iteration, it checks if a key performance indicator (e.g., <code>Doubling_Time</code>) meets a predefined constraint (e.g., is less than a certain <code>metric_max_value</code>).</li> <li>Ultimately, the algorithm converges and outputs the minimum TBR value that satisfies the constraint.</li> </ul> </li> <li>Interpretation: This \"inverse\" solving capability is extremely powerful. It transforms the design problem from \"forward validation\" to \"inverse optimization,\" helping engineers quickly determine the minimum design requirements to achieve key performance goals, thereby greatly accelerating the design iteration process.</li> </ul>"},{"location":"en/explanation/tricys_analysis/salib_integration.html","title":"TRICYS and SALib Integration: Achieving Global Sensitivity Analysis","text":"<p>TRICYS is deeply integrated with the industry-leading sensitivity analysis library SALib to provide users with a powerful, automated workflow for Global Sensitivity Analysis (GSA) and Uncertainty Quantification (UQ). This document introduces SALib and its core methods, and provides a detailed breakdown of how TRICYS collaborates with SALib through a three-step process.</p>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#1-introduction-to-salib-and-its-analysis-methods","title":"1. Introduction to SALib and its Analysis Methods","text":""},{"location":"en/explanation/tricys_analysis/salib_integration.html#11-what-is-salib","title":"1.1. What is SALib?","text":"<p>SALib is an open-source Python library specifically designed for conducting sensitivity analysis. Sensitivity analysis aims to study how the uncertainty in the output of a model can be apportioned to different sources of uncertainty in its inputs. In simple terms, it helps us answer a core question: \"Which input parameters have the greatest impact on the model's output?\"</p> <p>For complex simulation models like TRICYS, GSA is crucial because it helps us:</p> <ul> <li>Identify Key Parameters: Find the few parameters that have the most significant impact on system performance (e.g., startup inventory, doubling time) from a multitude of parameters.</li> <li>Understand Parameter Interactions: Reveal complex non-linear or interactive effects between parameters.</li> <li>Simplify Models: After identifying unimportant parameters, they can be fixed as constants in future studies, thereby reducing model complexity and computational cost.</li> </ul>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#12-core-salib-methods-supported-by-tricys","title":"1.2. Core SALib Methods Supported by TRICYS","text":"<p>The <code>TricysSALibAnalyzer</code> class in TRICYS integrates several of the most common and powerful analysis methods from SALib:</p>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#sobol-analysis-variance-based-method","title":"Sobol Analysis (Variance-Based Method)","text":"<ul> <li>Type: Global Sensitivity Analysis (GSA), based on variance decomposition.</li> <li>Core Indices:<ul> <li>First-order index (S1): Measures the direct contribution of a single parameter's variance to the output variance, i.e., the \"main effect.\" A higher S1 value indicates a greater independent impact of the parameter.</li> <li>Total-order index (ST): Measures the total contribution of a single parameter, including all its interactions with other parameters, to the output variance.</li> </ul> </li> <li>Interpretation: If a parameter's <code>ST</code> value is significantly larger than its <code>S1</code> value, it indicates that the parameter has strong non-linear effects or significant interactions with other parameters.</li> <li>Characteristics: The results are very reliable and comprehensive, but it is computationally expensive and typically requires a large number of samples (<code>N * (2D + 2)</code>, where D is the number of parameters).</li> </ul>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#morris-analysis-screening-method","title":"Morris Analysis (Screening Method)","text":"<ul> <li>Type: Global Sensitivity Analysis, a trajectory-based screening method.</li> <li>Core Indices:<ul> <li>\u03bc* (mu_star): Measures the overall influence of a parameter on the output, representing the mean of the absolute values of the elementary effects. A higher \u03bc* indicates a more important parameter.</li> <li>\u03c3 (sigma): Measures the standard deviation of the elementary effects. A higher \u03c3 indicates that the parameter's effect is non-linear or has interactions with other parameters.</li> </ul> </li> <li>Characteristics: It is computationally very efficient, especially suitable for the early exploratory stages of high-dimensional models (with a large number of input parameters) to quickly screen for the most influential parameters.</li> </ul>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#fast-analysis-fourier-amplitude-sensitivity-test","title":"FAST Analysis (Fourier Amplitude Sensitivity Test)","text":"<ul> <li>Type: Global Sensitivity Analysis, frequency-based.</li> <li>Core Indices: Similar to Sobol, it calculates first-order (S1) and total-order (ST) indices.</li> <li>Characteristics: In some cases, it is more computationally efficient than the Sobol method, but it has certain requirements for model applicability.</li> </ul>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#latin-hypercube-sampling-lhs-and-uncertainty-analysis","title":"Latin Hypercube Sampling (LHS) and Uncertainty Analysis","text":"<ul> <li>Type: Uncertainty Quantification (UQ).</li> <li>Purpose: LHS itself is an advanced parameter sampling technique designed to efficiently cover the entire parameter space. When used in conjunction with TRICYS for analysis, its purpose is not to calculate sensitivity indices but to study the statistical distribution characteristics of the output metrics (mean, std, percentiles) given the uncertainty in the inputs.</li> <li>Core Metrics:<ul> <li>Mean, standard deviation, maximum/minimum values.</li> <li>Percentiles (e.g., 5% and 95%) to assess the confidence interval of the output.</li> </ul> </li> <li>Interpretation: Through LHS analysis, we can understand the stability and fluctuation range of the model's output and evaluate its risks in the face of input uncertainties.</li> </ul>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#2-the-three-step-integration-workflow","title":"2. The Three-Step Integration Workflow","text":"<p>TRICYS breaks down the complex GSA process into a clear, automated three-step workflow. The <code>TricysSALibAnalyzer</code> class is responsible for orchestrating the entire process, with the core idea being \"SALib handles sampling and analysis, while TRICYS handles execution,\" with the two exchanging data via CSV files.</p> <pre><code>graph TD\n    subgraph \"A. SALib End\"\n        A1[\"&lt;b&gt;Step 1: Parameter Sampling&lt;/b&gt;&lt;br&gt;Executed in salib.py\"]\n        A1 --&gt; B1[\"1. Define Problem (`define_problem`)&lt;br&gt;Specify parameters and their ranges\"]\n        B1 --&gt; B2[\"2. Generate Samples (`generate_samples`)&lt;br&gt;Choose Sobol/Morris, etc.\"]\n        B2 --&gt; B3[\"3. Export Samples (`run_tricys_simulations`)&lt;br&gt;Generate &lt;b&gt;salib_sampling.csv&lt;/b&gt; file\"]\n    end\n\n    subgraph \"B. TRICYS End\"\n        C1[\"&lt;b&gt;Step 2: Batch Simulation&lt;/b&gt;&lt;br&gt;Executed in simulation_analysis.py\"]\n        C1 --&gt; D1[\"1. Generate a specific config file&lt;br&gt;to make TRICYS read the CSV\"]\n        D1 --&gt; D2[\"2. TRICYS starts&lt;br&gt;Treats each row of the CSV as an independent simulation job\"]\n        D2 --&gt; D3[\"3. Execute all simulations&lt;br&gt;and aggregate the result metrics&lt;br&gt;of all jobs into &lt;b&gt;sensitivity_analysis_summary.csv&lt;/b&gt;\"]\n    end\n\n    subgraph \"C. SALib End (Again)\"\n        E1[\"&lt;b&gt;Step 3: Result Analysis&lt;/b&gt;&lt;br&gt;Returns to salib.py for execution\"]\n        E1 --&gt; F1[\"1. Load Results (`load_tricys_results`)&lt;br&gt;Read &lt;b&gt;sensitivity_analysis_summary.csv&lt;/b&gt;\"]\n        F1 --&gt; F2[\"2. Compute Indices (`analyze_sobol`, etc.)&lt;br&gt;SALib analyzes the simulation results\"]\n        F2 --&gt; F3[\"3. Generate Report (`plot_results`, `save_report`)&lt;br&gt;Output charts, tables, and the final analysis report\"]\n    end\n\n    B3 -- \"As input\" --&gt; C1\n    D3 -- \"As input\" --&gt; E1\n</code></pre>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#step-1-parameter-sampling-salib-csv","title":"Step 1: Parameter Sampling (SALib -&gt; CSV)","text":"<p>This stage is entirely completed within the <code>TricysSALibAnalyzer</code> class in <code>salib.py</code>, with the goal of generating a CSV file containing all parameter combinations.</p> <ol> <li>Define Problem: By calling <code>define_problem()</code>, the user needs to provide a dictionary containing all the parameters to be analyzed and their value ranges (bounds).</li> <li>Generate Samples: Call <code>generate_samples()</code> and specify the sampling method (e.g., <code>'sobol'</code>) and the number of samples <code>N</code>. SALib will generate a series of parameter points in the defined parameter space according to the chosen method.</li> <li>Export File: Call the <code>run_tricys_simulations()</code> function (note: despite its name, this function does not execute simulations). This function writes all the parameter samples generated in the previous step into a file named <code>salib_sampling.csv</code>. This file acts as the bridge connecting SALib and TRICYS.</li> </ol>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#step-2-batch-simulation-tricys-reads-csv","title":"Step 2: Batch Simulation (TRICYS Reads CSV)","text":"<p>This stage is orchestrated by the <code>run_salib_analysis()</code> function in <code>simulation_analysis.py</code>, which calls TRICYS's core simulation engine to perform the calculations.</p> <ol> <li>Generate Specific Configuration: The <code>generate_tricys_config()</code> function in <code>salib.py</code> creates a temporary TRICYS configuration file. The key aspect of this configuration file is that it points <code>simulation_parameters</code> to the <code>salib_sampling.csv</code> file generated in the previous step.     <pre><code>\"simulation_parameters\": {\n  \"file\": \"/path/to/salib_sampling.csv\"\n}\n</code></pre></li> <li>TRICYS Startup and Execution: When <code>simulation_analysis.py</code> starts with this special configuration, it recognizes it as a file-based task. TRICYS will read <code>salib_sampling.csv</code> line by line, treating each row (i.e., a complete set of parameters) as an independent simulation job.</li> <li>Aggregate Results: TRICYS will execute all simulation jobs (either concurrently or sequentially). Once all tasks are complete, it will aggregate the performance metrics calculated from each job (e.g., <code>Startup_Inventory</code>) and generate a result file named <code>sensitivity_analysis_summary.csv</code>. Each row in this file corresponds to a row of input from <code>salib_sampling.csv</code>, thus perfectly matching the input parameters with the output results.</li> </ol>"},{"location":"en/explanation/tricys_analysis/salib_integration.html#step-3-result-analysis-and-reporting-salib-reads-results","title":"Step 3: Result Analysis and Reporting (SALib Reads Results)","text":"<p>After the simulation is complete, control returns to <code>salib.py</code> for final analysis and report generation.</p> <ol> <li>Load Results: The <code>load_tricys_results()</code> function reads <code>sensitivity_analysis_summary.csv</code> to load TRICYS's calculation results into memory.</li> <li>Calculate Sensitivity Indices: Based on the user's chosen analysis method, the corresponding analysis function, such as <code>analyze_sobol()</code>, is called. This function feeds the parameter samples and simulation results together into SALib's analysis engine to calculate sensitivity indices like S1, ST, etc.</li> <li>Generate Report: Finally, functions like <code>plot_*_results()</code> and <code>_save_sensitivity_report()</code> use the calculated indices to generate a series of visualizations (e.g., bar charts, \u03bc*-\u03c3 plots), data tables, and a complete Markdown analysis report (which also supports AI-enhanced in-depth interpretation).</li> </ol> <p>Through these three clear steps, TRICYS successfully decouples and integrates SALib's powerful sampling and analysis capabilities with its own efficient simulation execution capabilities, providing a fully automated GSA workflow from problem definition to final report.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html","title":"Co-simulation Principle","text":"<p>In co-simulation, TRICYS provides two methods for injecting external data into a Modelica model.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#1-interceptor-mode","title":"1. Interceptor Mode","text":""},{"location":"en/explanation/tricys_basic/co_simulation.html#11-how-it-works","title":"1.1. How It Works","text":"<p>The interceptor mode is a non-invasive method for data injection. It does not modify any original model files; instead, it works by automatically generating new models.</p> <p>The core idea is to dynamically insert a new \"interceptor\" model between the original submodel and downstream components. This interceptor acts like a configurable switch, receiving both the real-time output signals from the original submodel and predefined data from a CSV file. By setting model parameters at runtime, you can precisely control whether each output signal \"passes through\" the upstream real-time signal or is \"overridden\" with data from the CSV file.</p> <p>The advantage of this mode lies in its safety and flexibility. All modifications are made on automatically generated copies (e.g., <code>_Intercepted.mo</code>), leaving the original model and system design unchanged. This makes it ideal for \"what-if\" analysis, fault injection, or temporarily replacing parts of the system's behavior.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#12-architecture-diagram","title":"1.2. Architecture Diagram","text":"<pre><code>Original System Structure:\n  [Upstream Model] --&gt; [Submodel] --&gt; [Downstream Model]\n\nInterceptor Mode Structure:\n  [Upstream Model] --&gt; [Submodel] --&gt; [Interceptor] --&gt; [Downstream Model]\n                                     \u2191\n                                 [CSV Data]\n</code></pre>"},{"location":"en/explanation/tricys_basic/co_simulation.html#13-implementation-steps","title":"1.3. Implementation Steps","text":"<p><code>tricys</code> automatically completes the following steps to implement the interceptor mode:</p> <pre><code>graph TD\n    A[Start] --&gt; B{Read Co-simulation Config};\n    B --&gt; C[Analyze target submodel via&lt;br&gt;OMCSession to get all output ports];\n    C --&gt; D[Dynamically generate a corresponding&lt;br&gt;'..._Interceptor.mo' model file for the submodel];\n    D --&gt; E[Read the top-level system model's code];\n    E --&gt; F{Reconstruct connection&lt;br&gt;relationships in the system model};\n    F --&gt; G[1. Declare and instantiate the interceptor model];\n    F --&gt; H[2. Modify connect statements&lt;br&gt;to redirect original connections to the interceptor];\n    G &amp; H --&gt; I[Save the modified system model&lt;br&gt;as an '..._Intercepted.mo' file];\n    I --&gt; J[End];\n\n    style C fill:#f9f,stroke:#333,stroke-width:2px;\n    style D fill:#ccf,stroke:#333,stroke-width:2px;\n    style F fill:#f9f,stroke:#333,stroke-width:2px;\n    style I fill:#ccf,stroke:#333,stroke-width:2px;</code></pre> <p>Detailed breakdown of steps: 1.  Analyze Model: <code>tricys</code> first uses the OpenModelica (OMC) toolchain to analyze the target submodel, automatically identifying all its output ports, dimensions, and other metadata. 2.  Generate Interceptor: Based on the port information obtained in the previous step, a new Modelica model (<code>..._Interceptor.mo</code>) is dynamically generated. This model contains a <code>CombiTimeTable</code> component (for reading CSVs) and data selection logic. 3.  Modify System: <code>tricys</code> reads the code of the top-level system model and performs the following modifications:     *   Instantiate Interceptor: An instance declaration for the newly generated interceptor model is added before the <code>equation</code> section.     *   Redirect Connections: <code>connect</code> statements are automatically found and modified using regular expressions. The original connections from the submodel's output ports to downstream components are broken and rerouted through the interceptor:         *   <code>Submodel.OutputPort</code> -&gt; <code>Interceptor.PhysicalInputPort</code>         *   <code>Interceptor.FinalOutputPort</code> -&gt; <code>DownstreamComponent.InputPort</code> 4.  Save New System: The content of the modified top-level system model is saved to a new file with an <code>_Intercepted</code> suffix, ensuring the original system model file remains unaffected.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#14-interceptor-model-example","title":"1.4. Interceptor Model Example","text":"<pre><code>within example_model;\n\nmodel Plasma_Interceptor\n  // Receive original model output\n  Modelica.Blocks.Interfaces.RealInput physical_to_Pump[5];\n\n  // Final output\n  Modelica.Blocks.Interfaces.RealOutput final_to_Pump[5];\n\n  protected\n    parameter String fileName = \"plasma_data.csv\";\n\n    // Column mapping parameter: [time, y1, y2, y3, y4, y5]\n    // If a column is set to 1, it means use physical data instead of CSV\n    parameter Integer columns_to_Pump[6] = {1, 2, 3, 4, 5, 6};\n\n    // CSV reader\n    Modelica.Blocks.Sources.CombiTimeTable table_to_Pump(\n      tableName=\"csv_data_to_Pump\",\n      fileName=fileName,\n      columns=columns_to_Pump,\n      tableOnFile=true\n    );\n\n  equation\n    // Select data source element-wise\n    for i in 1:5 loop\n      final_to_Pump[i] = if columns_to_Pump[i+1] &lt;&gt; 1 \n                         then table_to_Pump.y[i]   // Use CSV\n                         else physical_to_Pump[i]; // Use physical data\n    end for;\n\nend Plasma_Interceptor;\n</code></pre>"},{"location":"en/explanation/tricys_basic/co_simulation.html#2-direct-replacement-mode","title":"2. Direct Replacement Mode","text":""},{"location":"en/explanation/tricys_basic/co_simulation.html#21-how-it-works","title":"2.1. How It Works","text":"<p>The direct replacement mode is an invasive but efficient method. It directly modifies the target submodel's file, completely replacing its original internal logic with a \"data player.\"</p> <p>The workflow is as follows: <code>tricys</code> first creates a backup file (<code>.bak</code>) for the target submodel. Then, it \"clears\" all internal equations and variables from the original model file, retaining only its input/output port declarations. Next, it adds <code>CombiTimeTable</code> components to the model and directly connects the output ports to the data outputs of these components.</p> <p>Ultimately, the submodel becomes a simple data source whose behavior is entirely defined by an external CSV file. This mode is suitable when you need to permanently or semi-permanently replace a computationally expensive or temporarily unavailable submodel with a fixed dataset (e.g., results from a high-fidelity simulation or experimental data).</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#22-architecture-diagram","title":"2.2. Architecture Diagram","text":"<pre><code>Original System Structure:\n  [Upstream Model] --&gt; [Submodel] --&gt; [Downstream Model]\n\nDirect Replacement Mode:\n  [Upstream Model] --&gt; [Submodel (CSV Version)] --&gt; [Downstream Model]\n                             \u2191\n                         [CSV Data]\n</code></pre>"},{"location":"en/explanation/tricys_basic/co_simulation.html#23-implementation-steps","title":"2.3. Implementation Steps","text":"<p><code>tricys</code> implements direct replacement through the following automated process:</p> <pre><code>graph TD\n    A[Start] --&gt; B{Read Co-simulation Config};\n    B --&gt; C[Locate the target submodel's '.mo' file];\n    C --&gt; D[Create a backup of the file&lt;br&gt;e.g., 'SubModel.mo' -&gt; 'SubModel.bak'];\n    D --&gt; E[Read the model code&lt;br&gt;retaining only port declarations and the model frame];\n    E --&gt; F[Generate new model content];\n    F --&gt; G[1. Add CombiTimeTable components&lt;br&gt;for reading CSV data];\n    F --&gt; H[2. Create a new equation section&lt;br&gt;to directly connect output ports to the Table's output];\n    G &amp; H --&gt; I[Overwrite the original '.mo' file&lt;br&gt;with the newly generated code];\n    I --&gt; J[End];\n\n    style D fill:#f9f,stroke:#333,stroke-width:2px;\n    style F fill:#f9f,stroke:#333,stroke-width:2px;\n    style I fill:#ccf,stroke:#333,stroke-width:2px;</code></pre> <p>Detailed breakdown of steps: 1.  Locate and Backup: Based on the <code>submodel_name</code>, <code>tricys</code> finds the corresponding <code>.mo</code> file in the project directory and immediately creates a backup file with a <code>.bak</code> suffix to prevent data loss. 2.  Parse and Clear: The program reads the original model code and parses its complete input/output port declarations. It then discards all other content in the model, such as variables in the <code>parameter</code> and <code>protected</code> sections, and all equations in the <code>equation</code> section. 3.  Generate New Code: <code>tricys</code> generates brand new model code based on the parsed port information:     *   It retains the original port declarations to ensure its external interface remains unchanged.     *   For each output port that needs to be driven by CSV data, it adds a <code>CombiTimeTable</code> instance and configures parameters like <code>fileName</code> and <code>columns</code>.     *   It creates a new <code>equation</code> section with simple mapping statements like <code>output_port = table.y</code> to directly connect the output ports to the <code>CombiTimeTable</code>'s data outputs. 4.  Overwrite File: Finally, <code>tricys</code> completely overwrites the original <code>.mo</code> file with the newly generated code, completing the replacement process. Since the submodel's interface (ports) has not changed, the top-level system model requires no modifications.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#24-post-replacement-model-example","title":"2.4. Post-Replacement Model Example","text":"<pre><code>within example_model;\n\nmodel Plasma\n  // Original port declarations remain unchanged\n  Modelica.Blocks.Interfaces.RealInput pulseInput;\n  Modelica.Blocks.Interfaces.RealOutput from_Fueling_System[5];\n  Modelica.Blocks.Interfaces.RealOutput to_FW[5];\n  Modelica.Blocks.Interfaces.RealOutput to_Div[5];\n  Modelica.Blocks.Interfaces.RealOutput to_Pump[5];\n\nprotected\n  parameter String fileName = \"plasma_data.csv\";\n\n  // CSV Data Source\n  Modelica.Blocks.Sources.CombiTimeTable table_to_Pump(\n    tableName=\"csv_data_to_Pump\",\n    fileName=fileName,\n    columns={1, 2, 3, 4, 5, 6},  // time + 5 data columns\n    tableOnFile=true\n  );\n\n  Modelica.Blocks.Sources.CombiTimeTable table_to_FW(\n    tableName=\"csv_data_to_FW\",\n    fileName=fileName,\n    columns={1, 7, 8, 9, 10, 11},\n    tableOnFile=true\n  );\n\n  // ... table definitions for other ports ...\n\nequation\n  // Directly map CSV to output (ignoring input)\n  for i in 1:5 loop\n    to_Pump[i] = table_to_Pump.y[i];\n    to_FW[i] = table_to_FW.y[i];\n    to_Div[i] = table_to_Div.y[i];\n    from_Fueling_System[i] = table_from_Fueling_System.y[i];\n  end for;\n\nend Plasma;\n</code></pre>"},{"location":"en/explanation/tricys_basic/co_simulation.html#3-writing-your-own-handler","title":"3. Writing Your Own Handler","text":"<p>Besides using the built-in processors, the most powerful feature of the <code>tricys</code> co-simulation framework is the ability to write your own Python functions (handlers) to dynamically generate data for injection into the Modelica model. This means you can integrate any complex external models, algorithms, or data sources.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#31-handler-configuration","title":"3.1. Handler Configuration","text":"<p>In the <code>co_simulation.handlers</code> list in <code>config.json</code>, each handler object contains the following fields to define its behavior:</p> <ul> <li> <p><code>handler_module</code> or <code>handler_script_path</code> (string, one is required):</p> <ul> <li><code>handler_module</code>: Specifies the full path of the Python module where the handler function is located. Suitable for cases where the code is part of a standard Python package.</li> <li><code>handler_script_path</code>: Specifies the path to the Python script file containing the handler function. This is more flexible and suitable for standalone script files.</li> </ul> </li> <li> <p><code>handler_function</code> (string, required):</p> <ul> <li>Description: The name of the function to be called within the specified module or script.</li> </ul> </li> <li> <p><code>params</code> (dictionary, optional):</p> <ul> <li>Description: A dictionary containing arbitrary keyword arguments to be passed to the handler function.</li> </ul> </li> </ul>"},{"location":"en/explanation/tricys_basic/co_simulation.html#32-function-signature-and-responsibilities","title":"3.2. Function Signature and Responsibilities","text":"<p>To be correctly called by the <code>tricys</code> framework, your handler function must follow a specific signature. The framework automatically passes two core paths via keyword arguments, which your function needs to define and accept:</p> <pre><code>def my_handler(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"\n    A standard handler function signature.\n\n    Args:\n        temp_input_csv (str): The path to a CSV file containing the output results\n                              from the upstream model. You can read this file\n                              to get the inputs that drive your calculation.\n        temp_output_csv (str): The path to a target CSV file where you need to\n                               write your calculation results. tricys will provide\n                               this file to Modelica's CombiTimeTable.\n        **kwargs: Used to receive all custom parameters from \"params\" in the JSON config.\n\n    Returns:\n        dict: A dictionary used to configure the column mapping for the Modelica CombiTimeTable.\n    \"\"\"\n    # ... Your code logic here ...\n</code></pre> <p>Core Responsibilities: 1.  Read Input (Optional): Use Pandas or another library to read the <code>temp_input_csv</code> file and get the dynamic output from the upstream model. 2.  Perform Calculation: Run your model, algorithm, or any other logic. 3.  Write Output: Save your calculation results (which must include a <code>time</code> column) in CSV format to the path specified by <code>temp_output_csv</code>.</p>"},{"location":"en/explanation/tricys_basic/co_simulation.html#33-return-value","title":"3.3. Return Value","text":"<p>The handler function must return a dictionary. The keys of this dictionary correspond to the output port names of the Modelica submodel, and the values are strings used to configure the <code>columns</code> parameter of the <code>CombiTimeTable</code>, defining how to read data columns from your generated CSV file.</p> <ul> <li>Example: <code>return {\"to_CL\": \"{1,2,3,4,5,6}\"}</code></li> <li>This tells <code>tricys</code> that for the output port named <code>to_CL</code>, the generated <code>CombiTimeTable</code> should use columns 1 through 6 of the data you wrote in <code>temp_output_csv</code> (where column 1 is typically <code>time</code>).</li> </ul>"},{"location":"en/explanation/tricys_basic/co_simulation.html#34-complete-example","title":"3.4. Complete Example","text":"<p>Taking the built-in <code>div_handler.py</code> as an example, it simulates a simple external model that does not depend on upstream input but generates its own data.</p> <p>Step 1: Create the Handler Script</p> <pre><code># tricys/handlers/div_handler.py\n\nimport os\nimport pandas as pd\n\ndef run_div_simulation(temp_input_csv, temp_output_csv, **kwargs):\n    \"\"\"\n    A simple handler that reads a predefined CSV file and writes its content\n    to the target output path specified by the framework.\n    \"\"\"\n    # Get the directory of the current file to locate the data file\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"div_handler.csv\")\n\n    # Read the source data\n    source_df = pd.read_csv(source_csv_path)\n\n    # Define the columns to be output to Modelica\n    columns_to_select = [\n        \"time\",\n        \"div.to_CL[1]\", \"div.to_CL[2]\", \"div.to_CL[3]\",\n        \"div.to_CL[4]\", \"div.to_CL[5]\",\n    ]\n    output_df = source_df[columns_to_select].copy()\n\n    # Write the processed data to the target CSV file specified by the framework\n    output_df.to_csv(temp_output_csv, index=False)\n\n    # Return the mapping between ports and columns\n    output_placeholder = {\"to_CL\": \"{1,2,3,4,5,6}\"}\n    return output_placeholder\n</code></pre> <p>Step 2: Configure in <code>config.json</code></p> <pre><code>\"co_simulation\": {\n    \"mode\": \"interceptor\",\n    \"handlers\": [\n        {\n            \"submodel_name\": \"example_model.DIV\",\n            \"instance_name\": \"div\",\n            \"handler_module\": \"tricys.handlers.div_handler\",\n            \"handler_function\": \"run_div_simulation\",\n            \"params\": {}\n        }\n    ]\n}\n</code></pre> <p>In this configuration, <code>tricys</code> will: 1.  Import the <code>tricys.handlers.div_handler</code> module. 2.  Call the <code>run_div_simulation</code> function. 3.  After the function executes, a new CSV file is generated. 4.  Use the returned <code>{\"to_CL\": \"{1,2,3,4,5,6}\"}</code> to configure the <code>CombiTimeTable</code> injected into the Modelica simulation.</p>"},{"location":"en/explanation/tricys_basic/concurrency.html","title":"TRICYS Concurrent Execution","text":"<p>TRICYS is designed to fully leverage the computational power of modern multi-core processors by using concurrent execution to significantly reduce the total time required for parameter sweeps and batch simulations. Depending on the simulation type, TRICYS intelligently adopts two different concurrency strategies: multi-threading (for standard simulations) and multi-processing (for co-simulations).</p> <p>You can control the concurrency behavior in <code>config.json</code> with the following parameters:</p> <pre><code>\"simulation\": {\n  \"concurrent\": true,  // Set to true to enable concurrent mode\n  \"max_workers\": 8     // Set the maximum number of concurrent workers, defaults to the number of CPU cores\n}\n</code></pre>"},{"location":"en/explanation/tricys_basic/concurrency.html#1-standard-simulation-multi-threaded-concurrency","title":"1. Standard Simulation: Multi-threaded Concurrency","text":"<p>For standard parameter sweep tasks that do not involve co-simulation, TRICYS defaults to a multi-threading model.</p>"},{"location":"en/explanation/tricys_basic/concurrency.html#11-how-it-works","title":"1.1. How It Works","text":"<p>TRICYS uses Python's <code>concurrent.futures.ThreadPoolExecutor</code> to manage a pool of worker threads. Each simulation task (i.e., a specific set of parameters) is submitted to the thread pool and executed by an available thread.</p> <pre><code># Simplified conceptual code\nfrom concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=8) as executor:\n    # _run_single_job is the task to be executed by each thread\n    futures = [executor.submit(_run_single_job, config, params, i) for i, params in enumerate(jobs)]\n    # ... wait for and collect results ...\n</code></pre>"},{"location":"en/explanation/tricys_basic/concurrency.html#12-why-use-multi-threading","title":"1.2. Why Use Multi-threading?","text":"<p>Although Python has a Global Interpreter Lock (GIL) that prevents true parallelism for CPU-bound code within a single process, multi-threading is still an efficient choice for standard Modelica simulation scenarios. Here's why:</p> <ul> <li>I/O-Bound: Calling <code>OMPython</code> to run a simulation is essentially launching an external <code>simulate.exe</code> executable. During this time, the Python thread is mostly in a waiting state (I/O-bound), waiting for the external process to complete its calculations and write back the result file. The GIL is released during this period, allowing other threads to run.</li> <li>Low Overhead: Threads are more lightweight than processes. They are created and destroyed faster and consume fewer system resources. For a large number of tasks where each simulation is not particularly time-consuming, using threads can reduce the overhead of task scheduling.</li> </ul>"},{"location":"en/explanation/tricys_basic/concurrency.html#2-co-simulation-multi-process-concurrency","title":"2. Co-simulation: Multi-process Concurrency","text":"<p>For complex co-simulation tasks, TRICYS switches to a more robust multi-processing model.</p>"},{"location":"en/explanation/tricys_basic/concurrency.html#21-how-it-works","title":"2.1. How It Works","text":"<p>TRICYS uses <code>concurrent.futures.ProcessPoolExecutor</code> to create a process pool. Each co-simulation task (<code>_run_co_simulation</code>) runs in a completely separate child process.</p> <pre><code># Simplified conceptual code\nfrom concurrent.futures import ProcessPoolExecutor\n\nwith ProcessPoolExecutor(max_workers=8) as executor:\n    # _run_co_simulation is executed in a separate process\n    futures = [executor.submit(_run_co_simulation, config, params, i) for i, params in enumerate(jobs)]\n    # ... wait for and collect results ...\n</code></pre>"},{"location":"en/explanation/tricys_basic/concurrency.html#22-why-must-multi-processing-be-used","title":"2.2. Why Must Multi-processing Be Used?","text":"<p>The co-simulation workflow involves extensive reading, writing, and modification of the file system, which is the core reason why it must use multi-processing:</p> <ul> <li>Environment Isolation: Each co-simulation task requires a clean, independent execution environment. It copies the original Modelica model package to a temporary directory and then modifies it (e.g., by generating an interceptor or replacing a model directly). If multi-threading were used, multiple tasks would simultaneously modify the shared model files, leading to file corruption and incorrect results.</li> <li>State Conflict Avoidance: Processes have independent memory spaces and file handles. This ensures that modifications to model code, the execution of external Python handlers, and all generated intermediate files by one task will not interfere with other parallel tasks.</li> <li>Bypassing the GIL: The Python handlers in co-simulation can themselves be computationally intensive. In a multi-processing model, each process has its own Python interpreter and GIL, enabling true parallel computation and full utilization of all CPU cores.</li> </ul>"},{"location":"en/explanation/tricys_basic/concurrency.html#3-performance-and-practical-recommendations","title":"3. Performance and Practical Recommendations","text":"<ul> <li> <p>Set <code>max_workers</code> Reasonably:</p> <ul> <li>For I/O-bound standard simulations, you can set <code>max_workers</code> to be slightly higher than the number of CPU cores (e.g., <code>cores * 1.5</code>).</li> <li>For CPU-bound co-simulations, <code>max_workers</code> is typically set to be equal to or slightly less than your number of CPU cores to avoid excessive context-switching overhead.</li> <li>Always consider memory limits. Each process consumes a significant amount of memory. If <code>max_workers</code> is set too high, it may lead to memory exhaustion.</li> </ul> </li> <li> <p>Task Granularity:</p> <ul> <li>Concurrency itself has overhead. If a single simulation is very short (e.g., less than a second), the performance gain from concurrency may not be enough to offset the scheduling overhead. In this case, serial execution (<code>\"concurrent\": false</code>) might be faster.</li> </ul> </li> <li> <p>Monitor System Resources:</p> <ul> <li>When running large-scale concurrent tasks, it is advisable to use system monitoring tools (like Task Manager or <code>htop</code>) to observe CPU and memory usage, which can help in tuning <code>max_workers</code> to its optimal value.</li> </ul> </li> </ul>"},{"location":"en/explanation/tricys_basic/simulation_flow.html","title":"Simulation Flow","text":""},{"location":"en/explanation/tricys_basic/simulation_flow.html#1-simulation-execution-flow","title":"1. Simulation Execution Flow","text":"<p>The core simulation flow of <code>tricys</code> is driven by the <code>tricys/simulation/simulation.py</code> script. It is designed as a highly configurable and robust orchestration engine for simulation business processes, capable of handling everything from simple single runs to complex multi-parameter, multi-mode (standard/co-simulation) simulations.</p> <p>Below is a complete flowchart and a detailed explanation of the steps involved.</p>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#2-detailed-flowchart","title":"2. Detailed Flowchart","text":"<pre><code>graph TD\n    %% 1. Initialization Phase\n    subgraph S1 [\"1. Initialization\"]\n        A[Start: Provide Config File] --&gt; B[Read and Prepare Configuration]\n        B --&gt; C[Set Up Logging]\n    end\n\n    %% 2. Job Generation Phase\n    subgraph S2 [\"2. Job Generation\"]\n        C --&gt; D[Generate Simulation Jobs based on simulation_parameters]\n    end\n\n    %% 3. Decision Phase\n    subgraph S3 [\"3. Execution Mode Decision\"]\n        D --&gt; E{co_simulation config detected?}\n        E -- Yes --&gt; F[Co-simulation Flow]\n        E -- No --&gt; G[Standard Simulation Flow]\n\n        G --&gt; H{Use concurrent mode?}\n        H -- Yes --&gt; I[Execute multiple _run_single_job in parallel]\n        H -- No --&gt; J[Execute _run_sequential_sweep sequentially]\n\n        F --&gt; K{Use concurrent mode?}\n        K -- Yes --&gt; L[Execute multiple _run_co_simulation in parallel]\n        K -- No --&gt; M[Execute multiple _run_co_simulation sequentially]\n    end\n\n    %% 4. Loop Entry Points\n    subgraph S4 [\"4. Job Execution Entry\"]\n        J --&gt; N((Standard Simulation Loop))\n        I --&gt; N\n\n        M --&gt; O((Co-simulation Loop))\n        L --&gt; O\n    end\n\n    %% Detailed Flow - Standard Simulation\n    subgraph S5 [\"Standard Simulation (_run_single_job / _run_sequential_sweep)\"]\n        N --&gt; N1[Create Independent Workspace - Parallel Mode]\n        N1 --&gt; N2[Get OMPython Session]\n        N2 --&gt; N3[Load Modelica Model]\n        N3 --&gt; N4[Set Simulation Parameters]\n        N4 --&gt; N5[Execute simulate]\n        N5 --&gt; N6[Clean and Save Result CSV]\n        N6 --&gt; P[Return Result File Path]\n    end\n\n    %% Detailed Flow - Co-simulation\n    subgraph S6 [\"Co-simulation (_run_co_simulation)\"]\n        O --&gt; O1[1. Create Independent Workspace]\n        O1 --&gt; O2[2. Copy Models and Asset Files]\n        O2 --&gt; O3[3. Stage 1: Run Preliminary Simulation to Generate Handler Inputs]\n        O3 --&gt; O4[4. Dynamically Load Python Handler Function]\n        O4 --&gt; O5[5. Execute Handler to Generate External Data CSV]\n        O5 --&gt; O6[6. Create and Integrate Interceptor Model]\n        O6 --&gt; O7[7. Stage 2: Run Final Simulation with Interceptor Model]\n        O7 --&gt; O8[8. Clean and Save Final Result CSV]\n        O8 --&gt; P\n    end\n\n    %% 5. Result Aggregation\n    subgraph S7 [\"5. Result Aggregation\"]\n        P --&gt; Q{Collect Result Paths from All Jobs}\n        Q --&gt; R[Read Each Result CSV]\n        R --&gt; S[\"Append Parameters to Variable Column Names (e.g., 'var&amp;p1=v1')\"]\n        S --&gt; T[Merge All Results into a Single DataFrame]\n        T --&gt; U[Save as 'sweep_results.csv']\n    end\n\n    %% 6. Post-processing\n    subgraph S8 [\"6. Post-processing\"]\n        U --&gt; V{post_processing config detected?}\n        V -- Yes --&gt; W[Dynamically Load and Execute Post-processing Functions]\n        V -- No --&gt; X[Skip Post-processing]\n    end\n\n    %% 7. Cleanup and End\n    subgraph S9 [\"7. Cleanup and End\"]\n        W --&gt; Y[Clean Up Temporary Files and Directories]\n        X --&gt; Y\n        Y --&gt; Z[End]\n    end</code></pre>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#3-detailed-explanation-of-the-flow","title":"3. Detailed Explanation of the Flow","text":""},{"location":"en/explanation/tricys_basic/simulation_flow.html#31-initialization","title":"3.1. Initialization","text":"<ul> <li>Read and Prepare Configuration: The process starts with a JSON configuration file. <code>tricys</code> reads this file, parses all paths, simulation settings, and parameters, and prepares an internal configuration object.</li> <li>Set Up Logging: Based on the logging settings in the configuration file, a global logger is initialized to record detailed steps, warnings, and errors throughout the entire process.</li> </ul>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#32-job-generation","title":"3.2. Job Generation","text":"<ul> <li><code>tricys</code> checks the <code>simulation_parameters</code> section in the configuration. If a parameter sweep is defined (e.g., a parameter has multiple values), it generates an independent \"job\" for each parameter combination. If no parameter sweep is defined, only a single default job is generated.</li> </ul>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#33-execution-mode-decision","title":"3.3. Execution Mode Decision","text":"<p>This is a critical branching point in the flow where <code>tricys</code> decides how to execute the generated jobs based on the configuration: - Standard vs. Co-simulation: It first checks for the presence of a <code>co_simulation</code> configuration block. If it exists, the co-simulation flow is initiated; otherwise, the standard simulation flow is followed. - Parallel vs. Sequential: Next, it checks the <code>simulation.concurrent</code> flag. If <code>true</code>, <code>tricys</code> uses a concurrent mode (multi-threading or multi-processing) to execute multiple jobs simultaneously. If <code>false</code>, the jobs are executed sequentially, one after another.</p> <p>These four combinations (Standard/Sequential, Standard/Parallel, Co-simulation/Sequential, Co-simulation/Parallel) correspond to different execution functions to achieve optimal performance and isolation.</p>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#34-job-execution","title":"3.4. Job Execution","text":"<p>Each job is executed in an independent, isolated workspace to prevent file conflicts.</p> <ul> <li>Standard Simulation Flow (<code>_run_single_job</code> / <code>_run_sequential_sweep</code>):</li> <li>Obtain an <code>OMPython</code> session.</li> <li>Load the specified Modelica model package.</li> <li>Apply the parameters for the current job to the model.</li> <li>Call <code>simulate()</code> to execute the simulation.</li> <li> <p>Clean the generated <code>_res.csv</code> result file (e.g., remove duplicate time points) and return its path.</p> </li> <li> <p>Co-simulation Flow (<code>_run_co_simulation</code>):   This is a more complex, multi-stage process used to integrate a Modelica model with external Python logic (called a \"Handler\"):</p> </li> <li>Create Workspace: Create a completely isolated temporary directory for the job.</li> <li>Copy Assets: Copy the model files (<code>.mo</code>) and any external files the Handler might need (like CSVs, lookup tables, etc.) to the workspace.</li> <li>Stage 1: Preliminary Simulation: Run an initial simulation. The purpose of this run is not to get the final results, but to generate the input signals required by the Handler. For example, if an external controller needs to know the current system temperature and pressure, this simulation will export the time series of these variables to <code>primary_inputs.csv</code>.</li> <li>Execute Handler: <code>tricys</code> dynamically loads the Python Handler function specified in the configuration file.</li> <li>Generate External Data: The Handler function is called. It reads <code>primary_inputs.csv</code>, executes its internal logic (e.g., a PID algorithm or a machine learning model), and then generates an output CSV file (e.g., <code>handler_outputs.csv</code>).</li> <li>Integrate Interceptor: <code>tricys</code> generates a new Modelica model (called an interceptor model) that can read the data from <code>handler_outputs.csv</code> and inject it as input into the main model, thereby replacing or \"intercepting\" a part of the original model.</li> <li>Stage 2: Final Simulation: Run the final, complete simulation using this new, modified, and intercepted model.</li> <li>Save Results: Clean the final simulation results and return its path.</li> </ul>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#35-result-aggregation","title":"3.5. Result Aggregation","text":"<p>After all jobs have finished executing: 1. <code>tricys</code> collects the result file paths from each successful job. 2. It reads each of these CSV files one by one and merges them into a single large Pandas DataFrame. 3. To distinguish data from different jobs, it renames the variable columns by appending the parameters that produced the data. For example, if a job's parameters were <code>{\"freq\": 10}</code>, the original <code>voltage</code> column would become <code>voltage&amp;freq=10</code>. 4. Finally, this merged DataFrame is saved as <code>sweep_results.csv</code> (for parameter sweeps) or <code>simulation_result.csv</code> (for single runs).</p>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#36-post-processing","title":"3.6. Post-processing","text":"<p>If <code>post_processing</code> tasks are defined in the configuration file, <code>tricys</code> executes them at this point. It dynamically loads the specified Python functions and passes the merged results DataFrame generated in the previous step as input. This allows users to seamlessly connect custom analysis, plotting, or report generation scripts.</p>"},{"location":"en/explanation/tricys_basic/simulation_flow.html#37-cleanup-and-end","title":"3.7. Cleanup and End","text":"<ul> <li>Unless <code>keep_temp_files: true</code> is set in the configuration, <code>tricys</code> automatically deletes all temporary workspaces and files created during execution.</li> <li>The process ends.</li> </ul>"},{"location":"en/guides/quickstart.html","title":"Quick Start","text":"<p>This guide will walk you through the installation process for <code>tricys</code> in a Windows environment and run a basic command-line simulation.</p>"},{"location":"en/guides/quickstart.html#1-prerequisites","title":"1. Prerequisites","text":"<p>Before you begin, please ensure your system meets the following requirements:</p> <ul> <li>Python: Version 3.8 or higher.</li> <li>Git: For cloning the project repository.</li> <li>OpenModelica: OpenModelica needs to be installed, and its command-line tool (<code>omc.exe</code>) must be added to the system's <code>PATH</code> environment variable.</li> </ul> <p>Tip</p> <p>When installing Python on Windows, be sure to check the \"Add Python to PATH\" option to ensure that the <code>python</code> and <code>pip</code> commands are available in the terminal.</p>"},{"location":"en/guides/quickstart.html#2-installation-steps","title":"2. Installation Steps","text":""},{"location":"en/guides/quickstart.html#a-clone-the-project-repository","title":"a. Clone the Project Repository","text":"<p>Open your terminal (e.g., PowerShell or Cmd) and use <code>git</code> to clone the <code>tricys</code> source code.</p> <pre><code>git clone https://github.com/asipp-neutronics/tricys.git\ncd tricys\n</code></pre>"},{"location":"en/guides/quickstart.html#b-create-and-activate-a-virtual-environment","title":"b. Create and Activate a Virtual Environment","text":"<p>In the project root directory, create an independent Python virtual environment to isolate project dependencies.</p> <pre><code># Create the virtual environment\npython -m venv venv\n\n# Activate the virtual environment\n.\\venv\\Scripts\\activate\n</code></pre> <p>After activation, you will see <code>(venv)</code> appear before your terminal prompt.</p>"},{"location":"en/guides/quickstart.html#c-install-project-dependencies","title":"c. Install Project Dependencies","text":"<p>Use <code>pip</code> to install <code>tricys</code> and all its development dependencies. The <code>-e</code> flag installs it in \"editable\" mode, which means any changes you make to the source code will take effect immediately.</p> <pre><code>pip install -e \".[win]\"\n\nor # or use the Makefile.bat script to install dependencies\n\nMakefile.bat win-install\n</code></pre>"},{"location":"en/guides/quickstart.html#3-run-an-example","title":"3. Run an Example","text":"<p><code>tricys</code> provides an interactive example runner to help you quickly explore and run all available examples, including basic simulations and advanced analysis tasks. This is the easiest way to verify your installation and understand the capabilities of <code>tricys</code>.</p>"},{"location":"en/guides/quickstart.html#a-start-the-example-runner","title":"a. Start the Example Runner","text":"<p>In a terminal with the virtual environment activated, execute the following command to start the example runner:</p> <pre><code>tricys example\n</code></pre>"},{"location":"en/guides/quickstart.html#b-select-and-run-an-example","title":"b. Select and Run an Example","text":"<p>This command starts a unified example runner that scans and lists all available examples from the <code>example/basic</code> and <code>example/analysis</code> directories.</p> <p>You will see a menu similar to the one below:</p> <pre><code>============================================================\n         TRICYS Unified Example Runner\n============================================================\n\n  1. [BASIC] Basic Configuration\n     Description: A basic simulation with a single run\n     Config: basic_configuration.json\n\n  2. [BASIC] Parameter Sweep\n     Description: A multi-run simulation with parameter sweeps\n     Config: parameter_sweep.json\n\n  ...\n\n  6. [ANALYSIS] Baseline Condition Analysis\n     Description: Baseline condition analysis for TBR search\n     Config: baseline_condition_analysis.json\n\n  ...\n\n  0. Exit\n  h. Show help\n  s. Rescan example directories\n\n============================================================\n</code></pre> <ul> <li>Enter a number (e.g., <code>1</code>) and press Enter to run the corresponding example.</li> <li>The program will automatically copy the example files to the <code>test_example</code> folder in the project root directory and execute the task there.</li> <li>This design ensures that the original example files are not modified and keeps the workspace clean.</li> </ul>"},{"location":"en/guides/quickstart.html#c-view-the-results","title":"c. View the Results","text":"<p>After the task is completed, the results will be saved in the <code>test_example</code> directory, inside the subfolder for the respective example.</p> <p>For example, if you ran the <code>Basic Configuration</code> example, the results will be located in the <code>test_example/basic/1_basic_configuration/</code> directory. There you will find:</p> <ul> <li><code>simulation_result.csv</code>: Contains data for all output variables over time.</li> <li><code>simualtion_{timestamp}.log</code>: A detailed log file for this run.</li> <li><code>basic_configuation.json</code>: A backup of the full configuration used for this run.</li> </ul>"},{"location":"en/guides/quickstart.html#4-run-the-graphical-user-interface-gui","title":"4. Run the Graphical User Interface (GUI)","text":"<p>If you prefer a graphical interface, you can start the <code>tricys</code> GUI.</p> <pre><code>tricys gui\n</code></pre> <p>The GUI provides an interactive interface for loading models, setting parameters, defining sweep ranges, and starting simulations.</p>"},{"location":"en/guides/quickstart.html#5-tricys-related-commands","title":"5. TRICYS Related Commands","text":"<p>Congratulations! You have successfully installed and run <code>tricys</code>. Next, you can explore more advanced features like Parameter Sweep or Co-Simulation.</p>"},{"location":"en/guides/models/cycle.html","title":"Tritium Fuel Cycle 0-D System Model","text":""},{"location":"en/guides/models/cycle.html#1-introduction-to-the-tritium-cycle-system","title":"1. Introduction to the Tritium Cycle System","text":"<p>The fusion reactor's tritium fuel cycle is architecturally divided into two highly coupled systems: the inner fuel cycle and the outer fuel cycle.</p> <p></p>"},{"location":"en/guides/models/cycle.html#11-inner-fuel-cycle","title":"1.1. Inner Fuel Cycle","text":"<p>This is a high-throughput, fast closed-loop circuit that processes unburnt fuel. Its material flow path is as follows:</p> <p>1)  Fuelling: The cycle begins at the Storage and Delivery System (SDS). High-purity D-T fuel is injected into the Tokamak vacuum chamber (Plasma) via the Fueling System (FS).</p> <p>2)  Exhaust: In the plasma, only a small amount of fuel undergoes fusion. The majority of unburnt fuel, fusion products (helium ash), and impurities are directed to the Divertor area.</p> <p>3)  Pumping: The Vacuum Pumping System (Pump_System) extracts these hot exhaust gases.</p> <p>4)  Purification (TEP): The exhaust gas is sent to the Tokamak Exhaust Processing (TEP) system. Here, TEP performs crucial chemical purification to recover hydrogen isotopes from impurities such as tritiated water (Q2O) and tritiated methane (CQ4).</p> <p>5)  Separation (ISS): The purified hydrogen isotope (Q2) gas mixture is sent to the Inner Isotope Separation System (I-ISS), where isotope separation is typically performed using cryogenic distillation.</p> <p>6) Return: Finally, the separated high-purity D2 and T2 fuels are returned to the SDS, enabling fuel recycling and completing the inner closed loop.</p>"},{"location":"en/guides/models/cycle.html#12-outer-fuel-cycle","title":"1.2. Outer Fuel Cycle","text":"<p>This is a low-throughput, slow loop responsible for producing new fuel to achieve tritium self-sufficiency. Its material flow path is as follows:</p> <p>1)  Breeding: High-energy neutrons from fusion enter the Breeding Blanket, where they react with lithium (Li) in the blanket to breed new tritium.</p> <p>2)  Extraction: The newly bred tritium is removed from the blanket material by the Tritium Extraction System (TES).</p> <p>3)  Permeation &amp; Purification: Simultaneously, a small amount of tritium inevitably permeates into the coolant loop (CL). The Coolant Purification System (CPS) is responsible for capturing and recovering this permeated tritium from the coolant.</p> <p>4)  Collection &amp; Separation: The tritium-rich stream from the TES (e.g., helium purge gas from a solid blanket or permeator product gas from a liquid blanket) merges with the recovered tritium stream from the CPS. Both are transported to the Outer Isotope Separation System (O-ISS) for purification.</p> <p>5)  Replenish: After removing helium and other impurities, the O-ISS sends high-purity tritium to the SDS to replenish the main fuel cycle, completing the plant-wide fuel closed loop.</p>"},{"location":"en/guides/models/cycle.html#2-modelica-example-model","title":"2. Modelica Example Model","text":"<p>The core of TRICYS is a 0-D system model of the tritium fuel cycle. This model abstracts the fusion reactor's tritium fuel cycle system into a series of interconnected subsystems, each representing a key functional module in the actual plant.</p> <p>A 0-D model means we focus on system-level material flow and inventory changes, rather than detailed spatial distribution. This modeling approach is particularly suitable for:</p> <ul> <li>System-level tritium inventory analysis</li> <li>Fuel self-sufficiency time assessment</li> <li>Design parameter optimization</li> <li>Operational strategy studies</li> <li>Safety assessment</li> </ul> <p></p> Abbreviation Chinese Full Name English Full Name <code>Plasma</code> \u7b49\u79bb\u5b50\u4f53 Plasma <code>Fueling_System</code> \u71c3\u6599\u6ce8\u5165\u7cfb\u7edf Fueling System <code>Pump_System</code> \u771f\u7a7a\u6cf5\u7cfb\u7edf Vacuum Pumping System <code>TEP_FEP</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u524d\u7aef Tokamak Exhaust Processing - Front-End Processing <code>TEP_IP</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u4e2d\u95f4\u5904\u7406 Tokamak Exhaust Processing - Intermediate Processing <code>TEP_FCU</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u6700\u7ec8\u51c0\u5316\u5355\u5143 Tokamak Exhaust Processing - Final Cleanup Unit <code>I_ISS</code> \u5185\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf Inner Isotope Separation System <code>SDS</code> \u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf Storage and Delivery System <code>Blanket</code> \u589e\u6b96\u5305\u5c42 Breeding Blanket <code>TES</code> \u6c1a\u63d0\u53d6\u7cfb\u7edf Tritium Extraction System <code>O_ISS</code> \u5916\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf Outer Isotope Separation System <code>FW</code> \u7b2c\u4e00\u58c1 First Wall <code>DIV</code> \u504f\u6ee4\u5668 Divertor <code>Coolant_Pipe</code> \u51b7\u5374\u5242\u56de\u8def Coolant Pipe <code>CPS</code> \u51b7\u5374\u5242\u51c0\u5316\u7cfb\u7edf Coolant Purification System <code>WDS</code> \u6c34\u53bb\u6c1a\u7cfb\u7edf Water Detritiation System"},{"location":"en/guides/models/cycle.html#3-further-learning","title":"3. Further Learning","text":"<ul> <li>Quickstart: Run your first simulation</li> <li>Basic Configuration: Learn how to configure model parameters</li> <li>Parameter Sweep: Systematically study the parameter space</li> <li>Sensitivity Analysis: Identify key parameters</li> </ul>"},{"location":"en/guides/tricys_analysis/index.html","title":"Automated Analysis (TRICYS ANALYSIS)","text":"<p><code>TRICYS ANALYSIS</code> is the advanced analysis module of <code>tricys</code>, designed to automate a series of complex simulation, post-processing, and report generation tasks. Unlike <code>TRICYS BASIC</code>, which executes a single simulation, the <code>ANALYSIS</code> module uses a unified configuration file to perform various advanced analysis tasks, from parameter sweeps and sensitivity analysis to uncertainty quantification.</p> <p>This chapter will first introduce the core configuration items common to all analysis tasks, and then provide a detailed introduction to each specific analysis mode in separate sections.</p>"},{"location":"en/guides/tricys_analysis/index.html#1-common-configuration-items","title":"1. Common Configuration Items","text":"<p>In the <code>tricys</code> analysis configuration file, the <code>sensitivity_analysis</code> object is at the core of all analysis tasks. The following are the key fields that are common across multiple analysis types.</p>"},{"location":"en/guides/tricys_analysis/index.html#11-multi-case-concurrent-execution","title":"1.1. Multi-Case Concurrent Execution","text":"<ul> <li><code>analysis_cases</code> (List of Analysis Cases)</li> <li>Description: This is an array and the core of the <code>TRICYS ANALYSIS</code> mode. It allows you to define multiple independent analysis tasks in a single configuration file. Each element in the array is a complete analysis case object, which can have its own independent <code>name</code>, <code>independent_variable</code>, <code>dependent_variables</code>, etc. <code>tricys</code> will execute each case in this list sequentially.</li> <li> <p>Application: This feature is very useful when you need to compare different model versions, different initial conditions, or different analysis methods (for example, running a single-parameter sensitivity analysis and a SOBOL analysis in the same batch).</p> </li> <li> <p><code>concurrent_cases</code> (Concurrent Case Execution)</p> </li> <li>Description: A boolean value (<code>true</code> or <code>false</code>), defaulting to <code>false</code>. When set to <code>true</code>, <code>tricys</code> will enable multi-process parallel computing to execute multiple cases from the <code>analysis_cases</code> list simultaneously.</li> <li> <p>Application: For configuration files containing a large number of independent analysis cases, enabling this option can leverage the power of multi-core CPUs to significantly reduce the total analysis time.</p> </li> <li> <p><code>max_case_workers</code> (Maximum Number of Concurrent Workers)</p> </li> <li>Description: An integer that is effective only when <code>concurrent_cases</code> is <code>true</code>. It is used to specify the maximum number of processes for parallel execution.</li> <li>Default Value: If not set, <code>tricys</code> will default to the number of CPU cores on your machine.</li> <li>Recommendation: It is recommended to set this to a value no greater than the number of physical CPU cores on your computer for optimal performance.</li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#12-metrics_definition-metric-definitions","title":"1.2. <code>metrics_definition</code> (Metric Definitions)","text":"<p>This is the most critical part, used to define the Key Performance Indicators (KPIs) you care about, which are the dependent variables in the analysis results.</p> <ul> <li>Structure: A dictionary where each key is a unique name you assign to the metric (e.g., <code>Startup_Inventory</code>).</li> <li>Value: An object describing how to calculate that metric.<ul> <li><code>source_column</code>: The source of the raw data for the calculation, i.e., the column name in the simulation results (<code>.csv</code>).</li> <li><code>method</code>: The name of the function in the <code>tricys.analysis.metric</code> module used for the calculation.</li> </ul> </li> <li>Details: <code>tricys</code> has several built-in functions for common metric calculations. For a detailed explanation of the physical meaning and calculation methods of core performance metrics (like <code>Startup_Inventory</code>, <code>Doubling_Time</code>, etc.), please refer to Core Performance Metrics Explained.</li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#13-glossary_path-glossary","title":"1.3. <code>glossary_path</code> (Glossary)","text":"<ul> <li>Description: A path to a \"glossary\" CSV file. Providing this file can greatly enhance the readability of the report, as it maps abbreviated variable names from the code (e.g., <code>sds.I[1]</code>) to easy-to-understand names and descriptions.</li> <li>Format: This is a standard CSV file, and its headers should include <code>Model Parameter</code> (required), <code>English Term</code>, <code>Chinese Translation</code>, etc.</li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#14-unit_map-unit-map","title":"1.4. <code>unit_map</code> (Unit Map)","text":"<ul> <li>Description: A dictionary used to customize the units in the report charts, making the results more intuitive.</li> <li>Key: The variable or metric name.</li> <li>Value: An object containing <code>unit</code> (the unit string) and <code>conversion_factor</code> (the conversion factor from the original simulation unit to the target unit). For example, if the simulation time unit is hours, a <code>\"conversion_factor\": 24</code> can convert the unit of <code>Doubling_Time</code> to days.</li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#15-ai-enhanced-analysis-ai-true","title":"1.5. AI-Enhanced Analysis (<code>\"ai\": true</code>)","text":"<p>All analysis modules in <code>tricys</code> have powerful built-in AI analysis capabilities.</p> <ul> <li>How to Enable: Add <code>\"ai\": true</code> to the configuration of a specific analysis case (e.g., within an element of <code>analysis_cases</code>, or in the <code>params</code> of a <code>post_processing</code> task) to activate it.</li> <li>Environment Setup: Before using this feature, you must create a file named <code>.env</code> in the project's root directory and fill in your Large Language Model (LLM) API credentials.     <pre><code># .env file\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre></li> <li>Functionality: When enabled, <code>tricys</code> will, in addition to generating standard charts and data reports, make an extra call to the LLM to:<ol> <li>Provide an in-depth interpretation of the analysis results and append it to the core Markdown report.</li> <li>Generate a well-structured academic-style report (<code>academic_report.md</code>) written entirely by the AI, which can be used directly for presentations or as a draft for a paper.</li> </ol> </li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#16-common-configuration-example","title":"1.6. Common Configuration Example","text":"<p>The following JSON snippet shows how the above common configuration items are used in the <code>sensitivity_analysis</code> object.</p> <pre><code>\"sensitivity_analysis\": {\n    \"enabled\": true,\n    \"concurrent_cases\": true,\n    \"max_case_workers\": 4,\n    \"analysis_cases\": [\n        // ... Definition of specific analysis cases here, see docs for each analysis type ...\n    ],\n    \"metrics_definition\": {\n        \"Startup_Inventory\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"calculate_startup_inventory\"\n        },\n        \"Doubling_Time\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"calculate_doubling_time\"\n        },\n        \"Required_TBR\": {\n            \"method\": \"bisection_search\",\n            \"parameter_to_optimize\": \"blanket.TBR\",\n            \"search_range\": [1, 1.5]\n        }\n    },\n    \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n    \"unit_map\": {\n        \"Doubling_Time\": {\n            \"unit\": \"days\",\n            \"conversion_factor\": 24\n        },\n        \"Startup_Inventory\": {\n            \"unit\": \"kg\",\n            \"conversion_factor\": 1000\n        }\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/index.html#2-common-analysis-report-output","title":"2. Common Analysis Report Output","text":"<p>Regardless of the type of analysis performed, <code>tricys</code> will create a folder named with a timestamp in the current working directory to store all results. For each analysis case defined in the <code>analysis_cases</code> configuration, a subfolder named after the case's <code>name</code> will be created inside the timestamp folder.</p> <p>A typical output directory structure is as follows:</p> <pre><code>&lt;run_timestamp&gt;/\n\u251c\u2500\u2500 Case_A_Name/\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u251c\u2500\u2500 analysis_report_Case_A_Name.md              # Core analysis report\n\u2502   \u2502   \u251c\u2500\u2500 academic_report_Case_A_Name_gpt-4.md      # (Optional) AI academic report\n\u2502   \u2502   \u251c\u2500\u2500 analysis_plot_1.svg                         # Analysis plot 1\n\u2502   \u2502   \u2514\u2500\u2500 analysis_plot_2.svg                         # Analysis plot 2\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u2514\u2500\u2500 ... (Intermediate data files)\n\u2502\n\u251c\u2500\u2500 Case_B_Name/\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u2514\u2500\u2500 ...\n\u2502\n\u2514\u2500\u2500 execution_report.md (Global execution report)\n</code></pre> <p>The core output of each case subfolder is located in its internal <code>report</code> folder, which usually contains the following:</p>"},{"location":"en/guides/tricys_analysis/index.html#21-core-analysis-report","title":"2.1. Core Analysis Report","text":"<ul> <li>File: <code>analysis_report_{case_name}.md</code></li> <li>Format: Markdown</li> <li>Content: This is a summary of the analysis results, integrating configuration, charts, and data in a structured way. Its common content includes:<ul> <li>Analysis Case Configuration Details: A detailed list of all configuration parameters used for this analysis, ensuring the transparency and reproducibility of the analysis process.</li> <li>Summary Table of Performance Metrics: A clear Markdown table listing each value of the independent variable and the corresponding calculated values of all dependent variables (performance metrics). This is the raw data source for all analysis charts.</li> <li>Analysis Charts: Embedded vector graphics in SVG format. The specific type and content of the charts depend on the analysis mode (e.g., trend line charts for single-parameter analysis, bar charts of sensitivity indices for SOBOL analysis, etc.). Please refer to the documentation for each analysis type for details.</li> </ul> </li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#22-optional-ai-enhanced-report","title":"2.2. (Optional) AI-Enhanced Report","text":"<p>If <code>\"ai\": true</code> is configured, the <code>report</code> folder will additionally contain:</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: An in-depth interpretation of the data and charts generated by the AI, appended to the end of the core report.</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: A well-structured, academic-style report written entirely by the AI, which can be used directly for presentations or as a draft for a paper.</li> </ul>"},{"location":"en/guides/tricys_analysis/index.html#3-analysis-type-navigation","title":"3. Analysis Type Navigation","text":"<p>Depending on your research objectives, you can choose from the following different analysis modes. Please click the links to view detailed configuration methods and application scenarios for each mode.</p> <ul> <li>Baseline Condition Analysis: For a comprehensive evaluation of a single, fixed parameter configuration.</li> <li>Single-Parameter Sensitivity Analysis: To study how changes in a single independent parameter affect system performance.</li> <li>Multi-Parameter Sensitivity Analysis: To analyze the interaction and coupling effects between multiple parameters, or to perform \"goal-seeking\" analysis.</li> <li>SOBOL Global Sensitivity Analysis: To quantify the contribution of multiple input parameters and their interactions to the variance of the model output.</li> <li>Latin Uncertainty Quantification Analysis: To assess how uncertainty in input parameters propagates to the model output and to analyze the probability distribution of the output.</li> </ul>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html","title":"Baseline Condition Analysis","text":"<p>Baseline Condition Analysis is a core feature of the <code>tricys</code> analysis toolset. It is used for a comprehensive evaluation of the system's behavior under a single, fixed parameter configuration (the \"baseline condition\") and automatically generates a standardized Markdown analysis report.</p> <p>This function is essentially a post-processing module of <code>tricys</code>. For general configurations of the post-processing module, please refer to the Post-Processing Module. For common configurations such as metric definitions, glossaries, and unit maps, please refer to the General Introduction.</p>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>The configuration for this analysis consists of a single simulation followed by a specific post-processing step. Therefore, the configuration file does not include a <code>sensitivity_analysis</code> scanning section.</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]|div.I[1]|cps.I[1]|tes.I[1]|blanket.I[1]|i_iss.I[1]|wds.I[1]|o_iss.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    },\n    \"post_processing\": [\n        {\n           \"module\": \"tricys.postprocess.baseline_analysis\",\n           \"function\": \"baseline_analysis\",\n           \"params\": {\n                \"detailed_var\": \"sds.I[1]\",\n                \"glossary_path\": \"../../example_glossary/example_glossary.csv\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#2-key-configuration-items-explained","title":"2. Key Configuration Items Explained","text":"<p>The core lies in the <code>post_processing</code> section configuration:</p> <ul> <li><code>module</code>: Fixed as <code>tricys.postprocess.baseline_analysis</code>.</li> <li><code>function</code>: Fixed as <code>baseline_analysis</code>.</li> <li><code>params</code>:<ul> <li><code>detailed_var</code> (string, optional):<ul> <li>Description: Specifies a variable in the model. The report will generate a time evolution curve chart with a \"detailed view\" for this variable, zooming in on the area around its \"self-sufficiency point\".</li> </ul> </li> <li><code>glossary_path</code> (string, optional):<ul> <li>Description: A path to a \"glossary\" CSV file.</li> </ul> </li> </ul> </li> </ul>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#3-analysis-report-output","title":"3. Analysis Report Output","text":"<p>The structure of the report is similar to that described in the General Introduction, but its core content is a snapshot analysis of a single run, including:</p> <ol> <li>Key Performance Indicators: <code>Startup Inventory</code>, <code>Self-Sufficiency Time</code>, and <code>Doubling Time</code> calculated based on <code>detailed_var</code>.</li> <li>Time-series Plot of Simulation Results: Includes a global view and a detailed view based on <code>detailed_var</code>.</li> <li>Final Values Bar Chart: A bar chart showing the distribution of tritium inventory across submodules at the end of the simulation.</li> <li>Data Tables: Includes a table of final values and data slices at key stages (initial, turning point, end).</li> </ol>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#4-ai-enhanced-analysis","title":"4. AI-Enhanced Analysis","text":"<p>All analysis modules in <code>tricys</code> are deeply integrated with Large Language Models (LLMs), capable of automatically converting raw charts and data into structured, academic-style reports.</p>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#41-how-to-enable","title":"4.1. How to Enable","text":"<p>For baseline condition analysis, the AI feature is activated by adding <code>\"ai\": true</code> to the <code>params</code> object of the <code>post_processing</code> task.</p> <pre><code>\"post_processing\": [\n    {\n       \"module\": \"tricys.postprocess.baseline_analysis\",\n       \"function\": \"baseline_analysis\",\n       \"params\": {\n            \"detailed_var\": \"sds.I[1]\",\n            \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n            \"ai\": true\n        }\n    }\n]\n</code></pre>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#42-environment-setup","title":"4.2. Environment Setup","text":"<p>Before using this feature, you must create a file named <code>.env</code> in the project's root directory and fill in your Large Language Model API credentials. This ensures that your keys are kept secure and are not committed to version control.</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"en/guides/tricys_analysis/baseline_condition_analysis.html#43-output-reports","title":"4.3. Output Reports","text":"<p>When enabled, in addition to the standard analysis report (<code>analysis_report_...md</code>), <code>tricys</code> will generate two additional reports in the case's <code>report</code> folder:</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: Appends an in-depth textual interpretation of the data and charts, generated by the AI, to the end of the core report.</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: A well-structured, academic-style report written entirely by the AI. This report typically includes sections such as Abstract, Introduction, Methods, Results and Discussion, and Conclusion, and can be used directly for presentations or as a draft for a paper.</li> </ul>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html","title":"Latin Uncertainty Quantification Analysis","text":"<p>Uncertainty Quantification (UQ) is a critical step in assessing the reliability of a model or system. Its purpose is not to find out which parameter is the most sensitive, but to answer a more important question: \"When my input parameters are uncertain within a certain range, what is the possible range of my output results (performance metrics)? What is their probability distribution?\"</p> <p><code>tricys</code> uses the efficient Latin Hypercube Sampling (LHS) technique to perform UQ analysis. LHS is a stratified sampling method that can uniformly explore the entire multi-dimensional parameter space with a relatively small number of sample points, thus efficiently assessing how input uncertainty propagates to the model output.</p> <p>For common configurations such as metric definitions, glossaries, and unit maps, please refer to the Automated Analysis Main Page.</p>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>The configuration for an LHS analysis is very similar to that of a SOBOL global sensitivity analysis, with the main difference being that <code>analyzer.method</code> is set to <code>\"latin\"</code>.</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_LATIN_Analysis\",\n                \"independent_variable\": [\"pulseSource.width\", \"plasma.nf\", \"plasma.fb\", \"tep_fep.to_SDS_Fraction[1]\", \"blanket.TBR\"],\n                \"independent_variable_sampling\": {\n                      \"pulseSource.width\": { \"bounds\": [50, 90], \"distribution\": \"unif\" },\n                      \"plasma.nf\": { \"bounds\": [0.1, 0.9], \"distribution\": \"unif\" },\n                      \"plasma.fb\": { \"bounds\": [0.03, 0.07], \"distribution\": \"unif\" },\n                      \"tep_fep.to_SDS_Fraction[1]\": { \"bounds\": [0.1, 0.8], \"distribution\": \"unif\" },\n                      \"blanket.TBR\": { \"bounds\": [1.05, 1.25], \"distribution\": \"unif\" }\n                },\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"analyzer\": {\n                    \"method\": \"latin\",\n                    \"sample_N\": 256\n                }\n            }\n        ],\n        // ... (Common configurations)\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#2-key-configuration-items-explained","title":"2. Key Configuration Items Explained","text":"<ul> <li><code>independent_variable</code> (list): A list of all input parameters considered as sources of uncertainty.</li> <li><code>independent_variable_sampling</code> (object): A dictionary that defines the sampling range and probability distribution for each uncertain parameter.</li> <li><code>analyzer</code> (object): Defines the analysis method to be used and its parameters.</li> <li><code>method</code>: Fixed as <code>\"latin\"</code>.</li> <li><code>sample_N</code>: The number of samples to be generated by Latin Hypercube Sampling, which directly corresponds to the total number of simulations to be run.</li> </ul>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#3-workflow-explained","title":"3. Workflow Explained","text":"<p>When <code>tricys</code> receives an analysis task that includes an <code>analyzer</code> field (like the LHS analysis in this example), it initiates a special workflow based on the <code>SALib</code> library.</p> <ol> <li>Identify Analysis Type: In the main flow of <code>tricys.simulation.simulation_analysis.py</code>, the program first detects that this is a SALib analysis task.</li> <li>Define Problem and Sample: The program delegates the task to the <code>tricys.analysis.salib.py</code> module, which defines a <code>SALib</code> \"problem space\" according to the configuration and calls the LHS sampling function to generate <code>N</code> parameter sample points.</li> <li>Execute Batch Simulations: The <code>N</code> generated parameter samples are written to a temporary CSV file, and <code>tricys</code> then executes a simulation for each sample point.</li> <li>Collect and Analyze Results: After all simulations are completed, the program calculates the <code>N</code> output results for each performance metric and performs a statistical analysis on them (calculating mean, standard deviation, percentiles, etc.).</li> <li>Generate Report and Charts: Finally, the program generates the final Markdown report based on the statistical analysis results, which includes detailed statistical data tables and output distribution charts (histograms and cumulative distribution function plots).</li> </ol>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#4-analysis-report-output","title":"4. Analysis Report Output","text":"<p>The core content of the report is an independent statistical analysis for each dependent variable (performance metric). For example, for the <code>Startup_Inventory</code> metric, the report will include:</p> <ol> <li>Statistical Summary: Provides a set of core statistics, including mean, standard deviation, minimum, and maximum values.</li> <li>Key Distribution Points / CDF: Provides a series of percentiles (e.g., 5%, 25%, 50% (median), 75%, 95%) to accurately describe the cumulative distribution of the output metric.</li> <li>Output Distribution (Histogram Data): A table showing the frequency distribution of the output results in different numerical intervals.</li> <li>Output Distribution Plot: An embedded <code>.png</code> chart containing two subplots:<ul> <li>Histogram: Visually displays the shape of the probability density distribution of the output metric.</li> <li>Cumulative Distribution Function (CDF): Shows the probability that the output metric value is less than or equal to a certain specific value.</li> </ul> </li> </ol>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#how-to-interpret-uq-results","title":"How to Interpret UQ Results","text":"<p>The focus of uncertainty quantification analysis is to understand the distribution of the output, not the ranking of parameter sensitivity.</p> <ul> <li>Look at Central Tendency: The Mean and Median tell you where the performance metric is most likely to fall.</li> <li>Look at Dispersion: The Standard Deviation and the range of the 5%-95% percentiles reveal how much uncertainty there is in the output. A wider range indicates that the uncertainty in the input parameters has a greater impact on the system's performance, and the system's robustness may be poorer.</li> <li>Look at Distribution Shape: The shape of the histogram is important. A symmetric, bell-shaped curve similar to a normal distribution is relatively ideal. If the distribution shows a long tail or is skewed, it may mean that the system is prone to extremely good or bad results under certain parameter combinations, which is crucial for risk assessment.</li> </ul>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#5-full-example-configuration","title":"5. Full Example Configuration","text":"example/analysis/5_latin_uncertainty_analysis/latin_uncertainty_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"SALIB_LATIN_Analysis\",                 \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\",\"plasma.fb\",\"tep_fep.to_SDS_Fraction[1]\",\"blanket.TBR\"],                 \"independent_variable_sampling\":{                       \"pulseSource.width\": {                           \"bounds\": [50,90],                           \"distribution\": \"unif\"                       },                       \"plasma.nf\": {                           \"bounds\": [0.1,0.9],                           \"distribution\": \"unif\"                       },                       \"plasma.fb\": {                           \"bounds\": [0.03,0.07],                           \"distribution\": \"unif\"                       },                       \"tep_fep.to_SDS_Fraction[1]\": {                           \"bounds\": [0.1,0.8],                           \"distribution\": \"unif\"                       },                       \"blanket.TBR\": {                           \"bounds\": [1.05, 1.25],                           \"distribution\": \"unif\"                       }                 },                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Self_Sufficiency_Time\",                     \"Doubling_Time\"                 ],                 \"analyzer\": {                     \"method\": \"latin\",                     \"sample_N\": 256                 }             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#6-ai-enhanced-analysis","title":"6. AI-Enhanced Analysis","text":"<p>All analysis modules in <code>tricys</code> are deeply integrated with Large Language Models (LLMs), capable of automatically converting raw charts and data into structured, academic-style reports.</p>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#61-how-to-enable","title":"6.1. How to Enable","text":"<p>In your analysis case configuration (i.e., within any object in the <code>analysis_cases</code> list or in the <code>params</code> of a <code>post_processing</code> task), add <code>\"ai\": true</code> to activate the AI analysis feature for that case.</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#62-environment-setup","title":"6.2. Environment Setup","text":"<p>Before using this feature, you must create a file named <code>.env</code> in the project's root directory and fill in your Large Language Model API credentials. This ensures that your keys are kept secure and are not committed to version control.</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"en/guides/tricys_analysis/latin_uncertainty_analysis.html#63-output-reports","title":"6.3. Output Reports","text":"<p>When enabled, in addition to the standard analysis report (<code>analysis_report_...md</code>), <code>tricys</code> will generate two additional reports in the case's <code>report</code> folder:</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: Appends an in-depth textual interpretation of the data and charts, generated by the AI, to the end of the core report.</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: A well-structured, academic-style report written entirely by the AI. This report typically includes sections such as Abstract, Introduction, Methods, Results and Discussion, and Conclusion, and can be used directly for presentations or as a draft for a paper.</li> </ul>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html","title":"Multi-Parameter Sensitivity Analysis","text":"<p>Building on single-parameter sensitivity analysis, <code>tricys</code> offers a more powerful multi-parameter sensitivity analysis. This feature allows you to study the impact of a primary independent parameter (X-axis) on performance metrics (Y-axis) while simultaneously sweeping one or more background parameters.</p> <p>This enables you to generate a \"family of sensitivity curves\" on a single chart, where each curve represents a specific value of a background parameter. In this way, you can gain a deep understanding of the interaction and coupling effects between parameters. Additionally, this feature supports a powerful \"goal-seeking\" analysis mode.</p> <p>For common configurations such as metric definitions, glossaries, and unit maps, please refer to the Automated Analysis Main Page.</p>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#1-core-concept-parameter-interaction-analysis","title":"1. Core Concept: Parameter Interaction Analysis","text":"<p>This is the most common use of multi-parameter analysis, and its core is to embed a <code>simulation_parameters</code> field inside a case within <code>analysis_cases</code>.</p>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#11-configuration-file-example","title":"1.1. Configuration File Example","text":"<pre><code>{\n    // ...\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"DIR_PLASMA_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\", // Primary independent parameter (X-axis)\n                \"independent_variable_sampling\": [0.1, 0.3, 0.6, 0.8],\n                \"dependent_variables\": [ \"Startup_Inventory\", \"Required_TBR\" ], // Dependent variables (Y-axis)\n                \"simulation_parameters\": {\n                    \"plasma.fb\": [0.02, 0.04, 0.08, 0.09, 0.1], // Background sweep parameter (generates multiple curves)\n                    \"plasma.nf\": 0.5 // Fixed background parameter\n                }\n            }\n        ],\n        // ... (Common configurations)\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#12-how-it-works","title":"1.2. How It Works","text":"<ul> <li>Primary Independent Parameter (<code>independent_variable</code>): <code>tep_fep.to_SDS_Fraction[1]</code>, serves as the X-axis of the chart.</li> <li>Background Sweep Parameters (<code>simulation_parameters</code>):<ul> <li>The value of <code>plasma.fb</code> is a list, which will become the Legend in the chart. Each curve corresponds to one value of <code>plasma.fb</code>.</li> <li>The value of <code>plasma.nf</code> is a scalar, which will remain constant across all simulations.</li> </ul> </li> <li>Execution Logic: The program executes a \"nested loop\". For each value of the <code>independent_variable</code>, the program runs a simulation for each value of <code>plasma.fb</code>. The total number of runs is <code>len(independent_variable_sampling) * len(plasma.fb)</code>.</li> </ul>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#2-advanced-usage-goal-seeking-analysis","title":"2. Advanced Usage: Goal-Seeking Analysis","text":"<p>This feature supports a \"reverse\" analysis mode, known as Goal-Seeking. You can specify a performance metric as a target and solve for the required value of an input parameter to achieve that target.</p>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#21-configuration-file-example","title":"2.1. Configuration File Example","text":"<p>The key is that <code>simulation_parameters</code> contains a special object with the same name as an optimization metric in <code>metrics_definition</code> (in this case, <code>Required_TBR</code>).</p> <pre><code>{\n    \"name\": \"DoubleTime_PLASMA_Analysis\",\n    \"independent_variable\": \"plasma.fb\", // Primary independent parameter (X-axis)\n    \"dependent_variables\": [ \"Startup_Inventory\", \"Required_TBR\" ], // Dependent variables (Y-axis)\n    \"simulation_parameters\": {\n        \"plasma.nf\": 0.5,\n        \"Required_TBR\": { // Special goal-seeking configuration\n            \"metric_name\": \"Doubling_Time\", // Target metric\n            \"metric_max_value\": [4380, 8760, 13140, 17530] // List of target values (unit: hours)\n        }\n    },\n    // ...\n    \"metrics_definition\": {\n        // ...\n        \"Required_TBR\": {\n            \"method\": \"bisection_search\",\n            \"parameter_to_optimize\": \"blanket.TBR\", // Parameter to be solved for\n            // ... (other configurations for bisection_search)\n        }\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#22-how-it-works","title":"2.2. How It Works","text":"<ul> <li>Problem Description: This configuration aims to answer the question: \"As <code>plasma.fb</code> changes, what is the required <code>blanket.TBR</code> to achieve different <code>Doubling_Time</code> targets (4380h, 8760h, ...)?\"</li> <li>Execution Logic: For each value of <code>plasma.fb</code> on the X-axis, the program initiates a <code>bisection_search</code> optimization loop for each target value in the <code>metric_max_value</code> list to solve for the corresponding <code>blanket.TBR</code> value.</li> <li>Result Interpretation: The final chart will show how the required TBR changes with <code>plasma.fb</code> under different doubling time target constraints.</li> </ul>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#3-analysis-report-output","title":"3. Analysis Report Output","text":"<p>The main difference from single-parameter analysis lies in the performance metric analysis chart:</p> <ul> <li>For parameter interaction analysis, the chart will contain a set of curves, with the legend corresponding to different values of the background parameter (e.g., <code>plasma.fb</code>).</li> <li>For goal-seeking analysis, the chart will also contain multiple curves, but the legend will correspond to different performance target constraints (e.g., <code>Doubling_Time = 4380h</code>).</li> </ul> <p>This allows multi-dimensional data relationships to be clearly presented in a single two-dimensional chart. The rest of the report follows the common structure.</p>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#4-full-example-configuration","title":"4. Full Example Configuration","text":"example/analysis/3_multi_parameter_sensitivity_analysis/multi_parameter_sensitivity_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"DIR_PLASMA_Analysis\",                 \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",                 \"independent_variable_sampling\": [0.1,0.3,0.6,0.8],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1],                     \"plasma.nf\":0.5                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             },             {                 \"name\": \"Pulse_PLASMA_Analysis\",                 \"independent_variable\": \"pulseSource.width\",                 \"independent_variable_sampling\": [50,60,70,80,90,99],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1],                     \"plasma.nf\":0.5                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             },             {                 \"name\": \"DoubleTime_PLASMA_Analysis\",                 \"independent_variable\": \"plasma.fb\",                 \"independent_variable_sampling\": [0.02,0.05,0.08,0.1],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.nf\":0.5,                     \"Required_TBR\": {                         \"metric_name\":\"Doubling_Time\",                         \"metric_max_value\": [4380,8760,13140,17530]                     }                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#5-ai-enhanced-analysis","title":"5. AI-Enhanced Analysis","text":"<p>All analysis modules in <code>tricys</code> are deeply integrated with Large Language Models (LLMs), capable of automatically converting raw charts and data into structured, academic-style reports.</p>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#51-how-to-enable","title":"5.1. How to Enable","text":"<p>In your analysis case configuration (i.e., within any object in the <code>analysis_cases</code> list or in the <code>params</code> of a <code>post_processing</code> task), add <code>\"ai\": true</code> to activate the AI analysis feature for that case.</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#52-environment-setup","title":"5.2. Environment Setup","text":"<p>Before using this feature, you must create a file named <code>.env</code> in the project's root directory and fill in your Large Language Model API credentials. This ensures that your keys are kept secure and are not committed to version control.</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"en/guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#53-output-reports","title":"5.3. Output Reports","text":"<p>When enabled, in addition to the standard analysis report (<code>analysis_report_...md</code>), <code>tricys</code> will generate two additional reports in the case's <code>report</code> folder:</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: Appends an in-depth textual interpretation of the data and charts, generated by the AI, to the end of the core report.</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: A well-structured, academic-style report written entirely by the AI. This report typically includes sections such as Abstract, Introduction, Methods, Results and Discussion, and Conclusion, and can be used directly for presentations or as a draft for a paper.</li> </ul>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html","title":"Single-Parameter Sensitivity Analysis","text":"<p>Single-parameter sensitivity analysis is one of the core features of <code>tricys</code>, designed to study how changes in a single independent parameter affect a series of user-defined Key Performance Indicators (KPIs).</p> <p>This feature automatically runs a series of simulations (one for each value of the independent parameter), calculates the performance metrics for each simulation result, and generates charts to visually represent the relationships between them. For common configurations such as metric definitions, glossaries, and unit maps, please refer to the Automated Analysis Main Page.</p>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>The core configuration for a single-parameter sensitivity analysis is located in the <code>analysis_cases</code> list. Each object represents an independent analysis case.</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            }\n        ],\n        // ... (Common configurations: metrics_definition, glossary_path, unit_map)\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#2-key-configuration-items-explained","title":"2. Key Configuration Items Explained","text":"<ul> <li><code>independent_variable</code> (string): The full model path of the independent parameter to be scanned. This will be the X-axis of the analysis chart.</li> <li><code>independent_variable_sampling</code> (list): A set of discrete values for the independent parameter. The program will run a simulation for each value in this list.</li> <li><code>dependent_variables</code> (list): A list of dependent variables to be analyzed (i.e., the metric names defined in <code>metrics_definition</code>). This will be the Y-axis of the analysis chart.</li> <li><code>plot_type</code> (string): The type of sensitivity chart to generate, typically <code>\"line\"</code>.</li> <li><code>combine_plots</code> (boolean): Whether to plot the analysis results of multiple dependent variables on the same chart. <code>true</code> generates a composite chart with multiple subplots, while <code>false</code> generates a separate chart for each dependent variable.</li> <li><code>sweep_time</code> (list): A list of raw variable names. For each variable in this list, the program will generate a \"family plot,\" which draws the time evolution curve from each parameter sweep on the same graph, making it easy to compare differences in dynamic behavior.</li> </ul>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#3-analysis-report-output","title":"3. Analysis Report Output","text":"<p>The structure of the analysis report is similar to that described in the General Introduction, but its core performance metric analysis chart has the following characteristics:</p> <ul> <li>The X-axis of the chart is the <code>independent_variable</code> you defined.</li> <li>The Y-axis is the performance metrics defined in <code>dependent_variables</code>.</li> <li>If <code>combine_plots</code> is <code>true</code>, the report will include a composite chart where each subplot shows the trend of one performance metric as the independent parameter changes.</li> <li>If <code>sweep_time</code> is defined, the report will also include a \"family plot\" showing the time evolution curves of the raw variable (e.g., <code>sds.I[1]</code>) for different values of the independent parameter.</li> </ul>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#4-full-example-configuration","title":"4. Full Example Configuration","text":"example/analysis/2_single_parameter_sensitivity_analysis/single_parameter_sensitivity_analysis.json <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 12000.0,\n        \"step_size\": 0.5\n    },\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"Width_Analysis\",\n                \"independent_variable\": \"pulseSource.width\",\n                \"independent_variable_sampling\": [50,60,70,80,90,99],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"Fueling_Efficiency_Analysis\",\n                \"independent_variable\": \"plasma.nf\",\n                \"independent_variable_sampling\": [0.01,0.05,0.1,0.2,0.4,0.5,0.6,0.7,0.8,0.9],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"Burn_Fraction_Analysis\",\n                \"independent_variable\": \"plasma.fb\",\n                \"independent_variable_sampling\": [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"DIR_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",\n                \"independent_variable_sampling\": [0.1,0.15,0.2,0.3,0.4,0.6,0.8],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05,1.1,1.15,1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"I_ISS_Analysis\",\n                \"independent_variable\": \"i_iss.T\",\n                \"independent_variable_sampling\": [4,6,8,10],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            }\n        ],\n        \"metrics_definition\": {\n            \"Startup_Inventory\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_startup_inventory\"\n            },\n            \"Self_Sufficiency_Time\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"time_of_turning_point\"\n            },\n            \"Doubling_Time\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_doubling_time\"\n            },\n            \"Required_TBR\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"bisection_search\",\n                \"parameter_to_optimize\": \"blanket.TBR\",\n                \"search_range\": [1,1.5],\n                \"tolerance\": 0.005,\n                \"max_iterations\": 10\n            }\n        },\n        \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n        \"unit_map\": {\n            \"Doubling_Time\": {\n                \"unit\": \"days\",\n                \"conversion_factor\": 24\n            },\n            \"Startup_Inventory\": {\n                \"unit\": \"kg\",\n                \"conversion_factor\": 1000\n            },\n            \"Self_Sufficiency_Time\": {\n                \"unit\": \"days\",\n                \"conversion_factor\": 24\n            },\n            \"power\":{\n                \"unit\": \"MW\"\n            },\n            \"period\":{\n                \"unit\": \"hours\"\n            },\n            \"width\":{\n                \"unit\": \"%\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#5-ai-enhanced-analysis","title":"5. AI-Enhanced Analysis","text":"<p>All analysis modules in <code>tricys</code> are deeply integrated with Large Language Models (LLMs), capable of automatically converting raw charts and data into structured, academic-style reports.</p>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#51-how-to-enable","title":"5.1. How to Enable","text":"<p>In your analysis case configuration (i.e., within any object in the <code>analysis_cases</code> list or in the <code>params</code> of a <code>post_processing</code> task), add <code>\"ai\": true</code> to activate the AI analysis feature for that case.</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#52-environment-setup","title":"5.2. Environment Setup","text":"<p>Before using this feature, you must create a file named <code>.env</code> in the project's root directory and fill in your Large Language Model API credentials. This ensures that your keys are kept secure and are not committed to version control.</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"en/guides/tricys_analysis/single_parameter_sensitivity_analysis.html#53-output-reports","title":"5.3. Output Reports","text":"<p>When enabled, in addition to the standard analysis report (<code>analysis_report_...md</code>), <code>tricys</code> will generate two additional reports in the case's <code>report</code> folder:</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: Appends an in-depth textual interpretation of the data and charts, generated by the AI, to the end of the core report.</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: A well-structured, academic-style report written entirely by the AI. This report typically includes sections such as Abstract, Introduction, Methods, Results and Discussion, and Conclusion, and can be used directly for presentations or as a draft for a paper.</li> </ul>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html","title":"SOBOL Global Sensitivity Analysis","text":"<p>Global Sensitivity Analysis (GSA) is a powerful tool for quantifying the contribution of model input parameters (and their interactions) to the variance of the model output. Unlike local sensitivity analysis, which changes one parameter at a time, GSA explores the entire parameter space simultaneously.</p> <p><code>tricys</code> integrates the industry-standard <code>SALib</code> library, providing direct support for the Sobol method. Sobol is a variance-based GSA method that can efficiently calculate the contribution of each parameter to the model output's uncertainty, including both the independent influence of parameters and their interaction effects.</p> <p>For common configurations such as metric definitions, glossaries, and unit maps, please refer to the Automated Analysis Main Page.</p>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>The configuration for a SOBOL analysis is significantly different from previous sensitivity analyses, mainly in that <code>independent_variable</code> becomes a list, <code>independent_variable_sampling</code> becomes an object, and a new <code>analyzer</code> field is added.</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_SOBOL_Analysis\",\n                \"independent_variable\": [\"pulseSource.width\", \"plasma.nf\", \"plasma.fb\", \"tep_fep.to_SDS_Fraction[1]\", \"blanket.TBR\"],\n                \"independent_variable_sampling\": {\n                      \"pulseSource.width\": { \"bounds\": [50, 90], \"distribution\": \"unif\" },\n                      \"plasma.nf\": { \"bounds\": [0.1, 0.9], \"distribution\": \"unif\" },\n                      \"plasma.fb\": { \"bounds\": [0.03, 0.07], \"distribution\": \"unif\" },\n                      \"tep_fep.to_SDS_Fraction[1]\": { \"bounds\": [0.1, 0.8], \"distribution\": \"unif\" },\n                      \"blanket.TBR\": { \"bounds\": [1.05, 1.25], \"distribution\": \"unif\" }\n                },\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"analyzer\": {\n                    \"method\": \"sobol\",\n                    \"sample_N\": 256\n                }\n            }\n        ],\n        // ... (Common configurations)\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#2-key-configuration-items-explained","title":"2. Key Configuration Items Explained","text":"<ul> <li><code>independent_variable</code> (list): A list containing all input parameters to be included in the global sensitivity analysis.</li> <li><code>independent_variable_sampling</code> (object): A dictionary that defines the sampling range and probability distribution for each parameter in the <code>independent_variable</code> list.</li> <li>Key: The full path of the parameter.</li> <li>Value: An object containing <code>bounds</code> (a list <code>[min, max]</code>) and <code>distribution</code> (a string, e.g., <code>\"unif\"</code>).</li> <li><code>analyzer</code> (object): Defines the GSA method to be used and its parameters.</li> <li><code>method</code>: For Sobol analysis, this is fixed as <code>\"sobol\"</code>.</li> <li><code>sample_N</code>: The base number of samples <code>N</code> required for Sobol sampling.<ul> <li>\u26a0\ufe0f Important: The total number of simulations to be run will be <code>N * (2D + 2)</code>, where <code>D</code> is the number of <code>independent_variable</code>s. For example, in this case, <code>D=5</code> and <code>N=256</code>, so the total number of simulations will be <code>256 * (2*5 + 2) = 3072</code>.</li> </ul> </li> </ul>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#3-analysis-report-output","title":"3. Analysis Report Output","text":"<p>The core content of the report is an independent analysis result for each dependent variable (performance metric). For example, for the <code>Startup_Inventory</code> metric, the report will include:</p> <ol> <li>Sobol Sensitivity Indices Table: A Markdown table that precisely lists the first-order (S1) and total-order (ST) sensitivity indices and their confidence intervals for each input parameter.</li> <li>Sensitivity Indices Chart: An embedded bar chart that visually compares the S1 and ST indices of each parameter, making it easy to quickly identify key influencing factors.</li> </ol>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#how-to-interpret-sobol-indices","title":"How to Interpret Sobol Indices","text":"<ul> <li>S1 (First-order index): The independent contribution of the parameter. A higher S1 value indicates that the parameter has a greater direct impact on the model output.</li> <li>ST (Total-order index): The total contribution of the parameter, including its independent effect and its interaction with all other parameters.</li> <li>Interaction: The difference <code>ST - S1</code> can be used to approximate the strength of the interaction effect of that parameter with others. If a parameter's <code>ST</code> is much larger than its <code>S1</code>, it means that much of its influence is realized through coupling and synergistic effects with other parameters.</li> </ul>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#4-full-example-configuration","title":"4. Full Example Configuration","text":"example/analysis/4_sobol_global_sensitivity_analysis/sobol_global_sensitivity_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"SALIB_SOBOL_Analysis\",                 \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\",\"plasma.fb\",\"tep_fep.to_SDS_Fraction[1]\",\"blanket.TBR\"],                 \"independent_variable_sampling\":{                       \"pulseSource.width\": {                           \"bounds\": [50,90],                           \"distribution\": \"unif\"                       },                       \"plasma.nf\": {                           \"bounds\": [0.1,0.9],                           \"distribution\": \"unif\"                       },                       \"plasma.fb\": {                           \"bounds\": [0.03,0.07],                           \"distribution\": \"unif\"                       },                       \"tep_fep.to_SDS_Fraction[1]\": {                           \"bounds\": [0.1,0.8],                           \"distribution\": \"unif\"                       },                       \"blanket.TBR\": {                           \"bounds\": [1.05, 1.25],                           \"distribution\": \"unif\"                       }                 },                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Self_Sufficiency_Time\",                     \"Doubling_Time\"                 ],                 \"analyzer\": {                     \"method\": \"sobol\",                     \"sample_N\": 256                 }             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#5-ai-enhanced-analysis","title":"5. AI-Enhanced Analysis","text":"<p>All analysis modules in <code>tricys</code> are deeply integrated with Large Language Models (LLMs), capable of automatically converting raw charts and data into structured, academic-style reports.</p>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#51-how-to-enable","title":"5.1. How to Enable","text":"<p>In your analysis case configuration (i.e., within any object in the <code>analysis_cases</code> list or in the <code>params</code> of a <code>post_processing</code> task), add <code>\"ai\": true</code> to activate the AI analysis feature for that case.</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#52-environment-setup","title":"5.2. Environment Setup","text":"<p>Before using this feature, you must create a file named <code>.env</code> in the project's root directory and fill in your Large Language Model API credentials. This ensures that your keys are kept secure and are not committed to version control.</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"en/guides/tricys_analysis/sobol_global_sensitivity_analysis.html#53-output-reports","title":"5.3. Output Reports","text":"<p>When enabled, in addition to the standard analysis report (<code>analysis_report_...md</code>), <code>tricys</code> will generate two additional reports in the case's <code>report</code> folder:</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: Appends an in-depth textual interpretation of the data and charts, generated by the AI, to the end of the core report.</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: A well-structured, academic-style report written entirely by the AI. This report typically includes sections such as Abstract, Introduction, Methods, Results and Discussion, and Conclusion, and can be used directly for presentations or as a draft for a paper.</li> </ul>"},{"location":"en/guides/tricys_basic/basic_configuration.html","title":"Basic Configuration","text":"<p>All simulation tasks in TRICYS are driven by a JSON configuration file. This file details every aspect of the process, including model paths, simulation parameters, variable sweeps, and post-processing.</p> <p>This section introduces the most basic configuration file for running a single simulation. Mastering the basic configuration is the first step to using TRICYS.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>A minimal configuration file is shown below. It defines which model to run and how to run it.</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    }\n}\n</code></pre> <p>This configuration will run a simulation of a tritium fuel cycle model for a duration of 2000 hours, outputting results every 0.5 hours, and saving only the time and the SDS system's tritium inventory variables.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#2-required-configuration-items","title":"2. Required Configuration Items","text":""},{"location":"en/guides/tricys_basic/basic_configuration.html#21-paths-path-configuration","title":"2.1. <code>paths</code> (Path Configuration)","text":"<p>This section is used to define all settings related to file paths.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#package_path-string-required","title":"<code>package_path</code> (string, required)","text":"<ul> <li>Description: Points to the root <code>package.mo</code> file of the Modelica model. TRICYS will load and parse your model from here.</li> <li>Path Type: Can be an absolute path or a relative path from the location of the JSON configuration file.</li> <li>Examples:   <pre><code>\"package_path\": \"C:/Models/example_model/package.mo\"  // Absolute path (Windows)\n\"package_path\": \"/home/user/models/package.mo\"         // Absolute path (Linux)\n\"package_path\": \"../models/package.mo\"                 // Relative path\n</code></pre></li> </ul> <p>Path Separators</p> <p>In JSON files, Windows paths can use either forward slashes <code>/</code> or double backslashes <code>\\</code>: <pre><code>\"package_path\": \"C:/Models/package.mo\"      // Recommended\n\"package_path\": \"C:\\\\Models\\\\package.mo\"    // Also works\n</code></pre></p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#22-simulation-simulation-configuration","title":"2.2. <code>simulation</code> (Simulation Configuration)","text":"<p>This section contains the core parameters required to run the simulation.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#model_name-string-required","title":"<code>model_name</code> (string, required)","text":"<ul> <li>Description: The full name of the Modelica model to be simulated. It follows the <code>PackageName.ModelName</code> format.</li> <li>Format: <code>&lt;PackageName&gt;.&lt;ModelName&gt;</code></li> <li>Example:   <pre><code>\"model_name\": \"example_model.Cycle\"\n</code></pre>   In this example, <code>example_model</code> is the package name (corresponding to <code>package.mo</code>), and <code>Cycle</code> is the specific model defined within it.</li> </ul> <p>Model Name Must Match Exactly</p> <p>The model name is case-sensitive and must exactly match the name defined in the Modelica file.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#variablefilter-string-required","title":"<code>variableFilter</code> (string, required)","text":"<ul> <li>Description: A regular expression used to filter the output results. Only variables whose names match this expression will be saved to the final <code>.csv</code> result file.</li> <li>Format: Use a vertical bar <code>|</code> to separate multiple variable names or patterns.</li> <li>Examples:   <pre><code>// Save only time and one variable\n\"variableFilter\": \"time|sds.I[1]\"\n\n// Save time and an array variable\n\"variableFilter\": \"time|sds.I[1-5]\"\n\n// Save multiple specific variables\n\"variableFilter\": \"time|sds.I[1]|blanket.I[1-5]|div.I[1-5]\"\n</code></pre></li> </ul> <p>Recommendation</p> <p>To reduce output file size and improve performance, it is recommended to save only the variables you actually need to analyze.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#stop_time-float-required","title":"<code>stop_time</code> (float, required)","text":"<ul> <li>Description: The total duration of the simulation. The simulation will run from time <code>0</code> to <code>stop_time</code>.</li> <li>Unit: hours</li> </ul>"},{"location":"en/guides/tricys_basic/basic_configuration.html#step_size-float-required","title":"<code>step_size</code> (float, required)","text":"<ul> <li>Description: The time step of the simulation. This is also the interval at which results are output.</li> <li>Trade-off: </li> <li>Smaller step size: higher accuracy, but longer simulation time and larger output files.</li> <li>Larger step size: faster, but may miss fast-changing details.</li> </ul>"},{"location":"en/guides/tricys_basic/basic_configuration.html#3-default-configuration-items","title":"3. Default Configuration Items","text":"<p>In addition to the required items above, TRICYS provides a series of optional configurations with reasonable default values. If these options are not set, the system will automatically use the following default behaviors:</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#31-paths-path-configuration","title":"3.1. <code>paths</code> (Path Configuration)","text":"Parameter Description Default Value <code>results_dir</code> Directory name for storing simulation results. <code>\"results\"</code> <code>temp_dir</code> Directory name for storing temporary files. <code>\"temp\"</code> <code>log_dir</code> Directory name for storing log files. <code>\"log\"</code> <code>db_path</code> Path to the SQLite database file for storing and reading model parameters. Dynamically created in the temporary directory at each run. <p>Output Directory Structure</p> <p>TRICYS will create a main run directory named with a timestamp in the current working directory (e.g., <code>20250116_103000/</code>). All the above output directories (<code>results</code>, <code>temp</code>, <code>log</code>) will be created inside this timestamped directory by default, ensuring that the outputs of each run are isolated from one another.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#32-simulation-simulation-configuration","title":"3.2. <code>simulation</code> (Simulation Configuration)","text":"Parameter Description Default Value <code>concurrent</code> Whether to enable concurrent (parallel) simulation, used to speed up parameter sweep tasks. <code>false</code> <code>max_workers</code> If concurrency is enabled, this option specifies the maximum number of parallel worker processes. Half the number of system CPU cores <code>keep_temp_files</code> Whether to keep temporary files (like model compilation files) after the simulation is finished. Very useful for debugging. <code>true</code>"},{"location":"en/guides/tricys_basic/basic_configuration.html#33-logging-logging-configuration","title":"3.3. <code>logging</code> (Logging Configuration)","text":"Parameter Description Default Value <code>log_level</code> The minimum level for logging. Options include \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\". <code>\"INFO\"</code> <code>log_to_console</code> Whether to output logs to the console in real-time. <code>true</code> <code>log_count</code> The maximum number of old log files to keep in the log directory. <code>5</code>"},{"location":"en/guides/tricys_basic/basic_configuration.html#4-configuration-templates","title":"4. Configuration Templates","text":"<p>Here are some configuration templates for common scenarios that you can copy and use directly:</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#41-quick-test-template","title":"4.1 Quick Test Template","text":"<p>This template is suitable for quickly verifying if a model can run correctly. It saves all variables and runs for a short duration.</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"path/to/your/package.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"YourModel.Name\",\n        \"variableFilter\": \"time|.*\",\n        \"stop_time\": 100.0,\n        \"step_size\": 1.0\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/basic_configuration.html#42-production-environment-template","title":"4.2 Production Environment Template","text":"<p>This template is suitable for formal, long-duration simulations. It saves only key variables, outputs results to a specified production directory, and configures stricter logging and debugging options.</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"path/to/your/package.mo\",\n        \"results_dir\": \"production_results\"\n    },\n    \"simulation\": {\n        \"model_name\": \"YourModel.Name\",\n        \"variableFilter\": \"time|key_var1|key_var2\",\n        \"stop_time\": 86400.0,\n        \"step_size\": 10.0,\n        \"keep_temp_files\": false\n    },\n    \"logging\": {\n        \"log_level\": \"INFO\",\n        \"log_to_console\": false,\n        \"log_count\": 10\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/basic_configuration.html#5-how-to-run","title":"5. How to Run","text":"<p>After configuring the file, there are two ways to run the simulation:</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#51-using-the-default-configuration-file","title":"5.1. Using the Default Configuration File","text":"<p>Save the configuration file as <code>config.json</code> and place it in the project root directory:</p> <pre><code>tricys\n</code></pre>"},{"location":"en/guides/tricys_basic/basic_configuration.html#52-specifying-a-configuration-file","title":"5.2. Specifying a Configuration File","text":"<pre><code>tricys -c my_config.json\n</code></pre>"},{"location":"en/guides/tricys_basic/basic_configuration.html#6-viewing-results","title":"6. Viewing Results","text":"<p>After the simulation is complete, the results are saved in a timestamped subdirectory:</p> <pre><code>Working Directory/\n\u2514\u2500\u2500 {timestamp}/\n    \u251c\u2500\u2500 log/        \n        \u2514\u2500\u2500 simulation_{timestamp}.log  // Run log\n    \u251c\u2500\u2500 result/                 \n        \u2514\u2500\u2500 simulation_result.csv       // Simulation result data\n    \u2514\u2500\u2500 temp/\n        \u2514\u2500\u2500 job_1/                      // Temporary job data\n</code></pre>"},{"location":"en/guides/tricys_basic/basic_configuration.html#61-analyzing-results-with-python","title":"6.1. Analyzing Results with Python","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the results\ndf = pd.read_csv('results/20250116_103000/simulation_result.csv')\n\n# View the data\nprint(df.head())\nprint(f\"Simulation duration: {df['time'].max()} seconds\")\nprint(f\"Final tritium inventory: {df['sds.I[1]'].iloc[-1]:.2f} g\")\n\n# Plot the tritium inventory change curve\nplt.figure(figsize=(10, 6))\nplt.plot(df['time'], df['sds.I[1]'], label='SDS Tritium Inventory')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Tritium Inventory (g)')\nplt.title('SDS Tritium Inventory Over Time')\nplt.legend()\nplt.grid(True)\nplt.savefig('inventory_plot.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"en/guides/tricys_basic/basic_configuration.html#62-viewing-with-excel","title":"6.2. Viewing with Excel","text":"<p>Directly open the <code>simulation_result.csv</code> file with Microsoft Excel or LibreOffice Calc.</p>"},{"location":"en/guides/tricys_basic/basic_configuration.html#7-next-steps","title":"7. Next Steps","text":"<p>After mastering the basic configuration, you can proceed to learn about:</p> <ul> <li>Parameter Sweep: Systematically study the impact of parameters on the results.</li> <li>Concurrent Operation: Speed up large-scale simulations.</li> <li>Post-Processing Module: Automate analysis and report generation.</li> <li>Co-Simulation: Integrate with external software.</li> </ul>"},{"location":"en/guides/tricys_basic/co_simulation_module.html","title":"Co-Simulation Module","text":"<p>Co-Simulation is an advanced and powerful feature in <code>tricys</code> that allows Modelica models to interact with external programs (like Aspen Plus, MATLAB, or custom Python scripts), enabling the integration of 0D system models with 3D sub-module multi-physics models.</p> <p>This is particularly useful for the following scenarios:</p> <ul> <li>A model for a subsystem already exists and is well-established in another specialized software.</li> <li>The behavior of a subsystem is too complex to be described directly in the Modelica language but can be calculated externally.</li> </ul>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#1-workflow","title":"1. Workflow","text":"<p>The core idea of co-simulation is \"Run-Process-Rerun\".</p> <pre><code>graph LR\n    A[1. Primary Run] --&gt; B[(Results)];\n    B --&gt; C[2. External Handler];\n    C --&gt; D[(New Data)];\n    D --&gt; E[3. Inject New Data];\n    E --&gt; F[4. Final Full Simulation];\n\n    style A fill:#A6C8FF\n    style C fill:#FFDDA6\n    style F fill:#A6FFC8</code></pre> <ol> <li>Primary Run: <code>tricys</code> first runs a preliminary simulation without the substituted subsystem.</li> <li>Call Handlers: The results of the primary run are passed to one or more user-defined \"handlers\".</li> <li>External Computation: The handler function receives the results and calls an external program (like Aspen) or executes an internal algorithm to compute new data.</li> <li>Data Injection: The handler returns a data dictionary. <code>tricys</code> dynamically creates a new top-level model, replacing the original subsystem with a <code>CombiTimeTable</code> (data table) module, and uses the data returned by the handler as the content for this table.</li> <li>Final Run: <code>tricys</code> runs this dynamically modified new model, which contains the injected data, to complete a full co-simulation.</li> </ol>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#2-configuration-file-example","title":"2. Configuration File Example","text":"<p>Enable this feature by defining the <code>co_simulation</code> field in <code>config.json</code>.</p> <pre><code>{\n    \"paths\": { ... },\n    \"simulation\": { ... },\n    \"simulation_parameters\": { ... },\n    \"co_simulation\": {\n        \"mode\": \"replacement\",\n        \"handlers\":[\n            {\n                \"submodel_name\": \"example_model.I_ISS\",\n                \"instance_name\": \"i_iss\",\n                \"handler_module\": \"tricys.handlers.i_iss_handler\",\n                \"handler_function\": \"run_dummy_simulation\",\n                \"params\": {\n                    \"description\": \"This is a dummy handler for i_iss.\",\n                    \"dummy_value\": 123.45\n                }\n            },\n            {\n                \"submodel_name\": \"example_model.DIV\",\n                \"instance_name\": \"div\",\n                \"handler_module\": \"tricys.handlers.div_handler\",\n                \"handler_function\": \"run_div_simulation\",\n                \"params\": {\n                    \"description\": \"This is a dummy handler for i_iss.\",\n                    \"dummy_value\": 123.45\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#3-configuration-details","title":"3. Configuration Details","text":""},{"location":"en/guides/tricys_basic/co_simulation_module.html#31-co_simulation-top-level-object","title":"3.1. <code>co_simulation</code> (Top-level Object)","text":"Parameter Type &amp; Requirement Description <code>mode</code> string, optional Defines the integration mode for co-simulation. Defaults to <code>\"interceptor\"</code>. <code>handlers</code> list, required A list of one or more \"handler configuration objects\", each defining how to process a specific submodel."},{"location":"en/guides/tricys_basic/co_simulation_module.html#32-mode-integration-mode","title":"3.2. <code>mode</code> (Integration Mode)","text":"<p>The <code>mode</code> field determines how <code>tricys</code> integrates the external computation results back into the Modelica model.</p> <ul> <li> <p><code>\"interceptor\"</code> (default mode):</p> <ul> <li>Non-invasive. It generates a \"wrapper\" interceptor model for the target submodel and redirects connections in a new top-level system model.</li> <li>Advantages: The original model files (both submodel and top-level model) remain unchanged, ensuring high safety.</li> <li>Use Case: Recommended for most situations, especially when you do not want to modify the original model library.</li> </ul> </li> <li> <p><code>\"replacement\"</code>:</p> <ul> <li>Invasive. It directly modifies the target submodel's <code>.mo</code> file (a <code>.bak</code> backup is created), completely replacing its internal logic with logic to read data from a CSV file.</li> <li>Advantages: More direct implementation, no need to generate a new top-level model.</li> <li>Use Case: When you want a permanent or semi-permanent replacement of a submodel's behavior, or in complex model structures where the \"interceptor\" mode has difficulty redirecting connections.</li> </ul> </li> </ul>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#33-handlers-configuration-object-list","title":"3.3. <code>handlers</code> (Configuration Object List)","text":"<p>Each object in the <code>handlers</code> list defines a specific replacement task.</p> Parameter Type &amp; Requirement Description <code>submodel_name</code> string, required The full Modelica class path of the submodel to be replaced by an external handler. E.g., <code>example_model.DIV</code>. <code>instance_name</code> string, required The instance name of this submodel in the top-level simulation model (<code>simulation.model_name</code>). E.g., if the top-level model has <code>DIV div;</code>, then the <code>instance_name</code> here is <code>div</code>. <code>handler_script_path</code> string, recommended The relative or absolute path to the Python script file containing the handler logic. This is the preferred method for specifying a handler. <code>handler_module</code> string, compatible The path to the Python module containing the handler logic (e.g., <code>tricys.handlers.div_handler</code>). Used for backward compatibility. If <code>handler_script_path</code> is also provided, the script path takes precedence. <code>handler_function</code> string, required The name of the handler function to be called within the script or module. <code>params</code> dictionary, optional A dictionary containing key-value pairs that will be passed as keyword arguments to the handler function."},{"location":"en/guides/tricys_basic/co_simulation_module.html#4-result-output","title":"4. Result Output","text":"<p>The final output of a co-simulation is similar to a standard simulation, generating a combined CSV file in the results directory (<code>results_dir</code>) based on the number of tasks:</p> <ul> <li>Single Run: <code>simulation_result.csv</code></li> <li>Parameter Sweep: <code>sweep_results.csv</code></li> </ul> <p>In this file, the variable columns corresponding to the externally simulated submodel will be populated with data generated by your Python handlers, not from the original Modelica model's calculations.</p>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#5-custom-handlers","title":"5. Custom Handlers","text":"<p>To truly leverage the power of co-simulation, you need to create your own handler functions.</p>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#51-handler-function-specification","title":"5.1. Handler Function Specification","text":"<p>Your handler must adhere to the following specifications:</p> <ol> <li> <p>Function Signature:     <pre><code>def my_handler(temp_input_csv: str, temp_output_csv: str, **params) -&gt; dict:\n    # ... function body ...\n</code></pre></p> <ul> <li><code>temp_input_csv</code>: The input file path passed by <code>tricys</code>. This CSV file contains all the input port data for the submodel, recorded during the first simulation stage.</li> <li><code>temp_output_csv</code>: The output file path where you need to write your calculation results.</li> <li><code>**params</code>: A dictionary containing all the <code>params</code> you configured for this handler in <code>config.json</code>.</li> </ul> </li> <li> <p>Core Logic:</p> <ul> <li>Read data from <code>temp_input_csv</code> using <code>pandas</code> or another library.</li> <li>Execute your core computation logic.</li> <li>Save the results (which must include a 'time' column) to the path specified by <code>temp_output_csv</code>.</li> </ul> </li> <li> <p>Return Value (Important):</p> <ul> <li>The function must return a dictionary that describes how to map the data columns in your output CSV file to the output ports of the Modelica submodel.</li> <li>Key: The name of the Modelica submodel's output port (string).</li> <li>Value: A string representing a Modelica array, in the format <code>\"{t, y1, y2, ...}\"</code>. Here, <code>t</code> is the index of the <code>time</code> column (usually 1), and <code>y1</code>, <code>y2</code>... are the indices of the data columns for each dimension of the port.</li> </ul> </li> </ol>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#52-handler-example","title":"5.2. Handler Example","text":"<p>Suppose we want to replace a Modelica submodel <code>MySubModel</code> that has a 5-dimensional output port <code>to_O_ISS</code>.</p> <p><code>my_div_handler.py</code>: <pre><code>import pandas as pd\n\ndef run_div_simulation(temp_input_csv: str, temp_output_csv: str, **params) -&gt; dict:\n    \"\"\"\n    A simple handler example.\n    It reads the input, multiplies all input values by a factor from the configuration, and writes them back.\n    \"\"\"\n    # Print the parameters passed from config.json\n    factor = params.get(\"factor\", 1.0)\n    print(f\"Running DIV handler with factor: {factor}\")\n\n    # 1. Read input data\n    input_df = pd.read_csv(temp_input_csv)\n\n    # 2. Perform calculation (Example: multiply all inputs by a factor)\n    # Assume input port names are 'div.from_plasma[1]' to '[5]'\n    output_df = pd.DataFrame()\n    output_df['time'] = input_df['time']\n    for i in range(1, 6):\n        input_col_name = f'div.from_plasma[{i}]'\n        output_col_name = f'to_O_ISS_{i}' # Custom column name in the CSV\n        if input_col_name in input_df.columns:\n            output_df[output_col_name] = input_df[input_col_name] * factor\n        else:\n            output_df[output_col_name] = 0 # Output 0 if input does not exist\n\n    # 3. Write the results to the specified output CSV file\n    output_df.to_csv(temp_output_csv, index=False)\n\n    # 4. Return the mapping from port to CSV columns\n    # The CSV has 6 columns: time, to_O_ISS_1, ..., to_O_ISS_5\n    # The Modelica port to_O_ISS is 5-dimensional\n    # Mapping:\n    # time -&gt; column 1\n    # to_O_ISS[1] -&gt; column 2 (to_O_ISS_1)\n    # to_O_ISS[2] -&gt; column 3 (to_O_ISS_2)\n    # ...\n    # to_O_ISS[5] -&gt; column 6 (to_O_ISS_5)\n    return {\n        \"to_O_ISS\": \"{1,2,3,4,5,6}\"\n    }\n</code></pre></p>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#53-updating-the-configuration-file","title":"5.3. Updating the Configuration File","text":"<p>Now, you can update your <code>config.json</code> to use this new local handler script. We recommend using <code>handler_script_path</code> as it is more direct than <code>handler_module</code>.</p> <p>You can also explicitly specify the co-simulation <code>mode</code>.</p> <pre><code>{\n    ...\n    \"co_simulation\": {\n        \"mode\": \"interceptor\", // \"interceptor\" (default) or \"replacement\"\n        \"handlers\": [\n            {\n                \"submodel_name\": \"example_model.DIV\",\n                \"instance_name\": \"div\",\n                \"handler_script_path\": \"path/to/my_div_handler.py\", // Use script path\n                \"handler_function\": \"run_div_simulation\",\n                \"params\": {\n                    \"factor\": 1.5 // Custom parameter passed to the function\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/co_simulation_module.html#6-advanced-how-it-works","title":"6. Advanced: How It Works","text":"<ul> <li>Co-Simulation Explanation: Learn about the two methods for injecting external data into a Modelica model during co-simulation.</li> </ul>"},{"location":"en/guides/tricys_basic/concurrent_operation.html","title":"Concurrent Operation","text":"<p>For parameter sweeps involving a large number of simulation tasks, executing them sequentially can be very time-consuming. <code>tricys</code> supports concurrent operation (parallel computing) to fully utilize your computer's multiple CPU cores, significantly reducing the total simulation time.</p>"},{"location":"en/guides/tricys_basic/concurrent_operation.html#1-how-to-enable-concurrency","title":"1. How to Enable Concurrency","text":"<p>Enabling concurrency is very simple. Just set the <code>concurrent</code> flag to <code>true</code> in the <code>simulation</code> section of your configuration file.</p> <pre><code>{\n    \"paths\": {\n        ...\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        ...\n        \"concurrent\": true,\n        \"max_workers\": 4\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/concurrent_operation.html#2-configuration-details","title":"2. Configuration Details","text":""},{"location":"en/guides/tricys_basic/concurrent_operation.html#21-simulationconcurrent","title":"2.1. <code>simulation.concurrent</code>","text":"<ul> <li>Description: Whether to enable concurrent operation.</li> <li>Type: Boolean (<code>true</code> or <code>false</code>).</li> <li>Default: <code>false</code>.</li> <li>How it works: When set to <code>true</code>, <code>tricys</code> will start a process pool and distribute the simulation tasks (e.g., each run in a parameter sweep) to different processes for parallel execution.</li> </ul>"},{"location":"en/guides/tricys_basic/concurrent_operation.html#22-simulationmax_workers","title":"2.2. <code>simulation.max_workers</code>","text":"<ul> <li>Description: Controls the maximum number of processes (or \"workers\") used for concurrent execution.</li> <li>Type: Integer (optional).</li> <li>Default: If this parameter is not specified, <code>tricys</code> will default to using all available CPU cores on your machine.</li> <li>Recommendations:<ul> <li>For compute-intensive tasks, it is recommended to set this value to no more than the number of physical cores on your machine for optimal performance.</li> <li>If you encounter memory shortage issues during the simulation, you can try lowering the value of <code>max_workers</code>, as each process loads the model independently and consumes a certain amount of memory.</li> </ul> </li> </ul> <p>In the example above, <code>\"concurrent\": true</code> and <code>\"max_workers\": 4</code> mean that <code>tricys</code> will create a process pool with 4 worker processes to handle the 10 simulation tasks generated by the parameter sweep in parallel.</p> <p>Applicable Scenarios</p> <p>Concurrent operation is not only applicable to standard parameter sweeps but also to Co-Simulation and Automated Analysis workflows, comprehensively improving the execution efficiency of <code>tricys</code>.</p>"},{"location":"en/guides/tricys_basic/parameter_sweep.html","title":"Parameter Sweep","text":"<p>Parameter sweep is one of the core features of <code>tricys</code>, allowing you to systematically study the effect of changes in one or more model parameters on the simulation results. You simply provide a set of values for each parameter of interest, and <code>tricys</code> will automatically create and run all possible combinations.</p>"},{"location":"en/guides/tricys_basic/parameter_sweep.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>On top of the basic configuration, we just need to add a <code>simulation_parameters</code> field to define the parameter sweep.</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    },\n    \"simulation_parameters\": {\n        \"tep_fep.to_SDS_Fraction[1]\": [0.1, 0.15, 0.2, 0.3, 0.4, 0.6, 0.8],\n        \"blanket.TBR\": \"linspace:1.05:1.15:3\"\n    }\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/parameter_sweep.html#2-configuration-details","title":"2. Configuration Details","text":"<ul> <li>Description: The <code>simulation_parameters</code> item is a dictionary (a collection of key-value pairs) used to define the parameters to be swept and their corresponding values.</li> <li>Key: Must be the full path of a variable in the Modelica model. For example, <code>blanket.TBR</code> or <code>tep_fep.to_SDS_Fraction[1]</code>.</li> <li> <p>Value: Can be in one of the following formats:</p> <ol> <li> <p>List of Discrete Values:</p> <ul> <li>Format: <code>[v1, v2, v3, ...]</code></li> <li>Example: <code>[0.1, 0.15, 0.2]</code></li> <li>Description: The program will run a simulation for each value in the list.</li> </ul> </li> <li> <p>Advanced Sweep Format (String):</p> <ul> <li>Description: <code>tricys</code> supports several compact string formats for generating numerical sequences, which are very suitable for defining linear, logarithmic, and other series.</li> <li>Example: <code>\"linspace:1.05:1.15:3\"</code> means generate 3 equally spaced numbers between 1.05 and 1.15.</li> <li>Supported Formats:</li> </ul> </li> </ol> </li> </ul> Format Syntax Description Range <code>\"start:stop:step\"</code> Generates an arithmetic sequence from <code>start</code> to <code>stop</code> with a step of <code>step</code>. E.g., <code>\"1:5:2\"</code> generates <code>[1, 3, 5]</code>. Linspace <code>\"linspace:start:stop:num\"</code> Generates <code>num</code> equally spaced values between <code>start</code> and <code>stop</code>. E.g., <code>\"linspace:0:10:3\"</code> generates <code>[0, 5, 10]</code>. Logspace <code>\"log:start:stop:num\"</code> Generates <code>num</code> logarithmically spaced values between <code>start</code> and <code>stop</code>, suitable for sweeps across orders of magnitude. E.g., <code>\"log:1:100:3\"</code> generates <code>[1, 10, 100]</code>. Random <code>\"rand:min:max:count\"</code> Generates <code>count</code> uniformly distributed random numbers between <code>min</code> and <code>max</code>. E.g., <code>\"rand:0:1:2\"</code> might generate <code>[0.23, 0.87]</code>. From File <code>\"file:path/to/data.csv:column_name\"</code> Reads numerical values from the <code>column_name</code> column of the specified CSV file to use as the sweep list. Array Expansion <code>\"{val1, val2, ...}\"</code> A special format for setting multiple elements of a Modelica array at once. For example, setting the value <code>\"{10, 25, 50}\"</code> for a parameter <code>my_array</code> will be automatically expanded to <code>my_array[1]=10</code>, <code>my_array[2]=25</code>, <code>my_array[3]=50</code>. The values inside the curly braces can themselves be strings in other advanced formats. <p>Multi-Parameter Sweep</p> <ul> <li>You can define multiple parameters to sweep simultaneously. <code>tricys</code> will calculate the Cartesian product of all parameter values to generate a list of simulation tasks covering all possible combinations.</li> <li>In the example above, <code>tep_fep.to_SDS_Fraction[1]</code> has 7 values, and <code>blanket.TBR</code> has 3 values, so the program will run a total of <code>7 * 3 = 21</code> simulations.</li> </ul>"},{"location":"en/guides/tricys_basic/parameter_sweep.html#3-result-output","title":"3. Result Output","text":"<p>For a parameter sweep task, in addition to the <code>simulation_result.csv</code> file for each individual run, <code>tricys</code> will also generate a summary file <code>sweep_results.csv</code>, as shown below:</p> <pre><code>Working Directory/\n\u2514\u2500\u2500 {timestamp}/\n    \u251c\u2500\u2500 log/        \n        \u2514\u2500\u2500 simulation_{timestamp}.log      # Run log\n    \u251c\u2500\u2500 result/                 \n        \u2514\u2500\u2500 sweep_results.csv               # Aggregated simulation result data\n    \u2514\u2500\u2500 temp/\n        \u251c\u2500\u2500 job_1/                      \n            \u2514\u2500\u2500 job_1_simulation_result.csv # Simulation result for task 1\n        \u251c\u2500\u2500 job_2/                      \n            \u2514\u2500\u2500 job_2_simulation_result.csv # Simulation result for task 2\n        \u2514\u2500\u2500 ......\n</code></pre> <ul> <li><code>sweep_results.csv</code>:</li> <li>First column: <code>time</code>, representing the time axis.</li> <li>Other columns: Each column represents the simulation result for a specific parameter combination. The column headers clearly indicate the parameters and their values used for that run, for example, <code>sds.I[1]&amp;tep_fep.to_SDS_Fraction[1]=0.1&amp;blanket.TBR=1.05</code>, making it easy to compare results from different conditions directly in the CSV file.</li> </ul>"},{"location":"en/guides/tricys_basic/parameter_sweep.html#4-next-steps","title":"4. Next Steps","text":"<p>After mastering parameter sweeps, you can explore more advanced features to improve efficiency and analysis depth:</p> <ul> <li>Concurrent Operation: Learn how to use multi-core processors to execute a large number of sweep tasks in parallel, significantly reducing simulation time.</li> <li>Post-Processing Module: Learn how to automatically analyze sweep results, such as calculating the maximum value, average value, or number of alarms for each condition.</li> <li>Sensitivity Analysis: Conduct more systematic studies of parameter impacts, such as Sobol global sensitivity analysis.</li> </ul>"},{"location":"en/guides/tricys_basic/post_processing_module.html","title":"Post-Processing Module","text":"<p><code>tricys</code> not only runs simulations but also provides a powerful Post-Processing framework that allows you to automatically analyze results, generate reports, or perform other custom operations after the simulation tasks are complete.</p> <p>The post-processing feature is enabled by adding a <code>post_processing</code> field to the configuration file.</p>"},{"location":"en/guides/tricys_basic/post_processing_module.html#1-configuration-file-example","title":"1. Configuration File Example","text":"<p>The following example shows how to automatically execute two analysis tasks after a parameter sweep is completed: one using a built-in <code>module</code> and the other using a user-defined <code>script_path</code>.</p> <pre><code>{\n    \"paths\": {\n        ...\n    },\n    \"simulation\": {\n        ...\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    },\n    \"post_processing\": [\n        {\n            \"module\": \"tricys.postprocess.static_alarm\",\n            \"function\": \"check_thresholds\",\n            \"params\": {\n                \"rules\": [{\"columns\": [\"sds.I[1]\"], \"min\": 0.0}]\n            }\n        },\n        {\n            \"script_path\": \"scripts/my_custom_analyzer.py\",\n            \"function\": \"analyze_peak_value\",\n            \"params\": {\n                \"target_column_pattern\": \"sds.I[1]*\",\n                \"report_filename\": \"peak_values.json\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"en/guides/tricys_basic/post_processing_module.html#2-configuration-details","title":"2. Configuration Details","text":""},{"location":"en/guides/tricys_basic/post_processing_module.html#21-post_processing","title":"2.1. <code>post_processing</code>","text":"<ul> <li>Description: This is a list (Array) where each element represents an independent post-processing step. These steps will be executed sequentially in the order they appear in the list.</li> <li>Execution Timing: After all simulation tasks (e.g., every run in a parameter sweep) are completed, <code>tricys</code> will load the aggregated results (<code>sweep_results.csv</code>) into a Pandas DataFrame and pass it to your specified post-processing functions.</li> </ul>"},{"location":"en/guides/tricys_basic/post_processing_module.html#22-post-processing-function","title":"2.2. Post-Processing Function","text":"<p>Each object in the list defines a Python function to be executed. You can specify the code to be called in one of two ways:</p>"},{"location":"en/guides/tricys_basic/post_processing_module.html#method-1-module-module-loading","title":"Method 1: <code>module</code> (Module Loading)","text":"<ul> <li><code>module</code> (string, required):</li> <li>Description: The full path of the module where the Python function to be called is located. This requires your code to be a Python package or module that can be loaded with an <code>import</code> statement (e.g., installed or located in a directory with an <code>__init__.py</code> file).</li> <li>Example: <code>tricys.postprocess.static_alarm</code></li> </ul>"},{"location":"en/guides/tricys_basic/post_processing_module.html#method-2-script_path-script-path-loading","title":"Method 2: <code>script_path</code> (Script Path Loading)","text":"<ul> <li><code>script_path</code> (string, required):</li> <li>Description: The path to a single Python script file containing the function to be called. This is more flexible and does not require your script to be part of a formal package.</li> <li>Example: <code>scripts/my_custom_analyzer.py</code></li> </ul> <p>Regardless of which method you use, you need to provide the following fields:</p> <ul> <li><code>function</code> (string, required):</li> <li>Description: The name of the function to be called in the specified module or script.</li> <li> <p>Example: <code>check_thresholds</code></p> </li> <li> <p><code>params</code> (dictionary, optional):</p> </li> <li>Description: A dictionary containing keyword arguments to be passed to the target function.</li> <li>Example: In the example above, <code>params</code> provides the <code>rules</code> argument to the <code>check_thresholds</code> function.</li> </ul>"},{"location":"en/guides/tricys_basic/post_processing_module.html#3-built-in-post-processing-modules","title":"3. Built-in Post-Processing Modules","text":"<p><code>tricys</code> comes with several common post-processing modules, located in the <code>tricys/postprocess</code> directory:</p> <ul> <li><code>rise_analysis</code>: For analyzing dynamic characteristics of signals, such as rise time, fall time, and peak values.</li> <li><code>static_alarm</code>: For checking if results exceed preset static thresholds (upper or lower limits).</li> <li><code>baseline_analysis</code>: For performing baseline condition analysis.</li> </ul>"},{"location":"en/guides/tricys_basic/post_processing_module.html#4-custom-post-processing-modules","title":"4. Custom Post-Processing Modules","text":"<p>The greatest advantage of the post-processing framework is its extensibility. You can easily write your own Python scripts to perform any analysis you want.</p>"},{"location":"en/guides/tricys_basic/post_processing_module.html#41-function-signature","title":"4.1. Function Signature","text":"<p>To be called correctly by the <code>tricys</code> framework, your custom post-processing function must follow a specific signature. The framework automatically passes two core pieces of data via keyword arguments:</p> <ol> <li><code>results_df</code> (pd.DataFrame): A Pandas DataFrame containing the aggregated results of all simulation runs.</li> <li><code>output_dir</code> (str): A dedicated output directory path for you to save reports, charts, and other analysis artifacts.</li> </ol> <p>Therefore, your function signature must be able to accept these two arguments, as well as any other custom arguments you define in <code>params</code>.</p> <p>A standard function signature is as follows:</p> <pre><code>import pandas as pd\n\ndef my_custom_function(results_df: pd.DataFrame, output_dir: str, **kwargs):\n    \"\"\"\n    A generic post-processing function signature.\n\n    - results_df: The simulation results passed in by tricys.\n    - output_dir: The directory provided by tricys for saving reports.\n    - **kwargs: Used to receive all custom parameters from \"params\" in the JSON configuration.\n    \"\"\"\n    # Get custom parameters from kwargs\n    my_param = kwargs.get(\"my_param\", \"default_value\")\n\n    # Write your analysis code here...\n    print(f\"Analysis report will be saved in: {output_dir}\")\n    print(f\"Received custom parameter my_param with value: {my_param}\")\n    print(\"Preview of result data:\")\n    print(results_df.head())\n</code></pre>"},{"location":"en/guides/tricys_basic/post_processing_module.html#42-complete-example","title":"4.2. Complete Example","text":"<p>Let's create a complete custom post-processing script and show how to call it from the configuration using <code>script_path</code>.</p> <p>Step 1: Create the analysis script</p> <p>Suppose we create a file named <code>scripts/my_custom_analyzer.py</code> in our project:</p> <pre><code># scripts/my_custom_analyzer.py\nimport pandas as pd\nimport os\nimport json\n\ndef analyze_peak_value(results_df: pd.DataFrame, output_dir: str, target_column_pattern: str, report_filename: str = \"peak_report.json\"):\n    \"\"\"\n    Finds the peak value in all matching columns and generates a report.\n    \"\"\"\n    # Filter for columns that match the pattern\n    target_columns = [col for col in results_df.columns if target_column_pattern in col]\n\n    if not target_columns:\n        print(f\"Warning: No columns found matching '{target_column_pattern}'.\")\n        return\n\n    # Calculate the peak value for each column\n    peak_values = results_df[target_columns].max().to_dict()\n\n    # Define the report output path\n    report_path = os.path.join(output_dir, report_filename)\n\n    # Save the report\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(peak_values, f, indent=4)\n\n    print(f\"Peak value analysis report saved to: {report_path}\")\n</code></pre> <p>Step 2: Update the configuration file</p> <p>Now, configure the <code>post_processing</code> section in your <code>config.json</code> to call this script:</p> <pre><code>{\n    ...\n    \"post_processing\": [\n        {\n            \"script_path\": \"scripts/my_custom_analyzer.py\",\n            \"function\": \"analyze_peak_value\",\n            \"params\": {\n                \"target_column_pattern\": \"sds.I[1]\",\n                \"report_filename\": \"sds_peak_values.json\"\n            }\n        }\n    ]\n}\n</code></pre> <p>When <code>tricys</code> finishes all simulations, it will automatically execute the <code>analyze_peak_value</code> function, calculate the peak values for all columns containing <code>sds.I[1]</code> in the simulation results, and finally save the results to the <code>post_processing/sds_peak_values.json</code> file.</p> <p>In this way, you can seamlessly integrate any complex data analysis process into the automated workflow of <code>tricys</code>.</p>"},{"location":"en/guides/tricys_basic/post_processing_module.html#5-next-steps","title":"5. Next Steps","text":"<p>After mastering how to create and use post-processing modules, you can apply them to more complex scenarios:</p> <ul> <li>Sensitivity Analysis: Write dedicated post-processing scripts for complex sensitivity analysis results to extract key metrics and generate visualizations.</li> <li>Co-Simulation: Integrate and analyze the results of co-simulations that include external modules.</li> </ul>"},{"location":"en/questions/advanced_features.html","title":"\ud83d\udd2c Advanced Features","text":"Q: What is co-simulation and how to use it? <p>Co-simulation allows TRICYS to interact with external software (like Aspen Plus):</p> <p>Workflow: 1. Run preliminary simulation 2. Call external processor (Handler) 3. External software calculates new data 4. Inject data back into the Modelica model 5. Run the final full simulation</p> <p>Configuration Example: <pre><code>{\n    \"co_simulation\": [\n        {\n            \"mode\": \"interceptor\",\n            \"submodel_name\": \"example_model.I_ISS\",\n            \"instance_name\": \"i_iss\",\n            \"handler_module\": \"tricys.handlers.i_iss_handler\",\n            \"handler_function\": \"run_aspen_simulation\",\n            \"params\": {\n                \"bkp_path\": \"path/to/aspen/file.bkp\"\n            }\n        }\n    ]\n}\n</code></pre> *   <code>mode</code>: <code>interceptor</code> (default) or <code>replacement</code>. *   <code>handler_module</code>: The module where the handler is located. *   <code>handler_script_path</code>: Alternatively, provide the direct path to the handler script.</p> <p>For details, see: Co-simulation Module</p> Q: How to create a custom post-processing module? <p>Post-processing modules are Python functions that receive simulation results and perform analysis:</p> <p>1. Create the handler function: <pre><code># my_postprocess.py\ndef analyze_results(df, output_filename=\"my_report.txt\"):\n    \"\"\"\n    Custom post-processing function\n\n    Args:\n        df: Pandas DataFrame containing simulation results\n        output_filename: Output file name\n    \"\"\"\n    # Perform analysis\n    max_inventory = df['sds.I[1]'].max()\n\n    # Save results\n    with open(output_filename, 'w') as f:\n        f.write(f\"Maximum tritium inventory: {max_inventory} g\\n\")\n</code></pre> Note: Please place your custom module (e.g., <code>my_postprocess.py</code>) in the root directory of the <code>tricys</code> project, or ensure it is in a path that Python can import.</p> <p>2. Reference it in the configuration file: <pre><code>{\n    \"post_processing\": [\n        {\n            \"module\": \"my_postprocess\",\n            \"function\": \"analyze_results\",\n            \"params\": {\n                \"output_filename\": \"custom_report.txt\"\n            }\n        }\n    ]\n}\n</code></pre></p> Q: How to perform sensitivity analysis? <p>TRICYS offers several sensitivity analysis methods:</p> <p>1. Single-parameter sensitivity analysis: <pre><code>tricys analysis -c single_param_analysis.json\n</code></pre></p> <p>Studies the impact of a single parameter on KPIs.</p> <p>2. Multi-parameter sensitivity analysis: <pre><code>tricys analysis -c multi_param_analysis.json\n</code></pre></p> <p>Studies the coupling effects between parameters.</p> <p>3. SOBOL global sensitivity analysis: <pre><code>tricys analysis -c sobol_analysis.json\n</code></pre></p> <p>Quantifies the contribution of parameters and their interactions.</p> <p>4. Latin Hypercube uncertainty quantification: <pre><code>tricys analysis -c latin_analysis.json\n</code></pre></p> <p>Assesses the impact of input uncertainty on the output.</p> <p>For details, see: Sensitivity Analysis Tutorial</p> Q: How to define custom performance metrics? <p>Performance metrics (KPIs) are defined in <code>sensitivity_analysis.metrics_definition</code>:</p> <p>Using built-in metrics: <pre><code>{\n    \"metrics_definition\": {\n        \"Max_Inventory\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"max_value\"\n        }\n    }\n}\n</code></pre></p> <p>Built-in metric methods: * <code>get_final_value</code> * <code>max_value</code>, <code>min_value</code>, <code>mean_value</code> * <code>time_of_max</code>, <code>time_of_min</code> * <code>time_of_turning_point</code> * <code>calculate_startup_inventory</code> * <code>calculate_doubling_time</code> * <code>calculate_required_tbr</code> (bisection search)</p> <p>For a detailed physical explanation of the built-in metrics, see Core Performance Metrics.</p> <p>Creating custom metrics: <pre><code># my_metrics.py\ndef calculate_peak_to_peak(series):\n    \"\"\"Calculate peak-to-peak value\"\"\"\n    return series.max() - series.min()\n</code></pre></p> <p>Register your function in <code>tricys/analysis/metric.py</code> or reference it directly in the configuration.</p>"},{"location":"en/questions/best_practices.html","title":"\ud83d\udca1 Best Practices","text":"Q: How to organize large simulation projects? <p>Recommended directory structure:</p> <pre><code>my_fusion_project/\n\u251c\u2500\u2500 models/                 # Modelica models\n\u2502   \u251c\u2500\u2500 package.mo\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 configs/                # Configuration files\n\u2502   \u251c\u2500\u2500 baseline.json\n\u2502   \u251c\u2500\u2500 sensitivity.json\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 scripts/                # Helper scripts\n\u2502   \u251c\u2500\u2500 prepare_data.py\n\u2502   \u2514\u2500\u2500 post_analysis.py\n\u251c\u2500\u2500 data/                   # Input data\n\u2502   \u2514\u2500\u2500 external_data.csv\n\u251c\u2500\u2500 results/                # Simulation results (auto-generated)\n\u2514\u2500\u2500 reports/                # Final reports\n</code></pre> Q: How to version control configuration files? <p>Use Git for version control:</p> <pre><code># Initialize Git repository\ngit init\n\n# Create .gitignore\necho \"results/\" &gt;&gt; .gitignore\necho \"*.log\" &gt;&gt; .gitignore\necho \"*.pyc\" &gt;&gt; .gitignore\necho \"__pycache__/\" &gt;&gt; .gitignore\n\n# Commit configuration files\ngit add configs/*.json\ngit commit -m \"feat: add baseline configuration\"\n</code></pre> Q: How to run distributed simulations on multiple machines? <p>Currently, TRICYS does not directly support distributed computing, but you can:</p> <ol> <li>Manually split tasks:</li> <li>Divide the parameter scan into multiple subsets</li> <li>Run different subsets on different machines</li> <li> <p>Manually merge the results</p> </li> <li> <p>Use a cluster scheduler (like SLURM):</p> </li> <li>Submit each parameter combination as a separate job</li> <li>Use a post-processing script to aggregate the results</li> </ol> Q: How to optimize model performance? <p>At the Modelica model level: 1. Simplify the model structure, avoid overly complex equations 2. Use appropriate numerical solver settings 3. Avoid algebraic loops and excessive events</p> <p>At the TRICYS level: 1. Enable concurrent execution 2. Reduce the number of output variables 3. Use co-simulation to replace complex subsystems</p>"},{"location":"en/questions/configuration.html","title":"\u2699\ufe0f Configuration & Execution","text":"Q: How to run a simulation? <p>TRICYS offers several ways to run simulations:</p> <p>1. Command-Line Interface (CLI): <pre><code># Use the default configuration file config.json\ntricys\n\n# Specify a configuration file\ntricys -c my_config.json\n\n# Run an analysis task\ntricys analysis -c analysis_config.json\n</code></pre></p> <p>2. Graphical User Interface (GUI): <pre><code>tricys gui\n</code></pre></p> <p>3. Interactive Examples: <pre><code># Run an interactive menu for all examples\ntricys example\n\n# Run basic simulation examples\ntricys basic example\n\n# Run analysis examples\ntricys analysis example\n</code></pre></p> Q: How to understand the output files? <p>After the simulation is complete, the results are saved in a timestamped subdirectory under <code>results/</code>:</p> Filename Description <code>simulation_result.csv</code> Detailed results for a single parameter combination, containing all variables over time. <code>sweep_results.csv</code> Aggregated results for multiple parameter combinations (parameter sweep). <code>sensitivity_analysis_summary.csv</code> [Analysis Tasks Only] Summary metrics for sensitivity analysis, where each row is the KPI for one run. <code>requierd_tbr_summary.csv</code> [Analysis Tasks Only] Optimization results generated when performing goal-seeking tasks like \"Required TBR\". <code>simulation_*.log</code> Detailed runtime log, including debugging information. <code>config.json</code> A backup of the full configuration used for this run. <code>*_report.md</code> [Analysis Tasks Only] Auto-generated AI analysis report. <code>*.png</code> / <code>*.csv</code> Various charts and data exports. <p>Result CSV File Structure</p> <p>Whether running one or multiple parameter combinations, the final CSV files follow similar column naming conventions.</p> <ul> <li> <p>Base Case (No Scanned Parameters):     If <code>simulation_parameters</code> is empty, the column names are simply the variable names defined in <code>variableFilter</code>.     <pre><code>time,sds.I[1],blanket.I[1],...\n0.0,10.5,2.3,...\n</code></pre></p> </li> <li> <p>Parameter Sweep Case:     When <code>simulation_parameters</code> is not empty, the column names will have parameter information appended.     <pre><code>time,sds.I[1]&amp;blanket.TBR=1.05,sds.I[1]&amp;blanket.TBR=1.1,...\n</code></pre></p> <ul> <li>Column Name Format: <code>&lt;variable_name&gt;&amp;&lt;param1&gt;=&lt;value1&gt;&amp;&lt;param2&gt;=&lt;value2&gt;...</code></li> <li>The <code>time</code> column remains unchanged.</li> <li>Each variable under each parameter combination becomes a separate column. The column name is formed by joining the variable name and parameter-value pairs, separated by the <code>&amp;</code> symbol.</li> </ul> </li> </ul> Q: How to define complex parameter scans? <p>TRICYS supports several parameter scan formats:</p> Feature Format Example Description Discrete List <code>[v1, v2, ...]</code> <code>[6, 12, 18]</code> A set of discrete values Arithmetic Series <code>\"start:stop:step\"</code> <code>\"1.05:1.15:0.05\"</code> Start, stop, and step size Linear Spacing <code>\"linspace:start:stop:num\"</code> <code>\"linspace:10:20:5\"</code> Generate <code>num</code> evenly spaced points Logarithmic Spacing <code>\"log:start:stop:num\"</code> <code>\"log:1:1000:4\"</code> Generate <code>num</code> logarithmically scaled points Read from File <code>\"file:path:column\"</code> <code>\"file:data.csv:voltage\"</code> Read from a specified column in a CSV file <p>Example Configuration: <pre><code>{\n    \"simulation_parameters\": {\n        \"blanket.TBR\": [1.05, 1.1, 1.15, 1.2],\n        \"plasma.fb\": \"linspace:0.01:0.1:10\",\n        \"tep_fep.to_SDS_Fraction[1]\": \"log:0.1:1.0:5\"\n    }\n}\n</code></pre></p> Q: How to filter output variables? <p>Use the <code>variableFilter</code> parameter to select the variables to be saved. This parameter supports regular expressions, but be mindful of the syntax to match Modelica's variable naming rules.</p> <p>Configuration Example: <pre><code>{\n    \"simulation\": {\n        \"variableFilter\": \"time|sds.I[1]|blanket.I[1-5]|div.I[1-5]\"\n    }\n}\n</code></pre></p> <p>Common Patterns: *   <code>time</code>: The time variable (must be included). *   <code>sds.I[1]</code>: Exact match for a single variable. *   <code>sds.I[1-5]</code>: Matches array variables from <code>sds.I[1]</code> to <code>sds.I[5]</code>. *   <code>blanket.I[1-5]|div.I[1-5]</code>: Matches multiple specific array variables.</p> Q: The simulation is very slow, how to speed it up? <p>You can take the following optimization measures:</p> <p>1. Enable concurrent execution: <pre><code>{\n    \"simulation\": {\n        \"concurrent\": true,\n        \"max_workers\": 4\n    }\n}\n</code></pre></p> <p>2. Reduce the number of output variables: <pre><code>{\n    \"simulation\": {\n        \"variableFilter\": \"time|sds.I[1]\"  # Only save key variables\n    }\n}\n</code></pre></p> <p>3. Increase the time step (trade-off with accuracy): <pre><code>{\n    \"simulation\": {\n        \"step_size\": 1.0  # Increase from 0.5 to 1.0\n    }\n}\n</code></pre></p> <p>4. Reduce the number of scan points: <pre><code>{\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1.05:1.15:5\"  # Reduce from 20 to 5\n    }\n}\n</code></pre></p>"},{"location":"en/questions/installation.html","title":"\ud83d\ude80 Installation & Environment","text":"Q: Which operating systems are supported? <p>TRICYS supports the following operating systems:</p> <ul> <li>Windows 10/11 (WSL2 + Docker recommended)</li> <li>Ubuntu 20.04+</li> <li>CentOS/Rocky Linux 8+</li> <li>macOS (via Docker)</li> </ul> Q: Is Docker mandatory? <p>No, it's not mandatory. Docker provides the easiest installation method, but you can also:</p> <ul> <li>Install locally on Windows (requires OpenModelica and Python)</li> <li>Install locally on Linux</li> <li>Use WSL2 (Windows Subsystem for Linux)</li> </ul> <p>The advantage of Docker is environment isolation and being ready to use out-of-the-box, which is suitable for beginners.</p> Q: What version of Python is required? <p>TRICYS requires Python 3.8 or higher. Python 3.10 or 3.11 is recommended for optimal performance and compatibility.</p> Q: Is OpenModelica required? <p>Yes. TRICYS uses OpenModelica as its modeling and simulation backend. Please ensure that:</p> <ol> <li>OpenModelica is installed</li> <li>The <code>omc</code> command is accessible from the command line (added to PATH)</li> </ol> <p>Verification method: <pre><code>omc --version\n</code></pre></p> Q: How to solve the \\\"omc command not found\\\" error? <p>Windows: 1. Confirm the OpenModelica installation path (usually <code>C:\\OpenModelica\\bin</code>) 2. Add it to the system environment variable PATH 3. Restart the terminal or VSCode</p> <p>Linux: <pre><code># Check the location of omc\nwhich omc\n\n# If not found, add it to PATH\nexport PATH=\"/opt/openmodelica/bin:$PATH\"\n\n# Or add it permanently to ~/.bashrc\necho 'export PATH=\"/opt/openmodelica/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> Q: What to do if Docker image download is slow? <p>You can use a local Docker image mirror:</p> <pre><code># Edit Docker configuration (Linux)\nsudo nano /etc/docker/daemon.json\n\n# Add mirror addresses\n{\n  \"registry-mirrors\": [\n    \"https://docker.mirrors.ustc.edu.cn\",\n    \"https://hub-mirror.c.163.com\"\n  ]\n}\n\n# Restart Docker\nsudo systemctl restart docker\n</code></pre>"},{"location":"en/questions/troubleshooting.html","title":"\ud83d\udc1b Troubleshooting","text":"Q: Simulation failed, how to debug? <p>1. Check the log file: <pre><code># View the log of the latest run\ntail -f results/&lt;timestamp&gt;/simulation_*.log\n</code></pre></p> <p>2. Common errors and solutions:</p> Error Message Possible Cause Solution <code>Model not found</code> Incorrect model path Check if <code>package_path</code> is correct <code>Failed to compile</code> Modelica syntax error Open the model in OMEdit to check for errors <code>Variable not found</code> Variable in <code>variableFilter</code> does not exist Check the variable name spelling and use the correct path <code>Out of memory</code> Too many concurrent processes or model is too large Reduce <code>max_workers</code> or increase system memory <code>Permission denied</code> File permission issue Check the read/write permissions of the working directory <p>3. Enable detailed logging: <pre><code>{\n    \"logging\": {\n        \"level\": \"DEBUG\"\n    }\n}\n</code></pre></p> Q: GUI fails to start or display incorrectly? <p>Windows/Linux Local: * Make sure Tkinter is installed: <code>pip install tk</code> * Check the display environment variable: <code>echo $DISPLAY</code></p> <p>Docker Container: * Windows 11: Make sure the WSLg feature of WSL2 is enabled * Linux: Run <code>xhost +local:</code> to allow the container to access X11 * Use an image with GUI support: <code>tricys_openmodelica_gui</code></p> Q: Parameter scan results are incomplete? <p>Possible reasons:</p> <ol> <li>Some simulations failed:</li> <li>Check the error messages in the log file</li> <li> <p>Check if the parameter values are reasonable (e.g., avoid division by zero, negative values, etc.)</p> </li> <li> <p>The output variable filter is too strict:</p> </li> <li> <p>Check if <code>variableFilter</code> matches the required variables</p> </li> <li> <p>Concurrency issues:</p> </li> <li>Try disabling concurrency: <code>\"concurrent\": false</code></li> <li>Check if any processes have crashed</li> </ol> Q: How to report a bug? <p>Please create a new issue in GitHub Issues and provide:</p> <ol> <li>Environment information:</li> <li>Operating system and version</li> <li>Python version</li> <li>OpenModelica version</li> <li> <p>TRICYS version</p> </li> <li> <p>Steps to reproduce:</p> </li> <li>The complete configuration file</li> <li>The command you ran</li> <li> <p>The model you used (if possible)</p> </li> <li> <p>Error information:</p> </li> <li>The full error stack trace</li> <li> <p>Relevant log snippets</p> </li> <li> <p>Expected behavior:</p> </li> <li>What you expected to happen</li> <li>What actually happened</li> </ol>"},{"location":"index.html","title":"TRICYS: \u6c1a\u71c3\u6599\u5faa\u73af\u96c6\u6210\u4eff\u771f\u5e73\u53f0","text":"<p>\u6b22\u8fce\u4f7f\u7528 TRICYS (TRitium Integrated CYcle Simulation) \u6c1a\u71c3\u6599\u5faa\u73af\u96c6\u6210\u4eff\u771f\u5e73\u53f0\u3002TRICYS \u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u6a21\u5757\u5316\u3001\u591a\u5c3a\u5ea6\u7684\u805a\u53d8\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u4eff\u771f\u5668\uff0c\u65e8\u5728\u63d0\u4f9b\u57fa\u4e8e\u7269\u7406\u7684\u52a8\u6001\u95ed\u73af\u5206\u6790\uff0c\u5e76\u4e25\u683c\u9075\u5b88\u5168\u5382\u8303\u56f4\u7684\u8d28\u91cf\u5b88\u6052\u539f\u5219\u3002</p> <p>\u6211\u4eec\u7684\u76ee\u6807\u662f\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u4e14\u5f3a\u5927\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u63a2\u7d22\u5404\u79cd\u6c1a\u7ba1\u7406\u7b56\u7565\u3001\u4f18\u5316\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5e76\u6df1\u5165\u7406\u89e3\u805a\u53d8\u53cd\u5e94\u5806\u73af\u5883\u4e2d\u6c1a\u7684\u6d41\u52a8\u4e0e\u5e93\u5b58\u52a8\u6001\u3002</p> <p>\u6211\u4eec\u6b22\u8fce\u793e\u533a\u8d21\u732e\uff01\u65e0\u8bba\u60a8\u662f\u805a\u53d8\u79d1\u5b66\u5bb6\u3001\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u8fd8\u662f\u5bf9\u5f00\u6e90\u9879\u76ee\u5145\u6ee1\u70ed\u60c5\u7684\u7231\u597d\u8005\uff0c\u90fd\u6709\u591a\u79cd\u65b9\u5f0f\u53c2\u4e0e TRICYS \u7684\u53d1\u5c55\u3002</p> <p>\u5feb\u901f\u5f00\u59cb \u62a5\u544a\u95ee\u9898 \u6c1a\u71c3\u6599\u5faa\u73af0\u7ef4\u7cfb\u7edf\u793a\u4f8b\u6a21\u578b</p>"},{"location":"index.html#tricys_1","title":"\ud83d\udcda TRICYS \u80fd\u505a\u4ec0\u4e48\uff1f","text":"<ul> <li>\u53c2\u6570\u626b\u63cf\u4e0e\u5e76\u53d1\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u591a\u4e2a\u53c2\u6570\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u652f\u6301\u5e76\u53d1\u8fd0\u884c\u548c\u5927\u89c4\u6a21\u6279\u91cf\u4eff\u771f\u3002</li> <li>\u5b50\u6a21\u5757\u534f\u540c\u4eff\u771f\uff1a\u652f\u6301\u4e0e\u5916\u90e8\u5de5\u5177\uff08\u5982 Aspen Plus\uff09\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u5b8c\u6210\u5b50\u6a21\u5757\u7cfb\u7edf\u96c6\u6210\u3002</li> <li>\u81ea\u52a8\u5316\u62a5\u544a\u751f\u6210\uff1a\u81ea\u52a8\u751f\u6210\u6807\u51c6\u5316\u7684 Markdown \u5206\u6790\u62a5\u544a\uff0c\u5305\u542b\u56fe\u8868\u3001\u7edf\u8ba1\u6570\u636e\u548c\u53ef\u89c6\u5316\u7ed3\u679c\u3002</li> <li>\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a\u652f\u6301\u7cfb\u7edf\u53c2\u6570\u7684\u81ea\u5b9a\u4e49\u654f\u611f\u6027\u5206\u6790\uff0c\u5e76\u96c6\u6210SALib\uff08Sensitivity Analysis Library in Python\uff09\u5e93\u91cf\u5316\u53c2\u6570\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002</li> </ul>"},{"location":"index.html#tricys_2","title":"\ud83d\udd2c \u4e3a\u4ec0\u4e48\u9009\u62e9 TRICYS\uff1f","text":"<ul> <li>\u51c6\u786e\u6027\u4e0e\u7075\u6d3b\u6027\uff1a\u7ed3\u5408\u8be6\u7ec6\u7684\u7269\u7406\u6a21\u578b\u548c\u9ad8\u5ea6\u53ef\u914d\u7f6e\u7684\u7cfb\u7edf\u67b6\u6784\u3002</li> <li>\u6a21\u5757\u5316\u8bbe\u8ba1\uff1a\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u3002</li> <li>\u5de5\u4e1a\u5e94\u7528\uff1a\u9002\u7528\u4e8e\u805a\u53d8\u5806\u8bbe\u8ba1\u4f18\u5316\u3001\u8fd0\u884c\u7b56\u7565\u8bc4\u4f30\u548c\u5b89\u5168\u5206\u6790\u3002</li> <li>\u793e\u533a\u9a71\u52a8\uff1a\u53d7\u76ca\u4e8e\u534f\u4f5c\u5f00\u53d1\u548c\u900f\u660e\u7684\u51b3\u7b56\u8fc7\u7a0b\u3002</li> <li>\u6559\u80b2\u5de5\u5177\uff1a\u4e3a\u5b66\u751f\u548c\u65b0\u7814\u7a76\u4eba\u5458\u7406\u89e3\u805a\u53d8\u71c3\u6599\u5faa\u73af\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u6781\u597d\u7684\u8d44\u6e90\u3002</li> </ul>"},{"location":"changelog.html","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<p>TRICYS \u9075\u5faa\u8bed\u4e49\u5316\u7248\u672c\u89c4\u8303\uff08Semantic Versioning\uff09\uff1a</p> <ul> <li>\u4e3b\u7248\u672c\u53f7\uff08Major\uff09\uff1a\u8fdb\u884c\u4e0d\u517c\u5bb9\u7684 API \u53d8\u66f4\u65f6\u9012\u589e</li> <li>\u6b21\u7248\u672c\u53f7\uff08Minor\uff09\uff1a\u4ee5\u5411\u540e\u517c\u5bb9\u7684\u65b9\u5f0f\u6dfb\u52a0\u65b0\u529f\u80fd\u65f6\u9012\u589e</li> <li>\u4fee\u8ba2\u53f7\uff08Patch\uff09\uff1a\u8fdb\u884c\u5411\u540e\u517c\u5bb9\u7684\u95ee\u9898\u4fee\u6b63\u65f6\u9012\u589e</li> </ul>"},{"location":"changelog.html#100-2025-11-15","title":"1.0.0 ( 2025-11-15 )","text":"<p>TRICYS 1.0.0 \u662f\u9879\u76ee\u7684\u9996\u4e2a\u6b63\u5f0f\u7a33\u5b9a\u7248\u672c\uff0c\u6807\u5fd7\u7740\u6838\u5fc3\u529f\u80fd\u7684\u5b8c\u5584\u548c\u751f\u4ea7\u73af\u5883\u5c31\u7eea\u3002</p> <ul> <li>\u53c2\u6570\u626b\u63cf\u4e0e\u5e76\u53d1\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u591a\u4e2a\u53c2\u6570\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u652f\u6301\u5e76\u53d1\u8fd0\u884c\u548c\u5927\u89c4\u6a21\u6279\u91cf\u4eff\u771f\u3002</li> <li>\u5b50\u6a21\u5757\u534f\u540c\u4eff\u771f\uff1a\u652f\u6301\u4e0e\u5916\u90e8\u5de5\u5177\uff08\u5982 Aspen Plus\uff09\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u5b8c\u6210\u5b50\u6a21\u5757\u7cfb\u7edf\u96c6\u6210\u3002</li> <li>\u81ea\u52a8\u5316\u62a5\u544a\u751f\u6210\uff1a\u81ea\u52a8\u751f\u6210\u6807\u51c6\u5316\u7684 Markdown \u5206\u6790\u62a5\u544a\uff0c\u5305\u542b\u56fe\u8868\u3001\u7edf\u8ba1\u6570\u636e\u548c\u53ef\u89c6\u679c\u3002</li> <li>\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a\u652f\u6301\u7cfb\u7edf\u53c2\u6570\u7684\u81ea\u5b9a\u4e49\u654f\u611f\u6027\u5206\u6790\uff0c\u5e76\u96c6\u6210SALib\uff08SensitivitAnalysis Library in Python\uff09\u5e93\u91cf\u5316\u53c2\u6570\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002</li> </ul>"},{"location":"license.html","title":"\u5f00\u6e90\u8bb8\u53ef","text":"<pre><code>                                                              Apache License\n                                                        Version 2.0, January 2004\n                                                     http://www.apache.org/licenses/\n\n                                TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n                                1. Definitions.\n\n                                   \"License\" shall mean the terms and conditions for use, reproduction,\n                                   and distribution as defined by Sections 1 through 9 of this document.\n\n                                   \"Licensor\" shall mean the copyright owner or entity authorized by\n                                   the copyright owner that is granting the License.\n\n                                   \"Legal Entity\" shall mean the union of the acting entity and all\n                                   other entities that control, are controlled by, or are under common\n                                   control with that entity. For the purposes of this definition,\n                                   \"control\" means (i) the power, direct or indirect, to cause the\n                                   direction or management of such entity, whether by contract or\n                                   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n                                   outstanding shares, or (iii) beneficial ownership of such entity.\n\n                                   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n                                   exercising permissions granted by this License.\n\n                                   \"Source\" form shall mean the preferred form for making modifications,\n                                   including but not limited to software source code, documentation\n                                   source, and configuration files.\n\n                                   \"Object\" form shall mean any form resulting from mechanical\n                                   transformation or translation of a Source form, including but\n                                   not limited to compiled object code, generated documentation,\n                                   and conversions to other media types.\n\n                                   \"Work\" shall mean the work of authorship, whether in Source or\n                                   Object form, made available under the License, as indicated by a\n                                   copyright notice that is included in or attached to the work\n                                   (an example is provided in the Appendix below).\n\n                                   \"Derivative Works\" shall mean any work, whether in Source or Object\n                                   form, that is based on (or derived from) the Work and for which the\n                                   editorial revisions, annotations, elaborations, or other modifications\n                                   represent, as a whole, an original work of authorship. For the purposes\n                                   of this License, Derivative Works shall not include works that remain\n                                   separable from, or merely link (or bind by name) to the interfaces of,\n                                   the Work and Derivative Works thereof.\n\n                                   \"Contribution\" shall mean any work of authorship, including\n                                   the original version of the Work and any modifications or additions\n                                   to that Work or Derivative Works thereof, that is intentionally\n                                   submitted to Licensor for inclusion in the Work by the copyright owner\n                                   or by an individual or Legal Entity authorized to submit on behalf of\n                                   the copyright owner. For the purposes of this definition, \"submitted\"\n                                   means any form of electronic, verbal, or written communication sent\n                                   to the Licensor or its representatives, including but not limited to\n                                   communication on electronic mailing lists, source code control systems,\n                                   and issue tracking systems that are managed by, or on behalf of, the\n                                   Licensor for the purpose of discussing and improving the Work, but\n                                   excluding communication that is conspicuously marked or otherwise\n                                   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n                                   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n                                   on behalf of whom a Contribution has been received by Licensor and\n                                   subsequently incorporated within the Work.\n\n                                2. Grant of Copyright License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   copyright license to reproduce, prepare Derivative Works of,\n                                   publicly display, publicly perform, sublicense, and distribute the\n                                   Work and such Derivative Works in Source or Object form.\n\n                                3. Grant of Patent License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   (except as stated in this section) patent license to make, have made,\n                                   use, offer to sell, sell, import, and otherwise transfer the Work,\n                                   where such license applies only to those patent claims licensable\n                                   by such Contributor that are necessarily infringed by their\n                                   Contribution(s) alone or by combination of their Contribution(s)\n                                   with the Work to which such Contribution(s) was submitted. If You\n                                   institute patent litigation against any entity (including a\n                                   cross-claim or counterclaim in a lawsuit) alleging that the Work\n                                   or a Contribution incorporated within the Work constitutes direct\n                                   or contributory patent infringement, then any patent licenses\n                                   granted to You under this License for that Work shall terminate\n                                   as of the date such litigation is filed.\n\n                                4. Redistribution. You may reproduce and distribute copies of the\n                                   Work or Derivative Works thereof in any medium, with or without\n                                   modifications, and in Source or Object form, provided that You\n                                   meet the following conditions:\n\n                                   (a) You must give any other recipients of the Work or\n                                       Derivative Works a copy of this License; and\n\n                                   (b) You must cause any modified files to carry prominent notices\n                                       stating that You changed the files; and\n\n                                   (c) You must retain, in the Source form of any Derivative Works\n                                       that You distribute, all copyright, patent, trademark, and\n                                       attribution notices from the Source form of the Work,\n                                       excluding those notices that do not pertain to any part of\n                                       the Derivative Works; and\n\n                                   (d) If the Work includes a \"NOTICE\" text file as part of its\n                                       distribution, then any Derivative Works that You distribute must\n                                       include a readable copy of the attribution notices contained\n                                       within such NOTICE file, excluding those notices that do not\n                                       pertain to any part of the Derivative Works, in at least one\n                                       of the following places: within a NOTICE text file distributed\n                                       as part of the Derivative Works; within the Source form or\n                                       documentation, if provided along with the Derivative Works; or,\n                                       within a display generated by the Derivative Works, if and\n                                       wherever such third-party notices normally appear. The contents\n                                       of the NOTICE file are for informational purposes only and\n                                       do not modify the License. You may add Your own attribution\n                                       notices within Derivative Works that You distribute, alongside\n                                       or as an addendum to the NOTICE text from the Work, provided\n                                       that such additional attribution notices cannot be construed\n                                       as modifying the License.\n\n                                   You may add Your own copyright statement to Your modifications and\n                                   may provide additional or different license terms and conditions\n                                   for use, reproduction, or distribution of Your modifications, or\n                                   for any such Derivative Works as a whole, provided Your use,\n                                   reproduction, and distribution of the Work otherwise complies with\n                                   the conditions stated in this License.\n\n                                5. Submission of Contributions. Unless You explicitly state otherwise,\n                                   any Contribution intentionally submitted for inclusion in the Work\n                                   by You to the Licensor shall be under the terms and conditions of\n                                   this License, without any additional terms or conditions.\n                                   Notwithstanding the above, nothing herein shall supersede or modify\n                                   the terms of any separate license agreement you may have executed\n                                   with Licensor regarding such Contributions.\n\n                                6. Trademarks. This License does not grant permission to use the trade\n                                   names, trademarks, service marks, or product names of the Licensor,\n                                   except as required for reasonable and customary use in describing the\n                                   origin of the Work and reproducing the content of the NOTICE file.\n\n                                7. Disclaimer of Warranty. Unless required by applicable law or\n                                   agreed to in writing, Licensor provides the Work (and each\n                                   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n                                   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n                                   implied, including, without limitation, any warranties or conditions\n                                   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n                                   PARTICULAR PURPOSE. You are solely responsible for determining the\n                                   appropriateness of using or redistributing the Work and assume any\n                                   risks associated with Your exercise of permissions under this License.\n\n                                8. Limitation of Liability. In no event and under no legal theory,\n                                   whether in tort (including negligence), contract, or otherwise,\n                                   unless required by applicable law (such as deliberate and grossly\n                                   negligent acts) or agreed to in writing, shall any Contributor be\n                                   liable to You for damages, including any direct, indirect, special,\n                                   incidental, or consequential damages of any character arising as a\n                                   result of this License or out of the use or inability to use the\n                                   Work (including but not limited to damages for loss of goodwill,\n                                   work stoppage, computer failure or malfunction, or any and all\n                                   other commercial damages or losses), even if such Contributor\n                                   has been advised of the possibility of such damages.\n\n                                9. Accepting Warranty or Additional Liability. While redistributing\n                                   the Work or Derivative Works thereof, You may choose to offer,\n                                   and charge a fee for, acceptance of support, warranty, indemnity,\n                                   or other liability obligations and/or rights consistent with this\n                                   License. However, in accepting such obligations, You may act only\n                                   on Your own behalf and on Your sole responsibility, not on behalf\n                                   of any other Contributor, and only if You agree to indemnify,\n                                   defend, and hold each Contributor harmless for any liability\n                                   incurred by, or claims asserted against, such Contributor by reason\n                                   of your accepting any such warranty or additional liability.\n\n                                END OF TERMS AND CONDITIONS\n\n                                APPENDIX: How to apply the Apache License to your work.\n\n                                   To apply the Apache License to your work, attach the following\n                                   boilerplate notice, with the fields enclosed by brackets \"[]\"\n                                   replaced with your own identifying information. (Don't include\n                                   the brackets!)  The text should be enclosed in the appropriate\n                                   comment syntax for the file format. We also recommend that a\n                                   file or class name and description of purpose be included on the\n                                   same \"printed page\" as the copyright notice for easier\n                                   identification within third-party archives.\n\n                                Copyright [yyyy] [name of copyright owner]\n\n                                Licensed under the Apache License, Version 2.0 (the \"License\");\n                                you may not use this file except in compliance with the License.\n                                You may obtain a copy of the License at\n\n                                    http://www.apache.org/licenses/LICENSE-2.0\n\n                                Unless required by applicable law or agreed to in writing, software\n                                distributed under the License is distributed on an \"AS IS\" BASIS,\n                                WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n                                See the License for the specific language governing permissions and\n                                limitations under the License.\n</code></pre>"},{"location":"api/tricys_analysis.html","title":"API \u53c2\u8003 - \u5206\u6790\u6a21\u5757 (Analysis)","text":"<p>\u5206\u6790\u6a21\u5757 (Analysis)</p> <p>\u5206\u6790\u6a21\u5757 (Analysis) \u63d0\u4f9b\u4e86\u7528\u4e8e\u5904\u7406\u3001\u53ef\u89c6\u5316\u548c\u62a5\u544a TRICYS \u4eff\u771f\u7ed3\u679c\u7684\u5de5\u5177\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Metric (\u6307\u6807)Plot (\u7ed8\u56fe)Report (\u62a5\u544a)SALib (\u654f\u611f\u6027) <p>Utility functions for plotting simulation results.</p> <p>This module provides functions to generate plots from the simulation output CSV files, such as visualizing startup tritium inventory or time-series data.</p>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.calculate_doubling_time","title":"<code>calculate_doubling_time(series, time_series)</code>","text":"<p>Calculates the time it takes for the inventory to double its initial value.</p> <p>This function finds the first time point, after the inventory's minimum (turning point), where the inventory level reaches or exceeds twice its initial value.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The inventory time series data.</p> required <code>time_series</code> <code>Series</code> <p>The corresponding time data.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The doubling time, or NaN if the inventory never doubles.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If time_series is None.</p> Note <p>Only considers the portion of the series after the turning point (minimum). Returns NaN if the inventory never reaches twice the initial value in the post-turning-point region.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def calculate_doubling_time(series: pd.Series, time_series: pd.Series) -&gt; float:\n    \"\"\"Calculates the time it takes for the inventory to double its initial value.\n\n    This function finds the first time point, after the inventory's minimum\n    (turning point), where the inventory level reaches or exceeds twice its\n    initial value.\n\n    Args:\n        series: The inventory time series data.\n        time_series: The corresponding time data.\n\n    Returns:\n        The doubling time, or NaN if the inventory never doubles.\n\n    Raises:\n        ValueError: If time_series is None.\n\n    Note:\n        Only considers the portion of the series after the turning point (minimum).\n        Returns NaN if the inventory never reaches twice the initial value in the\n        post-turning-point region.\n    \"\"\"\n    if time_series is None:\n        raise ValueError(\"time_series must be provided for calculate_doubling_time\")\n    initial_inventory = series.iloc[0]\n    doubled_inventory = 2 * initial_inventory\n\n    # Find the first index where the inventory is &gt;= doubled_inventory\n    # We should only consider the part of the series after the turning point\n    min_index = series.idxmin()\n    after_turning_point_series = series.loc[min_index:]\n\n    doubling_indices = after_turning_point_series[\n        after_turning_point_series &gt;= doubled_inventory\n    ].index\n\n    if not doubling_indices.empty:\n        doubling_index = doubling_indices[0]\n        return time_series.loc[doubling_index]\n    else:\n        # If it never doubles, return NaN\n        return np.nan\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.calculate_startup_inventory","title":"<code>calculate_startup_inventory(series, time_series=None)</code>","text":"<p>Calculates the startup inventory.</p> <p>The startup inventory is calculated as the difference between the initial inventory and the minimum inventory (the turning point).</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The inventory time series data.</p> required <code>time_series</code> <code>Optional[Series]</code> <p>The corresponding time data (unused).</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The calculated startup inventory.</p> Note <p>The time_series parameter is provided for interface consistency but is not used in the calculation. The startup inventory represents the amount of inventory consumed before reaching the minimum point.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def calculate_startup_inventory(\n    series: pd.Series, time_series: Optional[pd.Series] = None\n) -&gt; float:\n    \"\"\"Calculates the startup inventory.\n\n    The startup inventory is calculated as the difference between the initial\n    inventory and the minimum inventory (the turning point).\n\n    Args:\n        series: The inventory time series data.\n        time_series: The corresponding time data (unused).\n\n    Returns:\n        The calculated startup inventory.\n\n    Note:\n        The time_series parameter is provided for interface consistency but is not\n        used in the calculation. The startup inventory represents the amount of\n        inventory consumed before reaching the minimum point.\n    \"\"\"\n    initial_inventory = series.iloc[0]\n    minimum_inventory = series.min()\n    return initial_inventory - minimum_inventory\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.extract_metrics","title":"<code>extract_metrics(results_df, metrics_definition, analysis_case)</code>","text":"<p>Extracts summary metrics from detailed simulation results.</p> <p>This function processes a DataFrame from a parameter sweep, calculates various metrics for each run based on a definitions dictionary, and pivots the results into a summary DataFrame where each row corresponds to a unique parameter combination.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame from the combined sweep results.</p> required <code>metrics_definition</code> <code>Dict[str, Any]</code> <p>Dictionary defining how to calculate each metric (e.g., source column, method).</p> required <code>analysis_case</code> <code>Dict[str, Any]</code> <p>The analysis case configuration, used to identify dependent variables.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pivoted DataFrame with parameters as the index and metric names as columns.</p> Note <p>Parses column names in format \"variable&amp;param1=value1&amp;param2=value2\" to extract parameter values. Skips metrics with \"bisection_search\" method. Returns empty DataFrame if no valid metrics are found or if pivoting fails.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def extract_metrics(\n    results_df: pd.DataFrame,\n    metrics_definition: Dict[str, Any],\n    analysis_case: Dict[str, Any],\n) -&gt; pd.DataFrame:\n    \"\"\"Extracts summary metrics from detailed simulation results.\n\n    This function processes a DataFrame from a parameter sweep, calculates\n    various metrics for each run based on a definitions dictionary, and\n    pivots the results into a summary DataFrame where each row corresponds\n    to a unique parameter combination.\n\n    Args:\n        results_df: DataFrame from the combined sweep results.\n        metrics_definition: Dictionary defining how to calculate each metric\n            (e.g., source column, method).\n        analysis_case: The analysis case configuration, used to identify\n            dependent variables.\n\n    Returns:\n        A pivoted DataFrame with parameters as the index and metric names as columns.\n\n    Note:\n        Parses column names in format \"variable&amp;param1=value1&amp;param2=value2\" to extract\n        parameter values. Skips metrics with \"bisection_search\" method. Returns empty\n        DataFrame if no valid metrics are found or if pivoting fails.\n    \"\"\"\n\n    analysis_results = []\n\n    source_to_metric = {}\n    dependent_vars = analysis_case.get(\"dependent_variables\", [])\n\n    for metric_name in dependent_vars:\n        definition = metrics_definition.get(metric_name)\n\n        # If the metric is not in the definition or is calculated via optimization, skip it.\n        if not definition or definition.get(\"method\") == \"bisection_search\":\n            continue\n\n        source = definition[\"source_column\"]\n        if source not in source_to_metric:\n            source_to_metric[source] = []\n        source_to_metric[source].append(\n            {\n                \"metric_name\": metric_name,\n                \"method\": definition[\"method\"],\n            }\n        )\n\n    for col_name in results_df.columns:\n        if col_name.lower() == \"time\":\n            continue\n\n        source_var = None\n        for var in source_to_metric.keys():\n            if col_name.startswith(var):\n                source_var = var\n                break\n\n        if not source_var:\n            continue\n\n        param_str = col_name[len(source_var) :].lstrip(\"&amp;\")\n\n        try:\n            params = dict(item.split(\"=\") for item in param_str.split(\"&amp;\"))\n        except ValueError:\n            print(\n                f\"Warning: Could not parse parameters from column '{col_name}'. Skipping.\"\n            )\n            continue\n\n        for k, v in params.items():\n            try:\n                params[k] = float(v)\n            except ValueError:\n                params[k] = v\n\n        for metric_info in source_to_metric[source_var]:\n            method_name = metric_info[\"method\"]\n            metric_name = metric_info[\"metric_name\"]\n\n            if method_name == \"final_value\":\n                calculation_func = get_final_value\n            elif method_name == \"calculate_startup_inventory\":\n                calculation_func = calculate_startup_inventory\n            elif method_name == \"time_of_turning_point\":\n                calculation_func = time_of_turning_point\n            elif method_name == \"calculate_doubling_time\":\n                calculation_func = calculate_doubling_time\n            else:\n                print(\n                    f\"Warning: Calculation method '{method_name}' not implemented. Skipping.\"\n                )\n                continue\n\n            metric_value = calculation_func(results_df[col_name], results_df[\"time\"])\n\n            result_row = params.copy()\n            result_row[\"metric_name\"] = metric_name\n            result_row[\"metric_value\"] = metric_value\n            analysis_results.append(result_row)\n\n    if not analysis_results:\n        return pd.DataFrame()\n\n    summary_df = pd.DataFrame(analysis_results)\n\n    # Dynamically identify all parameter columns from the dataframe\n    param_cols = [\n        col for col in summary_df.columns if col not in [\"metric_name\", \"metric_value\"]\n    ]\n\n    if not param_cols:\n        return pd.DataFrame()\n\n    try:\n        pivot_df = summary_df.pivot_table(\n            index=param_cols, columns=\"metric_name\", values=\"metric_value\"\n        ).reset_index()\n        return pivot_df\n    except Exception as e:\n        print(f\"Error during pivoting: {e}\")\n        return pd.DataFrame()\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.get_final_value","title":"<code>get_final_value(series, time_series=None)</code>","text":"<p>Gets the final value of a time series.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The time series data.</p> required <code>time_series</code> <code>Optional[Series]</code> <p>The corresponding time data (unused).</p> <code>None</code> <p>Returns:</p> Type Description <code>float</code> <p>The last value in the series.</p> Note <p>The time_series parameter is kept for interface consistency but is not used in the calculation. Only the series data is required.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def get_final_value(\n    series: pd.Series, time_series: Optional[pd.Series] = None\n) -&gt; float:\n    \"\"\"Gets the final value of a time series.\n\n    Args:\n        series: The time series data.\n        time_series: The corresponding time data (unused).\n\n    Returns:\n        The last value in the series.\n\n    Note:\n        The time_series parameter is kept for interface consistency but is not used\n        in the calculation. Only the series data is required.\n    \"\"\"\n    return series.iloc[-1]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.metric.time_of_turning_point","title":"<code>time_of_turning_point(series, time_series)</code>","text":"<p>Finds the time of the turning point (minimum value) in a series.</p> <p>This function identifies the time corresponding to the minimum value in the series, which often represents the self-sufficiency time in tritium inventory simulations. To handle noisy data, it first smooths the series to find the general trend's minimum. If the smoothed minimum is not at the boundaries, it returns the time of the absolute minimum from the original data.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The time series data to analyze.</p> required <code>time_series</code> <code>Series</code> <p>The corresponding time data.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The time of the turning point, or NaN if the trend is monotonic.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If time_series is None.</p> Note <p>Uses a rolling window (0.1% of data length) for smoothing to identify the general trend. If the smoothed minimum is within the last 30% of the series, the trend is considered monotonic and NaN is returned. Otherwise, returns the time of the absolute minimum in the original data.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def time_of_turning_point(series: pd.Series, time_series: pd.Series) -&gt; float:\n    \"\"\"Finds the time of the turning point (minimum value) in a series.\n\n    This function identifies the time corresponding to the minimum value in the\n    series, which often represents the self-sufficiency time in tritium inventory\n    simulations. To handle noisy data, it first smooths the series to find the\n    general trend's minimum. If the smoothed minimum is not at the boundaries,\n    it returns the time of the absolute minimum from the original data.\n\n    Args:\n        series: The time series data to analyze.\n        time_series: The corresponding time data.\n\n    Returns:\n        The time of the turning point, or NaN if the trend is monotonic.\n\n    Raises:\n        ValueError: If time_series is None.\n\n    Note:\n        Uses a rolling window (0.1% of data length) for smoothing to identify the\n        general trend. If the smoothed minimum is within the last 30% of the series,\n        the trend is considered monotonic and NaN is returned. Otherwise, returns\n        the time of the absolute minimum in the original data.\n    \"\"\"\n\n    print(\n        f\"Calculating time_of_turning_point for series with length {len(series)} and {len(time_series)} \"\n    )\n    if time_series is None:\n        raise ValueError(\"time_series must be provided for time_of_turning_point\")\n\n    # Define a window size for the rolling average, e.g., 5% of the data length\n    # with a minimum size of 1. This helps in smoothing out local fluctuations.\n    window_size = max(1, int(len(series) * 0.001))\n    smoothed_series = series.rolling(\n        window=window_size, center=True, min_periods=1\n    ).mean()\n\n    # Find the index label of the minimum value in the smoothed series.\n    smooth_min_index = smoothed_series.idxmin()\n    min_index = series.idxmin()\n\n    # Check if the minimum of the smoothed data is within the first or last 5%\n    # of the series. If so, the trend is considered monotonic.\n    smooth_min_pos = series.index.get_loc(smooth_min_index)\n    five_percent_threshold = int(len(series) * 0.3)\n\n    if smooth_min_pos &gt;= len(series) - five_percent_threshold:\n        return np.nan\n    else:\n        # A clear turning point is identified in the overall trend.\n        # Now, find the precise turning point in the original, noisy data.\n        min_index = series.idxmin()\n        return time_series.loc[min_index]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.generate_analysis_plots","title":"<code>generate_analysis_plots(summary_df, analysis_case, save_dir, unit_map=None, glossary_path=None)</code>","text":"<p>Generates and saves plots based on the sensitivity analysis summary.</p> <p>This function first generates dedicated plots for all 'Required_***' metrics, then handles plotting for all other standard metrics.</p> <p>Parameters:</p> Name Type Description Default <code>summary_df</code> <code>DataFrame</code> <p>DataFrame containing the summarized analysis results.</p> required <code>analysis_case</code> <code>dict</code> <p>Configuration for the analysis cases.</p> required <code>save_dir</code> <code>str</code> <p>Directory to save the plot images.</p> required <code>unit_map</code> <code>dict</code> <p>Optional dictionary for unit conversion and labeling. Defaults to None.</p> <code>None</code> <code>glossary_path</code> <code>str</code> <p>Optional path to the glossary CSV file for professional labels.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of paths to the saved plot images.</p> Note <p>Handles Required_*** metrics separately with multi-subplot layouts. Standard metrics can be combined or plotted individually based on case configuration. Returns empty list if summary_df is empty. Loads glossary if path provided.</p> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def generate_analysis_plots(\n    summary_df: pd.DataFrame,\n    analysis_case: dict,\n    save_dir: str,\n    unit_map: dict = None,\n    glossary_path: str = None,\n) -&gt; list[str]:\n    \"\"\"Generates and saves plots based on the sensitivity analysis summary.\n\n    This function first generates dedicated plots for all 'Required_***' metrics,\n    then handles plotting for all other standard metrics.\n\n    Args:\n        summary_df: DataFrame containing the summarized analysis results.\n        analysis_case: Configuration for the analysis cases.\n        save_dir: Directory to save the plot images.\n        unit_map: Optional dictionary for unit conversion and labeling. Defaults to None.\n        glossary_path: Optional path to the glossary CSV file for professional labels.\n\n    Returns:\n        A list of paths to the saved plot images.\n\n    Note:\n        Handles Required_*** metrics separately with multi-subplot layouts. Standard\n        metrics can be combined or plotted individually based on case configuration.\n        Returns empty list if summary_df is empty. Loads glossary if path provided.\n    \"\"\"\n    if glossary_path:\n        load_glossary(glossary_path)\n\n    if summary_df.empty:\n        return []\n\n    analysis_cases = [analysis_case]  # Keep as a list for consistency\n    sns.set_theme(style=\"whitegrid\")\n    line_colors = sns.color_palette(\"viridis\", 10)\n\n    plot_paths = []\n\n    # If unit_map is not provided, initialize as empty dict\n    if unit_map is None:\n        unit_map = {}\n\n    # --- 1. Handle ALL 'Required_***' plots first and separately ---\n    all_required_vars_from_config = {\n        var\n        for case in analysis_cases\n        for var in case.get(\"dependent_variables\", [])\n        if var.startswith(\"Required_\")\n    }\n\n    for req_var in all_required_vars_from_config:\n        # Find all actual columns in the dataframe for this base name\n        matching_cols = sorted(\n            [\n                c\n                for c in summary_df.columns\n                if c == req_var or c.startswith(req_var + \"(\")\n            ]\n        )\n\n        if not matching_cols:\n            continue\n\n        case_for_plot = analysis_cases[0]\n\n        if len(matching_cols) &gt; 1:\n            # Multi-value case -&gt; generate a multi-subplot figure\n            multi_plot_paths = _generate_multi_required_plot(\n                summary_df,\n                case_for_plot,\n                matching_cols,\n                req_var,\n                save_dir,\n                unit_map=unit_map,\n            )\n            plot_paths.extend(multi_plot_paths)\n        elif len(matching_cols) == 1:\n            # Single-value case -&gt; generate a single, individual plot\n            plot_config = {\n                \"case_name\": case_for_plot[\"name\"],\n                \"x_var\": case_for_plot[\"independent_variable\"],\n                \"y_var\": matching_cols[0],\n                \"plot_type\": \"line\",\n                \"hue_vars\": sorted(\n                    list(case_for_plot.get(\"default_simulation_values\", {}).keys())\n                ),\n            }\n            single_plot_path = _generate_individual_plots(\n                summary_df, [plot_config], save_dir, line_colors, unit_map=unit_map\n            )\n            plot_paths.extend(single_plot_path)\n\n    # --- 2. Handle all other (non-Required) plots ---\n\n    # Collect plot configurations for remaining standard variables\n    valid_plots_for_combine = []\n    for case in analysis_cases:\n        case_name = case[\"name\"]\n        x_var = case[\"independent_variable\"]\n\n        # Filter out the Required_*** vars that we just plotted\n        y_vars = [\n            v\n            for v in case.get(\"dependent_variables\", [])\n            if not v.startswith(\"Required_\")\n        ]\n\n        if x_var not in summary_df.columns:\n            print(\n                f\"Warning: Independent variable '{x_var}' not found in summary data for case '{case_name}'. Skipping.\"\n            )\n            continue\n\n        case_sim_params = case.get(\"default_simulation_values\", {})\n        hue_vars = sorted(list(case_sim_params.keys()))\n\n        for y_var in y_vars:\n            if y_var not in summary_df.columns:\n                print(\n                    f\"Warning: Dependent variable '{y_var}' not found in summary data for case '{case_name}'. Skipping.\"\n                )\n                continue\n\n            # We assume standard metrics have a 1-to-1 name match in the dataframe\n            valid_plots_for_combine.append(\n                {\n                    \"case_name\": case_name,\n                    \"x_var\": x_var,\n                    \"y_var\": y_var,\n                    \"plot_type\": \"line\",\n                    \"hue_vars\": hue_vars,\n                }\n            )\n\n    if valid_plots_for_combine:\n        combine_plots = any(case.get(\"combine_plots\", False) for case in analysis_cases)\n        generated_paths = []\n        if combine_plots:\n            generated_paths = _generate_combined_plots(\n                summary_df,\n                valid_plots_for_combine,\n                save_dir,\n                line_colors,\n                unit_map=unit_map,\n            )\n        else:\n            # If not combining, plot them individually anyway\n            generated_paths = _generate_individual_plots(\n                summary_df,\n                valid_plots_for_combine,\n                save_dir,\n                line_colors,\n                unit_map=unit_map,\n            )\n        plot_paths.extend(generated_paths)\n\n    return plot_paths\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.load_glossary","title":"<code>load_glossary(glossary_path)</code>","text":"<p>Loads glossary data from a CSV file.</p> <p>The CSV file should contain columns for the model parameter, the English term, and the Chinese translation. This data is used to format plot labels.</p> <p>Parameters:</p> Name Type Description Default <code>glossary_path</code> <code>str</code> <p>The path to the glossary CSV file.</p> required Note <p>Expected CSV columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\", and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Prints warning if file not found or columns missing. Clears existing glossary maps on error.</p> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def load_glossary(glossary_path: str) -&gt; None:\n    \"\"\"Loads glossary data from a CSV file.\n\n    The CSV file should contain columns for the model parameter, the English\n    term, and the Chinese translation. This data is used to format plot labels.\n\n    Args:\n        glossary_path: The path to the glossary CSV file.\n\n    Note:\n        Expected CSV columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\",\n        and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Prints warning if file not found or\n        columns missing. Clears existing glossary maps on error.\n    \"\"\"\n    global _english_glossary_map, _chinese_glossary_map\n\n    if not glossary_path or not os.path.exists(glossary_path):\n        print(\n            f\"Warning: Glossary file not found at {glossary_path}. No labels will be loaded.\"\n        )\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n        return\n\n    try:\n        df = pd.read_csv(glossary_path)\n        if (\n            \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\" in df.columns\n            and \"\u82f1\u6587\u672f\u8bed (English Term)\" in df.columns\n            and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\" in df.columns\n        ):\n            df.dropna(subset=[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"], inplace=True)\n            _english_glossary_map = pd.Series(\n                df[\"\u82f1\u6587\u672f\u8bed (English Term)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            _chinese_glossary_map = pd.Series(\n                df[\"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            print(f\"Successfully loaded glossary from {glossary_path}.\")\n        else:\n            print(\"Warning: Glossary CSV does not contain expected columns.\")\n            _english_glossary_map = {}\n            _chinese_glossary_map = {}\n    except Exception as e:\n        print(f\"Warning: Failed to load or parse glossary file. Error: {e}\")\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.plot_sweep_time_series","title":"<code>plot_sweep_time_series(csv_path, save_dir, y_var_name, independent_var_name, independent_var_alias=None, default_params=None, glossary_path=None)</code>","text":"<p>Generates a single figure with two subplots: an overall time-series view and a zoomed-in view.</p> <p>The time axis is in days. The overall view hides data points for a curve if they exceed twice its initial value.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>str</code> <p>Path to the scan result CSV file.</p> required <code>save_dir</code> <code>str</code> <p>Directory to save the image.</p> required <code>y_var_name</code> <code>Union[str, List[str]]</code> <p>Name(s) of the Y-axis variable(s).</p> required <code>independent_var_name</code> <code>str</code> <p>Full name of the scan parameter.</p> required <code>independent_var_alias</code> <code>str</code> <p>Alias for the scan parameter for cleaner plot titles.</p> <code>None</code> <code>default_params</code> <code>Dict[str, Any]</code> <p>A dictionary of default parameters. If provided, only curves matching these parameters will be plotted.</p> <code>None</code> <code>glossary_path</code> <code>str</code> <p>Path to the glossary file for professional labels.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of paths to the saved plot images, or an empty list on failure.</p> Note <p>Converts time from hours to days. Generates bilingual plots (English and Chinese). Overall view masks data exceeding 2x initial value. Zoomed view shows region from t=0 to 2 days past minimum, with red rectangle indicator on overall view. Data is converted from grams to kilograms for display.</p> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def plot_sweep_time_series(\n    csv_path: str,\n    save_dir: str,\n    y_var_name: Union[str, List[str]],\n    independent_var_name: str,\n    independent_var_alias: str = None,\n    default_params: Dict[str, Any] = None,\n    glossary_path: str = None,\n) -&gt; List[str]:\n    \"\"\"Generates a single figure with two subplots: an overall time-series view and a zoomed-in view.\n\n    The time axis is in days. The overall view hides data points for a curve if\n    they exceed twice its initial value.\n\n    Args:\n        csv_path: Path to the scan result CSV file.\n        save_dir: Directory to save the image.\n        y_var_name: Name(s) of the Y-axis variable(s).\n        independent_var_name: Full name of the scan parameter.\n        independent_var_alias: Alias for the scan parameter for cleaner plot titles.\n        default_params: A dictionary of default parameters. If provided, only curves\n            matching these parameters will be plotted.\n        glossary_path: Path to the glossary file for professional labels.\n\n    Returns:\n        A list of paths to the saved plot images, or an empty list on failure.\n\n    Note:\n        Converts time from hours to days. Generates bilingual plots (English and Chinese).\n        Overall view masks data exceeding 2x initial value. Zoomed view shows region from\n        t=0 to 2 days past minimum, with red rectangle indicator on overall view. Data is\n        converted from grams to kilograms for display.\n    \"\"\"\n    if glossary_path:\n        load_glossary(glossary_path)\n\n    try:\n        df = pd.read_csv(csv_path)\n    except FileNotFoundError:\n        print(f\"Error: Could not find results file at {csv_path}\")\n        return []\n\n    if \"time\" not in df.columns:\n        print(f\"Error: 'time' column not found in {csv_path}\")\n        return []\n\n    # Convert time from hours to days\n    time_days = df[\"time\"] / 24\n\n    # Use alias if provided, otherwise format the original name\n    raw_plot_alias = (\n        independent_var_alias if independent_var_alias else independent_var_name\n    )\n\n    if isinstance(y_var_name, str):\n        y_var_names = [y_var_name]\n    else:\n        y_var_names = y_var_name\n\n    y_var_columns = []\n    for y_var in y_var_names:\n        y_var_columns.extend(\n            [col for col in df.columns if col != \"time\" and y_var in col]\n        )\n    y_var_columns = list(dict.fromkeys(y_var_columns))\n\n    # If default_params are provided, filter columns to only plot baseline curves\n    if default_params:\n        filtered_columns = []\n        for col in y_var_columns:\n            try:\n                param_str = col.split(\"&amp;\", 1)[1]\n                col_params = dict(p.split(\"=\", 1) for p in param_str.split(\"&amp;\"))\n\n                # Check if all default_params match the parameters in the column name\n                is_match = all(\n                    col_params.get(key) == str(val)\n                    for key, val in default_params.items()\n                )\n\n                if is_match:\n                    filtered_columns.append(col)\n            except IndexError:\n                # This column does not have parameters in its name, so it can't be a match\n                continue\n        y_var_columns = filtered_columns\n\n    if not y_var_columns:\n        print(\n            f\"Warning: No columns found containing any of {y_var_names} in {csv_path} that match the criteria.\"\n        )\n        return []\n\n    # Convert y-axis data from grams to kilograms\n    for col in y_var_columns:\n        df[col] = df[col] / 1000.0\n\n    # Generate clean labels (values only) for the legend\n    plot_labels = []\n    for col in y_var_columns:\n        label = col\n        try:\n            param_parts = col.split(\"&amp;\")[1:]\n            for part in param_parts:\n                if part.startswith(independent_var_name + \"=\"):\n                    label = part.split(\"=\", 1)[1]  # Extract just the value\n                    break\n        except IndexError:\n            pass  # No parameters in name, use full column name\n        plot_labels.append(label)\n\n    print(\n        f\"Found {len(y_var_columns)} columns to plot containing {y_var_names}: {y_var_columns}\"\n    )\n\n    sns.set_theme(style=\"whitegrid\")\n    plot_paths = []\n    original_lang_is_chinese = _use_chinese_labels\n\n    for lang in [\"en\", \"cn\"]:\n        set_plot_language(lang)\n\n        colors = sns.color_palette(\"plasma\", len(y_var_columns))\n\n        # Create a figure with two subplots (overall and zoom)\n        fig, (ax1, ax2) = plt.subplots(\n            2, 1, figsize=(12, 16), sharex=False, gridspec_kw={\"height_ratios\": [2, 1]}\n        )\n        y_var_names_formatted = [_format_label(y) for y in y_var_names]\n\n        min_y_global = float(\"inf\")\n        min_x_global = float(\"inf\")\n\n        # Define the y-axis label with units\n        y_label = f\"{', '.join(y_var_names_formatted)} ({_get_text('kg')})\"\n\n        # --- Subplot 1: Overall View ---\n        for i, column in enumerate(y_var_columns):\n            y_data = df[column]\n\n            # For the global view, mask data that is more than 2x the initial value\n            if not y_data.empty:\n                initial_value = y_data.iloc[0]\n                threshold = 2 * initial_value\n                y_masked = y_data.where(y_data &lt;= threshold)\n            else:\n                y_masked = y_data\n\n            ax1.plot(\n                time_days,\n                y_masked,\n                label=plot_labels[i],\n                color=colors[i],\n                linewidth=1.2,\n                alpha=0.85,\n            )\n\n            # Calculations for zoom window should use the original, unmasked data\n            if not y_data.empty:\n                min_idx = y_data.idxmin()\n                current_min_y = y_data.loc[min_idx]\n                if current_min_y &lt; min_y_global:\n                    min_y_global = current_min_y\n                    min_x_global = time_days.loc[min_idx]\n\n        ax1.set_ylabel(y_label, fontsize=12)\n        ax1.set_title(_get_text(\"overall_view\"), fontsize=12)\n        ax1.legend(loc=\"best\", title=_format_label(independent_var_name))\n        ax1.grid(True)\n\n        # --- Subplot 2: Zoomed-in View (uses original data) ---\n        if min_y_global != float(\"inf\") and np.isfinite(min_y_global):\n            for i, column in enumerate(y_var_columns):\n                # Plot original, unmasked data in the zoom plot\n                ax2.plot(\n                    time_days,\n                    df[column],\n                    label=plot_labels[i],\n                    color=colors[i],\n                    linewidth=1.8,\n                    alpha=0.9,\n                )\n\n            # Define the zoom window from t=0 to a bit after the minimum\n            x1 = 0\n            x2 = min_x_global + 2  # Show 2 days past the minimum\n\n            # Filter the DataFrame to the new x-range to find the y-range\n            zoom_mask = (time_days &gt;= x1) &amp; (time_days &lt;= x2)\n            df_zoom_range = df[zoom_mask]\n\n            # Find y-min and y-max within this specific range\n            y_min_in_range = df_zoom_range[y_var_columns].min().min()\n            y_max_in_range = df_zoom_range[y_var_columns].max().max()\n\n            # Add padding to the y-axis\n            y_padding = (y_max_in_range - y_min_in_range) * 0.05\n            y1 = y_min_in_range - y_padding\n            y2 = y_max_in_range + y_padding\n\n            ax2.set_xlim(x1, x2)\n            ax2.set_ylim(y1, y2)\n\n            ax2.set_xlabel(_get_text(\"time_days\"), fontsize=12)\n            ax2.set_ylabel(y_label, fontsize=12)\n            ax2.set_title(_get_text(\"detailed_view\"), fontsize=12)\n            ax2.grid(True, linestyle=\"--\")\n\n            # Add a rectangle to the main plot to indicate the new zoom area\n            rect = patches.Rectangle(\n                (x1, y1),\n                (x2 - x1),\n                (y2 - y1),\n                linewidth=1,\n                edgecolor=\"r\",\n                facecolor=\"none\",\n                linestyle=\"--\",\n                alpha=0.7,\n            )\n            ax1.add_patch(rect)\n        else:\n            # If no zoom, hide the second subplot\n            ax2.set_visible(False)\n\n        ax1.set_xlabel(_get_text(\"time_days\"), fontsize=12)\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust for suptitle\n\n        # --- Save Figure ---\n        safe_y_vars = \"_\".join(\n            [\n                var.replace(\".\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\")\n                for var in y_var_names\n            ]\n        )\n        safe_param = raw_plot_alias.replace(\".\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\")\n        suffix = \"_zh\" if lang == \"cn\" else \"\"\n        svg_path = os.path.join(\n            save_dir, f\"sweep_{safe_y_vars}_vs_{safe_param}{suffix}.svg\"\n        )\n\n        try:\n            # Force text to be rendered as paths in SVG.\n            plt.rcParams[\"svg.fonttype\"] = \"path\"\n            plt.savefig(svg_path, format=\"svg\", bbox_inches=\"tight\")\n            print(f\"Successfully generated combined sweep plot: {svg_path}\")\n            plot_paths.append(svg_path)\n        except Exception as e:\n            print(f\"Error saving plot: {e}\")\n        finally:\n            plt.close(fig)\n\n    set_plot_language(\"cn\" if original_lang_is_chinese else \"en\")\n    return plot_paths\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.plot.set_plot_language","title":"<code>set_plot_language(lang='en')</code>","text":"<p>Sets the preferred language for plot labels and text.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>The language to set. 'en' for English (default), 'cn' for Chinese.</p> <code>'en'</code> Note <p>For Chinese language, sets font to SimHei and adjusts unicode_minus handling. For English, restores matplotlib default settings. Changes apply to all subsequent plots until called again.</p> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def set_plot_language(lang: str = \"en\") -&gt; None:\n    \"\"\"Sets the preferred language for plot labels and text.\n\n    Args:\n        lang: The language to set. 'en' for English (default), 'cn' for Chinese.\n\n    Note:\n        For Chinese language, sets font to SimHei and adjusts unicode_minus handling.\n        For English, restores matplotlib default settings. Changes apply to all\n        subsequent plots until called again.\n    \"\"\"\n    global _use_chinese_labels\n    _use_chinese_labels = lang.lower() == \"cn\"\n\n    if _use_chinese_labels:\n        # To display Chinese characters correctly, specify a list of fallback fonts.\n        plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # \u66ff\u6362\u6210\u4f60\u7535\u8111\u4e0a\u6709\u7684\u5b57\u4f53\n        plt.rcParams[\"axes.unicode_minus\"] = False  # To display minus sign correctly.\n        plt.rcParams[\"font.family\"] = \"sans-serif\"  # \u786e\u4fdd\u5b57\u4f53\u5bb6\u65cf\u8bbe\u7f6e\u751f\u6548\n    else:\n        # Restore default settings\n        plt.rcParams[\"font.sans-serif\"] = plt.rcParamsDefault[\"font.sans-serif\"]\n        plt.rcParams[\"axes.unicode_minus\"] = plt.rcParamsDefault[\"axes.unicode_minus\"]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.call_openai_analysis_api","title":"<code>call_openai_analysis_api(case_name, df, api_key, base_url, ai_model, independent_variable, report_content, original_config, case_data, reference_col_for_turning_point=None)</code>","text":"<p>Constructs a text-only prompt, calls the OpenAI API for analysis, and returns the result string.</p> <p>Parameters:</p> Name Type Description Default <code>case_name</code> <code>str</code> <p>Name of the analysis case.</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame containing summary data.</p> required <code>api_key</code> <code>str</code> <p>OpenAI API key.</p> required <code>base_url</code> <code>str</code> <p>Base URL for the OpenAI API.</p> required <code>ai_model</code> <code>str</code> <p>Model name to use for analysis.</p> required <code>independent_variable</code> <code>str</code> <p>Name of the independent variable.</p> required <code>report_content</code> <code>str</code> <p>The report content to analyze.</p> required <code>original_config</code> <code>dict</code> <p>Original configuration dictionary.</p> required <code>case_data</code> <code>dict</code> <p>Case-specific data dictionary.</p> required <code>reference_col_for_turning_point</code> <code>str</code> <p>Optional reference column for turning point analysis.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The combined prompt and LLM analysis result, or None if failed.</p> Note <p>Constructs dynamic prompts based on case configuration. Includes sections for global sensitivity analysis, interaction effects (if simulation parameters present), and dynamic process analysis (if reference column provided). Retries up to 3 times on failure with 5-second delays.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def call_openai_analysis_api(\n    case_name: str,\n    df: pd.DataFrame,\n    api_key: str,\n    base_url: str,\n    ai_model: str,\n    independent_variable: str,\n    report_content: str,\n    original_config: dict,\n    case_data: dict,\n    reference_col_for_turning_point: str = None,\n) -&gt; Optional[str]:\n    \"\"\"Constructs a text-only prompt, calls the OpenAI API for analysis, and returns the result string.\n\n    Args:\n        case_name: Name of the analysis case.\n        df: DataFrame containing summary data.\n        api_key: OpenAI API key.\n        base_url: Base URL for the OpenAI API.\n        ai_model: Model name to use for analysis.\n        independent_variable: Name of the independent variable.\n        report_content: The report content to analyze.\n        original_config: Original configuration dictionary.\n        case_data: Case-specific data dictionary.\n        reference_col_for_turning_point: Optional reference column for turning point analysis.\n\n    Returns:\n        The combined prompt and LLM analysis result, or None if failed.\n\n    Note:\n        Constructs dynamic prompts based on case configuration. Includes sections for\n        global sensitivity analysis, interaction effects (if simulation parameters present),\n        and dynamic process analysis (if reference column provided). Retries up to 3 times\n        on failure with 5-second delays.\n    \"\"\"\n    try:\n        logger.info(f\"Proceeding with LLM analysis for case {case_name}.\")\n\n        # 1. Construct the prompt for the API\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u805a\u53d8\u53cd\u5e94\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u7684\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7**\u5b8c\u5168\u57fa\u4e8e**\u4e0b\u65b9\u63d0\u4f9b\u7684**\u4e24\u7c7b\u6570\u636e\u8868\u683c**\uff0c\u5bf9\u805a\u53d8\u5806\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684**\u654f\u611f\u6027\u5206\u6790**\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\u3002\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n**\u5206\u6790\u6570\u636e\uff1a**(\u6ce8\u610f\uff1a\u5206\u6790\u4e2d\u4e0d\u53ef\u4f7f\u7528\u4efb\u4f55\u56fe\u8868\u4fe1\u606f\uff0c\u6240\u6709\u7ed3\u8bba\u5fc5\u987b\u6e90\u4e8e\u6570\u636e\u8868\u683c\u3002)\n\n{report_content}\n\"\"\"\n\n        # --- Dynamic Prompt Construction ---\n\n        # 1. Detect analysis scenario\n        has_sim_params = bool(case_data.get(\"simulation_parameters\"))\n\n        # 2. Build prompt sections dynamically\n        prompt_sections = []\n\n        # Section 1: Global Sensitivity Analysis\n        global_sensitivity_points = [\n            \"1.  **\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (\u53c2\u8003\u201c\u6027\u80fd\u6307\u6807\u603b\u8868\u201d) :**\",\n            \"    *   \u5206\u6790\u6027\u80fd\u6307\u6807\u603b\u8868\uff08 `Startup_Inventory`, `Doubling_Time` \u4ee5\u53ca\u4ee5 `Required_` \u5f00\u5934\u7684\u6c42\u89e3\u6307\u6807\u7b49\uff09\u5448\u73b0\u51fa\u600e\u6837\u7684**\u603b\u4f53\u8d8b\u52bf**\uff1f\u8bf7\u8fdb\u884c\u91cf\u5316\u63cf\u8ff0\u3002\",\n            f\"    *   \u5982\u679c\u5b58\u5728\u591a\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u6790\u54ea\u4e2a\u6027\u80fd\u6307\u6807\u5bf9\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u7684\u53d8\u5316\u6700\u4e3a\u654f\u611f\uff1f\u54ea\u4e2a\u6700\u4e0d\u654f\u611f\uff1f\\n\",\n        ]\n\n        # Interaction effect analysis, with refined description\n        if has_sim_params:\n            param_names_list = []\n            for p in case_data[\"simulation_parameters\"].keys():\n                if p == \"Required_TBR\":\n                    label = \"`Required_TBR\u7ea6\u675f\u503c (hour)`\"\n                else:\n                    label = f\"`{p}`\"\n                param_names_list.append(label)\n            param_names = \", \".join(param_names_list)\n\n            interaction_text = (\n                f\"2.  **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a** \u672c\u6b21\u5206\u6790\u5305\u542b\u4e86\u591a\u53d8\u91cf\u7684\u4ea4\u4e92\u6548\u5e94\u3002\u8bf7\u5206\u6790\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \"\n                f\"\u4e0e\u80cc\u666f\u626b\u63cf\u53c2\u6570 ({param_names}) \u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u5404\u9879\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\u3002\"\n                \"\u8bf7\u6ce8\u610f\uff0c\u72ec\u7acb\u53d8\u91cf\u6216\u80cc\u666f\u626b\u63cf\u53c2\u6570\u4e2d\uff0c\u53ef\u80fd\u5305\u542b\u5e38\u89c4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u53ef\u80fd\u5305\u542b\u4e3a\u6ee1\u8db3\u7279\u5b9a\u6027\u80fd\u76ee\u6807\uff08\u9650\u5236\u500d\u589e\u65f6\u95f4Double_Time\u8fbe\u5230\u500d\u589e\uff09\u800c\u6c42\u89e3\u51fa\u7684\u7279\u6b8a\u53d8\u91cf\uff08\u7ea6\u675f\u9650\u5236\u53d8\u91cfDouble_Time\uff09\u3002\"\n                \"\u8bf7\u8ba8\u8bba\u5728\u4e0d\u540c\u7684\u53d8\u91cf\u7ec4\u5408\u4e0b\uff0c\u6027\u80fd\u6307\u6807\u7684\u654f\u611f\u6027\u6709\u4f55\u4e0d\u540c\uff1f\u662f\u5426\u5b58\u5728\u663e\u8457\u7684\u4ea4\u4e92\u6548\u5e94\uff1f\"\n            )\n            global_sensitivity_points.append(interaction_text)\n\n        prompt_sections.append(\"\\n\".join(global_sensitivity_points))\n\n        # Section 2: Dynamic Process Analysis\n        if reference_col_for_turning_point:\n            dynamic_process_points = [\n                \"3.  **\u52a8\u6001\u8fc7\u7a0b\u5206\u6790 (\u53c2\u8003\u201c\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u8fc7\u7a0b\u6570\u636e\u201d) :**\",\n                \"    *   \u89c2\u5bdf\u8fc7\u7a0b\u6570\u636e\u5207\u7247\uff1a\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u9636\u6bb5\u201d\u548c\u201c\u7ed3\u675f\u9636\u6bb5\u201d\u7684\u884c\u4e3a\u6709\u4f55\u4e0d\u540c\uff1f\",\n                f\"    *   \u4ee5 `{reference_col_for_turning_point}` \u4e3a\u53c2\u8003\uff0c\u5176\u201c\u8f6c\u6298\u70b9\u9636\u6bb5\u201d\u7684\u6570\u636e\u63ed\u793a\u4e86\u4ec0\u4e48\u7269\u7406\u8fc7\u7a0b\uff1f\uff08\u4f8b\u5982\uff0c\u5b83\u662f\u5426\u662f\u6c1a\u5e93\u5b58\u7531\u6d88\u8017\u8f6c\u4e3a\u51c0\u589e\u957f\u7684\u5173\u952e\u65f6\u523b\uff1f\uff09\",\n            ]\n            prompt_sections.append(\"\\n\".join(dynamic_process_points))\n\n        # Section 3: Overall Conclusion (renumbered from 4)\n        conclusion_points = [\"3.  **\u7efc\u5408\u7ed3\u8bba\uff1a**\"]\n        conclusion_intro = \"\u7ed3\u5408\u6240\u6709\u5206\u6790\uff08\u5305\u62ec\u4e3b\u8d8b\u52bf\"\n        if has_sim_params:\n            conclusion_intro += \"\u3001\u80cc\u666f\u53c2\u6570\u4ea4\u4e92\u6548\u5e94\"\n        conclusion_intro += \"\uff09\uff0c\"\n\n        conclusion_points.append(\n            conclusion_intro\n            + f\"\u603b\u7ed3\u5728\u4e0d\u540c\u7684\u8fd0\u884c\u573a\u666f\u4e0b\uff0c\u8c03\u6574 `{independent_variable}` \u5bf9\u6574\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u7684\u7efc\u5408\u5f71\u54cd\u548c\u6f5c\u5728\u7684\u5229\u5f0a\u6743\u8861\u3002\"\n        )\n        conclusion_points.append(\n            \"    *   \u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u53ef\u4ee5\u5f97\u51fa\u54ea\u4e9b\u5173\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\u6216\u8fd0\u884c\u4f18\u5316\u7684\u521d\u6b65\u5efa\u8bae\uff1f\"\n        )\n        prompt_sections.append(\"\\n\".join(conclusion_points))\n\n        # Assemble the final prompt\n        points_prompt = \"\\n\\n\".join(prompt_sections)\n        points_prompt = (\n            \"\\n**\u5206\u6790\u8981\u70b9 (\u5fc5\u987b\u4e25\u683c\u4f9d\u636e\u6570\u636e\u8868\u683c\u4f5c\u7b54)\uff1a**\\n\\n\" + points_prompt\n        )\n\n        # 2. Call API with retry logic\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for case {case_name} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, analysis_prompt, points_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                analysis_result = response.choices[0].message.content\n\n                logger.info(f\"LLM analysis successful for case {case_name}.\")\n                return (\n                    role_prompt\n                    + points_prompt\n                    + \"\\n```\\n\\n\"\n                    + \"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\"\n                    + analysis_result\n                )  # Return the result string\n\n            except Exception as e:\n                logger.error(f\"Error calling OpenAI API on attempt {attempt + 1}: {e}\")\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to call OpenAI API after {max_retries} attempts.\"\n                    )\n                    return None  # Return None on failure\n\n    except Exception as e:\n        logger.error(\n            f\"Error in call_openai_analysis_api for case {case_name}: {e}\",\n            exc_info=True,\n        )\n        return None\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.consolidate_reports","title":"<code>consolidate_reports(case_configs, original_config)</code>","text":"<p>Consolidates generated reports and their images into a 'report' directory for each case.</p> <p>Parameters:</p> Name Type Description Default <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries.</p> required <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary.</p> required Note <p>Moves analysis reports, academic reports, and plot images from results directory to report directory. Uses move operation (not copy). Creates report directory if it doesn't exist. Skips cases where source directory not found.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def consolidate_reports(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Consolidates generated reports and their images into a 'report' directory for each case.\n\n    Args:\n        case_configs: List of case configuration dictionaries.\n        original_config: Original configuration dictionary.\n\n    Note:\n        Moves analysis reports, academic reports, and plot images from results directory\n        to report directory. Uses move operation (not copy). Creates report directory\n        if it doesn't exist. Skips cases where source directory not found.\n    \"\"\"\n    logger.info(\"Consolidating analysis reports...\")\n    try:\n        for case_info in case_configs:\n            case_workspace = case_info[\"workspace\"]\n            source_dir = os.path.join(case_workspace, \"results\")\n            dest_dir = os.path.join(case_workspace, \"report\")\n\n            if not os.path.isdir(source_dir):\n                logger.warning(\n                    f\"Source directory not found, skipping consolidation for case: {case_workspace}\"\n                )\n                continue\n\n            # Find files to copy\n            files_to_copy = []\n            for filename in os.listdir(source_dir):\n                if (\n                    filename.startswith(\"analysis_report\")\n                    or filename.startswith(\"academic_report\")\n                ) and filename.endswith(\".md\"):\n                    files_to_copy.append(filename)\n                elif filename.endswith((\".svg\", \".png\")):\n                    files_to_copy.append(filename)\n\n            if not files_to_copy:\n                logger.info(\n                    f\"No reports or images found in {source_dir}, skipping consolidation.\"\n                )\n                continue\n\n            # Create destination directory and copy files\n            os.makedirs(dest_dir, exist_ok=True)\n            logger.info(f\"Consolidating reports into: {dest_dir}\")\n\n            for filename in files_to_copy:\n                source_path = os.path.join(source_dir, filename)\n                shutil.move(source_path, dest_dir)\n                logger.info(f\"Moved {filename} to {dest_dir}\")\n\n    except Exception as e:\n        logger.error(f\"Error during report consolidation: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.generate_analysis_cases_summary","title":"<code>generate_analysis_cases_summary(case_configs, original_config)</code>","text":"<p>Generate summary report for analysis_cases.</p> <p>Parameters:</p> Name Type Description Default <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries.</p> required <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary containing run timestamp.</p> required Note <p>Creates an execution report with basic information, case details, and status. Saves report to {run_timestamp}/execution_report_{run_timestamp}.md in current working directory. Also triggers generate_prompt_templates and consolidate_reports. Logs summary of successfully executed cases.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def generate_analysis_cases_summary(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Generate summary report for analysis_cases.\n\n    Args:\n        case_configs: List of case configuration dictionaries.\n        original_config: Original configuration dictionary containing run timestamp.\n\n    Note:\n        Creates an execution report with basic information, case details, and status.\n        Saves report to {run_timestamp}/execution_report_{run_timestamp}.md in current\n        working directory. Also triggers generate_prompt_templates and consolidate_reports.\n        Logs summary of successfully executed cases.\n    \"\"\"\n    try:\n        run_timestamp = original_config[\"run_timestamp\"]\n        # Generate report in current working directory\n        current_dir = os.getcwd()\n\n        # Create summary report\n        summary_data = []\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n            case_workspace = case_info[\"workspace\"]\n\n            # Check if case results exist\n            case_results_dir = os.path.join(case_workspace, \"results\")\n            has_results = (\n                os.path.exists(case_results_dir)\n                and len(os.listdir(case_results_dir)) &gt; 0\n            )\n\n            summary_entry = {\n                \"case_name\": case_data.get(\"name\", f\"Case{case_info['index']+1}\"),\n                \"independent_variable\": case_data[\"independent_variable\"],\n                \"independent_variable_sampling\": case_data[\n                    \"independent_variable_sampling\"\n                ],\n                \"workspace_path\": case_workspace,\n                \"has_results\": has_results,\n                \"config_file\": case_info[\"config_path\"],\n            }\n            summary_data.append(summary_entry)\n\n        # Generate text report\n        report_lines = [\n            \"# Analysis Cases Execution Report\",\n            \"\\n## Basic Information\",\n            f\"- Execution time: {run_timestamp}\",\n            f\"- Total cases: {len(case_configs)}\",\n            f\"- Successfully executed: {sum(1 for entry in summary_data if entry['has_results'])}\",\n            f\"- Working directory: {current_dir}\",\n            \"\\n## Case Details\",\n        ]\n\n        for i, entry in enumerate(summary_data, 1):\n            status = \"\u2713 Success\" if entry[\"has_results\"] else \"\u2717 Failed\"\n            report_lines.extend(\n                [\n                    f\"\\n### {i}. {entry['case_name']}\",\n                    f\"- Status: {status}\",\n                    f\"- Independent variable: {entry['independent_variable']}\",\n                    f\"- Sampling method: {entry['independent_variable_sampling']}\",\n                    f\"- Working directory: {entry['workspace_path']}\",\n                    f\"- Configuration file: {entry['config_file']}\",\n                ]\n            )\n\n        # Save report to current directory\n        report_path = os.path.join(\n            current_dir,\n            run_timestamp,\n            f\"execution_report_{run_timestamp}.md\",\n        )\n        os.makedirs(os.path.dirname(report_path), exist_ok=True)\n        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(report_lines))\n\n        logger.info(\"Summary report generated:\")\n        logger.info(f\"  - Detailed report: {report_path}\")\n\n        # Generate prompt engineering template for each case\n        generate_prompt_templates(case_configs, original_config)\n\n        # Consolidate all generated reports\n        consolidate_reports(case_configs, original_config)\n\n    except Exception as e:\n        logger.error(f\"Error generating summary report: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.generate_prompt_templates","title":"<code>generate_prompt_templates(case_configs, original_config)</code>","text":"<p>Generate detailed Markdown analysis reports for each analysis case.</p> <p>Parameters:</p> Name Type Description Default <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries containing case data and workspace info.</p> required <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary with sensitivity analysis settings.</p> required Note <p>Skips SALib cases (those with analyzer.method defined). For each case, generates a detailed Markdown report including configuration details, optimization configs, time-series plots, performance metric plots, and data tables. Supports AI-enhanced reporting if API credentials are available. Creates bilingual plots prioritizing Chinese versions (_zh suffix).</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def generate_prompt_templates(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Generate detailed Markdown analysis reports for each analysis case.\n\n    Args:\n        case_configs: List of case configuration dictionaries containing case data and workspace info.\n        original_config: Original configuration dictionary with sensitivity analysis settings.\n\n    Note:\n        Skips SALib cases (those with analyzer.method defined). For each case, generates\n        a detailed Markdown report including configuration details, optimization configs,\n        time-series plots, performance metric plots, and data tables. Supports AI-enhanced\n        reporting if API credentials are available. Creates bilingual plots prioritizing\n        Chinese versions (_zh suffix).\n    \"\"\"\n\n    def _find_unit_config(var_name: str, unit_map: dict) -&gt; dict | None:\n        \"\"\"\n        Finds the unit configuration for a variable name from the unit_map.\n        1. Checks for an exact match.\n        2. Checks if the last part of a dot-separated name matches.\n        3. Checks for a simple substring containment as a fallback, matching longest keys first.\n        \"\"\"\n        if not unit_map or not var_name:\n            return None\n        if var_name in unit_map:\n            return unit_map[var_name]\n        components = var_name.split(\".\")\n        if len(components) &gt; 1 and components[-1] in unit_map:\n            return unit_map[components[-1]]\n        for key in sorted(unit_map.keys(), key=len, reverse=True):\n            if key in var_name:\n                return unit_map[key]\n        return None\n\n    def _format_label(label: str) -&gt; str:\n        \"\"\"Formats a label for display, replacing underscores/dots with spaces and capitalizing each word.\"\"\"\n        if not isinstance(label, str):\n            return label\n        label = label.replace(\"_\", \" \")\n        label = re.sub(r\"(?&lt;!\\d)\\.|\\.(?!\\d)\", \" \", label)\n        return label  # .title()\n\n    try:\n        sensitivity_analysis_config = original_config.get(\"sensitivity_analysis\", {})\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n\n            if \"analyzer\" in case_data and case_data.get(\"analyzer\", {}).get(\"method\"):\n                logger.info(\n                    f\"Skipping default report generation for SALib case: {case_data.get('name', 'Unknown')}\"\n                )\n                continue\n\n            case_workspace = case_info[\"workspace\"]\n            case_name = case_data.get(\"name\", f\"Case{case_info['index']+1}\")\n\n            case_results_dir = os.path.join(case_workspace, \"results\")\n            if not os.path.exists(case_results_dir):\n                continue\n\n            summary_csv_path = os.path.join(\n                case_results_dir, \"sensitivity_analysis_summary.csv\"\n            )\n            sweep_csv_path = os.path.join(case_results_dir, \"sweep_results.csv\")\n\n            if not os.path.exists(summary_csv_path):\n                logger.warning(\n                    f\"summary_csv not found for case {case_name}, skipping report generation.\"\n                )\n                continue\n\n            summary_df = pd.read_csv(summary_csv_path)\n            independent_variable = case_data.get(\"independent_variable\", \"\u71c3\u70e7\u7387\")\n\n            # Use a dictionary to ensure we only get one version of each plot, prioritizing Chinese\n            all_plots_all_langs = [\n                f for f in os.listdir(case_results_dir) if f.endswith(\".svg\")\n            ]\n            plot_map = {}\n            for plot in sorted(\n                all_plots_all_langs, reverse=True\n            ):  # Process _zh.svg first\n                base_name = plot.replace(\"_zh.svg\", \".svg\")\n                if base_name not in plot_map:\n                    plot_map[base_name] = plot\n\n            all_plots = list(plot_map.values())\n            sweep_plots = [f for f in all_plots if f.startswith(\"sweep_\")]\n            combined_plots = [f for f in all_plots if f.startswith(\"combined_\")]\n            multi_metric_plots = [\n                f\n                for f in all_plots\n                if f.startswith(\"multi_\") and f.endswith(\"_analysis_by_param.svg\")\n            ]\n            all_individual_plots = [\n                f\n                for f in all_plots\n                if not f.startswith(\"sweep_\")\n                and not f.startswith(\"combined_\")\n                and not f.startswith(\"multi_\")\n            ]\n            required_individual_plots = [\n                f for f in all_individual_plots if f.startswith(\"line_Required_\")\n            ]\n            standard_individual_plots = [\n                f for f in all_individual_plots if not f.startswith(\"line_Required_\")\n            ]\n\n            # --- Markdown Generation (with dynamic title) ---\n            sim_params = case_data.get(\"simulation_parameters\")\n            if sim_params:\n                main_var_label = _format_label(independent_variable)\n\n                other_vars_labels_list = []\n                for p in sim_params.keys():\n                    if p == \"Required_TBR\":\n                        label = \"Required_TBR\u7ea6\u675f\u503c\"\n                    else:\n                        label = _format_label(p)\n                    other_vars_labels_list.append(label)\n                other_vars_labels = \"\u3001\".join(other_vars_labels_list)\n\n                report_title = (\n                    f\"# {main_var_label} \u4e0e {other_vars_labels} \u4ea4\u4e92\u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n                )\n            else:\n                report_title = (\n                    f\"# {_format_label(independent_variable)} \u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n                )\n\n            prompt_lines = [\n                report_title,\n                f\"\u751f\u6210\u65f6\u95f4: {pd.Timestamp.now()}\\n\\n\",\n            ]\n\n            config_details_lines = [\n                \"## \u5206\u6790\u6848\u4f8b\u914d\u7f6e\u8be6\u60c5\\n\\n\",\n                \"\u672c\u5206\u6790\u6848\u4f8b\u7684\u5177\u4f53\u914d\u7f6e\u5982\u4e0b\uff0c\u8fd9\u51b3\u5b9a\u4e86\u4eff\u771f\u7684\u626b\u63cf\u65b9\u5f0f\u548c\u5206\u6790\u7684\u91cd\u70b9\uff1a\\n\\n\",\n                \"| \u914d\u7f6e\u9879 | \u503c | \u8bf4\u660e |\",\n                \"| :--- | :--- | :--- |\",\n            ]\n\n            def format_for_md(value):\n                return f\"`{json.dumps(value, ensure_ascii=False)}`\".replace(\"|\", \"\\\\|\")\n\n            config_details_lines.extend(\n                [\n                    f\"| **`name`** | {format_for_md(case_name)} | \u672c\u6b21\u5206\u6790\u6848\u4f8b\u7684\u540d\u79f0\u3002 |\",\n                    f\"| **`independent_variable`** | {format_for_md(independent_variable)} | \u72ec\u7acb\u626b\u63cf\u53d8\u91cf\uff0c\u5373\u672c\u6b21\u5206\u6790\u4e2d\u4e3b\u8981\u6539\u53d8\u7684\u53c2\u6570\u3002 |\",\n                    f\"| **`independent_variable_sampling`** | {format_for_md(case_data.get('independent_variable_sampling'))} | \u72ec\u7acb\u53d8\u91cf\u7684\u91c7\u6837\u65b9\u6cd5\u548c\u8303\u56f4\u3002 |\",\n                ]\n            )\n            if \"default_independent_values\" in case_data:\n                config_details_lines.append(\n                    f\"| **`default_independent_values`** | {format_for_md(case_data['default_independent_values'])} | \u72ec\u7acb\u626b\u63cf\u53d8\u91cf\u5728\u6a21\u578b\u4e2d\u7684\u539f\u59cb\u9ed8\u8ba4\u503c\u3002 |\"\n                )\n            if (\n                \"simulation_parameters\" in case_data\n                and case_data[\"simulation_parameters\"]\n            ):\n                config_details_lines.append(\n                    f\"| **`simulation_parameters`** | {format_for_md(case_data['simulation_parameters'])} | \u80cc\u666f\u626b\u63cf\u53c2\u6570\uff0c\u4e0e\u72ec\u7acb\u53d8\u91cf\u7ec4\u5408\u5f62\u6210\u591a\u7ef4\u626b\u63cf\u3002 |\"\n                )\n            if (\n                \"default_simulation_values\" in case_data\n                and case_data[\"default_simulation_values\"]\n            ):\n                config_details_lines.append(\n                    f\"| **`default_simulation_values`** | {format_for_md(case_data['default_simulation_values'])} | \u80cc\u666f\u626b\u63cf\u53c2\u6570\u5728\u6a21\u578b\u4e2d\u7684\u539f\u59cb\u9ed8\u8ba4\u503c\u3002 |\"\n                )\n            config_details_lines.append(\n                f\"| **`dependent_variables`** | {format_for_md(case_data.get('dependent_variables'))} | \u56e0\u53d8\u91cf\uff0c\u5373\u6211\u4eec\u5173\u5fc3\u7684\u3001\u968f\u81ea\u53d8\u91cf\u53d8\u5316\u7684\u6027\u80fd\u6307\u6807\u3002 |\"\n            )\n            config_details_lines.append(\"\\n\")\n            prompt_lines.extend(config_details_lines)\n\n            optimization_metrics = [\n                v\n                for v in case_data.get(\"dependent_variables\", [])\n                if v.startswith(\"Required_\")\n            ]\n            if optimization_metrics:\n                for metric_name in optimization_metrics:\n                    metric_config = (\n                        original_config.get(\"sensitivity_analysis\", {})\n                        .get(\"metrics_definition\", {})\n                        .get(metric_name)\n                    )\n                    if metric_config:\n                        details_lines = [\n                            f\"## \u201c{metric_name}\u201d\u4f18\u5316\u914d\u7f6e\\n\",\n                            f\"\u5f53\u201c{metric_name}\u201d\u4f5c\u4e3a\u56e0\u53d8\u91cf\u65f6\uff0c\u7cfb\u7edf\u4f1a\u542f\u7528\u4e00\u4e2a\u4e8c\u5206\u67e5\u627e\u7b97\u6cd5\u6765\u5bfb\u627e\u6ee1\u8db3\u7279\u5b9a\u6027\u80fd\u6307\u6807\u7684\u6700\u5c0f`{metric_config.get('parameter_to_optimize', 'N/A')}`\u503c\u3002\u4ee5\u4e0b\u662f\u672c\u6b21\u4f18\u5316\u4efb\u52a1\u7684\u5177\u4f53\u914d\u7f6e\uff1a\\n\\n\",\n                            \"| \u914d\u7f6e\u9879 | \u503c | \u8bf4\u660e |\",\n                            \"| :--- | :--- | :--- |\",\n                        ]\n                        config_map = {\n                            \"source_column\": \"\u9650\u5236\u6761\u4ef6\u7684\u6570\u636e\u6e90\u5217\u3002\",\n                            \"parameter_to_optimize\": \"\u4f18\u5316\u7684\u76ee\u6807\u53c2\u6570\u3002\",\n                            \"search_range\": \"\u53c2\u6570\u7684\u641c\u7d22\u8303\u56f4\u3002\",\n                            \"tolerance\": \"\u641c\u7d22\u7684\u6536\u655b\u7cbe\u5ea6\u3002\",\n                            \"max_iterations\": \"\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002\",\n                            \"metric_name\": \"\u9650\u5236\u6761\u4ef6\u7684\u6027\u80fd\u6307\u6807\u3002\",\n                            \"metric_max_value\": \"\u9650\u5236\u6761\u4ef6\u6ee1\u8db3\u7684\u4e0a\u9650\u503c\u3002\uff08hour\uff09\",\n                        }\n                        for key, description in config_map.items():\n                            if key in metric_config:\n                                value = metric_config[key]\n                                details_lines.append(\n                                    f\"| **`{key}`** | {format_for_md(value)} | {description} |\"\n                                )\n\n                            metric_config_sim = case_data.get(\n                                \"simulation_parameters\", {}\n                            ).get(\"Required_TBR\", {})\n                            if metric_config_sim and key in metric_config_sim:\n                                value = metric_config_sim[key]\n                                details_lines.append(\n                                    f\"| **`{key} (from simulation_parameters)`** | {format_for_md(value)} | {description} |\"\n                                )\n\n                        details_lines.append(\"\\n\")\n                        prompt_lines.extend(details_lines)\n\n            for plot in sweep_plots:\n                prompt_lines.extend(\n                    [\n                        \"## SDS Inventory \u7684\u65f6\u95f4\u66f2\u7ebf\u56fe:\\n\\n\",\n                        f\"![SDS Inventory \u7684\u65f6\u95f4\u66f2\u7ebf\u56fe]({plot})\\n\\n\",\n                    ]\n                )\n                if \"default_simulation_values\" in case_data and case_data.get(\n                    \"default_simulation_values\"\n                ):\n                    default_values_str = json.dumps(\n                        case_data[\"default_simulation_values\"],\n                        ensure_ascii=False,\n                        indent=4,\n                    )\n                    note = (\n                        \"**\u7b5b\u9009\u8bf4\u660e**\uff1a\u5f53\u5b58\u5728\u591a\u4e2a\u80cc\u666f\u626b\u63cf\u53c2\u6570 (`simulation_parameters`) \u65f6\uff0c\u4e3a\u7a81\u51fa\u91cd\u70b9\uff0c\u4e0a\u56fe\u9ed8\u8ba4\u4ec5\u663e\u793a\u4e0e\u539f\u59cb\u9ed8\u8ba4\u503c \"\n                        f\"(`default_simulation_values`) \u76f8\u5339\u914d\u7684\u57fa\u51c6\u60c5\u666f\u66f2\u7ebf\u3002\u672c\u6b21\u5206\u6790\u4e2d\u7528\u4e8e\u7b5b\u9009\u7684\u9ed8\u8ba4\u503c\u4e3a\uff1a\\n\\n\"\n                        f\"```json\\n{default_values_str}\\n```\\n\\n\"\n                        \"\u6b64\u65b9\u6cd5\u6709\u52a9\u4e8e\u5728\u56fa\u5b9a\u7684\u57fa\u51c6\u6761\u4ef6\u4e0b\uff0c\u6e05\u6670\u5730\u89c2\u5bdf\u72ec\u7acb\u53d8\u91cf\u53d8\u5316\u5e26\u6765\u7684\u5f71\u54cd\u3002\\n\"\n                    )\n                    prompt_lines.append(note)\n\n            if combined_plots:\n                for plot in combined_plots:\n                    title = \"\u6027\u80fd\u6307\u6807\u8d8b\u52bf\u66f2\u7ebf\u56fe\"\n                    prompt_lines.extend([f\"## {title}\\n\\n\", f\"![{title}]({plot})\\n\"])\n            elif standard_individual_plots:\n                prompt_lines.append(\"## \u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\\n\\n\")\n                for plot in standard_individual_plots:\n                    title = _format_label(\n                        os.path.splitext(plot)[0].replace(\"line_\", \"\")\n                    )\n                    prompt_lines.extend([f\"### {title}\\n\", f\"![{title}]({plot})\\n\\n\"])\n\n            if multi_metric_plots or required_individual_plots:\n                prompt_lines.append(\"## \u7ea6\u675f\u6c42\u89e3\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\\n\\n\")\n                for plot_file in multi_metric_plots:\n                    try:\n                        base_metric_name = plot_file.replace(\"multi_\", \"\").replace(\n                            \"_analysis_by_param.svg\", \"\"\n                        )\n                        friendly_name = _format_label(base_metric_name)\n                    except Exception:\n                        friendly_name = \"Optimization\"\n                    prompt_lines.extend(\n                        [\n                            f\"### \u4e0d\u540c\u7ea6\u675f\u503c\u4e0b\u7684\u201c{friendly_name}\u201d\u5206\u6790 (\u6309\u53c2\u6570\u5206\u7ec4)\\n\",\n                            f\"\u4e0b\u56fe\u5c55\u793a\u4e86\u201c{friendly_name}\u201d\u6307\u6807\u968f\u72ec\u7acb\u53d8\u91cf\u53d8\u5316\u7684\u8d8b\u52bf\u3002\u6bcf\u4e2a\u5b50\u56fe\u5bf9\u5e94\u4e00\u7ec4\u7279\u5b9a\u7684\u80cc\u666f\u626b\u63cf\u53c2\u6570\u7ec4\u5408\uff0c\u5b50\u56fe\u5185\u7684\u6bcf\u6761\u66f2\u7ebf\u4ee3\u8868\u4e00\u4e2a\u5177\u4f53\u7684\u7ea6\u675f\u503c\u3002\\n\\n\",\n                            f\"![\u4e0d\u540c\u7ea6\u675f\u503c\u4e0b\u7684{friendly_name}\u5206\u6790]({plot_file})\\n\\n\",\n                        ]\n                    )\n                for plot_file in required_individual_plots:\n                    title = _format_label(\n                        os.path.splitext(plot_file)[0].replace(\"line_\", \"\")\n                    )\n                    prompt_lines.extend(\n                        [f\"### {title}\\n\", f\"![{title}]({plot_file})\\n\\n\"]\n                    )\n\n            def _format_df_to_md(\n                sub_df: pd.DataFrame,\n                ind_var: str,\n                case_data: dict,\n                current_unit_map: dict,\n            ) -&gt; str:\n                if sub_df.empty:\n                    return \"\u65e0\u6570\u636e\u3002\"\n                all_markdown_lines = []\n                all_cols = sub_df.columns.tolist()\n                if ind_var in all_cols:\n                    all_cols.remove(ind_var)\n                standard_cols = [\n                    c\n                    for c in all_cols\n                    if not (c.startswith(\"Required_\") or \"_for_Required_\" in c)\n                ]\n                required_groups = {}\n                required_base_names = [\n                    v\n                    for v in case_data.get(\"dependent_variables\", [])\n                    if v.startswith(\"Required_\")\n                ]\n                for base_name in required_base_names:\n                    group_cols = []\n                    # pattern = re.compile(f\"_for_{re.escape(base_name)}(?:\\\\(.*\\\\))?$\")\n                    for col in all_cols:\n                        if col == base_name or col.startswith(base_name + \"(\"):\n                            group_cols.append(col)\n                    if group_cols:\n                        required_groups[base_name] = group_cols\n\n                def _format_slice_to_md(df_slice: pd.DataFrame, umap: dict) -&gt; str:\n                    if df_slice.empty:\n                        return \"\"\n                    df_formatted = df_slice.copy()\n                    new_columns = {}\n                    for col_name in df_formatted.columns:\n                        unit_config = _find_unit_config(col_name, umap)\n                        new_col_name = _format_label(col_name)\n                        if unit_config:\n                            unit = unit_config.get(\"unit\")\n                            factor = unit_config.get(\"conversion_factor\")\n                            if factor and pd.api.types.is_numeric_dtype(\n                                df_formatted[col_name]\n                            ):\n                                df_formatted[col_name] = df_formatted[col_name] / float(\n                                    factor\n                                )\n                            if unit:\n                                new_col_name = f\"{new_col_name} ({unit})\"\n                        new_columns[col_name] = new_col_name\n                    df_formatted.rename(columns=new_columns, inplace=True)\n                    format_map = {}\n                    for original_col_name in df_slice.columns:\n                        if original_col_name.startswith(\"Required_\"):\n                            format_map[new_columns[original_col_name]] = \"{:.4f}\"\n                    default_format = \"{:.2f}\"\n                    for col in df_formatted.columns:\n                        if pd.api.types.is_numeric_dtype(df_formatted[col]):\n                            formatter = format_map.get(col, default_format)\n                            df_formatted[col] = df_formatted[col].apply(\n                                lambda x: formatter.format(x) if pd.notnull(x) else x\n                            )\n                    return df_formatted.to_markdown(index=False)\n\n                if standard_cols:\n                    all_markdown_lines.append(\"##### \u6027\u80fd\u6307\u6807\\n\")\n                    std_df_slice = sub_df[[ind_var] + sorted(standard_cols)]\n                    all_markdown_lines.append(\n                        _format_slice_to_md(std_df_slice, current_unit_map)\n                    )\n                    all_markdown_lines.append(\"\\n\")\n                if required_groups:\n                    for base_name, cols in required_groups.items():\n                        existing_cols = [c for c in cols if c in sub_df.columns]\n                        if not existing_cols:\n                            continue\n\n                        all_markdown_lines.append(\n                            f\"##### \u201c{_format_label(base_name)}\u201d \u76f8\u5173\u6570\u636e\\n\"\n                        )\n                        req_df_slice = sub_df[[ind_var] + sorted(existing_cols)]\n\n                        try:\n                            # --- PIVOT LOGIC to transform data from wide to long format ---\n                            # e.g., from [A, B(v1), B(v2)] to [A, new_col, B]\n\n                            # Columns to unpivot, e.g., ['Required_TBR(7.0)', 'Required_TBR(10.0)']\n                            value_vars = [\n                                c\n                                for c in req_df_slice.columns\n                                if c.startswith(base_name)\n                                and \"(\" in c\n                                and c.endswith(\")\")\n                            ]\n\n                            # If no columns are in the format B(v), pivot is not applicable.\n                            if not value_vars:\n                                all_markdown_lines.append(\n                                    _format_slice_to_md(req_df_slice, current_unit_map)\n                                )\n                                all_markdown_lines.append(\"\\n\")\n                                continue\n\n                            # Melt the dataframe from wide to long format\n                            melted_df = req_df_slice.melt(\n                                id_vars=[ind_var],\n                                value_vars=value_vars,\n                                var_name=\"variable_col\",\n                                value_name=base_name,\n                            )\n\n                            # Determine the name for the new column from config (e.g., 'Doubling_Time')\n                            new_col_name = \"Constraint\"  # Default name\n                            metric_def = case_data.get(\"simulation_parameters\").get(\n                                \"Required_TBR\"\n                            )\n                            if metric_def and metric_def.get(\"metric_name\"):\n                                new_col_name = \"Constraint \" + metric_def[\"metric_name\"]\n\n                            # Extract constraint value from old column name, e.g., '7.0' from 'Required_TBR(7.0)'\n                            pattern_str = f\"{re.escape(base_name)}\\\\((.*)\\\\)\"\n                            melted_df[new_col_name] = melted_df[\n                                \"variable_col\"\n                            ].str.extract(pat=pattern_str)\n\n                            # Create the final dataframe with the desired columns: [A, new_col, B]\n                            final_df = melted_df[\n                                [ind_var, new_col_name, base_name]\n                            ].copy()\n                            final_df.dropna(subset=[base_name], inplace=True)\n\n                            all_markdown_lines.append(final_df.to_markdown(index=False))\n                            all_markdown_lines.append(\"\\n\")\n\n                        except Exception as e:\n                            logger.warning(\n                                f\"Could not pivot data for '{base_name}', displaying in wide format. Error: {e}\"\n                            )\n                            all_markdown_lines.append(\n                                _format_slice_to_md(req_df_slice, current_unit_map)\n                            )\n                            all_markdown_lines.append(\"\\n\")\n                return \"\\n\".join(all_markdown_lines)\n\n            reference_col_for_turning_point = None\n            if case_data.get(\"sweep_time\") and os.path.exists(sweep_csv_path):\n                try:\n                    logger.info(\"Loading sweep_results.csv for dynamic slicing.\")\n                    sweep_df = pd.read_csv(sweep_csv_path)\n                    if \"time\" in sweep_df.columns and len(sweep_df.columns) &gt; 1:\n                        reference_col_for_turning_point = sweep_df.columns[\n                            len(sweep_df.columns) // 2\n                        ]\n                    if reference_col_for_turning_point:\n                        data_to_slice_df = sweep_df.copy()\n                        data_to_slice_df.reset_index(drop=True, inplace=True)\n                        if not data_to_slice_df.empty:\n                            prompt_lines.append(\"## \u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u8fc7\u7a0b\u6570\u636e\\n\\n\")\n                            prompt_lines.append(\n                                f\"\u4e0b\u8868\u5c55\u793a\u4e86\u8fc7\u7a0b\u6570\u636e\u4e2d\uff0c\u4ee5 `{reference_col_for_turning_point}` \u4e3a\u53c2\u8003\u53d8\u91cf\uff0c\u5728\u5173\u952e\u9636\u6bb5\u7684\u6570\u636e\u5207\u7247\u3002**\u6ce8\u610f\uff1a\u4e0b\u8868\u4e2d\u7684\u9ed8\u8ba4\u5355\u4f4d\u4e3a\uff1a\u65f6\u95f4(h), \u5e93\u5b58(g), \u529f\u7387(MW)\u3002**\\n\\n\"\n                            )\n                            base_var_name = reference_col_for_turning_point.split(\"&amp;\")[\n                                0\n                            ]\n                            cols_to_rename = [\n                                c for c in data_to_slice_df.columns if c != \"time\"\n                            ]\n                            rename_map = {\n                                col: f\"C{i+1}\" for i, col in enumerate(cols_to_rename)\n                            }\n                            legend_lines = [\n                                \"**\u8868\u683c\u56fe\u4f8b\u8bf4\u660e**\uff1a\",\n                                \"| \u7b80\u79f0 | \u53c2\u6570\u7ec4\u5408 |\",\n                                \"| :--- | :--- |\",\n                            ]\n                            for original_name, abbr in rename_map.items():\n                                param_parts = original_name.split(\"&amp;\", 1)\n                                param_str = (\n                                    param_parts[1] if len(param_parts) &gt; 1 else \"\u65e0\"\n                                )\n                                param_str_formatted = (\n                                    \"`\" + \"`, `\".join(param_str.split(\"&amp;\")) + \"`\"\n                                )\n                                legend_lines.append(\n                                    f\"| **{abbr}** | {param_str_formatted} |\"\n                                )\n                            base_var_info = f\"**\u6ce8**\uff1a\u8868\u683c\u4e2d\u6240\u6709\u7b80\u79f0\u5217\uff08C1, C2, ...\uff09\u7684\u6570\u636e\u5747\u4ee3\u8868\u53d8\u91cf `{base_var_name}` \u5728\u4e0d\u540c\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u503c\u3002\\n\"\n                            legend_md = base_var_info + \"\\n\".join(legend_lines) + \"\\n\\n\"\n                            prompt_lines.append(legend_md)\n                            primary_y_var = reference_col_for_turning_point\n                            min_idx = -1\n                            if primary_y_var in data_to_slice_df.columns:\n                                y_data = data_to_slice_df[primary_y_var]\n                                if not y_data.empty:\n                                    min_idx = y_data.idxmin()\n                            num_points, interval = 20, 2\n                            window_size = (num_points - 1) * interval + 1\n                            start_data = data_to_slice_df.iloc[:window_size:interval]\n                            end_data = data_to_slice_df.iloc[-(window_size)::interval]\n                            prompt_lines.append(\n                                f\"### 1. \u521d\u59cb\u9636\u6bb5 (\u524d {num_points} \u4e2a\u6570\u636e\u70b9, \u95f4\u9694 {interval})\\n\"\n                            )\n                            prompt_lines.append(\n                                start_data.rename(columns=rename_map).to_markdown(\n                                    index=False\n                                )\n                                + \"\\n\\n\"\n                            )\n                            if min_idx != -1:\n                                window_radius_indices = (num_points // 2) * interval\n                                start_idx = max(0, min_idx - window_radius_indices)\n                                end_idx = min(\n                                    len(data_to_slice_df),\n                                    min_idx + window_radius_indices,\n                                )\n                                turning_point_data = data_to_slice_df.iloc[\n                                    start_idx:end_idx:interval\n                                ]\n                                prompt_lines.append(\n                                    f\"### 2. \u8f6c\u6298\u70b9\u9636\u6bb5 (\u56f4\u7ed5 '{primary_y_var}' \u6700\u5c0f\u503c)\\n\"\n                                )\n                                prompt_lines.append(\n                                    turning_point_data.rename(\n                                        columns=rename_map\n                                    ).to_markdown(index=False)\n                                    + \"\\n\\n\"\n                                )\n                            prompt_lines.append(\n                                f\"### 3. \u7ed3\u675f\u9636\u6bb5 (\u540e {num_points} \u4e2a\u6570\u636e\u70b9, \u95f4\u9694 {interval})\\n\"\n                            )\n                            prompt_lines.append(\n                                end_data.rename(columns=rename_map).to_markdown(\n                                    index=False\n                                )\n                                + \"\\n\\n\"\n                            )\n                except Exception as e:\n                    logger.warning(\n                        f\"Could not generate dynamic data slices for case {case_name}: {e}\"\n                    )\n\n            grouping_vars = list(case_data.get(\"default_simulation_values\", {}).keys())\n            if not grouping_vars:\n                prompt_lines.append(\"## \u6027\u80fd\u6307\u6807\u603b\u8868\\n\\n\")\n                prompt_lines.append(\n                    _format_df_to_md(\n                        summary_df, independent_variable, case_data, unit_map\n                    )\n                )\n            else:\n                prompt_lines.append(\n                    f\"## \u6027\u80fd\u6307\u6807\u603b\u8868 (\u5206\u7ec4: `{'`, `'.join(grouping_vars)}`)\\n\\n\"\n                )\n                groups = dict(list(summary_df.groupby(grouping_vars)))\n                default_values = case_data.get(\"default_simulation_values\")\n                default_group_key = None\n                if default_values:\n                    try:\n                        default_group_key = tuple(\n                            default_values[key] for key in grouping_vars\n                        )\n                    except KeyError:\n                        logger.warning(\n                            \"Mismatch between default_simulation_values and grouping_vars. Cannot find default group.\"\n                        )\n                        default_group_key = None\n                if default_group_key and default_group_key in groups:\n                    default_group_df = groups.pop(default_group_key)\n                    header = \" &amp; \".join(\n                        f\"`{var}={val}`\"\n                        for var, val in zip(grouping_vars, default_group_key)\n                    )\n                    prompt_lines.append(f\"#### \u6570\u636e\u5b50\u8868 (\u539f\u59cb\u9ed8\u8ba4\u503c: {header})\\n\")\n                    sub_df_to_format = default_group_df.drop(\n                        columns=grouping_vars, errors=\"ignore\"\n                    )\n                    prompt_lines.append(\n                        _format_df_to_md(\n                            sub_df_to_format, independent_variable, case_data, unit_map\n                        )\n                    )\n                    prompt_lines.append(\"\\n---\\n\")\n                if groups:\n                    prompt_lines.append(\"&gt; \u5176\u4ed6\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u6570\u636e\u5b50\u8868\uff1a\\n\")\n                for group_name, group_df in groups.items():\n                    header = (\n                        \" &amp; \".join(\n                            f\"`{var}={val}`\"\n                            for var, val in zip(grouping_vars, group_name)\n                        )\n                        if isinstance(group_name, tuple)\n                        else f\"`{grouping_vars[0]}={group_name}`\"\n                    )\n                    prompt_lines.append(f\"#### \u6570\u636e\u5b50\u8868 (\u5f53 {header} \u65f6)\\n\")\n                    sub_df_to_format = group_df.drop(\n                        columns=grouping_vars, errors=\"ignore\"\n                    )\n                    prompt_lines.append(\n                        _format_df_to_md(\n                            sub_df_to_format, independent_variable, case_data, unit_map\n                        )\n                    )\n                    prompt_lines.append(\"\\n\")\n\n            base_report_content = \"\\n\".join(prompt_lines)\n\n            # --- AI Analysis and Report Writing ---\n            if not case_data.get(\"ai\", False):\n                # AI is off: write a single, simple report\n                report_path = os.path.join(\n                    case_results_dir, f\"analysis_report_{case_name}.md\"\n                )\n                with open(report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Detailed analysis report generated for {case_name}: {report_path}\"\n                )\n                continue  # Go to next case\n\n            # AI is ON: go into multi-model logic\n            load_dotenv()\n            api_key = os.environ.get(\"API_KEY\")\n            base_url = os.environ.get(\"BASE_URL\")\n\n            ai_models_str = os.environ.get(\"AI_MODELS\")\n            if not ai_models_str:\n                ai_models_str = os.environ.get(\"AI_MODEL\")\n\n            if not all((api_key, base_url, ai_models_str)):\n                logger.warning(\n                    \"API_KEY, BASE_URL, or AI_MODELS/AI_MODEL not found in environment variables. Skipping LLM analysis.\"\n                )\n                # Also write the base report here so something is generated\n                report_path = os.path.join(\n                    case_results_dir, f\"analysis_report_{case_name}.md\"\n                )\n                with open(report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Wrote base report for {case_name} because AI credentials were not found: {report_path}\"\n                )\n                continue\n\n            ai_models = [model.strip() for model in ai_models_str.split(\",\")]\n\n            for ai_model in ai_models:\n                logger.info(\n                    f\"Generating AI analysis for case '{case_name}' with model '{ai_model}'.\"\n                )\n\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                model_report_filename = (\n                    f\"analysis_report_{case_name}_{sanitized_model_name}.md\"\n                )\n                model_report_path = os.path.join(\n                    case_results_dir, model_report_filename\n                )\n\n                with open(model_report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Generated base report for model {ai_model}: {model_report_path}\"\n                )\n\n                llm_analysis = call_openai_analysis_api(\n                    case_name=case_name,\n                    df=summary_df,\n                    api_key=api_key,\n                    base_url=base_url,\n                    ai_model=ai_model,\n                    independent_variable=independent_variable,\n                    report_content=base_report_content,\n                    original_config=original_config,\n                    case_data=case_data,\n                    reference_col_for_turning_point=reference_col_for_turning_point,\n                )\n\n                if llm_analysis:\n                    with open(model_report_path, \"a\", encoding=\"utf-8\") as f:\n                        f.write(\n                            f\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd ({ai_model})\\n\\n```markdown\\n\"\n                        )\n                        f.write(llm_analysis)\n                        f.write(\"\\n```\\n\")\n                    logger.info(f\"Appended LLM analysis to {model_report_path}\")\n\n                    generate_sensitivity_academic_report(\n                        case_name=case_name,\n                        case_workspace=case_workspace,\n                        independent_variable=independent_variable,\n                        original_config=original_config,\n                        case_data=case_data,\n                        ai_model=ai_model,\n                        report_path=model_report_path,\n                    )\n\n    except Exception as e:\n        logger.error(f\"Error generating detailed analysis reports: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.generate_sensitivity_academic_report","title":"<code>generate_sensitivity_academic_report(case_name, case_workspace, independent_variable, original_config, case_data, ai_model, report_path)</code>","text":"<p>Generates a professional academic analysis summary for a sensitivity analysis case.</p> <p>Sends the existing report and a glossary of terms to an LLM for academic formatting.</p> <p>Parameters:</p> Name Type Description Default <code>case_name</code> <code>str</code> <p>Name of the analysis case.</p> required <code>case_workspace</code> <code>str</code> <p>Path to the case workspace directory.</p> required <code>independent_variable</code> <code>str</code> <p>Name of the independent variable.</p> required <code>original_config</code> <code>dict</code> <p>Original configuration dictionary.</p> required <code>case_data</code> <code>dict</code> <p>Case-specific data dictionary.</p> required <code>ai_model</code> <code>str</code> <p>Model name to use for generating the report.</p> required <code>report_path</code> <code>str</code> <p>Path to the existing report file.</p> required Note <p>Requires report file and glossary file to exist. Loads API credentials from environment variables. Generates academic report with proper structure including title, abstract, introduction, methodology, results &amp; discussion, and conclusion. Retries up to 3 times on API failure. Saves result to academic_report_{case_name}_{model}.md.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def generate_sensitivity_academic_report(\n    case_name: str,\n    case_workspace: str,\n    independent_variable: str,\n    original_config: dict,\n    case_data: dict,\n    ai_model: str,\n    report_path: str,\n) -&gt; None:\n    \"\"\"Generates a professional academic analysis summary for a sensitivity analysis case.\n\n    Sends the existing report and a glossary of terms to an LLM for academic formatting.\n\n    Args:\n        case_name: Name of the analysis case.\n        case_workspace: Path to the case workspace directory.\n        independent_variable: Name of the independent variable.\n        original_config: Original configuration dictionary.\n        case_data: Case-specific data dictionary.\n        ai_model: Model name to use for generating the report.\n        report_path: Path to the existing report file.\n\n    Note:\n        Requires report file and glossary file to exist. Loads API credentials from\n        environment variables. Generates academic report with proper structure including\n        title, abstract, introduction, methodology, results &amp; discussion, and conclusion.\n        Retries up to 3 times on API failure. Saves result to academic_report_{case_name}_{model}.md.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Starting generation of the academic analysis summary for case {case_name} with model {ai_model}.\"\n        )\n\n        # 1. Read the existing report\n        results_dir = os.path.join(case_workspace, \"results\")\n        report_filename = os.path.basename(report_path)\n\n        if not os.path.exists(report_path):\n            logger.error(\n                f\"Cannot generate academic summary: Original report '{report_path}' not found.\"\n            )\n            return\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            original_report_content = f.read()\n\n        # 2. Read the glossary\n        glossary_path = original_config.get(\"sensitivity_analysis\", {}).get(\n            \"glossary_path\", \"./sheets.csv\"\n        )\n        if not os.path.exists(glossary_path):\n            logger.error(\n                f\"Cannot generate academic summary: Glossary file '{glossary_path}' not found.\"\n            )\n            return\n        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n            glossary_content = f.read()\n\n        # 3. Check for API credentials\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        if not all([api_key, base_url, ai_model]):\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not found. Skipping academic summary generation.\"\n            )\n            return\n\n        # 4. Construct the prompt\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e**\u654f\u611f\u6027\u5206\u6790**\u7684\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7684\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\"\"\"\n\n        # Extract relevant details from case_data for the prompt\n        sampling_range = case_data.get(\"independent_variable_sampling\", {})\n        simulation_parameters = case_data.get(\"simulation_parameters\", {})\n        dependent_variables = case_data.get(\"dependent_variables\", [])\n\n        simulation_params_str = \"\"\n        if simulation_parameters:\n            params_list = []\n            # Access metric definitions from the original config\n            metrics_definitions = original_config.get(\"sensitivity_analysis\", {}).get(\n                \"metrics_definition\", {}\n            )\n\n            for k, v in simulation_parameters.items():\n                # Check if the parameter is a 'Required_' metric and has configurations defined\n                if (\n                    k.startswith(\"Required_\")\n                    and k in metrics_definitions\n                    and \"configurations\" in metrics_definitions[k]\n                ):\n                    try:\n                        metric_configs = metrics_definitions[k][\"configurations\"]\n                        # Look up the metric_max_value for each configuration key in the scan list `v`\n                        actual_values = [\n                            metric_configs.get(conf_name, {}).get(\n                                \"metric_max_value\", conf_name\n                            )\n                            for conf_name in v\n                        ]\n                        params_list.append(f\"`{k}` (\u7ea6\u675f\u626b\u63cf\u503c): {actual_values}\")\n                    except Exception:\n                        # If lookup fails for any reason, fall back to the original representation\n                        params_list.append(f\"`{k}`: {v}\")\n                else:\n                    # For regular parameters\n                    params_list.append(f\"`{k}`: {v}\")\n\n            simulation_params_str = (\n                \"\\n        *   **\u80cc\u666f\u626b\u63cf\u53c2\u6570 (Simulation Parameters):** \"\n                + \", \".join(params_list)\n            )\n\n        dependent_vars_str = \"\"\n        if dependent_variables:\n            dependent_vars_str = (\n                \"\\n        *   **\u56e0\u53d8\u91cf (Dependent Variables):** \"\n                + \", \".join([f\"`{v}`\" for v in dependent_variables])\n            )\n\n        # Find all plots to instruct the LLM to include them, prioritizing Chinese versions\n        all_files = [f for f in os.listdir(results_dir) if f.endswith((\".svg\", \".png\"))]\n\n        plot_map = {}\n        # Handle SVGs, prioritizing _zh versions\n        svg_plots = sorted([f for f in all_files if f.endswith(\".svg\")], reverse=True)\n        for plot in svg_plots:\n            base_name = plot.replace(\"_zh.svg\", \".svg\")\n            if base_name not in plot_map:\n                plot_map[base_name] = plot\n\n        # Add PNGs (which are not bilingual)\n        png_plots = [f for f in all_files if f.endswith(\".png\")]\n        for plot in png_plots:\n            plot_map[plot] = plot  # Use plot name as key for uniqueness\n\n        all_plots = list(plot_map.values())\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n\n        # Dynamically build the \"Results and Discussion\" section for the prompt\n        results_and_discussion_points = []\n\n        # 1. Main Effect Analysis (always included)\n        main_effect_text = (\n            f\"           *   **\u4e3b\u6548\u5e94\u5206\u6790\uff1a** \u8be6\u7ec6\u5206\u6790\u72ec\u7acb\u53d8\u91cf **`{independent_variable}`** \u7684\u53d8\u5316\u5bf9\u4e3b\u8981\u6027\u80fd\u6307\u6807\uff08\u5982 `Startup_Inventory`, `Doubling_Time` \u7b49\uff09\u7684\u603b\u4f53\u5f71\u54cd\u8d8b\u52bf\u3002\"\n            \"\u8bc4\u4f30\u4e0d\u540c\u6307\u6807\u5bf9\u81ea\u53d8\u91cf\u53d8\u5316\u7684\u654f\u611f\u5ea6\uff0c\u5e76\u8ba8\u8bba\u6307\u6807\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\"\n        )\n        results_and_discussion_points.append(main_effect_text)\n\n        # 2. Interaction Effect Analysis (conditional)\n        if simulation_parameters:\n            interaction_text = (\n                f\"           *   **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a** \u6df1\u5165\u63a2\u8ba8\u72ec\u7acb\u53d8\u91cf\u4e0e\u80cc\u666f\u53c2\u6570\u95f4\u7684**\u4ea4\u4e92\u6548\u5e94**\u3002\"\n                \"\u80cc\u666f\u53c2\u6570\u53ef\u80fd\u5305\u542b\u5e38\u89c4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u53ef\u80fd\u5305\u542b\u7ea6\u675f\u76f8\u5173\u7684\u53d8\u91cf\uff08\u4f8b\u5982 `Required_TBR`\uff09\u3002\"\n                f\"\u8bf7\u9610\u8ff0\u5728\u4e0d\u540c\u7684\u80cc\u666f\u53c2\u6570\u7ec4\u5408\u4e0b\uff0c`{independent_variable}` \u5bf9\u6027\u80fd\u6307\u6807\u7684\u654f\u611f\u6027\u662f\u5426\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08\u4f8b\u5982\uff0c\u662f\u88ab\u653e\u5927\u8fd8\u662f\u51cf\u5f31\uff09\u3002\"\n                \"\u8bf7\u7279\u522b\u5173\u6ce8\u5f53\u72ec\u7acb\u53d8\u91cf\u4e0e\u7ea6\u675f\u7c7b\u80cc\u666f\u53c2\u6570\u4ea4\u4e92\u65f6\uff0c\u5bf9\u7cfb\u7edf\u6027\u80fd\u548c\u8fbe\u6210\u5de5\u7a0b\u76ee\u6807\u7684\u5f71\u54cd\u3002\"\n            )\n            results_and_discussion_points.append(interaction_text)\n\n        # 3. Dynamic Behavior Analysis (conditional)\n        if \"\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\" in original_report_content:\n            dynamic_text = (\n                f\"           *   **\u52a8\u6001\u884c\u4e3a\u5206\u6790\uff1a** \u89e3\u8bfb\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u201d\u3001\u201c\u8f6c\u6298\u70b9\u201d\u548c\u201c\u7ed3\u675f\u201d\u9636\u6bb5\u7684\u884c\u4e3a\u53d8\u5316\u3002\"\n                f\"\u5206\u6790 **`{independent_variable}`** \u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u5982\u8fbe\u5230\u5e73\u8861\u7684\u65f6\u95f4\u3001\u5e93\u5b58\u7684\u8f6c\u6298\u70b9\u7b49\u3002\"\n            )\n            results_and_discussion_points.append(dynamic_text)\n\n        results_and_discussion_str = \"\\n\".join(results_and_discussion_points)\n\n        # Dynamically create the title instruction\n        if simulation_parameters:\n            title_instruction_text = \"\u8bf7\u5728\u6807\u9898\u4e2d\u660e\u786e\u6307\u51fa\uff0c\u672c\u6b21\u5206\u6790\u662f\u5173\u4e8e\u201c\u72ec\u7acb\u53d8\u91cf\u201d\u4e0e\u201c\u80cc\u666f\u626b\u63cf\u53c2\u6570\u201d\u7684\u3010\u4ea4\u4e92\u654f\u611f\u6027\u5206\u6790\u3011\u3002\"\n        else:\n            title_instruction_text = (\n                \"\u8bf7\u5728\u6807\u9898\u4e2d\u660e\u786e\u6307\u51fa\uff0c\u672c\u6b21\u5206\u6790\u662f\u5173\u4e8e\u201c\u72ec\u7acb\u53d8\u91cf\u201d\u7684\u3010\u654f\u611f\u6027\u5206\u6790\u3011\u3002\"\n            )\n\n        instructions_prompt = f\"\"\"**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\u4f8b\u5982\uff0c\u5e94\u5c06\u201c`sds`\u7684\u5e93\u5b58\u201d\u8868\u8ff0\u4e3a\u201c\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS) \u7684\u6c1a\u5e93\u5b58\u91cf (Tritium Inventory)\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\u907f\u514d\u4f7f\u7528\u201c\u770b\u8d77\u6765\u201d\u3001\u201c\u597d\u50cf\u201d\u7b49\u6a21\u7cca\u8bcd\u6c47\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u6027\u80fd\u6307\u6807\u603b\u8868\u6216\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u654f\u611f\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6807\u9898 (Title):** {title_instruction_text}\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u654f\u611f\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u660e\u72ec\u7acb\u53d8\u91cf\u662f **`{independent_variable}`** \u4ee5\u53ca\u80cc\u666f\u626b\u63cf\u53c2\u6570\uff0c\u603b\u7ed3\u5176\u5bf9\u54ea\u4e9b\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u542f\u52a8\u5e93\u5b58\u3001\u589e\u6b96\u65f6\u95f4\u7b49\uff09\u5f71\u54cd\u6700\u663e\u8457\uff0c\u5e76\u9648\u8ff0\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u5173\u4e8e **`{independent_variable}`** \u7684\u654f\u611f\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30 **`{independent_variable}`** \u7684\u53d8\u5316\u5bf9\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\n        *   **\u72ec\u7acb\u53d8\u91cf\u91c7\u6837 (Independent Variable Sampling):** \u672c\u6b21\u5206\u6790\u4e2d\uff0c\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u626b\u63cf\u8303\u56f4\u4e3a `{sampling_range}`\u3002\n{simulation_params_str}{dependent_vars_str}\n    *   **\u65b9\u6cd5 (Methodology):** \u7b80\u8981\u8bf4\u660e\u5206\u6790\u65b9\u6cd5\uff0c\u5305\u62ec\u63d0\u53ca **`{independent_variable}`** \u7684\u626b\u63cf\u8303\u56f4\u548c\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u6240\u6709\u56fe\u8868\u548c\u6570\u636e\u8868\u683c\uff0c\u5e76\u6839\u636e\u5206\u6790\u5185\u5bb9\uff0c\u7ec4\u7ec7\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n{results_and_discussion_str}\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u654f\u611f\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff0c\u5e76\u5bf9\u53cd\u5e94\u5806\u8bbe\u8ba1\u6216\u672a\u6765\u8fd0\u884c\u7b56\u7565\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\uff08\u5305\u62ec\u56fe\u8868\u548c\u8868\u683c\uff09\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n---\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a (`{report_filename}`)\n---\n{original_report_content}\n\n---\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868 (`sheets.csv`)\n---\n{glossary_content}\n\"\"\"\n\n        # 5. Call the API\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for academic summary for case {case_name} with model {ai_model} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, instructions_prompt, analysis_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                academic_summary = response.choices[0].message.content\n\n                # 6. Save the result\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                summary_filename = (\n                    f\"academic_report_{case_name}_{sanitized_model_name}.md\"\n                )\n                summary_path = os.path.join(results_dir, summary_filename)\n                with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(academic_summary)\n\n                logger.info(\n                    f\"Successfully generated academic analysis summary: {summary_path}\"\n                )\n                return  # Exit after success\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling OpenAI API for academic summary on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to generate academic summary for {case_name} after {max_retries} attempts.\"\n                    )\n                    return  # Exit after all retries failed\n\n    except Exception as e:\n        logger.error(\n            f\"Error in generate_sensitivity_academic_report for case {case_name}: {e}\",\n            exc_info=True,\n        )\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.report.retry_ai_analysis","title":"<code>retry_ai_analysis(case_configs, original_config)</code>","text":"<p>Retries AI analysis for cases where it might have failed due to network issues.</p> <p>Checks for existing reports and re-runs only the AI-dependent parts if they are missing. This function can be triggered by setting an environment variable.</p> <p>Parameters:</p> Name Type Description Default <code>case_configs</code> <code>List[Dict[str, Any]]</code> <p>List of case configuration dictionaries.</p> required <code>original_config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary.</p> required Note <p>Routes to _retry_salib_case for SALib cases or _retry_standard_case for standard cases. Only regenerates missing AI analysis and academic reports. Does not re-run simulations. Logs all retry attempts and failures.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def retry_ai_analysis(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Retries AI analysis for cases where it might have failed due to network issues.\n\n    Checks for existing reports and re-runs only the AI-dependent parts if they are missing.\n    This function can be triggered by setting an environment variable.\n\n    Args:\n        case_configs: List of case configuration dictionaries.\n        original_config: Original configuration dictionary.\n\n    Note:\n        Routes to _retry_salib_case for SALib cases or _retry_standard_case for standard cases.\n        Only regenerates missing AI analysis and academic reports. Does not re-run simulations.\n        Logs all retry attempts and failures.\n    \"\"\"\n    logger.info(\"Starting AI analysis retry process...\")\n    try:\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n            if \"analyzer\" in case_data and case_data.get(\"analyzer\", {}).get(\"method\"):\n                _retry_salib_case(case_info, original_config)\n            else:\n                _retry_standard_case(case_info, original_config)\n    except Exception as e:\n        logger.error(f\"Error during AI analysis retry process: {e}\", exc_info=True)\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer","title":"<code>TricysSALibAnalyzer</code>","text":"<p>Integrated SALib's Tricys Sensitivity Analyzer.</p> <p>Supported Analysis Methods: - Sobol: Variance-based global sensitivity analysis - Morris: Screening-based sensitivity analysis - FAST: Fourier Amplitude Sensitivity Test - LHS: Latin Hypercube Sampling uncertainty analysis</p> <p>Attributes:</p> Name Type Description <code>base_config</code> <p>Copy of the Tricys base configuration.</p> <code>problem</code> <p>SALib problem definition dictionary.</p> <code>parameter_samples</code> <p>Generated parameter samples array.</p> <code>simulation_results</code> <p>Results from simulations.</p> <code>sensitivity_results</code> <p>Dictionary storing sensitivity analysis results by method.</p> Note <p>Automatically sets up Chinese font support and validates Tricys configuration on initialization. Supports multiple sensitivity analysis methods with appropriate sampling strategies.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>class TricysSALibAnalyzer:\n    \"\"\"Integrated SALib's Tricys Sensitivity Analyzer.\n\n    Supported Analysis Methods:\n    - Sobol: Variance-based global sensitivity analysis\n    - Morris: Screening-based sensitivity analysis\n    - FAST: Fourier Amplitude Sensitivity Test\n    - LHS: Latin Hypercube Sampling uncertainty analysis\n\n    Attributes:\n        base_config: Copy of the Tricys base configuration.\n        problem: SALib problem definition dictionary.\n        parameter_samples: Generated parameter samples array.\n        simulation_results: Results from simulations.\n        sensitivity_results: Dictionary storing sensitivity analysis results by method.\n\n    Note:\n        Automatically sets up Chinese font support and validates Tricys configuration\n        on initialization. Supports multiple sensitivity analysis methods with appropriate\n        sampling strategies.\n    \"\"\"\n\n    def __init__(self, base_config: Dict[str, Any]) -&gt; None:\n        \"\"\"Initialize the analyzer.\n\n        Args:\n            base_config: Tricys base configuration dictionary.\n\n        Note:\n            Creates a deep copy of base_config. Initializes problem, samples, and results\n            to None. Calls _setup_chinese_font() and _validate_tricys_config() automatically.\n        \"\"\"\n        self.base_config = base_config.copy()\n        self.problem = None\n        self.parameter_samples = None\n        self.simulation_results = None\n        self.sensitivity_results = {}\n\n        self._setup_chinese_font()\n        self._validate_tricys_config()\n\n    def _setup_chinese_font(self) -&gt; None:\n        \"\"\"Set the Chinese font to ensure proper display of Chinese characters in charts.\n\n        Note:\n            Tries multiple Chinese fonts in order of preference. Falls back to default\n            if no Chinese font found. Also sets axes.unicode_minus to False for proper\n            minus sign display. Logs warnings if font setup fails.\n        \"\"\"\n        try:\n            import matplotlib.font_manager as fm\n\n            chinese_fonts = [\n                \"SimHei\",  # \u9ed1\u4f53\n                \"Microsoft YaHei\",  # \u5fae\u8f6f\u96c5\u9ed1\n                \"KaiTi\",  # \u6977\u4f53\n                \"FangSong\",  # \u4eff\u5b8b\n                \"STSong\",  # \u534e\u6587\u5b8b\u4f53\n                \"STKaiti\",  # \u534e\u6587\u6977\u4f53\n                \"STHeiti\",  # \u534e\u6587\u9ed1\u4f53\n                \"DejaVu Sans\",  # \u5907\u7528\u5b57\u4f53\n                \"Arial Unicode MS\",  # \u5907\u7528\u5b57\u4f53\n            ]\n\n            available_font = None\n            system_fonts = [f.name for f in fm.fontManager.ttflist]\n\n            for font in chinese_fonts:\n                if font in system_fonts:\n                    available_font = font\n                    break\n\n            if available_font:\n                plt.rcParams[\"font.sans-serif\"] = [available_font] + plt.rcParams[\n                    \"font.sans-serif\"\n                ]\n                logger.info(\"Using Chinese font\", extra={\"font\": available_font})\n            else:\n                logger.warning(\n                    \"No suitable Chinese font found, which may affect Chinese display\"\n                )\n\n            plt.rcParams[\"axes.unicode_minus\"] = False\n\n        except Exception as e:\n            logger.warning(\n                \"Failed to set Chinese font, using default font\",\n                extra={\"error\": str(e)},\n            )\n\n    def _handle_nan_values(\n        self, Y: np.ndarray, method_name: str = \"Sensitivity analysis\"\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Handling NaN values with maximum interpolation\n\n        Args:\n            Y: Output array that may contain NaN values\n            method_name: Analysis method name for logging\n\n        Returns:\n            Processed output array\n        \"\"\"\n        nan_indices = np.isnan(Y)\n        if np.any(nan_indices):\n            n_nan = np.sum(nan_indices)\n            logger.info(\n                \"Found NaN values, using maximum value for imputation\",\n                extra={\n                    \"method_name\": method_name,\n                    \"nan_count\": n_nan,\n                },\n            )\n\n            valid_values = Y[~nan_indices]\n\n            if len(valid_values) &gt; 0:\n                max_value = np.max(valid_values)\n                Y_processed = Y.copy()\n                Y_processed[nan_indices] = max_value\n                return Y_processed\n            else:\n                logger.error(\n                    \"All values are NaN, analysis cannot be performed\",\n                    extra={\n                        \"method_name\": method_name,\n                    },\n                )\n                raise ValueError(\n                    f\"{method_name}: All simulation results are NaN, sensitivity analysis cannot be performed\"\n                )\n        return Y\n\n    def _validate_tricys_config(self) -&gt; None:\n        \"\"\"Validate the Tricys configuration for required sections and keys.\"\"\"\n        required_keys = {\n            \"paths\": [\"package_path\"],\n            \"simulation\": [\"model_name\", \"stop_time\"],\n        }\n\n        for section, keys in required_keys.items():\n            if section not in self.base_config:\n                logger.warning(\n                    \"Missing configuration section, default values will be used\",\n                    extra={\n                        \"section\": section,\n                    },\n                )\n                continue\n\n            for key in keys:\n                if key not in self.base_config[section]:\n                    logger.warning(\n                        \"Missing configuration item, using default value\",\n                        extra={\n                            \"section\": section,\n                            \"key\": key,\n                        },\n                    )\n\n        package_path = self.base_config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            logger.warning(\n                \"Model file does not exist, which may cause simulation failure\",\n                extra={\n                    \"package_path\": package_path,\n                },\n            )\n\n    def _find_unit_config(self, var_name: str, unit_map: dict) -&gt; dict | None:\n        \"\"\"\n        Finds the unit configuration for a variable name from the unit_map.\n        1. Checks for an exact match.\n        2. Checks if the last part of a dot-separated name matches.\n        3. Checks for a simple substring containment as a fallback, matching longest keys first.\n        \"\"\"\n        if not unit_map or not var_name:\n            return None\n        if var_name in unit_map:\n            return unit_map[var_name]\n        components = var_name.split(\".\")\n        if len(components) &gt; 1 and components[-1] in unit_map:\n            return unit_map[components[-1]]\n        # Fallback to substring match, longest key first\n        for key in sorted(unit_map.keys(), key=len, reverse=True):\n            if key in var_name:\n                return unit_map[key]\n        return None\n\n    def define_problem(\n        self,\n        param_bounds: Dict[str, Tuple[float, float]],\n        param_distributions: Dict[str, str] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Define SALib problem space.\n\n        Args:\n            param_bounds: Parameter bounds dictionary {'param_name': (min_val, max_val)}.\n            param_distributions: Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}.\n                Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'.\n\n        Returns:\n            SALib problem definition dictionary.\n\n        Note:\n            Defaults to 'unif' distribution if not specified. Validates distribution types\n            and warns if invalid. Logs parameter definitions including bounds and distributions.\n        \"\"\"\n        if param_distributions is None:\n            param_distributions = {name: \"unif\" for name in param_bounds.keys()}\n\n        valid_dists = [\"unif\", \"triang\", \"norm\", \"truncnorm\", \"lognorm\"]\n        for name, dist in param_distributions.items():\n            if dist not in valid_dists:\n                logger.warning(\n                    \"Invalid distribution type, using 'unif' instead\",\n                    extra={\n                        \"parameter_name\": name,\n                        \"invalid_distribution\": dist,\n                    },\n                )\n                param_distributions[name] = \"unif\"\n\n        self.problem = {\n            \"num_vars\": len(param_bounds),\n            \"names\": list(param_bounds.keys()),\n            \"bounds\": list(param_bounds.values()),\n            \"dists\": [\n                param_distributions.get(name, \"unif\") for name in param_bounds.keys()\n            ],\n        }\n\n        logger.info(\n            \"Defined a problem space\",\n            extra={\n                \"num_parameters\": self.problem[\"num_vars\"],\n            },\n        )\n        for i, name in enumerate(self.problem[\"names\"]):\n            logger.info(\n                \"Parameter definition\",\n                extra={\n                    \"parameter_name\": name,\n                    \"bounds\": self.problem[\"bounds\"][i],\n                    \"distribution\": self.problem[\"dists\"][i],\n                },\n            )\n\n        return self.problem\n\n    def generate_samples(\n        self, method: str = \"sobol\", N: int = 1024, **kwargs\n    ) -&gt; np.ndarray:\n        \"\"\"Generate parameter samples.\n\n        Args:\n            method: Sampling method ('sobol', 'morris', 'fast', 'latin').\n            N: Number of samples (for Sobol this is the base sample count, actual count is N*(2*D+2)).\n            **kwargs: Method-specific parameters.\n\n        Returns:\n            Parameter sample array (n_samples, n_params).\n\n        Raises:\n            ValueError: If problem not defined or unsupported method.\n\n        Note:\n            Sobol generates N*(2*D+2) samples. Morris generates N trajectories. Samples are\n            rounded to 5 decimal places. Stores last sampling method for compatibility checking.\n        \"\"\"\n        if self.problem is None:\n            raise ValueError(\n                \"You must first call define_problem() to define the problem space.\"\n            )\n\n        logger.info(\n            \"Generating samples\",\n            extra={\n                \"method\": method,\n                \"base_sample_count\": N,\n            },\n        )\n\n        if method.lower() == \"sobol\":\n            # Sobol method: generate N*(2*D+2) samples\n            self.parameter_samples = saltelli.sample(self.problem, N, **kwargs)\n            actual_samples = N * (2 * self.problem[\"num_vars\"] + 2)\n\n        elif method.lower() == \"morris\":\n            # Morris method: Generate N trajectories\n            # Note: Different versions of SALib may have different parameter names\n            morris_kwargs = {\"num_levels\": 4}\n            # Check the SALib version and use the correct parameter names\n            try:\n                morris_kwargs.update(kwargs)\n                self.parameter_samples = morris.sample(self.problem, N, **morris_kwargs)\n            except TypeError as e:\n                if \"grid_jump\" in str(e):\n                    morris_kwargs = {\n                        k: v for k, v in morris_kwargs.items() if k != \"grid_jump\"\n                    }\n                    morris_kwargs.update(\n                        {k: v for k, v in kwargs.items() if k != \"grid_jump\"}\n                    )\n                    self.parameter_samples = morris.sample(\n                        self.problem, N, **morris_kwargs\n                    )\n                else:\n                    raise e\n\n            actual_samples = len(self.parameter_samples)\n\n        elif method.lower() == \"fast\":\n            # FAST method\n            fast_kwargs = {\"M\": 4}\n            fast_kwargs.update(kwargs)\n            self.parameter_samples = fast_sampler.sample(self.problem, N, **fast_kwargs)\n            actual_samples = len(self.parameter_samples)\n\n        elif method.lower() == \"latin\":\n            # Latin Hypercube Sampling\n            self.parameter_samples = latin.sample(self.problem, N, **kwargs)\n            actual_samples = N\n\n        else:\n            raise ValueError(f\"Unsupported sampling method: {method}\")\n\n        logger.info(\n            \"Successfully generated samples\", extra={\"actual_samples\": actual_samples}\n        )\n\n        if self.parameter_samples is not None:\n            self.parameter_samples = np.round(self.parameter_samples, decimals=5)\n            logger.info(\"Parameter sample precision adjusted to 5 decimal places\")\n\n        self._last_sampling_method = method.lower()\n\n        return self.parameter_samples\n\n    def run_tricys_simulations(self, output_metrics: List[str] = None) -&gt; str:\n        \"\"\"\n        Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.\n\n        Args:\n            output_metrics: List of output metrics to be extracted (for recording but does not affect CSV generation)\n            max_workers: Number of concurrent worker processes (reserved for compatibility, currently unused)\n\n        Returns:\n            Path to the generated CSV file\n        \"\"\"\n        if self.parameter_samples is None:\n            raise ValueError(\n                \"You must first call generate_samples() to generate samples.\"\n            )\n\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        logger.info(\"Target output metrics\", extra={\"output_metrics\": output_metrics})\n\n        sampled_param_names = self.problem[\"names\"]\n\n        base_params = self.base_config.get(\"simulation_parameters\", {}).copy()\n        csv_output_path = (\n            Path(self.base_config.get(\"paths\", {}).get(\"temp_dir\"))\n            / \"salib_sampling.csv\"\n        )\n\n        os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n\n        param_data = []\n        for i, sample in enumerate(self.parameter_samples):\n            sampled_params = {\n                sampled_param_names[j]: sample[j]\n                for j in range(len(sampled_param_names))\n            }\n\n            job_params = base_params.copy()\n            job_params.update(sampled_params)\n\n            param_data.append(job_params)\n\n        df = pd.DataFrame(param_data)\n\n        for col in df.columns:\n            if df[col].dtype in [\"float64\", \"float32\"]:\n                df[col] = df[col].round(5)\n\n        df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n\n        logger.info(\n            \"Successfully generated parameter samples\",\n            extra={\"num_samples\": len(param_data)},\n        )\n        logger.info(\"Parameter file saved\", extra={\"file_path\": csv_output_path})\n        logger.info(\"Parameter file columns\", extra={\"columns\": list(df.columns)})\n        logger.info(\"Parameter precision set to 5 decimal places\")\n        logger.info(\"Sample statistics\", extra={\"statistics\": df.describe().to_dict()})\n\n        self.sampling_csv_path = csv_output_path\n\n        return csv_output_path\n\n    def generate_tricys_config(\n        self, csv_file_path: str = None, output_metrics: List[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Generate Tricys configuration file for reading CSV parameter files and executing simulations\n        This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs\n\n        Args:\n            csv_file_path: Path to the CSV parameter file. If None, the last generated file is used\n            output_metrics: List of output metrics to be calculated\n\n        Returns:\n            Path of the generated configuration file\n        \"\"\"\n        if csv_file_path is None:\n            if hasattr(self, \"sampling_csv_path\"):\n                csv_file_path = self.sampling_csv_path\n            else:\n                raise ValueError(\n                    \"CSV file path not found, please first call run_tricys_simulations() or specify csv_file_path\"\n                )\n\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        csv_abs_path = os.path.abspath(csv_file_path)\n\n        import copy\n\n        tricys_config = copy.deepcopy(self.base_config)\n        tricys_config[\"simulation_parameters\"] = {\"file\": csv_abs_path}\n\n        if \"sensitivity_analysis\" not in tricys_config:\n            tricys_config[\"sensitivity_analysis\"] = {\"enabled\": True}\n\n        tricys_config[\"sensitivity_analysis\"][\"analysis_case\"] = {\n            \"name\": \"SALib_Analysis\",\n            \"independent_variable\": \"file\",\n            \"independent_variable_sampling\": csv_abs_path,\n            \"dependent_variables\": output_metrics,\n        }\n\n        return tricys_config\n\n    def load_tricys_results(\n        self, sensitivity_summary_csv: str, output_metrics: List[str] = None\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys\n\n        Args:\n            sensitivity_summary_csv: Path to the sensitivity analysis summary CSV file output by Tricys\n            output_metrics: List of output metrics to extract\n\n        Returns:\n            Simulation result array (n_samples, n_metrics)\n        \"\"\"\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        logger.info(f\"Read data from the Tricys result file: {sensitivity_summary_csv}\")\n\n        df = pd.read_csv(sensitivity_summary_csv)\n\n        logger.info(f\"Read {len(df)} simulation results\")\n        logger.info(f\"Result file columns: {list(df.columns)}\")\n\n        param_cols = []\n        metric_cols = []\n\n        for col in df.columns:\n            if col in output_metrics:\n                metric_cols.append(col)\n            elif col in self.problem[\"names\"] if self.problem else False:\n                param_cols.append(col)\n\n        logger.info(f\"Recognized parameter columns: {param_cols}\")\n        logger.info(f\"Identified metric columns: {metric_cols}\")\n\n        ordered_metric_cols = []\n        for metric in output_metrics:\n            if metric in metric_cols:\n                ordered_metric_cols.append(metric)\n            else:\n                logger.warning(f\"Metric column not found: {metric}\")\n\n        if not ordered_metric_cols:\n            raise ValueError(f\"No valid output metrics columns found: {output_metrics}\")\n\n        results_data = df[ordered_metric_cols].values\n\n        self.simulation_results = results_data\n\n        logger.info(f\"Successfully loaded simulation results: {results_data.shape}\")\n        logger.info(\n            f\"Result Statistics:\\n{pd.DataFrame(results_data, columns=ordered_metric_cols).describe()}\"\n        )\n        logger.info(\n            f\"Result preview:\\n{pd.DataFrame(results_data, columns=metric_cols).head()}\"\n        )\n        return self.simulation_results\n\n    def get_compatible_analysis_methods(self, sampling_method: str) -&gt; List[str]:\n        \"\"\"\n        Get analysis methods compatible with the specified sampling method.\n\n        Args:\n            sampling_method: Sampling method\n\n        Returns:\n            List of compatible analysis methods\n        \"\"\"\n        compatibility_map = {\n            \"sobol\": [\"sobol\"],\n            \"morris\": [\"morris\"],\n            \"fast\": [\"fast\"],\n            \"latin\": [\"latin\"],\n            \"unknown\": [],\n        }\n\n        return compatibility_map.get(sampling_method, [])\n\n    def run_tricys_analysis(\n        self, csv_file_path: str = None, output_metrics: List[str] = None\n    ) -&gt; str:\n        \"\"\"\n        Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results\n\n        Args:\n            csv_file_path: Path to the CSV parameter file. If None, the last generated file will be used\n            output_metrics: List of output metrics to be calculated\n            config_output_path: Path for the configuration file output. If None, it will be automatically generated\n\n        Returns:\n            Path to the sensitivity_analysis_summary.csv file\n        \"\"\"\n        # Generate Tricys configuration file\n        tricys_config = self.generate_tricys_config(\n            csv_file_path=csv_file_path, output_metrics=output_metrics\n        )\n\n        logger.info(\"Starting Tricys simulation analysis...\")\n\n        try:\n            # Call the Tricys simulation engine\n            from datetime import datetime\n\n            from tricys.simulation.simulation_analysis import run_simulation\n\n            tricys_config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n            run_simulation(tricys_config)\n\n            results_dir = tricys_config[\"paths\"][\"results_dir\"]\n\n            return Path(results_dir) / \"sensitivity_analysis_summary.csv\"\n\n        except Exception as e:\n            logger.error(f\"Tricys simulation execution failed: {e}\")\n            raise\n\n    def analyze_sobol(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform Sobol Sensitivity Analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Sobol analysis parameters\n\n        Returns:\n            Sobol sensitivity analysis results\n\n        Note:\n            Sobol analysis requires samples generated using the Saltelli sampling method!\n            Results from Morris or FAST sampling cannot be used.\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        # Check sampling method compatibility\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"sobol\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f Currently using {self._last_sampling_method} sampling, but Sobol analysis requires Saltelli sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('sobol')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"Sobol\u5206\u6790\")\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n        #    X = self.parameter_samples[valid_indices]\n        # else:\n        #    X = self.parameter_samples\n\n        try:\n            Si = sobol.analyze(self.problem, Y, **kwargs)\n\n            if \"sobol\" not in self.sensitivity_results:\n                self.sensitivity_results[\"sobol\"] = {}\n\n            metric_name = f\"metric_{output_index}\"\n            self.sensitivity_results[\"sobol\"][metric_name] = {\n                \"output_index\": output_index,\n                \"Si\": Si,\n                \"S1\": Si[\"S1\"],\n                \"ST\": Si[\"ST\"],\n                \"S2\": Si.get(\"S2\", None),\n                \"S1_conf\": Si[\"S1_conf\"],\n                \"ST_conf\": Si[\"ST_conf\"],\n                \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n            }\n\n            logger.info(f\"Sobol sensitivity analysis completed (index {output_index})\")\n            return self.sensitivity_results[\"sobol\"][metric_name]\n\n        except Exception as e:\n            if \"saltelli\" in str(e).lower() or \"sample\" in str(e).lower():\n                raise ValueError(\n                    f\"Sobol analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('sobol')\"\n                ) from e\n            else:\n                raise\n\n    def analyze_morris(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform Morris sensitivity analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Morris analysis parameters\n\n        Returns:\n            Morris sensitivity analysis results\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"Morris\u5206\u6790\")\n        X = self.parameter_samples\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n        #    X = self.parameter_samples[valid_indices]\n        # else:\n        #    X = self.parameter_samples\n\n        # Perform Morris analysis\n        logger.info(\n            f\"Start Morris sensitivity analysis: X.shape={X.shape}, Y.shape={Y.shape}, X.dtype={X.dtype}\"\n        )\n\n        try:\n            Si = morris_analyze.analyze(self.problem, X, Y, **kwargs)\n        except Exception as e:\n            logger.error(f\"Morris analysis execution failed: {e}\")\n            logger.error(f\"problem: {self.problem}\")\n            logger.error(f\"X shape: {X.shape}, type: {X.dtype}\")\n            logger.error(f\"Yshape: {Y.shape}, type: {Y.dtype}\")\n            if hasattr(X, \"dtype\") and X.dtype == \"object\":\n                logger.error(\n                    \"X contains non-numeric data, please check the sampled data\"\n                )\n            raise\n\n        if \"morris\" not in self.sensitivity_results:\n            self.sensitivity_results[\"morris\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"morris\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"mu\": Si[\"mu\"],\n            \"mu_star\": Si[\"mu_star\"],\n            \"sigma\": Si[\"sigma\"],\n            \"mu_star_conf\": Si[\"mu_star_conf\"],\n        }\n\n        logger.info(f\"Morris sensitivity analysis completed (metric {output_index})\")\n        return self.sensitivity_results[\"morris\"][metric_name]\n\n    def analyze_fast(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform FAST sensitivity analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: FAST analysis parameters\n\n        Returns:\n            FAST sensitivity analysis results\n\n        Note:\n            FAST analysis requires samples generated by the fast_sampler sampling method!\n            Results from Morris or Sobol sampling cannot be used.\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"fast\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but FAST analysis requires FAST sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('fast')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"FAST\u5206\u6790\")\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n\n        try:\n            # Perform FAST analysis\n            Si = fast.analyze(self.problem, Y, **kwargs)\n\n            if \"fast\" not in self.sensitivity_results:\n                self.sensitivity_results[\"fast\"] = {}\n\n            metric_name = f\"metric_{output_index}\"\n            self.sensitivity_results[\"fast\"][metric_name] = {\n                \"output_index\": output_index,\n                \"Si\": Si,\n                \"S1\": Si[\"S1\"],\n                \"ST\": Si[\"ST\"],\n                \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n            }\n\n            logger.info(\n                f\"FAST sensitivity analysis completed (indicator {output_index})\"\n            )\n            return self.sensitivity_results[\"fast\"][metric_name]\n\n        except Exception as e:\n            if \"fast\" in str(e).lower() or \"sample\" in str(e).lower():\n                raise ValueError(\n                    f\"FAST analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('fast')\"\n                ) from e\n            else:\n                raise\n\n    def analyze_lhs(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform LHS (Latin Hypercube Sampling) uncertainty analysis\n\n        Note: This is a basic statistical analysis method for LHS samples,\n        providing descriptive statistics and basic sensitivity indices.\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Analysis parameters (reserved for future use)\n\n        Returns:\n            LHS uncertainty analysis results\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"latin\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but LHS analysis is designed for Latin Hypercube Sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('latin')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        # Handle NaN values\n        Y = self._handle_nan_values(Y, \"LHS\u5206\u6790\")\n\n        # Basic statistical analysis\n        mean_val = np.mean(Y)\n        std_val = np.std(Y)\n        min_val = np.min(Y)\n        max_val = np.max(Y)\n        percentile_5 = np.percentile(Y, 5)\n        percentile_95 = np.percentile(Y, 95)\n\n        # Create results dictionary\n        Si = {\n            \"mean\": mean_val,\n            \"std\": std_val,\n            \"min\": min_val,\n            \"max\": max_val,\n            \"percentile_5\": percentile_5,\n            \"percentile_95\": percentile_95,\n        }\n\n        if \"latin\" not in self.sensitivity_results:\n            self.sensitivity_results[\"latin\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"latin\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"mean\": mean_val,\n            \"std\": std_val,\n            \"min\": min_val,\n            \"max\": max_val,\n            \"percentile_5\": percentile_5,\n            \"percentile_95\": percentile_95,\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(f\"LHS uncertainty analysis completed (\u6307\u6807 {output_index})\")\n        return self.sensitivity_results[\"latin\"][metric_name]\n\n    def run_salib_analysis_from_tricys_results(\n        self,\n        sensitivity_summary_csv: str,\n        param_bounds: Dict[str, Tuple[float, float]] = None,\n        output_metrics: List[str] = None,\n        methods: List[str] = [\"sobol\", \"morris\", \"fast\"],\n        save_dir: str = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys\n\n        Args:\n            sensitivity_summary_csv: Path to the sensitivity summary CSV file output by Tricys\n            param_bounds: Dictionary of parameter bounds, inferred from the CSV file if None\n            output_metrics: List of output metrics to analyze\n            methods: List of sensitivity analysis methods to execute\n            save_dir: Directory to save the results\n\n        Returns:\n            Dictionary containing all analysis results\n        \"\"\"\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        if save_dir is None:\n            save_dir = os.path.join(\n                os.path.dirname(sensitivity_summary_csv), \"salib_analysis\"\n            )\n        os.makedirs(save_dir, exist_ok=True)\n\n        df = pd.read_csv(sensitivity_summary_csv)\n\n        if param_bounds is None:\n            param_bounds = {}\n            param_candidates = []\n            for col in df.columns:\n                if col not in output_metrics and \".\" in col:\n                    param_candidates.append(col)\n\n            for param in param_candidates:\n                param_data = df[param].dropna()\n                if len(param_data) &gt; 0:\n                    param_bounds[param] = (param_data.min(), param_data.max())\n\n        if not param_bounds:\n            raise ValueError(\n                \"Unable to determine parameter boundaries, please provide the param_bounds parameter\"\n            )\n\n        self.define_problem(param_bounds)\n\n        self.load_tricys_results(sensitivity_summary_csv, output_metrics)\n\n        detected_method = self._last_sampling_method\n\n        methods = self.get_compatible_analysis_methods(detected_method)\n\n        all_results = {}\n\n        for metric_idx, metric_name in enumerate(output_metrics):\n            if metric_idx &gt;= self.simulation_results.shape[1]:\n                logger.warning(f\"The metric {metric_name} is out of range, skipping\")\n                continue\n\n            logger.info(f\"\\n=== Analysis indicators: {metric_name} ===\")\n            metric_results = {}\n\n            # Check data validity\n            Y = self.simulation_results[:, metric_idx]\n            valid_ratio = np.sum(~np.isnan(Y)) / len(Y)\n            logger.info(f\"Valid data ratio: {valid_ratio:.2%}\")\n\n            if valid_ratio &lt; 0.5:\n                logger.warning(\n                    f\"The metric {metric_name} has less than 50% valid data, which may affect the analysis quality.\"\n                )\n\n            # Sobol analysis\n            if \"sobol\" in methods:\n                try:\n                    logger.info(\"Performing Sobol sensitivity analysis...\")\n                    sobol_result = self.analyze_sobol(output_index=metric_idx)\n                    metric_results[\"sobol\"] = sobol_result\n\n                    # Display Sobol results summary\n                    logger.info(\"\\nSobol sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        s1 = sobol_result[\"S1\"][i]\n                        st = sobol_result[\"ST\"][i]\n                        logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"Sobol analysis failed: {e}\")\n\n            # Morris analysis\n            if \"morris\" in methods:\n                try:\n                    logger.info(\"Performing Morris sensitivity analysis...\")\n                    morris_result = self.analyze_morris(output_index=metric_idx)\n                    metric_results[\"morris\"] = morris_result\n\n                    # Display Morris results summary\n                    logger.info(\"\\nMorris sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        mu_star = morris_result[\"mu_star\"][i]\n                        sigma = morris_result[\"sigma\"][i]\n                        logger.info(f\"  {param_name}: \u03bc*={mu_star:.4f}, \u03c3={sigma:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"Morris analysis failed: {e}\")\n\n            # FAST analysis\n            if \"fast\" in methods:\n                try:\n                    logger.info(\"Performing FAST sensitivity analysis...\")\n                    fast_result = self.analyze_fast(output_index=metric_idx)\n                    metric_results[\"fast\"] = fast_result\n\n                    # Display FAST results summary\n                    logger.info(\"\\nFAST sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        s1 = fast_result[\"S1\"][i]\n                        st = fast_result[\"ST\"][i]\n                        logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"FAST analysis failed: {e}\")\n\n            # LHS analysis\n            if \"latin\" in methods:\n                try:\n                    logger.info(\"Performing LHS uncertainty analysis...\")\n                    lhs_result = self.analyze_lhs(output_index=metric_idx)\n                    metric_results[\"latin\"] = lhs_result\n\n                    # Display LHS results summary\n                    logger.info(\"\\nLHS\u5206\u6790\u7ed3\u679c:\")\n                    logger.info(f\"  \u5747\u503c: {lhs_result['mean']:.4f}\")\n                    logger.info(f\"  \u6807\u51c6\u5dee: {lhs_result['std']:.4f}\")\n                    logger.info(f\"  \u6700\u5c0f\u503c: {lhs_result['min']:.4f}\")\n                    logger.info(f\"  \u6700\u5927\u503c: {lhs_result['max']:.4f}\")\n                    logger.info(f\"  5%\u5206\u4f4d\u6570: {lhs_result['percentile_5']:.4f}\")\n                    logger.info(f\"  95%\u5206\u4f4d\u6570: {lhs_result['percentile_95']:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"LHS\u5206\u6790\u5931\u8d25: {e}\")\n\n            all_results[metric_name] = metric_results\n\n        try:\n            if \"sobol\" in methods and \"sobol\" in self.sensitivity_results:\n                self.plot_sobol_results(save_dir=save_dir, metric_names=output_metrics)\n\n            if \"morris\" in methods and \"morris\" in self.sensitivity_results:\n                self.plot_morris_results(save_dir=save_dir, metric_names=output_metrics)\n\n            if \"fast\" in methods and \"fast\" in self.sensitivity_results:\n                self.plot_fast_results(save_dir=save_dir, metric_names=output_metrics)\n\n            # Plot LHS results\n            if \"latin\" in methods and \"latin\" in self.sensitivity_results:\n                self.plot_lhs_results(save_dir=save_dir, metric_names=output_metrics)\n\n        except Exception as e:\n            logger.warning(f\"Drawing failed: {e}\")\n\n        try:\n            self.save_results(\n                save_dir=save_dir, format=\"csv\", metric_names=output_metrics\n            )\n\n            report_content = self._save_sensitivity_report(all_results, save_dir)\n            report_path = os.path.join(save_dir, \"analysis_report.md\")\n\n            load_dotenv()\n\n            # --- LLM Calls for analysis ---\n            api_key = os.environ.get(\"API_KEY\")\n            base_url = os.environ.get(\"BASE_URL\")\n            ai_model = os.environ.get(\"AI_MODEL\")\n\n            sa_config = self.base_config.get(\"sensitivity_analysis\", {})\n            case_config = sa_config.get(\"analysis_case\", {})\n            ai_config = case_config.get(\"ai\")\n\n            ai_enabled = False\n            if isinstance(ai_config, bool):\n                ai_enabled = ai_config\n            elif isinstance(ai_config, dict):\n                ai_enabled = ai_config.get(\"enabled\", False)\n\n            if api_key and base_url and ai_model and ai_enabled:\n                # First LLM call for initial analysis\n                wrapper_prompt, llm_summary = call_llm_for_salib_analysis(\n                    report_content=report_content,\n                    api_key=api_key,\n                    base_url=base_url,\n                    ai_model=ai_model,\n                    method=detected_method,\n                )\n                if wrapper_prompt and llm_summary:\n                    with open(report_path, \"a\", encoding=\"utf-8\") as f:\n                        f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd\\n\\n\")\n                        f.write(\"```markdown\\n\")\n                        f.write(wrapper_prompt)\n                        f.write(\"\\n```\\n\\n\")\n                        f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\")\n                        f.write(llm_summary)\n                    logger.info(f\"Appended LLM prompt and summary to {report_path}\")\n\n                    # Second LLM call for academic report\n                    glossary_path = None\n                    if isinstance(case_config, dict):\n                        glossary_path = sa_config.get(\"glossary_path\")\n\n                    if glossary_path and os.path.exists(glossary_path):\n                        try:\n                            with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n                                glossary_content = f.read()\n\n                            (\n                                academic_wrapper_prompt,\n                                academic_report,\n                            ) = call_llm_for_academic_report(\n                                analysis_report=llm_summary,\n                                glossary_content=glossary_content,\n                                api_key=api_key,\n                                base_url=base_url,\n                                ai_model=ai_model,\n                                problem_details=self.problem,\n                                metric_names=output_metrics,\n                                method=detected_method,\n                                save_dir=save_dir,\n                            )\n\n                            if academic_wrapper_prompt and academic_report:\n                                academic_report_path = os.path.join(\n                                    save_dir, \"academic_report.md\"\n                                )\n                                with open(\n                                    academic_report_path, \"w\", encoding=\"utf-8\"\n                                ) as f:\n                                    f.write(academic_report)\n                                logger.info(\n                                    f\"Generated academic report: {academic_report_path}\"\n                                )\n                        except Exception as e:\n                            logger.error(\n                                f\"Failed to generate or save academic report: {e}\"\n                            )\n                    elif glossary_path:\n                        logger.warning(\n                            f\"Glossary file not found at {glossary_path}, skipping academic report generation.\"\n                        )\n\n            else:\n                logger.warning(\n                    \"API_KEY, BASE_URL, or AI_MODEL not set, or AI analysis is disabled. Skipping LLM summary generation.\"\n                )\n\n        except Exception as e:\n            logger.warning(f\"Failed to save result: {e}\")\n\n        logger.info(\"\\n\u2705 SALib sensitivity analysis completed!\")\n        logger.info(f\"\ud83d\udcc1 The result has been saved to: {save_dir}\")\n\n        return all_results\n\n    def _save_sensitivity_report(\n        self, all_results: Dict[str, Any], save_dir: str\n    ) -&gt; str:\n        \"\"\"The result has been saved to: {save_dir}\"\"\"\n        report_file = os.path.join(save_dir, \"analysis_report.md\")\n        # Determine analysis type based on sampling method\n        is_uncertainty_analysis = (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method == \"latin\"\n        )\n        report_title = (\n            \"# SALib \u4e0d\u786e\u5b9a\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n            if is_uncertainty_analysis\n            else \"# SALib \u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n        )\n        report_lines = []\n        report_lines.append(report_title)\n        report_lines.append(f\"\u751f\u6210\u65f6\u95f4: {pd.Timestamp.now()}\\n\\n\")\n        # Get unit_map from config\n        sensitivity_analysis_config = self.base_config.get(\"sensitivity_analysis\", {})\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n        report_lines.append(\"## \u5206\u6790\u53c2\u6570\\n\\n\")\n        if self.problem:\n            for i, param_name in enumerate(self.problem[\"names\"]):\n                bounds = self.problem[\"bounds\"][i]\n                # --- Unit Conversion Logic for Bounds ---\n                unit_config = self._find_unit_config(param_name, unit_map)\n                display_bounds = list(bounds)\n                unit_str = \"\"\n                if unit_config:\n                    unit = unit_config.get(\"unit\")\n                    factor = unit_config.get(\"conversion_factor\")\n                    if factor:\n                        display_bounds[0] /= float(factor)\n                        display_bounds[1] /= float(factor)\n                    if unit:\n                        unit_str = f\" ({unit})\"\n                # --- End Conversion Logic ---\n                report_lines.append(\n                    f\"- **{param_name}**: [{display_bounds[0]:.4f}, {display_bounds[1]:.4f}]{unit_str}\\n\"\n                )\n        report_lines.append(\"\\n\")\n        for metric_name, metric_results in all_results.items():\n            metric_section_title = (\n                f\"## {metric_name} \u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7ed3\u679c\\n\\n\"\n                if is_uncertainty_analysis\n                else f\"## {metric_name} \u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\\n\\n\"\n            )\n            report_lines.append(metric_section_title)\n            if \"sobol\" in metric_results:\n                report_lines.append(\"### Sobol\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\n                    \"| \u53c2\u6570 | S1 (\u4e00\u9636) | ST (\u603b) | S1\u7f6e\u4fe1\u533a\u95f4 | ST\u7f6e\u4fe1\u533a\u95f4 |\\n\"\n                )\n                report_lines.append(\n                    \"|------|----------|---------|------------|------------|\\n\"\n                )\n                sobol_data = metric_results[\"sobol\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = sobol_data[\"S1\"][i]\n                    st = sobol_data[\"ST\"][i]\n                    s1_conf = sobol_data[\"S1_conf\"][i]\n                    st_conf = sobol_data[\"ST_conf\"][i]\n                    report_lines.append(\n                        f\"| {param_name} | {s1:.4f} | {st:.4f} | \u00b1{s1_conf:.4f} | \u00b1{st_conf:.4f} |\\n\"\n                    )\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'sobol_sensitivity_indices_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![Sobol Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"morris\" in metric_results:\n                report_lines.append(\"### Morris\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\n                    \"| \u53c2\u6570 | \u03bc* (\u5e73\u5747\u7edd\u5bf9\u6548\u5e94) | \u03c3 (\u6807\u51c6\u5dee) | \u03bc*\u7f6e\u4fe1\u533a\u95f4 |\\n\"\n                )\n                report_lines.append(\n                    \"|------|-------------------|------------|------------|\\n\"\n                )\n                morris_data = metric_results[\"morris\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    mu_star = morris_data[\"mu_star\"][i]\n                    sigma = morris_data[\"sigma\"][i]\n                    mu_star_conf = morris_data[\"mu_star_conf\"][i]\n                    report_lines.append(\n                        f\"| {param_name} | {mu_star:.4f} | {sigma:.4f} | \u00b1{mu_star_conf:.4f} |\\n\"\n                    )\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'morris_sensitivity_analysis_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![Morris Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"fast\" in metric_results:\n                report_lines.append(\"### FAST\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\"| \u53c2\u6570 | S1 (\u4e00\u9636) | ST (\u603b) |\\n\")\n                report_lines.append(\"|------|----------|---------|\\n\")\n                fast_data = metric_results[\"fast\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = fast_data[\"S1\"][i]\n                    st = fast_data[\"ST\"][i]\n                    report_lines.append(f\"| {param_name} | {s1:.4f} | {st:.4f} |\\n\")\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'fast_sensitivity_indices_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![FAST Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"latin\" in metric_results:\n                # --- Unit Conversion Logic for Metrics ---\n                unit_config = self._find_unit_config(metric_name, unit_map)\n                unit_str = \"\"\n                factor = 1.0\n                if unit_config:\n                    unit = unit_config.get(\"unit\")\n                    conv_factor = unit_config.get(\"conversion_factor\")\n                    if conv_factor:\n                        factor = float(conv_factor)\n                    if unit:\n                        unit_str = f\" ({unit})\"\n                # --- End Conversion Logic ---\n                # 1. Get raw data and clean it\n                output_index = metric_results[\"latin\"][\"output_index\"]\n                Y = self.simulation_results[:, output_index]\n                Y_clean = Y[~np.isnan(Y)]\n                # --- Modify report generation ---\n                report_lines.append(\"### \u7edf\u8ba1\u6458\u8981\\n\\n\")\n                lhs_data = metric_results[\"latin\"]\n                report_lines.append(\n                    f\"- \u5747\u503c: {lhs_data['mean']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6807\u51c6\u5dee: {lhs_data['std']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6700\u5c0f\u503c: {lhs_data['min']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6700\u5927\u503c: {lhs_data['max']/factor:.4f}{unit_str}\\n\\n\"\n                )\n                # 2. Calculate more percentiles\n                if len(Y_clean) &gt; 0:\n                    percentiles_to_calc = [5, 10, 25, 50, 75, 90, 95]\n                    percentile_values = np.percentile(Y_clean, percentiles_to_calc)\n                    report_lines.append(\"### \u5206\u5e03\u5173\u952e\u70b9 (CDF)\\n\\n\")\n                    report_lines.append(\n                        f\"- 5%\u5206\u4f4d\u6570: {percentile_values[0]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 10%\u5206\u4f4d\u6570: {percentile_values[1]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 25%\u5206\u4f4d\u6570 (Q1): {percentile_values[2]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 50%\u5206\u4f4d\u6570 (\u4e2d\u4f4d\u6570): {percentile_values[3]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 75%\u5206\u4f4d\u6570 (Q3): {percentile_values[4]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 90%\u5206\u4f4d\u6570: {percentile_values[5]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 95%\u5206\u4f4d\u6570: {percentile_values[6]/factor:.4f}{unit_str}\\n\\n\"\n                    )\n                    # 3. Calculate histogram data\n                    hist_freq, bin_edges = np.histogram(Y_clean, bins=10)\n                    report_lines.append(\"### \u8f93\u51fa\u5206\u5e03 (\u76f4\u65b9\u56fe\u6570\u636e)\\n\\n\")\n                    report_lines.append(\"| \u6570\u503c\u8303\u56f4 | \u9891\u6570 |\\n\")\n                    report_lines.append(\"|:---|---:|\\n\")\n                    for i in range(len(hist_freq)):\n                        lower_bound = bin_edges[i] / factor\n                        upper_bound = bin_edges[i + 1] / factor\n                        freq = hist_freq[i]\n                        report_lines.append(\n                            f\"| {lower_bound:.2f} - {upper_bound:.2f} | {freq} |\\n\"\n                        )\n                    report_lines.append(\"\\n\")\n                plot_filename = f'lhs_analysis_{metric_name.replace(\" \", \"_\")}.png'\n                report_lines.append(\n                    f\"![LHS Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n        report_content = \"\".join(report_lines)\n        with open(report_file, \"w\", encoding=\"utf-8\") as f:\n            f.write(report_content)\n        logger.info(f\"The sensitivity analysis report has been saved.: {report_file}\")\n        return report_content\n\n    def plot_sobol_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot Sobol analysis results\"\"\"\n        if \"sobol\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results for the Sobol method were found.\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        sobol_results = self.sensitivity_results[\"sobol\"]\n\n        if not sobol_results:\n            raise ValueError(\"Sobol analysis results not found\")\n\n        # Generate charts for each metric\n        for metric_key, results in sobol_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Bar chart of first-order and total sensitivity indices\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # First-order sensitivity index\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax1.barh(y_pos, Si[\"S1\"], xerr=Si[\"S1_conf\"], alpha=0.7, color=\"skyblue\")\n            ax1.set_yticks(y_pos)\n            ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax1.set_xlabel(\"First-order sensitivity index (S1)\", fontsize=12)\n            ax1.set_title(\n                f\"First-order Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax1.grid(True, alpha=0.3)\n\n            # # Total Sensitivity Index\n            ax2.barh(y_pos, Si[\"ST\"], xerr=Si[\"ST_conf\"], alpha=0.7, color=\"orange\")\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"Total Sensitivity Index (ST)\", fontsize=12)\n            ax2.set_title(\n                f\"Total Sensitivity Indices\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = (\n                f'sobol_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n            )\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"Sobol result chart has been saved: {filename}\")\n\n    def plot_morris_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot the Morris analysis results\"\"\"\n        if \"morris\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results were found for the Morris method.\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Obtain the results of all indicators\n        morris_results = self.sensitivity_results[\"morris\"]\n\n        if not morris_results:\n            raise ValueError(\"No Morris analysis results found\")\n\n        for metric_key, results in morris_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Morris \u03bc*-\u03c3 diagram\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # \u03bc*-\u03c3 scatter plot\n            ax1.scatter(Si[\"mu_star\"], Si[\"sigma\"], s=100, alpha=0.7, color=\"red\")\n            for i, name in enumerate(self.problem[\"names\"]):\n                ax1.annotate(\n                    name,\n                    (Si[\"mu_star\"][i], Si[\"sigma\"][i]),\n                    xytext=(5, 5),\n                    textcoords=\"offset points\",\n                    fontsize=9,\n                )\n\n            ax1.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n            ax1.set_ylabel(\"\u03c3 (Standard Deviation)\", fontsize=12)\n            ax1.set_title(\n                f\"Morris \u03bc*-\u03c3 Plot\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax1.grid(True, alpha=0.3)\n\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax2.barh(\n                y_pos, Si[\"mu_star\"], xerr=Si[\"mu_star_conf\"], alpha=0.7, color=\"green\"\n            )\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n            ax2.set_title(\n                f\"Morris Elementary Effects\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = f'morris_sensitivity_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"Morris result chart has been saved: {filename}\")\n\n    def plot_fast_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot FAST analysis results\"\"\"\n        if \"fast\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results found for the FAST method\")\n\n        # No analysis results found for the FAST method\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        fast_results = self.sensitivity_results[\"fast\"]\n\n        if not fast_results:\n            raise ValueError(\"FAST analysis results not found\")\n\n        # Generate a chart for each metric\n        for metric_key, results in fast_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            # Determine the indicator name\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Bar charts of first-order and total sensitivity indices\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # first-order sensitivity index\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax1.barh(y_pos, Si[\"S1\"], alpha=0.7, color=\"purple\")\n            ax1.set_yticks(y_pos)\n            ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax1.set_xlabel(\"\u4e00\u9636\u654f\u611f\u6027\u6307\u6570 (S1)\", fontsize=12)\n            ax1.set_title(\n                f\"FAST First-order Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax1.grid(True, alpha=0.3)\n\n            # Total Sensitivity Index\n            ax2.barh(y_pos, Si[\"ST\"], alpha=0.7, color=\"darkgreen\")\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"\u603b\u654f\u611f\u6027\u6307\u6570 (ST)\", fontsize=12)\n            ax2.set_title(\n                f\"FAST Total Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = (\n                f'fast_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n            )\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"The FAST result chart has been saved: {filename}\")\n\n    def plot_lhs_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot LHS (Latin Hypercube Sampling) uncertainty analysis results\"\"\"\n        if \"latin\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results found for the LHS method\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        lhs_results = self.sensitivity_results[\"latin\"]\n\n        if not lhs_results:\n            raise ValueError(\"LHS analysis results not found\")\n\n        # Generate charts for each metric\n        for metric_key, results in lhs_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            # Determine the indicator name\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Get unit from config\n            sensitivity_analysis_config = self.base_config.get(\n                \"sensitivity_analysis\", {}\n            )\n            unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n            unit_config = self._find_unit_config(metric_display_name, unit_map)\n            unit_str = \"\"\n            if unit_config:\n                unit = unit_config.get(\"unit\")\n                if unit:\n                    unit_str = f\" ({unit})\"\n\n            xlabel = f\"{metric_display_name}{unit_str}\"\n\n            # Create a figure with two subplots\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # Plot 1: Distribution histogram\n            ax1.hist(\n                self.simulation_results[:, output_index],\n                bins=30,\n                alpha=0.7,\n                color=\"skyblue\",\n                edgecolor=\"black\",\n            )\n            ax1.set_xlabel(xlabel, fontsize=12)\n            ax1.set_ylabel(\"\u9891\u7387\", fontsize=12)\n            ax1.set_title(\"\u8f93\u51fa\u5206\u5e03\u76f4\u65b9\u56fe\", fontsize=14, pad=10)\n            ax1.grid(True, alpha=0.3)\n\n            # Add statistics text to the histogram plot\n            stats_text = f\"\u5747\u503c: {Si['mean']:.4f}\\n\u6807\u51c6\u5dee: {Si['std']:.4f}\\n\u6700\u5c0f\u503c: {Si['min']:.4f}\\n\u6700\u5927\u503c: {Si['max']:.4f}\"\n            ax1.text(\n                0.05,\n                0.95,\n                stats_text,\n                transform=ax1.transAxes,\n                fontsize=10,\n                verticalalignment=\"top\",\n                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n            )\n\n            # Plot 2: Cumulative distribution function\n            sorted_data = np.sort(self.simulation_results[:, output_index])\n            y_vals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n            ax2.plot(sorted_data, y_vals, linewidth=2, color=\"darkgreen\")\n            ax2.set_xlabel(xlabel, fontsize=12)\n            ax2.set_ylabel(\"\u7d2f\u79ef\u6982\u7387\", fontsize=12)\n            ax2.set_title(\"\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\", fontsize=14, pad=10)\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = f'lhs_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"LHS\u5206\u6790\u7ed3\u679c\u56fe\u8868\u5df2\u4fdd\u5b58: {filename}\")\n\n    def save_results(\n        self, save_dir: str = None, format: str = \"csv\", metric_names: List[str] = None\n    ) -&gt; None:\n        \"\"\"\n        Save sensitivity analysis results\n\n        Args:\n            save_dir: Save directory\n            format: Save format ('csv\n        \"\"\"\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        for method, method_results in self.sensitivity_results.items():\n            if not method_results:\n                continue\n\n            for metric_key, results in method_results.items():\n                output_index = results[\"output_index\"]\n\n                if metric_names and output_index &lt; len(metric_names):\n                    metric_display_name = metric_names[output_index]\n                else:\n                    metric_display_name = f\"Metric_{output_index}\"\n\n                if format == \"csv\":\n                    if method == \"sobol\":\n                        sobol_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"S1\": results[\"S1\"],\n                                \"ST\": results[\"ST\"],\n                                \"S1_conf\": results[\"S1_conf\"],\n                                \"ST_conf\": results[\"ST_conf\"],\n                            }\n                        )\n                        filename = (\n                            f'sobol_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        sobol_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"Sobol results have been saved: {filename}\")\n\n                    elif method == \"morris\":\n                        morris_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"mu\": results[\"mu\"],\n                                \"mu_star\": results[\"mu_star\"],\n                                \"sigma\": results[\"sigma\"],\n                                \"mu_star_conf\": results[\"mu_star_conf\"],\n                            }\n                        )\n                        filename = f'morris_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        morris_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"Morris results have been saved: {filename}\")\n\n                    elif method == \"fast\":\n                        fast_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"S1\": results[\"S1\"],\n                                \"ST\": results[\"ST\"],\n                            }\n                        )\n                        filename = (\n                            f'fast_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        fast_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"FAST results have been saved: {filename}\")\n\n                    elif method == \"latin\":\n                        # Save LHS statistics\n                        lhs_stats_df = pd.DataFrame(\n                            {\n                                \"Metric\": [metric_display_name],\n                                \"Mean\": [results[\"mean\"]],\n                                \"Std\": [results[\"std\"]],\n                                \"Min\": [results[\"min\"]],\n                                \"Max\": [results[\"max\"]],\n                                \"Percentile_5\": [results[\"percentile_5\"]],\n                                \"Percentile_95\": [results[\"percentile_95\"]],\n                            }\n                        )\n                        filename_stats = (\n                            f'lhs_stats_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        lhs_stats_df.to_csv(\n                            os.path.join(save_dir, filename_stats), index=False\n                        )\n                        logger.info(f\"LHS\u7edf\u8ba1\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_stats}\")\n\n                        # Remove LHS sensitivity indices saving\n                        # lhs_sens_df = pd.DataFrame({\n                        #     \"Parameter\": self.problem[\"names\"],\n                        #     \"Partial_Correlation\": results[\"partial_correlations\"]\n                        # })\n                        # filename_sens = f'lhs_sensitivity_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        # lhs_sens_df.to_csv(os.path.join(save_dir, filename_sens), index=False)\n                        # logger.info(f\"LHS\u654f\u611f\u6027\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_sens}\")\n\n        logger.info(f\"The result has been saved to: {save_dir}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.__init__","title":"<code>__init__(base_config)</code>","text":"<p>Initialize the analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>base_config</code> <code>Dict[str, Any]</code> <p>Tricys base configuration dictionary.</p> required Note <p>Creates a deep copy of base_config. Initializes problem, samples, and results to None. Calls _setup_chinese_font() and _validate_tricys_config() automatically.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def __init__(self, base_config: Dict[str, Any]) -&gt; None:\n    \"\"\"Initialize the analyzer.\n\n    Args:\n        base_config: Tricys base configuration dictionary.\n\n    Note:\n        Creates a deep copy of base_config. Initializes problem, samples, and results\n        to None. Calls _setup_chinese_font() and _validate_tricys_config() automatically.\n    \"\"\"\n    self.base_config = base_config.copy()\n    self.problem = None\n    self.parameter_samples = None\n    self.simulation_results = None\n    self.sensitivity_results = {}\n\n    self._setup_chinese_font()\n    self._validate_tricys_config()\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_fast","title":"<code>analyze_fast(output_index=0, **kwargs)</code>","text":"<p>Perform FAST sensitivity analysis</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>FAST analysis parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>FAST sensitivity analysis results</p> Note <p>FAST analysis requires samples generated by the fast_sampler sampling method! Results from Morris or Sobol sampling cannot be used.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_fast(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform FAST sensitivity analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: FAST analysis parameters\n\n    Returns:\n        FAST sensitivity analysis results\n\n    Note:\n        FAST analysis requires samples generated by the fast_sampler sampling method!\n        Results from Morris or Sobol sampling cannot be used.\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"fast\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but FAST analysis requires FAST sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('fast')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"FAST\u5206\u6790\")\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n\n    try:\n        # Perform FAST analysis\n        Si = fast.analyze(self.problem, Y, **kwargs)\n\n        if \"fast\" not in self.sensitivity_results:\n            self.sensitivity_results[\"fast\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"fast\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"S1\": Si[\"S1\"],\n            \"ST\": Si[\"ST\"],\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(\n            f\"FAST sensitivity analysis completed (indicator {output_index})\"\n        )\n        return self.sensitivity_results[\"fast\"][metric_name]\n\n    except Exception as e:\n        if \"fast\" in str(e).lower() or \"sample\" in str(e).lower():\n            raise ValueError(\n                f\"FAST analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('fast')\"\n            ) from e\n        else:\n            raise\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_lhs","title":"<code>analyze_lhs(output_index=0, **kwargs)</code>","text":"<p>Perform LHS (Latin Hypercube Sampling) uncertainty analysis</p> <p>Note: This is a basic statistical analysis method for LHS samples, providing descriptive statistics and basic sensitivity indices.</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Analysis parameters (reserved for future use)</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>LHS uncertainty analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_lhs(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform LHS (Latin Hypercube Sampling) uncertainty analysis\n\n    Note: This is a basic statistical analysis method for LHS samples,\n    providing descriptive statistics and basic sensitivity indices.\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Analysis parameters (reserved for future use)\n\n    Returns:\n        LHS uncertainty analysis results\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"latin\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but LHS analysis is designed for Latin Hypercube Sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('latin')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    # Handle NaN values\n    Y = self._handle_nan_values(Y, \"LHS\u5206\u6790\")\n\n    # Basic statistical analysis\n    mean_val = np.mean(Y)\n    std_val = np.std(Y)\n    min_val = np.min(Y)\n    max_val = np.max(Y)\n    percentile_5 = np.percentile(Y, 5)\n    percentile_95 = np.percentile(Y, 95)\n\n    # Create results dictionary\n    Si = {\n        \"mean\": mean_val,\n        \"std\": std_val,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"percentile_5\": percentile_5,\n        \"percentile_95\": percentile_95,\n    }\n\n    if \"latin\" not in self.sensitivity_results:\n        self.sensitivity_results[\"latin\"] = {}\n\n    metric_name = f\"metric_{output_index}\"\n    self.sensitivity_results[\"latin\"][metric_name] = {\n        \"output_index\": output_index,\n        \"Si\": Si,\n        \"mean\": mean_val,\n        \"std\": std_val,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"percentile_5\": percentile_5,\n        \"percentile_95\": percentile_95,\n        \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n    }\n\n    logger.info(f\"LHS uncertainty analysis completed (\u6307\u6807 {output_index})\")\n    return self.sensitivity_results[\"latin\"][metric_name]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_morris","title":"<code>analyze_morris(output_index=0, **kwargs)</code>","text":"<p>Perform Morris sensitivity analysis</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Morris analysis parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Morris sensitivity analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_morris(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform Morris sensitivity analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Morris analysis parameters\n\n    Returns:\n        Morris sensitivity analysis results\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"Morris\u5206\u6790\")\n    X = self.parameter_samples\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n    #    X = self.parameter_samples[valid_indices]\n    # else:\n    #    X = self.parameter_samples\n\n    # Perform Morris analysis\n    logger.info(\n        f\"Start Morris sensitivity analysis: X.shape={X.shape}, Y.shape={Y.shape}, X.dtype={X.dtype}\"\n    )\n\n    try:\n        Si = morris_analyze.analyze(self.problem, X, Y, **kwargs)\n    except Exception as e:\n        logger.error(f\"Morris analysis execution failed: {e}\")\n        logger.error(f\"problem: {self.problem}\")\n        logger.error(f\"X shape: {X.shape}, type: {X.dtype}\")\n        logger.error(f\"Yshape: {Y.shape}, type: {Y.dtype}\")\n        if hasattr(X, \"dtype\") and X.dtype == \"object\":\n            logger.error(\n                \"X contains non-numeric data, please check the sampled data\"\n            )\n        raise\n\n    if \"morris\" not in self.sensitivity_results:\n        self.sensitivity_results[\"morris\"] = {}\n\n    metric_name = f\"metric_{output_index}\"\n    self.sensitivity_results[\"morris\"][metric_name] = {\n        \"output_index\": output_index,\n        \"Si\": Si,\n        \"mu\": Si[\"mu\"],\n        \"mu_star\": Si[\"mu_star\"],\n        \"sigma\": Si[\"sigma\"],\n        \"mu_star_conf\": Si[\"mu_star_conf\"],\n    }\n\n    logger.info(f\"Morris sensitivity analysis completed (metric {output_index})\")\n    return self.sensitivity_results[\"morris\"][metric_name]\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.analyze_sobol","title":"<code>analyze_sobol(output_index=0, **kwargs)</code>","text":"<p>Perform Sobol Sensitivity Analysis</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Sobol analysis parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Sobol sensitivity analysis results</p> Note <p>Sobol analysis requires samples generated using the Saltelli sampling method! Results from Morris or FAST sampling cannot be used.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_sobol(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform Sobol Sensitivity Analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Sobol analysis parameters\n\n    Returns:\n        Sobol sensitivity analysis results\n\n    Note:\n        Sobol analysis requires samples generated using the Saltelli sampling method!\n        Results from Morris or FAST sampling cannot be used.\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    # Check sampling method compatibility\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"sobol\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f Currently using {self._last_sampling_method} sampling, but Sobol analysis requires Saltelli sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('sobol')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"Sobol\u5206\u6790\")\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n    #    X = self.parameter_samples[valid_indices]\n    # else:\n    #    X = self.parameter_samples\n\n    try:\n        Si = sobol.analyze(self.problem, Y, **kwargs)\n\n        if \"sobol\" not in self.sensitivity_results:\n            self.sensitivity_results[\"sobol\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"sobol\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"S1\": Si[\"S1\"],\n            \"ST\": Si[\"ST\"],\n            \"S2\": Si.get(\"S2\", None),\n            \"S1_conf\": Si[\"S1_conf\"],\n            \"ST_conf\": Si[\"ST_conf\"],\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(f\"Sobol sensitivity analysis completed (index {output_index})\")\n        return self.sensitivity_results[\"sobol\"][metric_name]\n\n    except Exception as e:\n        if \"saltelli\" in str(e).lower() or \"sample\" in str(e).lower():\n            raise ValueError(\n                f\"Sobol analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('sobol')\"\n            ) from e\n        else:\n            raise\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.define_problem","title":"<code>define_problem(param_bounds, param_distributions=None)</code>","text":"<p>Define SALib problem space.</p> <p>Parameters:</p> Name Type Description Default <code>param_bounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Parameter bounds dictionary {'param_name': (min_val, max_val)}.</p> required <code>param_distributions</code> <code>Dict[str, str]</code> <p>Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}. Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>SALib problem definition dictionary.</p> Note <p>Defaults to 'unif' distribution if not specified. Validates distribution types and warns if invalid. Logs parameter definitions including bounds and distributions.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def define_problem(\n    self,\n    param_bounds: Dict[str, Tuple[float, float]],\n    param_distributions: Dict[str, str] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"Define SALib problem space.\n\n    Args:\n        param_bounds: Parameter bounds dictionary {'param_name': (min_val, max_val)}.\n        param_distributions: Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}.\n            Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'.\n\n    Returns:\n        SALib problem definition dictionary.\n\n    Note:\n        Defaults to 'unif' distribution if not specified. Validates distribution types\n        and warns if invalid. Logs parameter definitions including bounds and distributions.\n    \"\"\"\n    if param_distributions is None:\n        param_distributions = {name: \"unif\" for name in param_bounds.keys()}\n\n    valid_dists = [\"unif\", \"triang\", \"norm\", \"truncnorm\", \"lognorm\"]\n    for name, dist in param_distributions.items():\n        if dist not in valid_dists:\n            logger.warning(\n                \"Invalid distribution type, using 'unif' instead\",\n                extra={\n                    \"parameter_name\": name,\n                    \"invalid_distribution\": dist,\n                },\n            )\n            param_distributions[name] = \"unif\"\n\n    self.problem = {\n        \"num_vars\": len(param_bounds),\n        \"names\": list(param_bounds.keys()),\n        \"bounds\": list(param_bounds.values()),\n        \"dists\": [\n            param_distributions.get(name, \"unif\") for name in param_bounds.keys()\n        ],\n    }\n\n    logger.info(\n        \"Defined a problem space\",\n        extra={\n            \"num_parameters\": self.problem[\"num_vars\"],\n        },\n    )\n    for i, name in enumerate(self.problem[\"names\"]):\n        logger.info(\n            \"Parameter definition\",\n            extra={\n                \"parameter_name\": name,\n                \"bounds\": self.problem[\"bounds\"][i],\n                \"distribution\": self.problem[\"dists\"][i],\n            },\n        )\n\n    return self.problem\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.generate_samples","title":"<code>generate_samples(method='sobol', N=1024, **kwargs)</code>","text":"<p>Generate parameter samples.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Sampling method ('sobol', 'morris', 'fast', 'latin').</p> <code>'sobol'</code> <code>N</code> <code>int</code> <p>Number of samples (for Sobol this is the base sample count, actual count is N(2D+2)).</p> <code>1024</code> <code>**kwargs</code> <p>Method-specific parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Parameter sample array (n_samples, n_params).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If problem not defined or unsupported method.</p> Note <p>Sobol generates N(2D+2) samples. Morris generates N trajectories. Samples are rounded to 5 decimal places. Stores last sampling method for compatibility checking.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def generate_samples(\n    self, method: str = \"sobol\", N: int = 1024, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"Generate parameter samples.\n\n    Args:\n        method: Sampling method ('sobol', 'morris', 'fast', 'latin').\n        N: Number of samples (for Sobol this is the base sample count, actual count is N*(2*D+2)).\n        **kwargs: Method-specific parameters.\n\n    Returns:\n        Parameter sample array (n_samples, n_params).\n\n    Raises:\n        ValueError: If problem not defined or unsupported method.\n\n    Note:\n        Sobol generates N*(2*D+2) samples. Morris generates N trajectories. Samples are\n        rounded to 5 decimal places. Stores last sampling method for compatibility checking.\n    \"\"\"\n    if self.problem is None:\n        raise ValueError(\n            \"You must first call define_problem() to define the problem space.\"\n        )\n\n    logger.info(\n        \"Generating samples\",\n        extra={\n            \"method\": method,\n            \"base_sample_count\": N,\n        },\n    )\n\n    if method.lower() == \"sobol\":\n        # Sobol method: generate N*(2*D+2) samples\n        self.parameter_samples = saltelli.sample(self.problem, N, **kwargs)\n        actual_samples = N * (2 * self.problem[\"num_vars\"] + 2)\n\n    elif method.lower() == \"morris\":\n        # Morris method: Generate N trajectories\n        # Note: Different versions of SALib may have different parameter names\n        morris_kwargs = {\"num_levels\": 4}\n        # Check the SALib version and use the correct parameter names\n        try:\n            morris_kwargs.update(kwargs)\n            self.parameter_samples = morris.sample(self.problem, N, **morris_kwargs)\n        except TypeError as e:\n            if \"grid_jump\" in str(e):\n                morris_kwargs = {\n                    k: v for k, v in morris_kwargs.items() if k != \"grid_jump\"\n                }\n                morris_kwargs.update(\n                    {k: v for k, v in kwargs.items() if k != \"grid_jump\"}\n                )\n                self.parameter_samples = morris.sample(\n                    self.problem, N, **morris_kwargs\n                )\n            else:\n                raise e\n\n        actual_samples = len(self.parameter_samples)\n\n    elif method.lower() == \"fast\":\n        # FAST method\n        fast_kwargs = {\"M\": 4}\n        fast_kwargs.update(kwargs)\n        self.parameter_samples = fast_sampler.sample(self.problem, N, **fast_kwargs)\n        actual_samples = len(self.parameter_samples)\n\n    elif method.lower() == \"latin\":\n        # Latin Hypercube Sampling\n        self.parameter_samples = latin.sample(self.problem, N, **kwargs)\n        actual_samples = N\n\n    else:\n        raise ValueError(f\"Unsupported sampling method: {method}\")\n\n    logger.info(\n        \"Successfully generated samples\", extra={\"actual_samples\": actual_samples}\n    )\n\n    if self.parameter_samples is not None:\n        self.parameter_samples = np.round(self.parameter_samples, decimals=5)\n        logger.info(\"Parameter sample precision adjusted to 5 decimal places\")\n\n    self._last_sampling_method = method.lower()\n\n    return self.parameter_samples\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.generate_tricys_config","title":"<code>generate_tricys_config(csv_file_path=None, output_metrics=None)</code>","text":"<p>Generate Tricys configuration file for reading CSV parameter files and executing simulations This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs</p> <p>Parameters:</p> Name Type Description Default <code>csv_file_path</code> <code>str</code> <p>Path to the CSV parameter file. If None, the last generated file is used</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be calculated</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Path of the generated configuration file</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def generate_tricys_config(\n    self, csv_file_path: str = None, output_metrics: List[str] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Generate Tricys configuration file for reading CSV parameter files and executing simulations\n    This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs\n\n    Args:\n        csv_file_path: Path to the CSV parameter file. If None, the last generated file is used\n        output_metrics: List of output metrics to be calculated\n\n    Returns:\n        Path of the generated configuration file\n    \"\"\"\n    if csv_file_path is None:\n        if hasattr(self, \"sampling_csv_path\"):\n            csv_file_path = self.sampling_csv_path\n        else:\n            raise ValueError(\n                \"CSV file path not found, please first call run_tricys_simulations() or specify csv_file_path\"\n            )\n\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    csv_abs_path = os.path.abspath(csv_file_path)\n\n    import copy\n\n    tricys_config = copy.deepcopy(self.base_config)\n    tricys_config[\"simulation_parameters\"] = {\"file\": csv_abs_path}\n\n    if \"sensitivity_analysis\" not in tricys_config:\n        tricys_config[\"sensitivity_analysis\"] = {\"enabled\": True}\n\n    tricys_config[\"sensitivity_analysis\"][\"analysis_case\"] = {\n        \"name\": \"SALib_Analysis\",\n        \"independent_variable\": \"file\",\n        \"independent_variable_sampling\": csv_abs_path,\n        \"dependent_variables\": output_metrics,\n    }\n\n    return tricys_config\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.get_compatible_analysis_methods","title":"<code>get_compatible_analysis_methods(sampling_method)</code>","text":"<p>Get analysis methods compatible with the specified sampling method.</p> <p>Parameters:</p> Name Type Description Default <code>sampling_method</code> <code>str</code> <p>Sampling method</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of compatible analysis methods</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def get_compatible_analysis_methods(self, sampling_method: str) -&gt; List[str]:\n    \"\"\"\n    Get analysis methods compatible with the specified sampling method.\n\n    Args:\n        sampling_method: Sampling method\n\n    Returns:\n        List of compatible analysis methods\n    \"\"\"\n    compatibility_map = {\n        \"sobol\": [\"sobol\"],\n        \"morris\": [\"morris\"],\n        \"fast\": [\"fast\"],\n        \"latin\": [\"latin\"],\n        \"unknown\": [],\n    }\n\n    return compatibility_map.get(sampling_method, [])\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.load_tricys_results","title":"<code>load_tricys_results(sensitivity_summary_csv, output_metrics=None)</code>","text":"<p>Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys</p> <p>Parameters:</p> Name Type Description Default <code>sensitivity_summary_csv</code> <code>str</code> <p>Path to the sensitivity analysis summary CSV file output by Tricys</p> required <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to extract</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Simulation result array (n_samples, n_metrics)</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def load_tricys_results(\n    self, sensitivity_summary_csv: str, output_metrics: List[str] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys\n\n    Args:\n        sensitivity_summary_csv: Path to the sensitivity analysis summary CSV file output by Tricys\n        output_metrics: List of output metrics to extract\n\n    Returns:\n        Simulation result array (n_samples, n_metrics)\n    \"\"\"\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    logger.info(f\"Read data from the Tricys result file: {sensitivity_summary_csv}\")\n\n    df = pd.read_csv(sensitivity_summary_csv)\n\n    logger.info(f\"Read {len(df)} simulation results\")\n    logger.info(f\"Result file columns: {list(df.columns)}\")\n\n    param_cols = []\n    metric_cols = []\n\n    for col in df.columns:\n        if col in output_metrics:\n            metric_cols.append(col)\n        elif col in self.problem[\"names\"] if self.problem else False:\n            param_cols.append(col)\n\n    logger.info(f\"Recognized parameter columns: {param_cols}\")\n    logger.info(f\"Identified metric columns: {metric_cols}\")\n\n    ordered_metric_cols = []\n    for metric in output_metrics:\n        if metric in metric_cols:\n            ordered_metric_cols.append(metric)\n        else:\n            logger.warning(f\"Metric column not found: {metric}\")\n\n    if not ordered_metric_cols:\n        raise ValueError(f\"No valid output metrics columns found: {output_metrics}\")\n\n    results_data = df[ordered_metric_cols].values\n\n    self.simulation_results = results_data\n\n    logger.info(f\"Successfully loaded simulation results: {results_data.shape}\")\n    logger.info(\n        f\"Result Statistics:\\n{pd.DataFrame(results_data, columns=ordered_metric_cols).describe()}\"\n    )\n    logger.info(\n        f\"Result preview:\\n{pd.DataFrame(results_data, columns=metric_cols).head()}\"\n    )\n    return self.simulation_results\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_fast_results","title":"<code>plot_fast_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot FAST analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_fast_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot FAST analysis results\"\"\"\n    if \"fast\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results found for the FAST method\")\n\n    # No analysis results found for the FAST method\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    fast_results = self.sensitivity_results[\"fast\"]\n\n    if not fast_results:\n        raise ValueError(\"FAST analysis results not found\")\n\n    # Generate a chart for each metric\n    for metric_key, results in fast_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        # Determine the indicator name\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Bar charts of first-order and total sensitivity indices\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # first-order sensitivity index\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax1.barh(y_pos, Si[\"S1\"], alpha=0.7, color=\"purple\")\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax1.set_xlabel(\"\u4e00\u9636\u654f\u611f\u6027\u6307\u6570 (S1)\", fontsize=12)\n        ax1.set_title(\n            f\"FAST First-order Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax1.grid(True, alpha=0.3)\n\n        # Total Sensitivity Index\n        ax2.barh(y_pos, Si[\"ST\"], alpha=0.7, color=\"darkgreen\")\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"\u603b\u654f\u611f\u6027\u6307\u6570 (ST)\", fontsize=12)\n        ax2.set_title(\n            f\"FAST Total Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = (\n            f'fast_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n        )\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"The FAST result chart has been saved: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_lhs_results","title":"<code>plot_lhs_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot LHS (Latin Hypercube Sampling) uncertainty analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_lhs_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot LHS (Latin Hypercube Sampling) uncertainty analysis results\"\"\"\n    if \"latin\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results found for the LHS method\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    lhs_results = self.sensitivity_results[\"latin\"]\n\n    if not lhs_results:\n        raise ValueError(\"LHS analysis results not found\")\n\n    # Generate charts for each metric\n    for metric_key, results in lhs_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        # Determine the indicator name\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Get unit from config\n        sensitivity_analysis_config = self.base_config.get(\n            \"sensitivity_analysis\", {}\n        )\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n        unit_config = self._find_unit_config(metric_display_name, unit_map)\n        unit_str = \"\"\n        if unit_config:\n            unit = unit_config.get(\"unit\")\n            if unit:\n                unit_str = f\" ({unit})\"\n\n        xlabel = f\"{metric_display_name}{unit_str}\"\n\n        # Create a figure with two subplots\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # Plot 1: Distribution histogram\n        ax1.hist(\n            self.simulation_results[:, output_index],\n            bins=30,\n            alpha=0.7,\n            color=\"skyblue\",\n            edgecolor=\"black\",\n        )\n        ax1.set_xlabel(xlabel, fontsize=12)\n        ax1.set_ylabel(\"\u9891\u7387\", fontsize=12)\n        ax1.set_title(\"\u8f93\u51fa\u5206\u5e03\u76f4\u65b9\u56fe\", fontsize=14, pad=10)\n        ax1.grid(True, alpha=0.3)\n\n        # Add statistics text to the histogram plot\n        stats_text = f\"\u5747\u503c: {Si['mean']:.4f}\\n\u6807\u51c6\u5dee: {Si['std']:.4f}\\n\u6700\u5c0f\u503c: {Si['min']:.4f}\\n\u6700\u5927\u503c: {Si['max']:.4f}\"\n        ax1.text(\n            0.05,\n            0.95,\n            stats_text,\n            transform=ax1.transAxes,\n            fontsize=10,\n            verticalalignment=\"top\",\n            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n        )\n\n        # Plot 2: Cumulative distribution function\n        sorted_data = np.sort(self.simulation_results[:, output_index])\n        y_vals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n        ax2.plot(sorted_data, y_vals, linewidth=2, color=\"darkgreen\")\n        ax2.set_xlabel(xlabel, fontsize=12)\n        ax2.set_ylabel(\"\u7d2f\u79ef\u6982\u7387\", fontsize=12)\n        ax2.set_title(\"\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\", fontsize=14, pad=10)\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = f'lhs_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"LHS\u5206\u6790\u7ed3\u679c\u56fe\u8868\u5df2\u4fdd\u5b58: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_morris_results","title":"<code>plot_morris_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot the Morris analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_morris_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot the Morris analysis results\"\"\"\n    if \"morris\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results were found for the Morris method.\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Obtain the results of all indicators\n    morris_results = self.sensitivity_results[\"morris\"]\n\n    if not morris_results:\n        raise ValueError(\"No Morris analysis results found\")\n\n    for metric_key, results in morris_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Morris \u03bc*-\u03c3 diagram\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # \u03bc*-\u03c3 scatter plot\n        ax1.scatter(Si[\"mu_star\"], Si[\"sigma\"], s=100, alpha=0.7, color=\"red\")\n        for i, name in enumerate(self.problem[\"names\"]):\n            ax1.annotate(\n                name,\n                (Si[\"mu_star\"][i], Si[\"sigma\"][i]),\n                xytext=(5, 5),\n                textcoords=\"offset points\",\n                fontsize=9,\n            )\n\n        ax1.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n        ax1.set_ylabel(\"\u03c3 (Standard Deviation)\", fontsize=12)\n        ax1.set_title(\n            f\"Morris \u03bc*-\u03c3 Plot\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax1.grid(True, alpha=0.3)\n\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax2.barh(\n            y_pos, Si[\"mu_star\"], xerr=Si[\"mu_star_conf\"], alpha=0.7, color=\"green\"\n        )\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n        ax2.set_title(\n            f\"Morris Elementary Effects\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = f'morris_sensitivity_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"Morris result chart has been saved: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.plot_sobol_results","title":"<code>plot_sobol_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot Sobol analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_sobol_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot Sobol analysis results\"\"\"\n    if \"sobol\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results for the Sobol method were found.\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    sobol_results = self.sensitivity_results[\"sobol\"]\n\n    if not sobol_results:\n        raise ValueError(\"Sobol analysis results not found\")\n\n    # Generate charts for each metric\n    for metric_key, results in sobol_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Bar chart of first-order and total sensitivity indices\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # First-order sensitivity index\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax1.barh(y_pos, Si[\"S1\"], xerr=Si[\"S1_conf\"], alpha=0.7, color=\"skyblue\")\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax1.set_xlabel(\"First-order sensitivity index (S1)\", fontsize=12)\n        ax1.set_title(\n            f\"First-order Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax1.grid(True, alpha=0.3)\n\n        # # Total Sensitivity Index\n        ax2.barh(y_pos, Si[\"ST\"], xerr=Si[\"ST_conf\"], alpha=0.7, color=\"orange\")\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"Total Sensitivity Index (ST)\", fontsize=12)\n        ax2.set_title(\n            f\"Total Sensitivity Indices\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = (\n            f'sobol_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n        )\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"Sobol result chart has been saved: {filename}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.run_salib_analysis_from_tricys_results","title":"<code>run_salib_analysis_from_tricys_results(sensitivity_summary_csv, param_bounds=None, output_metrics=None, methods=['sobol', 'morris', 'fast'], save_dir=None)</code>","text":"<p>Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys</p> <p>Parameters:</p> Name Type Description Default <code>sensitivity_summary_csv</code> <code>str</code> <p>Path to the sensitivity summary CSV file output by Tricys</p> required <code>param_bounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Dictionary of parameter bounds, inferred from the CSV file if None</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to analyze</p> <code>None</code> <code>methods</code> <code>List[str]</code> <p>List of sensitivity analysis methods to execute</p> <code>['sobol', 'morris', 'fast']</code> <code>save_dir</code> <code>str</code> <p>Directory to save the results</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing all analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_salib_analysis_from_tricys_results(\n    self,\n    sensitivity_summary_csv: str,\n    param_bounds: Dict[str, Tuple[float, float]] = None,\n    output_metrics: List[str] = None,\n    methods: List[str] = [\"sobol\", \"morris\", \"fast\"],\n    save_dir: str = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys\n\n    Args:\n        sensitivity_summary_csv: Path to the sensitivity summary CSV file output by Tricys\n        param_bounds: Dictionary of parameter bounds, inferred from the CSV file if None\n        output_metrics: List of output metrics to analyze\n        methods: List of sensitivity analysis methods to execute\n        save_dir: Directory to save the results\n\n    Returns:\n        Dictionary containing all analysis results\n    \"\"\"\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    if save_dir is None:\n        save_dir = os.path.join(\n            os.path.dirname(sensitivity_summary_csv), \"salib_analysis\"\n        )\n    os.makedirs(save_dir, exist_ok=True)\n\n    df = pd.read_csv(sensitivity_summary_csv)\n\n    if param_bounds is None:\n        param_bounds = {}\n        param_candidates = []\n        for col in df.columns:\n            if col not in output_metrics and \".\" in col:\n                param_candidates.append(col)\n\n        for param in param_candidates:\n            param_data = df[param].dropna()\n            if len(param_data) &gt; 0:\n                param_bounds[param] = (param_data.min(), param_data.max())\n\n    if not param_bounds:\n        raise ValueError(\n            \"Unable to determine parameter boundaries, please provide the param_bounds parameter\"\n        )\n\n    self.define_problem(param_bounds)\n\n    self.load_tricys_results(sensitivity_summary_csv, output_metrics)\n\n    detected_method = self._last_sampling_method\n\n    methods = self.get_compatible_analysis_methods(detected_method)\n\n    all_results = {}\n\n    for metric_idx, metric_name in enumerate(output_metrics):\n        if metric_idx &gt;= self.simulation_results.shape[1]:\n            logger.warning(f\"The metric {metric_name} is out of range, skipping\")\n            continue\n\n        logger.info(f\"\\n=== Analysis indicators: {metric_name} ===\")\n        metric_results = {}\n\n        # Check data validity\n        Y = self.simulation_results[:, metric_idx]\n        valid_ratio = np.sum(~np.isnan(Y)) / len(Y)\n        logger.info(f\"Valid data ratio: {valid_ratio:.2%}\")\n\n        if valid_ratio &lt; 0.5:\n            logger.warning(\n                f\"The metric {metric_name} has less than 50% valid data, which may affect the analysis quality.\"\n            )\n\n        # Sobol analysis\n        if \"sobol\" in methods:\n            try:\n                logger.info(\"Performing Sobol sensitivity analysis...\")\n                sobol_result = self.analyze_sobol(output_index=metric_idx)\n                metric_results[\"sobol\"] = sobol_result\n\n                # Display Sobol results summary\n                logger.info(\"\\nSobol sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = sobol_result[\"S1\"][i]\n                    st = sobol_result[\"ST\"][i]\n                    logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"Sobol analysis failed: {e}\")\n\n        # Morris analysis\n        if \"morris\" in methods:\n            try:\n                logger.info(\"Performing Morris sensitivity analysis...\")\n                morris_result = self.analyze_morris(output_index=metric_idx)\n                metric_results[\"morris\"] = morris_result\n\n                # Display Morris results summary\n                logger.info(\"\\nMorris sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    mu_star = morris_result[\"mu_star\"][i]\n                    sigma = morris_result[\"sigma\"][i]\n                    logger.info(f\"  {param_name}: \u03bc*={mu_star:.4f}, \u03c3={sigma:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"Morris analysis failed: {e}\")\n\n        # FAST analysis\n        if \"fast\" in methods:\n            try:\n                logger.info(\"Performing FAST sensitivity analysis...\")\n                fast_result = self.analyze_fast(output_index=metric_idx)\n                metric_results[\"fast\"] = fast_result\n\n                # Display FAST results summary\n                logger.info(\"\\nFAST sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = fast_result[\"S1\"][i]\n                    st = fast_result[\"ST\"][i]\n                    logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"FAST analysis failed: {e}\")\n\n        # LHS analysis\n        if \"latin\" in methods:\n            try:\n                logger.info(\"Performing LHS uncertainty analysis...\")\n                lhs_result = self.analyze_lhs(output_index=metric_idx)\n                metric_results[\"latin\"] = lhs_result\n\n                # Display LHS results summary\n                logger.info(\"\\nLHS\u5206\u6790\u7ed3\u679c:\")\n                logger.info(f\"  \u5747\u503c: {lhs_result['mean']:.4f}\")\n                logger.info(f\"  \u6807\u51c6\u5dee: {lhs_result['std']:.4f}\")\n                logger.info(f\"  \u6700\u5c0f\u503c: {lhs_result['min']:.4f}\")\n                logger.info(f\"  \u6700\u5927\u503c: {lhs_result['max']:.4f}\")\n                logger.info(f\"  5%\u5206\u4f4d\u6570: {lhs_result['percentile_5']:.4f}\")\n                logger.info(f\"  95%\u5206\u4f4d\u6570: {lhs_result['percentile_95']:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"LHS\u5206\u6790\u5931\u8d25: {e}\")\n\n        all_results[metric_name] = metric_results\n\n    try:\n        if \"sobol\" in methods and \"sobol\" in self.sensitivity_results:\n            self.plot_sobol_results(save_dir=save_dir, metric_names=output_metrics)\n\n        if \"morris\" in methods and \"morris\" in self.sensitivity_results:\n            self.plot_morris_results(save_dir=save_dir, metric_names=output_metrics)\n\n        if \"fast\" in methods and \"fast\" in self.sensitivity_results:\n            self.plot_fast_results(save_dir=save_dir, metric_names=output_metrics)\n\n        # Plot LHS results\n        if \"latin\" in methods and \"latin\" in self.sensitivity_results:\n            self.plot_lhs_results(save_dir=save_dir, metric_names=output_metrics)\n\n    except Exception as e:\n        logger.warning(f\"Drawing failed: {e}\")\n\n    try:\n        self.save_results(\n            save_dir=save_dir, format=\"csv\", metric_names=output_metrics\n        )\n\n        report_content = self._save_sensitivity_report(all_results, save_dir)\n        report_path = os.path.join(save_dir, \"analysis_report.md\")\n\n        load_dotenv()\n\n        # --- LLM Calls for analysis ---\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n        ai_model = os.environ.get(\"AI_MODEL\")\n\n        sa_config = self.base_config.get(\"sensitivity_analysis\", {})\n        case_config = sa_config.get(\"analysis_case\", {})\n        ai_config = case_config.get(\"ai\")\n\n        ai_enabled = False\n        if isinstance(ai_config, bool):\n            ai_enabled = ai_config\n        elif isinstance(ai_config, dict):\n            ai_enabled = ai_config.get(\"enabled\", False)\n\n        if api_key and base_url and ai_model and ai_enabled:\n            # First LLM call for initial analysis\n            wrapper_prompt, llm_summary = call_llm_for_salib_analysis(\n                report_content=report_content,\n                api_key=api_key,\n                base_url=base_url,\n                ai_model=ai_model,\n                method=detected_method,\n            )\n            if wrapper_prompt and llm_summary:\n                with open(report_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd\\n\\n\")\n                    f.write(\"```markdown\\n\")\n                    f.write(wrapper_prompt)\n                    f.write(\"\\n```\\n\\n\")\n                    f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\")\n                    f.write(llm_summary)\n                logger.info(f\"Appended LLM prompt and summary to {report_path}\")\n\n                # Second LLM call for academic report\n                glossary_path = None\n                if isinstance(case_config, dict):\n                    glossary_path = sa_config.get(\"glossary_path\")\n\n                if glossary_path and os.path.exists(glossary_path):\n                    try:\n                        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n                            glossary_content = f.read()\n\n                        (\n                            academic_wrapper_prompt,\n                            academic_report,\n                        ) = call_llm_for_academic_report(\n                            analysis_report=llm_summary,\n                            glossary_content=glossary_content,\n                            api_key=api_key,\n                            base_url=base_url,\n                            ai_model=ai_model,\n                            problem_details=self.problem,\n                            metric_names=output_metrics,\n                            method=detected_method,\n                            save_dir=save_dir,\n                        )\n\n                        if academic_wrapper_prompt and academic_report:\n                            academic_report_path = os.path.join(\n                                save_dir, \"academic_report.md\"\n                            )\n                            with open(\n                                academic_report_path, \"w\", encoding=\"utf-8\"\n                            ) as f:\n                                f.write(academic_report)\n                            logger.info(\n                                f\"Generated academic report: {academic_report_path}\"\n                            )\n                    except Exception as e:\n                        logger.error(\n                            f\"Failed to generate or save academic report: {e}\"\n                        )\n                elif glossary_path:\n                    logger.warning(\n                        f\"Glossary file not found at {glossary_path}, skipping academic report generation.\"\n                    )\n\n        else:\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not set, or AI analysis is disabled. Skipping LLM summary generation.\"\n            )\n\n    except Exception as e:\n        logger.warning(f\"Failed to save result: {e}\")\n\n    logger.info(\"\\n\u2705 SALib sensitivity analysis completed!\")\n    logger.info(f\"\ud83d\udcc1 The result has been saved to: {save_dir}\")\n\n    return all_results\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.run_tricys_analysis","title":"<code>run_tricys_analysis(csv_file_path=None, output_metrics=None)</code>","text":"<p>Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results</p> <p>Parameters:</p> Name Type Description Default <code>csv_file_path</code> <code>str</code> <p>Path to the CSV parameter file. If None, the last generated file will be used</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be calculated</p> <code>None</code> <code>config_output_path</code> <p>Path for the configuration file output. If None, it will be automatically generated</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the sensitivity_analysis_summary.csv file</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_tricys_analysis(\n    self, csv_file_path: str = None, output_metrics: List[str] = None\n) -&gt; str:\n    \"\"\"\n    Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results\n\n    Args:\n        csv_file_path: Path to the CSV parameter file. If None, the last generated file will be used\n        output_metrics: List of output metrics to be calculated\n        config_output_path: Path for the configuration file output. If None, it will be automatically generated\n\n    Returns:\n        Path to the sensitivity_analysis_summary.csv file\n    \"\"\"\n    # Generate Tricys configuration file\n    tricys_config = self.generate_tricys_config(\n        csv_file_path=csv_file_path, output_metrics=output_metrics\n    )\n\n    logger.info(\"Starting Tricys simulation analysis...\")\n\n    try:\n        # Call the Tricys simulation engine\n        from datetime import datetime\n\n        from tricys.simulation.simulation_analysis import run_simulation\n\n        tricys_config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        run_simulation(tricys_config)\n\n        results_dir = tricys_config[\"paths\"][\"results_dir\"]\n\n        return Path(results_dir) / \"sensitivity_analysis_summary.csv\"\n\n    except Exception as e:\n        logger.error(f\"Tricys simulation execution failed: {e}\")\n        raise\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.run_tricys_simulations","title":"<code>run_tricys_simulations(output_metrics=None)</code>","text":"<p>Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.</p> <p>Parameters:</p> Name Type Description Default <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be extracted (for recording but does not affect CSV generation)</p> <code>None</code> <code>max_workers</code> <p>Number of concurrent worker processes (reserved for compatibility, currently unused)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the generated CSV file</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_tricys_simulations(self, output_metrics: List[str] = None) -&gt; str:\n    \"\"\"\n    Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.\n\n    Args:\n        output_metrics: List of output metrics to be extracted (for recording but does not affect CSV generation)\n        max_workers: Number of concurrent worker processes (reserved for compatibility, currently unused)\n\n    Returns:\n        Path to the generated CSV file\n    \"\"\"\n    if self.parameter_samples is None:\n        raise ValueError(\n            \"You must first call generate_samples() to generate samples.\"\n        )\n\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    logger.info(\"Target output metrics\", extra={\"output_metrics\": output_metrics})\n\n    sampled_param_names = self.problem[\"names\"]\n\n    base_params = self.base_config.get(\"simulation_parameters\", {}).copy()\n    csv_output_path = (\n        Path(self.base_config.get(\"paths\", {}).get(\"temp_dir\"))\n        / \"salib_sampling.csv\"\n    )\n\n    os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n\n    param_data = []\n    for i, sample in enumerate(self.parameter_samples):\n        sampled_params = {\n            sampled_param_names[j]: sample[j]\n            for j in range(len(sampled_param_names))\n        }\n\n        job_params = base_params.copy()\n        job_params.update(sampled_params)\n\n        param_data.append(job_params)\n\n    df = pd.DataFrame(param_data)\n\n    for col in df.columns:\n        if df[col].dtype in [\"float64\", \"float32\"]:\n            df[col] = df[col].round(5)\n\n    df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n\n    logger.info(\n        \"Successfully generated parameter samples\",\n        extra={\"num_samples\": len(param_data)},\n    )\n    logger.info(\"Parameter file saved\", extra={\"file_path\": csv_output_path})\n    logger.info(\"Parameter file columns\", extra={\"columns\": list(df.columns)})\n    logger.info(\"Parameter precision set to 5 decimal places\")\n    logger.info(\"Sample statistics\", extra={\"statistics\": df.describe().to_dict()})\n\n    self.sampling_csv_path = csv_output_path\n\n    return csv_output_path\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.TricysSALibAnalyzer.save_results","title":"<code>save_results(save_dir=None, format='csv', metric_names=None)</code>","text":"<p>Save sensitivity analysis results</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>str</code> <p>Save directory</p> <code>None</code> <code>format</code> <code>str</code> <p>Save format ('csv</p> <code>'csv'</code> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def save_results(\n    self, save_dir: str = None, format: str = \"csv\", metric_names: List[str] = None\n) -&gt; None:\n    \"\"\"\n    Save sensitivity analysis results\n\n    Args:\n        save_dir: Save directory\n        format: Save format ('csv\n    \"\"\"\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    for method, method_results in self.sensitivity_results.items():\n        if not method_results:\n            continue\n\n        for metric_key, results in method_results.items():\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            if format == \"csv\":\n                if method == \"sobol\":\n                    sobol_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"S1\": results[\"S1\"],\n                            \"ST\": results[\"ST\"],\n                            \"S1_conf\": results[\"S1_conf\"],\n                            \"ST_conf\": results[\"ST_conf\"],\n                        }\n                    )\n                    filename = (\n                        f'sobol_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    sobol_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"Sobol results have been saved: {filename}\")\n\n                elif method == \"morris\":\n                    morris_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"mu\": results[\"mu\"],\n                            \"mu_star\": results[\"mu_star\"],\n                            \"sigma\": results[\"sigma\"],\n                            \"mu_star_conf\": results[\"mu_star_conf\"],\n                        }\n                    )\n                    filename = f'morris_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    morris_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"Morris results have been saved: {filename}\")\n\n                elif method == \"fast\":\n                    fast_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"S1\": results[\"S1\"],\n                            \"ST\": results[\"ST\"],\n                        }\n                    )\n                    filename = (\n                        f'fast_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    fast_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"FAST results have been saved: {filename}\")\n\n                elif method == \"latin\":\n                    # Save LHS statistics\n                    lhs_stats_df = pd.DataFrame(\n                        {\n                            \"Metric\": [metric_display_name],\n                            \"Mean\": [results[\"mean\"]],\n                            \"Std\": [results[\"std\"]],\n                            \"Min\": [results[\"min\"]],\n                            \"Max\": [results[\"max\"]],\n                            \"Percentile_5\": [results[\"percentile_5\"]],\n                            \"Percentile_95\": [results[\"percentile_95\"]],\n                        }\n                    )\n                    filename_stats = (\n                        f'lhs_stats_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    lhs_stats_df.to_csv(\n                        os.path.join(save_dir, filename_stats), index=False\n                    )\n                    logger.info(f\"LHS\u7edf\u8ba1\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_stats}\")\n\n                    # Remove LHS sensitivity indices saving\n                    # lhs_sens_df = pd.DataFrame({\n                    #     \"Parameter\": self.problem[\"names\"],\n                    #     \"Partial_Correlation\": results[\"partial_correlations\"]\n                    # })\n                    # filename_sens = f'lhs_sensitivity_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    # lhs_sens_df.to_csv(os.path.join(save_dir, filename_sens), index=False)\n                    # logger.info(f\"LHS\u654f\u611f\u6027\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_sens}\")\n\n    logger.info(f\"The result has been saved to: {save_dir}\")\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.call_llm_for_academic_report","title":"<code>call_llm_for_academic_report(analysis_report, glossary_content, api_key, base_url, ai_model, problem_details, metric_names, method, save_dir)</code>","text":"<p>Sends an analysis report and a glossary to an LLM to generate a professional academic report.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def call_llm_for_academic_report(\n    analysis_report: str,\n    glossary_content: str,\n    api_key: str,\n    base_url: str,\n    ai_model: str,\n    problem_details: dict,\n    metric_names: list,\n    method: str,\n    save_dir: str,\n) -&gt; Tuple[str, str]:\n    \"\"\"Sends an analysis report and a glossary to an LLM to generate a professional academic report.\"\"\"\n    try:\n        logger.info(\"Proceeding with LLM for academic report generation.\")\n\n        param_names_str = \", \".join(\n            [f\"`{name}`\" for name in problem_details.get(\"names\", [])]\n        )\n        metric_names_str = \", \".join([f\"`{name}`\" for name in metric_names])\n\n        all_plots = [f for f in os.listdir(save_dir) if f.endswith((\".svg\", \".png\"))]\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n\n        method_details = {\n            \"sobol\": {\n                \"name\": \"Sobol\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**Sobol\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u6280\u672f\uff0c\u80fd\u591f\u91cf\u5316\u5355\u4e2a\u53c2\u6570\u4ee5\u53ca\u53c2\u6570\u95f4\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u548c\u603b\u4f53\u654f\u611f\u6027\uff08ST\uff09\u6700\u9ad8\uff1f\u8bf7\u7ed3\u5408\u56fe\u8868\uff08\u5982\u6761\u5f62\u56fe\uff09\u8fdb\u884c\u89e3\u8bfb\u3002\n        *   S1\u548cST\u6307\u6570\u4e4b\u95f4\u7684\u5dee\u5f02\u63ed\u793a\u4e86\u4ec0\u4e48\uff1f\uff08\u4f8b\u5982\uff0cST\u663e\u8457\u5927\u4e8eS1\u610f\u5473\u7740\u8be5\u53c2\u6570\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u663e\u8457\u7684\u4ea4\u4e92\u4f5c\u7528\u6216\u5176\u5f71\u54cd\u662f\u975e\u7ebf\u6027\u7684\uff09\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n            \"morris\": {\n                \"name\": \"Morris\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**Morris\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8f68\u8ff9\u7684\u201c\u4e00\u6b21\u6027\u201d\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e38\u7528\u4e8e\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53c2\u6570\u7b5b\u9009\uff0c\u4ee5\u8bc6\u522b\u51fa\u5f71\u54cd\u6700\u5927\u7684\u5c11\u6570\u51e0\u4e2a\u53c2\u6570\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u53c2\u6570\u7684 `\u03bc*` (mu_star) \u503c\u6700\u9ad8\uff0c\u8868\u660e\u5176\u5bf9\u8f93\u51fa\u7684\u603b\u4f53\u5f71\u54cd\u6700\u91cd\u8981\uff1f\n        *   `\u03c3` (sigma) \u503c\u7684\u5927\u5c0f\u53c8\u8bf4\u660e\u4e86\u4ec0\u4e48\uff1f\u8f83\u9ad8\u7684 `\u03c3` \u503c\u901a\u5e38\u8868\u660e\u53c2\u6570\u5177\u6709\u975e\u7ebf\u6027\u6548\u5e94\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\n        *   \u8bf7\u7ed3\u5408 `\u03bc*-\u03c3` \u56fe\u8fdb\u884c\u5206\u6790\uff0c\u5bf9\u53c2\u6570\u8fdb\u884c\u5206\u7c7b\uff08\u4f8b\u5982\uff0c\u9ad8 `\u03bc*`/\u9ad8 `\u03c3` vs. \u9ad8 `\u03bc*`/\u4f4e `\u03c3`\uff09\uff0c\u5e76\u89e3\u91ca\u5176\u542b\u4e49\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n            \"fast\": {\n                \"name\": \"FAST\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**FAST\uff08\u5085\u91cc\u53f6\u5e45\u5ea6\u654f\u611f\u6027\u68c0\u9a8c\uff09\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u6280\u672f\uff0c\u901a\u8fc7\u5c06\u53c2\u6570\u5728\u5085\u91cc\u53f6\u7ea7\u6570\u4e2d\u5c55\u5f00\u6765\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u6700\u9ad8\uff1f\n        *   \uff08\u5982\u679c\u53ef\u7528\uff09\u603b\u4f53\u654f\u611f\u6027\uff08ST\uff09\u4e0e\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u7684\u6bd4\u8f83\u63ed\u793a\u4e86\u4ec0\u4e48\uff1f\u8f83\u5927\u7684\u5dee\u5f02\u901a\u5e38\u8868\u660e\u5b58\u5728\u53c2\u6570\u4ea4\u4e92\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n        }\n\n        if method == \"latin\":\n            ACADEMIC_REPORT_PROMPT_WRAPPER = f\"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\uff0c\u64c5\u957f\u8fdb\u884c**\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (UQ)** \u548c\u98ce\u9669\u8bc4\u4f30\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u57fa\u4e8e**\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837 (LHS)** \u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\n**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u4e13\u4e1a\u8bcd\u6c47\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\uff0c\u805a\u7126\u4e8e**\u4e0d\u786e\u5b9a\u6027**\u7684\u91cf\u5316\u548c\u89e3\u8bfb\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u7edf\u8ba1\u6458\u8981\u3001\u5206\u5e03\u6570\u636e\u7b49\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u4e0d\u786e\u5b9a\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u4e0d\u786e\u5b9a\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u51fa\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u662f {param_names_str}\uff0c\u603b\u7ed3\u8fd9\u4e9b\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u5173\u952e\u6027\u80fd\u6307\u6807 ({metric_names_str}) \u7684\u8f93\u51fa\u5206\u5e03\uff08\u5982\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u7f6e\u4fe1\u533a\u95f4\uff09\u6709\u4f55\u5f71\u54cd\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30\u5f53\u8f93\u5165\u53c2\u6570 {param_names_str} \u5728\u5176\u5b9a\u4e49\u57df\u5185\u53d8\u5316\u65f6\uff0c\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u5173\u952e\u6027\u80fd\u6307\u6807\u7684\u7edf\u8ba1\u5206\u5e03\u548c\u7a33\u5b9a\u6027\u3002\n    *   **\u65b9\u6cd5 (Methodology):** \u7b80\u8981\u8bf4\u660e\u5206\u6790\u65b9\u6cd5\u3002\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\uff08LHS\uff09\u65b9\u6cd5\u6765\u5bf9\u8f93\u5165\u53c2\u6570\u7a7a\u95f4\u8fdb\u884c\u62bd\u6837\u3002\u8bf4\u660e\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u662f {metric_names_str}\uff0c\u4ee5\u53ca\u8f93\u5165\u53c2\u6570\u7684\u6982\u7387\u5206\u5e03\u548c\u8303\u56f4\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u7edf\u8ba1\u6570\u636e\u548c\u60a8\u5d4c\u5165\u7684\u56fe\u8868\uff08\u5982\u76f4\u65b9\u56fe\u3001\u7d2f\u79ef\u5206\u5e03\u56fe\uff09\uff0c\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n        *   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5176\u8f93\u51fa\u7684**\u6982\u7387\u5206\u5e03**\u662f\u600e\u6837\u7684\uff1f\uff08\u4f8b\u5982\uff0c\u662f\u6b63\u6001\u5206\u5e03\u3001\u504f\u6001\u5206\u5e03\u8fd8\u662f\u53cc\u5cf0\u5206\u5e03\uff1f\uff09\n        *   \u8f93\u51fa\u6307\u6807\u7684**\u4e0d\u786e\u5b9a\u6027\u8303\u56f4**\u6709\u591a\u5927\uff1f\uff08\u53c2\u8003\u6807\u51c6\u5dee\u548c5%-95%\u767e\u5206\u4f4d\u6570\u533a\u95f4\uff09\u3002\u8fd9\u4e2a\u8303\u56f4\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u662f\u5426\u53ef\u4ee5\u63a5\u53d7\uff1f\n        *   \u662f\u5426\u5b58\u5728\u67d0\u4e9b\u6307\u6807\u7684\u6ce2\u52a8\u8303\u56f4\u8fc7\u5927\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u6027\u80fd\u4f4e\u4e8e\u8bbe\u8ba1\u8981\u6c42\u6216\u5b58\u5728\u8fd0\u884c\u98ce\u9669\uff1f\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff08\u4f8b\u5982\uff0c\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u3001\u8f93\u51fa\u6307\u6807\u7684\u53ef\u9760\u6027\u7b49\uff09\uff0c\u5e76\u5bf9\u964d\u4f4e\u5173\u952e\u6307\u6807\u4e0d\u786e\u5b9a\u6027\u6216\u672a\u6765\u7684\u98ce\u9669\u8bc4\u4f30\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n        else:\n            selected_method = method_details.get(method)\n            if not selected_method:\n                # Fallback for unknown methods\n                selected_method = {\n                    \"name\": method.capitalize(),\n                    \"methodology\": f\"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u63d0\u53ca\u5177\u4f53\u7684\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\u4e3a**{method.capitalize()}**\u3002\",\n                    \"results_discussion\": \"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u8bc6\u522b\u51fa\u6700\u91cd\u8981\u7684\u8f93\u5165\u53c2\u6570\u3002\\n*   \u8ba8\u8bba\u8fd9\u4e9b\u53d1\u73b0\u7684\u610f\u4e49\u3002\",\n                }\n\n            ACADEMIC_REPORT_PROMPT_WRAPPER = f\"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e**SALib {selected_method['name']} \u65b9\u6cd5\u654f\u611f\u6027\u5206\u6790**\u7684\u7a0b\u5e8f\u751f\u6210\u7684\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\n**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u654f\u611f\u6027\u6307\u6570\u8868\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u654f\u611f\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u654f\u611f\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u660e\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u662f {param_names_str}\uff0c\u603b\u7ed3\u54ea\u4e9b\u53c2\u6570\u5bf9\u5173\u952e\u6027\u80fd\u6307\u6807 ({metric_names_str}) \u5f71\u54cd\u6700\u663e\u8457\uff0c\u5e76\u9648\u8ff0\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u654f\u611f\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30\u8f93\u5165\u53c2\u6570\u7684\u53d8\u5316\u5bf9\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\n    *   **\u65b9\u6cd5 (Methodology):** {selected_method['methodology']} \u8bf4\u660e\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u662f {metric_names_str}\uff0c\u4ee5\u53ca\u8f93\u5165\u53c2\u6570 {param_names_str} \u7684\u53d8\u5316\u8303\u56f4\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u548c\u60a8\u5d4c\u5165\u7684\u56fe\u8868\uff0c\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n{selected_method['results_discussion']}\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u654f\u611f\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff0c\u5e76\u5bf9\u53cd\u5e94\u5806\u8bbe\u8ba1\u6216\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        full_prompt = f\"{ACADEMIC_REPORT_PROMPT_WRAPPER}\\n\\n---\\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a\\n---\\n{analysis_report}\\n\\n---\\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868\\n---\\n{glossary_content}\"\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending data for academic report to LLM (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_prompt}],\n                    max_tokens=4000,\n                )\n                academic_report = response.choices[0].message.content\n\n                logger.info(\"LLM academic report generation successful.\")\n                return ACADEMIC_REPORT_PROMPT_WRAPPER, academic_report\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling LLM for academic report on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to get LLM academic report after {max_retries} attempts.\"\n                    )\n                    return None, None\n\n    except Exception as e:\n        logger.error(f\"Error in call_llm_for_academic_report: {e}\", exc_info=True)\n        return None, None\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.call_llm_for_salib_analysis","title":"<code>call_llm_for_salib_analysis(report_content, api_key, base_url, ai_model, method)</code>","text":"<p>Sends a SALib analysis report to an LLM for summarization and returns the prompt and summary.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def call_llm_for_salib_analysis(\n    report_content: str, api_key: str, base_url: str, ai_model: str, method: str\n) -&gt; Tuple[str, str]:\n    \"\"\"Sends a SALib analysis report to an LLM for summarization and returns the prompt and summary.\"\"\"\n    try:\n        logger.info(\"Proceeding with LLM analysis for SALib report.\")\n\n        PROMPT_TEMPLATES = {\n            \"sobol\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**Sobol\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684**\u4e00\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1\uff09**\u548c**\u603b\u654f\u611f\u6027\u6307\u6570\uff08ST\uff09**\u6700\u9ad8\u3002\n3.  **\u89e3\u8bfb\u6307\u6570\u542b\u4e49**\uff1a\u89e3\u91caS1\u548cST\u6307\u6570\u7684\u542b\u4e49\u3002\u4f8b\u5982\uff0c\u9ad8S1\u503c\u8868\u793a\u53c2\u6570\u5bf9\u8f93\u51fa\u6709\u91cd\u8981\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u800cST\u4e0eS1\u7684\u663e\u8457\u5dee\u5f02\u8868\u793a\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u4ea4\u4e92\u4f5c\u7528\u6216\u975e\u7ebf\u6027\u6548\u5e94\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"morris\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**Morris\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u6839\u636e**\u03bc* (mu_star)**\u503c\u5bf9\u53c2\u6570\u8fdb\u884c\u6392\u5e8f\uff0c\u8bc6\u522b\u51fa\u5bf9\u6a21\u578b\u8f93\u51fa\u5f71\u54cd\u6700\u5927\u7684\u53c2\u6570\u3002\n3.  **\u89e3\u8bfb\u53c2\u6570\u6548\u5e94**\uff1a\u89e3\u91ca**\u03bc***\u548c**\u03c3 (sigma)**\u7684\u542b\u4e49\u3002\u9ad8\u03bc*\u8868\u793a\u53c2\u6570\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9ad8\u03c3\u8868\u793a\u53c2\u6570\u5b58\u5728\u975e\u7ebf\u6027\u5f71\u54cd\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u6709\u4ea4\u4e92\u4f5c\u7528\u3002\u7ed3\u5408\u03bc*-\u03c3\u56fe\u8fdb\u884c\u5206\u6790\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"fast\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**FAST\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684**\u4e00\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1\uff09**\u548c**\u603b\u654f\u611f\u6027\u6307\u6570\uff08ST\uff09**\u6700\u9ad8\u3002\n3.  **\u89e3\u8bfb\u6307\u6570\u542b\u4e49**\uff1a\u89e3\u91caS1\u548cST\u6307\u6570\u7684\u542b\u4e49\u3002\u9ad8S1\u503c\u8868\u793a\u53c2\u6570\u5bf9\u8f93\u51fa\u6709\u91cd\u8981\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u800cST\u4e0eS1\u7684\u5dee\u5f02\u8868\u793a\u53c2\u6570\u53ef\u80fd\u5b58\u5728\u4ea4\u4e92\u4f5c\u7528\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"latin\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u7edf\u8ba1\u5b66\u548c\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\uff08LHS\uff09\u751f\u6210\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u89e3\u8bfb\u7edf\u8ba1\u6570\u636e**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u89e3\u8bfb\u5176\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5927/\u6700\u5c0f\u503c\u548c\u767e\u5206\u4f4d\u6570\u3002\n2.  **\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027**\uff1a\u57fa\u4e8e\u6807\u51c6\u5dee\u548c5%/95%\u767e\u5206\u4f4d\u6570\u7684\u8303\u56f4\uff0c\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u6ce2\u52a8\u8303\u56f4\u6709\u591a\u5927\u3002\n3.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u603b\u7ed3\u5728\u7ed9\u5b9a\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4e0b\uff0c\u6a21\u578b\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPIs\uff09\u8868\u73b0\u5982\u4f55\uff0c\u662f\u5426\u5b58\u5728\u8f83\u5927\u7684\u98ce\u9669\uff08\u4f8b\u5982\uff0c\u8f93\u51fa\u503c\u6ce2\u52a8\u8303\u56f4\u8fc7\u5927\uff09\uff0c\u5e76\u5bf9\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u7ed9\u51fa\u8bc4\u4ef7\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u805a\u7126\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\u548c\u89e3\u8bfb\uff0c\u800c\u4e0d\u662f\u53c2\u6570\u7684\u654f\u611f\u6027\u6392\u5e8f\u3002\n\"\"\",\n        }\n\n        wrapper_prompt = PROMPT_TEMPLATES.get(\n            method,\n            \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684\u654f\u611f\u6027\u5206\u6790\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u7b80\u660e\u627c\u8981\u5730\u603b\u7ed3\u62a5\u544a\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u3001\u201c\u500d\u589e\u65f6\u95f4\u201d\u7b49\uff09\uff0c\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u5bf9\u5b83\u7684\u5f71\u54cd\u6700\u5927\uff08\u5373\u6700\u654f\u611f\uff09\u3002\n3.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff08\u5982\u679c\u53ef\u80fd\uff09\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n        )\n\n        full_prompt = f\"{wrapper_prompt}\\n\\n---\\n**\u5206\u6790\u62a5\u544a\u539f\u6587\uff1a**\\n\\n{report_content}\"\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending SALib report to LLM (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_prompt}],\n                    max_tokens=4000,\n                )\n                llm_summary = response.choices[0].message.content\n\n                logger.info(\"LLM analysis successful for SALib report.\")\n                return wrapper_prompt, llm_summary  # Return wrapper prompt and summary\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling LLM for SALib report on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to get LLM summary for SALib report after {max_retries} attempts.\"\n                    )\n                    return None, None  # Return None on failure\n\n    except Exception as e:\n        logger.error(f\"Error in call_llm_for_salib_analysis: {e}\", exc_info=True)\n        return None, None\n</code></pre>"},{"location":"api/tricys_analysis.html#tricys.analysis.salib.run_salib_analysis","title":"<code>run_salib_analysis(config)</code>","text":"<p>Orchestrates the SALib sensitivity analysis workflow.</p> <p>This function extracts the necessary configuration, defines the problem space for SALib, and then runs the analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary.</p> required Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_salib_analysis(config: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Orchestrates the SALib sensitivity analysis workflow.\n\n    This function extracts the necessary configuration, defines the problem\n    space for SALib, and then runs the analysis.\n\n    Args:\n        config: The main configuration dictionary.\n    \"\"\"\n    # 1. Extract sensitivity analysis configuration\n    sa_config = config.get(\"sensitivity_analysis\")\n    if not sa_config or not sa_config.get(\"enabled\"):\n        logger.info(\"Sensitivity analysis is not enabled in the configuration file.\")\n        return\n\n    # 2. Create analyzer\n    analyzer = TricysSALibAnalyzer(config)\n\n    # 3. Define the problem space from configuration\n    analysis_case = sa_config.get(\"analysis_case\", {})\n    param_names = analysis_case.get(\"independent_variable\")\n    sampling_details = analysis_case.get(\"independent_variable_sampling\")\n\n    if not isinstance(param_names, list):\n        raise ValueError(\"'independent_variable' must be a list of parameter names.\")\n    if not isinstance(sampling_details, dict):\n        raise ValueError(\n            \"'independent_variable_sampling' must be an object with parameter details.\"\n        )\n\n    param_bounds = {\n        name: sampling_details[name][\"bounds\"]\n        for name in param_names\n        if name in sampling_details\n    }\n    param_dists = {\n        name: sampling_details[name].get(\"distribution\", \"unif\")\n        for name in param_names\n        if name in sampling_details\n    }\n\n    if len(param_bounds) != len(param_names):\n        raise ValueError(\n            \"The keys of 'independent_variable' and 'independent_variable_sampling' do not match\"\n        )\n\n    problem = analyzer.define_problem(param_bounds, param_dists)\n    logger.info(\n        f\"\\n\ud83d\udd0d The problem space with {problem['num_vars']} parameters was defined from the configuration file\"\n    )\n\n    # 4. Generate samples from configuration\n    analyzer_config = analysis_case.get(\"analyzer\", {})\n    enabled_method_name = analyzer_config.get(\"method\")\n    if not enabled_method_name:\n        raise ValueError(\n            \"No method found in 'sensitivity_analysis.analysis_case.analyzer'\"\n        )\n\n    N = analyzer_config.get(\"sample_N\", 1024)\n\n    sample_kwargs = {}\n\n    samples = analyzer.generate_samples(\n        method=enabled_method_name, N=N, **sample_kwargs\n    )\n    logger.info(f\"\u2713 Generated {len(samples)} parameter samples\")\n\n    # 5. Run Tricys simulation\n    output_metrics = analysis_case.get(\"dependent_variables\", [])\n\n    csv_file_path = analyzer.run_tricys_simulations(output_metrics=output_metrics)\n    logger.info(f\"\u2713 Parameter file has been generated: {csv_file_path}\")\n\n    summary_file = None\n    try:\n        logger.info(\"\\nAttempting to run Tricys analysis directly...\")\n        summary_file = analyzer.run_tricys_analysis(\n            csv_file_path=csv_file_path, output_metrics=output_metrics\n        )\n        if summary_file:\n            logger.info(f\"\u2713 Tricys analysis completed, result file: {summary_file}\")\n        else:\n            logger.info(\"\u26a0\ufe0f  Tricys analysis result file not found\")\n            return\n    except Exception as e:\n        logger.info(f\"\u26a0\ufe0f  Tricys analysis failed: {e}\")\n        logger.info(\"Please check if the model path and configuration are correct\")\n        return\n\n    # 6. Run SALib analysis from Tricys results\n    try:\n        logger.info(\"\\nRunning SALib analysis from Tricys results...\")\n        all_results = analyzer.run_salib_analysis_from_tricys_results(\n            sensitivity_summary_csv=summary_file,\n            param_bounds=param_bounds,\n            output_metrics=output_metrics,\n            methods=[enabled_method_name],\n            save_dir=os.path.dirname(summary_file),\n        )\n\n        logger.info(f\"\\n\u2705 SALib {enabled_method_name.upper()} analysis completed!\")\n        logger.info(\n            f\"\ud83d\udcc1 The results have been saved to: {os.path.join(os.path.dirname(summary_file), f'salib_analysis_{enabled_method_name}')}\"\n        )\n\n        logger.info(\"\\n\ud83d\udcc8 Brief results:\")\n        for metric_name, metric_results in all_results.items():\n            logger.info(f\"\\n--- {metric_name} ---\")\n            if enabled_method_name in metric_results:\n                result_data = metric_results[enabled_method_name]\n                if enabled_method_name == \"sobol\":\n                    logger.info(\"\ud83d\udd25 Most sensitive parameters (Sobol ST):\")\n                    st_values = list(zip(analyzer.problem[\"names\"], result_data[\"ST\"]))\n                    st_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, st in st_values[:3]:\n                        logger.info(f\"   {param}: {st:.4f}\")\n                elif enabled_method_name == \"morris\":\n                    logger.info(\"\ud83d\udcca Most Sensitive Parameter (Morris \u03bc*):\")\n                    mu_star_values = list(\n                        zip(analyzer.problem[\"names\"], result_data[\"mu_star\"])\n                    )\n                    mu_star_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, mu_star in mu_star_values[:3]:\n                        logger.info(f\"   {param}: {mu_star:.4f}\")\n                elif enabled_method_name == \"fast\":\n                    logger.info(\"\u26a1 Most Sensitive Parameter (Morris \u03bc*):\")\n                    st_values = list(zip(analyzer.problem[\"names\"], result_data[\"ST\"]))\n                    st_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, st in st_values[:3]:\n                        logger.info(f\"   {param}: {st:.4f}\")\n\n        return analyzer, all_results\n\n    except Exception as e:\n        logger.error(f\"SALib analysis failed: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"api/tricys_core.html","title":"API \u53c2\u8003 - \u6838\u5fc3\u6a21\u5757 (Core)","text":"<p>\u6838\u5fc3\u6a21\u5757 (Core)</p> <p>\u6838\u5fc3\u6a21\u5757 (Core) \u5305\u542b\u4e86 TRICYS \u7684\u6838\u5fc3\u529f\u80fd\uff0c\u5982\u4f5c\u4e1a\u7ba1\u7406\u3001Modelica \u4ea4\u4e92\u548c\u4e8b\u4ef6\u62e6\u622a\u5668\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Jobs (\u4f5c\u4e1a\u7ba1\u7406)Modelica (\u6a21\u578b\u4ea4\u4e92)Interceptor (\u62e6\u622a\u5668) <p>Utilities for interacting with OpenModelica via OMPython.</p> <p>This module provides a set of functions to manage an OpenModelica session, load models, retrieve parameter details, and format parameter values for simulation.</p>"},{"location":"api/tricys_core.html#tricys.core.jobs.generate_simulation_jobs","title":"<code>generate_simulation_jobs(simulation_params)</code>","text":"<p>Generates a list of simulation jobs from parameters, handling sweeps and array expansion.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_params</code> <code>Dict[str, Any]</code> <p>Dictionary of simulation parameters. Can include: - \"file\": Path to CSV file for batch job loading - Parameter names with values (single values, lists, or special format strings) - Array-like parameters in format \"{value1, value2, ...}\"</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of job dictionaries. Each job contains one combination of parameter</p> <code>List[Dict[str, Any]]</code> <p>values for simulation. Single-value parameters are included in all jobs.</p> Note <p>If \"file\" parameter is present, jobs are loaded from CSV and other parameters are merged into each CSV job. For parameter sweeps, generates all combinations using Cartesian product. Array-like parameters are expanded using 1-based indexing before sweep generation. Returns empty dict list [{}] if no parameters provided.</p> Source code in <code>tricys/core/jobs.py</code> <pre><code>def generate_simulation_jobs(\n    simulation_params: Dict[str, Any],\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Generates a list of simulation jobs from parameters, handling sweeps and array expansion.\n\n    Args:\n        simulation_params: Dictionary of simulation parameters. Can include:\n            - \"file\": Path to CSV file for batch job loading\n            - Parameter names with values (single values, lists, or special format strings)\n            - Array-like parameters in format \"{value1, value2, ...}\"\n\n    Returns:\n        A list of job dictionaries. Each job contains one combination of parameter\n        values for simulation. Single-value parameters are included in all jobs.\n\n    Note:\n        If \"file\" parameter is present, jobs are loaded from CSV and other parameters\n        are merged into each CSV job. For parameter sweeps, generates all combinations\n        using Cartesian product. Array-like parameters are expanded using 1-based indexing\n        before sweep generation. Returns empty dict list [{}] if no parameters provided.\n    \"\"\"\n\n    logger.info(\n        \"Generating simulation jobs\",\n        extra={\n            \"simulation_parameters\": simulation_params,\n        },\n    )\n    if \"file\" in simulation_params:\n        file_value = simulation_params[\"file\"]\n        if isinstance(file_value, str):\n            csv_jobs = _load_jobs_from_csv(file_value)\n\n            other_params = {k: v for k, v in simulation_params.items() if k != \"file\"}\n            for job in csv_jobs:\n                job.update(other_params)\n\n            return csv_jobs\n\n    # First, expand any array-like parameters before processing.\n    processed_params = _expand_array_parameters(simulation_params)\n\n    sweep_params = {}\n    single_value_params = {}\n\n    for name, value in processed_params.items():\n        parsed_values = parse_parameter_value(value)\n        if len(parsed_values) &gt; 1:\n            sweep_params[name] = parsed_values\n        else:\n            single_value_params[name] = parsed_values[0] if parsed_values else None\n\n    if not sweep_params:\n        return [single_value_params] if single_value_params else [{}]\n\n    sweep_names = list(sweep_params.keys())\n    sweep_values = list(sweep_params.values())\n    jobs = []\n    for combo in itertools.product(*sweep_values):\n        job = single_value_params.copy()\n        job.update(dict(zip(sweep_names, combo)))\n        jobs.append(job)\n    return jobs\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.jobs.parse_parameter_value","title":"<code>parse_parameter_value(value)</code>","text":"<p>Parses a parameter value which can be a single value, a list, or a string with special formats.</p> Supported special string formats <ul> <li>\"start:stop:step\" -&gt; e.g., \"1:10:2\" for a linear range with step</li> <li>\"linspace:start:stop:num\" -&gt; e.g., \"linspace:0:10:5\" for 5 evenly spaced points</li> <li>\"log:start:stop:num\" -&gt; e.g., \"log:1:1000:4\" for 4 points on log scale</li> <li>\"rand:min:max:count\" -&gt; e.g., \"rand:0:1:10\" for 10 random uniform values</li> <li>\"file:path:column\" -&gt; e.g., \"file:data.csv:voltage\" to read a CSV column</li> <li>\"file:path\" -&gt; e.g., \"file:sampling.csv\" to read all parameters from CSV</li> </ul> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The parameter value to parse. Can be a single value, list, or special format string.</p> required <p>Returns:</p> Type Description <code>List[Any]</code> <p>A list of parsed values. Single values and strings without colons return</p> <code>List[Any]</code> <p>a single-element list. Special format strings return expanded value lists.</p> Note <p>Numbers are rounded to 8 decimal places to avoid floating point precision issues. If parsing fails, returns the original value as a single-element list and logs an error. For \"file:\" format, Windows paths with drive letters (C:) are handled.</p> Source code in <code>tricys/core/jobs.py</code> <pre><code>def parse_parameter_value(value: Any) -&gt; List[Any]:\n    \"\"\"Parses a parameter value which can be a single value, a list, or a string with special formats.\n\n    Supported special string formats:\n        - \"start:stop:step\" -&gt; e.g., \"1:10:2\" for a linear range with step\n        - \"linspace:start:stop:num\" -&gt; e.g., \"linspace:0:10:5\" for 5 evenly spaced points\n        - \"log:start:stop:num\" -&gt; e.g., \"log:1:1000:4\" for 4 points on log scale\n        - \"rand:min:max:count\" -&gt; e.g., \"rand:0:1:10\" for 10 random uniform values\n        - \"file:path:column\" -&gt; e.g., \"file:data.csv:voltage\" to read a CSV column\n        - \"file:path\" -&gt; e.g., \"file:sampling.csv\" to read all parameters from CSV\n\n    Args:\n        value: The parameter value to parse. Can be a single value, list, or special\n            format string.\n\n    Returns:\n        A list of parsed values. Single values and strings without colons return\n        a single-element list. Special format strings return expanded value lists.\n\n    Note:\n        Numbers are rounded to 8 decimal places to avoid floating point precision issues.\n        If parsing fails, returns the original value as a single-element list and logs\n        an error. For \"file:\" format, Windows paths with drive letters (C:\\\\) are handled.\n    \"\"\"\n    if not isinstance(value, str):\n        return value if isinstance(value, list) else [value]\n\n    if \":\" not in value:\n        return [value]  # Just a plain string\n\n    try:\n        prefix, args_str = value.split(\":\", 1)\n        prefix = prefix.lower()\n\n        if prefix == \"linspace\":\n            start, stop, num = map(float, args_str.split(\":\"))\n            return np.linspace(start, stop, int(num)).round(8).tolist()\n\n        if prefix == \"log\":\n            start, stop, num = map(float, args_str.split(\":\"))\n            if start &lt;= 0 or stop &lt;= 0:\n                raise ValueError(\"Log scale start and stop values must be positive.\")\n            return (\n                np.logspace(np.log10(start), np.log10(stop), int(num)).round(8).tolist()\n            )\n\n        if prefix == \"rand\":\n            low, high, count = map(float, args_str.split(\":\"))\n            return np.random.uniform(low, high, int(count)).round(8).tolist()\n\n        if prefix == \"file\":\n            # Handle file paths that may contain colons (e.g., Windows C:\\...)\n            try:\n                # Check if there's a column name specified\n                if \":\" in args_str:\n                    file_path, column_name = args_str.rsplit(\":\", 1)\n                    if not os.path.isabs(file_path.strip()):\n                        abs_file_path = os.path.abspath(\n                            os.path.join(os.getcwd(), file_path.strip())\n                        )\n                    else:\n                        abs_file_path = file_path.strip()\n                    df = pd.read_csv(abs_file_path)\n                    return df[column_name.strip()].tolist()\n                else:\n                    # Return the file path for later processing\n                    return [args_str.strip()]\n            except (ValueError, FileNotFoundError, KeyError):\n                # Re-raise to be caught by the outer try-except block\n                raise\n\n        # Fallback to original start:stop:step logic if no prefix matches\n        start, stop, step = map(float, value.split(\":\"))\n        return np.arange(start, stop + step / 2, step).round(8).tolist()\n\n    except (ValueError, FileNotFoundError, KeyError, IndexError) as e:\n        logger.error(\n            \"Invalid format or error processing parameter value\",\n            extra={\n                \"value\": value,\n                \"error\": str(e),\n            },\n        )\n        return [value]  # On any error, treat as a single literal value\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.format_parameter_value","title":"<code>format_parameter_value(name, value)</code>","text":"<p>Formats a parameter value into a string recognized by OpenModelica.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the parameter.</p> required <code>value</code> <code>Any</code> <p>The value of the parameter (can be number, string, list, or bool).</p> required <p>Returns:</p> Type Description <code>str</code> <p>A formatted string for use in simulation overrides (e.g., \"p=1.0\",</p> <code>str</code> <p>\"name={1,2,3}\", or 'path=\"value\"').</p> Note <p>Lists are formatted as {v1,v2,...}. Strings are quoted with double quotes. Numbers and booleans use direct string conversion.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def format_parameter_value(name: str, value: Any) -&gt; str:\n    \"\"\"Formats a parameter value into a string recognized by OpenModelica.\n\n    Args:\n        name: The name of the parameter.\n        value: The value of the parameter (can be number, string, list, or bool).\n\n    Returns:\n        A formatted string for use in simulation overrides (e.g., \"p=1.0\",\n        \"name={1,2,3}\", or 'path=\"value\"').\n\n    Note:\n        Lists are formatted as {v1,v2,...}. Strings are quoted with double quotes.\n        Numbers and booleans use direct string conversion.\n    \"\"\"\n    if isinstance(value, list):\n        # Format lists as {v1,v2,...}\n        return f\"{name}={{{','.join(map(str, value))}}}\"\n    elif isinstance(value, str):\n        # Format strings as \"value\"\n        return f'{name}=\"{value}\"'\n    # For numbers and booleans, direct string conversion is fine\n    return f\"{name}={value}\"\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_all_parameters_details","title":"<code>get_all_parameters_details(omc, model_name)</code>","text":"<p>Recursively retrieves detailed information for all parameters in a given model.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>model_name</code> <code>str</code> <p>The full name of the model.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of dictionaries, where each dictionary contains the detailed</p> <code>List[Dict[str, Any]]</code> <p>information of a single parameter including name, type, defaultValue,</p> <code>List[Dict[str, Any]]</code> <p>comment, and dimensions.</p> Note <p>Uses _recursive_get_parameters() to traverse the model hierarchy. Returns empty list if model is not found or on error. Each parameter dict includes 'name' (hierarchical), 'type', 'defaultValue', 'comment', and 'dimensions' fields.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_all_parameters_details(\n    omc: OMCSessionZMQ, model_name: str\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Recursively retrieves detailed information for all parameters in a given model.\n\n    Args:\n        omc: The active OpenModelica session object.\n        model_name: The full name of the model.\n\n    Returns:\n        A list of dictionaries, where each dictionary contains the detailed\n        information of a single parameter including name, type, defaultValue,\n        comment, and dimensions.\n\n    Note:\n        Uses _recursive_get_parameters() to traverse the model hierarchy.\n        Returns empty list if model is not found or on error. Each parameter\n        dict includes 'name' (hierarchical), 'type', 'defaultValue', 'comment',\n        and 'dimensions' fields.\n    \"\"\"\n    logger.info(\n        \"Getting detailed parameters via recursion\", extra={\"model_name\": model_name}\n    )\n    all_params_details = []\n    try:\n        if not omc.sendExpression(f\"isModel({model_name})\"):\n            logger.error(\"Model not found in package\", extra={\"model_name\": model_name})\n            return []\n        _recursive_get_parameters(omc, model_name, \"\", all_params_details)\n        logger.info(\n            \"Successfully found parameter details\",\n            extra={\"count\": len(all_params_details)},\n        )\n        return all_params_details\n    except Exception as e:\n        logger.error(\n            \"Failed to get detailed parameters via recursion\",\n            exc_info=True,\n            extra={\"error\": str(e)},\n        )\n        return []\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_model_default_parameters","title":"<code>get_model_default_parameters(omc, model_name)</code>","text":"<p>Retrieves the default values for all parameters in a given model.</p> <p>This function leverages get_all_parameters_details to fetch detailed parameter information and then extracts and parses the name and default value into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>model_name</code> <code>str</code> <p>The full name of the model.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary mapping parameter names to their default values</p> <code>Dict[str, Any]</code> <p>(e.g., float, list, bool, str). Returns an empty dictionary if</p> <code>Dict[str, Any]</code> <p>the model is not found or has no parameters.</p> Note <p>Values are parsed from OpenModelica string format to Python types using _parse_om_value(). Handles arrays, booleans, strings, and numeric values.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_model_default_parameters(omc: OMCSessionZMQ, model_name: str) -&gt; Dict[str, Any]:\n    \"\"\"Retrieves the default values for all parameters in a given model.\n\n    This function leverages get_all_parameters_details to fetch detailed\n    parameter information and then extracts and parses the name and default value\n    into a dictionary.\n\n    Args:\n        omc: The active OpenModelica session object.\n        model_name: The full name of the model.\n\n    Returns:\n        A dictionary mapping parameter names to their default values\n        (e.g., float, list, bool, str). Returns an empty dictionary if\n        the model is not found or has no parameters.\n\n    Note:\n        Values are parsed from OpenModelica string format to Python types using\n        _parse_om_value(). Handles arrays, booleans, strings, and numeric values.\n    \"\"\"\n    logger.info(\n        \"Getting and parsing default parameter values\", extra={\"model_name\": model_name}\n    )\n\n    # Use the existing detailed function to get all parameter info\n    all_params_details = get_all_parameters_details(omc, model_name)\n\n    if not all_params_details:\n        logger.warning(\n            \"No parameters found for model\", extra={\"model_name\": model_name}\n        )\n        return {}\n\n    # Convert the list of dicts into a single dict of name: parsed_defaultValue\n    default_params = {\n        param[\"name\"]: _parse_om_value(param[\"defaultValue\"])\n        for param in all_params_details\n    }\n\n    logger.info(\n        \"Found and parsed default parameters\",\n        extra={\n            \"count\": len(default_params),\n            \"model_name\": model_name,\n        },\n    )\n    return default_params\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_model_parameter_names","title":"<code>get_model_parameter_names(omc, model_name)</code>","text":"<p>Parses and returns all subcomponent parameter names for a given model.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>model_name</code> <code>str</code> <p>The full name of the model (e.g., 'example.Cycle').</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of all available parameter names in hierarchical format</p> <code>List[str]</code> <p>(e.g., ['blanket.TBR', 'divertor.heatLoad']).</p> Note <p>Only traverses components whose type starts with the package name. Returns empty list if model is not found or has no components. Uses getComponents() and getParameterNames() OMC API calls.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_model_parameter_names(omc: OMCSessionZMQ, model_name: str) -&gt; List[str]:\n    \"\"\"Parses and returns all subcomponent parameter names for a given model.\n\n    Args:\n        omc: The active OpenModelica session object.\n        model_name: The full name of the model (e.g., 'example.Cycle').\n\n    Returns:\n        A list of all available parameter names in hierarchical format\n        (e.g., ['blanket.TBR', 'divertor.heatLoad']).\n\n    Note:\n        Only traverses components whose type starts with the package name.\n        Returns empty list if model is not found or has no components. Uses\n        getComponents() and getParameterNames() OMC API calls.\n    \"\"\"\n    logger.info(\"Getting parameter names for model\", extra={\"model_name\": model_name})\n    all_params = []\n    try:\n        if not omc.sendExpression(f\"isModel({model_name})\"):\n            logger.warning(\n                \"Model not found in package\", extra={\"model_name\": model_name}\n            )\n            return []\n\n        components = omc.sendExpression(f\"getComponents({model_name})\")\n        if not components:\n            logger.warning(\n                \"No components found for model\", extra={\"model_name\": model_name}\n            )\n            return []\n\n        for comp in components:\n            comp_type, comp_name = comp[0], comp[1]\n            if comp_type.startswith(model_name.split(\".\")[0]):\n                params = omc.sendExpression(f\"getParameterNames({comp_type})\")\n                for param in params:\n                    full_param = f\"{comp_name}.{param}\"\n                    if full_param not in all_params:\n                        all_params.append(full_param)\n\n        logger.info(\"Found parameter names\", extra={\"count\": len(all_params)})\n        return all_params\n\n    except Exception as e:\n        logger.error(\n            \"Failed to get parameter names\", exc_info=True, extra={\"error\": str(e)}\n        )\n        return []\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.get_om_session","title":"<code>get_om_session()</code>","text":"<p>Initializes and returns a new OMCSessionZMQ session.</p> <p>Returns:</p> Type Description <code>OMCSessionZMQ</code> <p>An active OpenModelica session object.</p> Note <p>Creates a new ZMQ-based connection to OpenModelica Compiler. Each call creates an independent session that should be properly closed after use.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_om_session() -&gt; OMCSessionZMQ:\n    \"\"\"Initializes and returns a new OMCSessionZMQ session.\n\n    Returns:\n        An active OpenModelica session object.\n\n    Note:\n        Creates a new ZMQ-based connection to OpenModelica Compiler. Each call\n        creates an independent session that should be properly closed after use.\n    \"\"\"\n    logger.debug(\"Initializing new OMCSessionZMQ session\")\n    return OMCSessionZMQ()\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.modelica.load_modelica_package","title":"<code>load_modelica_package(omc, package_path)</code>","text":"<p>Loads a Modelica package into the OpenModelica session.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>package_path</code> <code>str</code> <p>The file path to the Modelica package (<code>package.mo</code>).</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the package was loaded successfully, False otherwise.</p> Note <p>Uses sendExpression('loadFile(...)') command. Logs error if loading fails. The package must be a valid Modelica package file.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def load_modelica_package(omc: OMCSessionZMQ, package_path: str) -&gt; bool:\n    \"\"\"Loads a Modelica package into the OpenModelica session.\n\n    Args:\n        omc: The active OpenModelica session object.\n        package_path: The file path to the Modelica package (`package.mo`).\n\n    Returns:\n        True if the package was loaded successfully, False otherwise.\n\n    Note:\n        Uses sendExpression('loadFile(...)') command. Logs error if loading fails.\n        The package must be a valid Modelica package file.\n    \"\"\"\n    logger.info(\"Loading package\", extra={\"package_path\": package_path})\n    load_result = omc.sendExpression(f'loadFile(\"{package_path}\")')\n    if not load_result:\n        logger.error(\"Failed to load package\", extra={\"package_path\": package_path})\n        return False\n    return True\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.interceptor.integrate_interceptor_model","title":"<code>integrate_interceptor_model(package_path, model_name, interception_configs)</code>","text":"<p>Integrates CSV data replacement into a system model.</p> <p>This function supports two modes (all handlers must use the same mode): 1. \"interceptor\" (default): Creates interceptor models between submodels and system. 2. \"replacement\": Directly modifies submodels to use CSV data.</p> <p>Parameters:</p> Name Type Description Default <code>package_path</code> <code>str</code> <p>The file path to the Modelica package. For multi-file packages, this should be the path to <code>package.mo</code>. For single-file packages, this should be the path to the <code>.mo</code> file containing the package.</p> required <code>model_name</code> <code>str</code> <p>The full name of the system model to be modified.</p> required <code>interception_configs</code> <code>list[Dict[str, Any]]</code> <p>A list of dictionaries, each defining an interception task. All configs must have the same 'mode' field. Each dict should contain 'submodel_name', 'csv_uri', 'instance_name', 'output_placeholder', and optionally 'mode' (defaults to 'interceptor').</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary containing the paths to modified models. Structure varies by mode: - interceptor mode: interceptor_model_paths, system_model_path - replacement mode: replaced_models, system_model_path</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If interception_configs is empty or if mixed modes are detected.</p> <code>FileNotFoundError</code> <p>If package_path is invalid or package.mo not found.</p> Note <p>Mode is determined from the first config's 'mode' field. All configs must use the same mode or ValueError is raised. Automatically detects single-file vs multi-file package structure and routes to appropriate handler.</p> Source code in <code>tricys/core/interceptor.py</code> <pre><code>def integrate_interceptor_model(\n    package_path: str, model_name: str, interception_configs: list[Dict[str, Any]]\n) -&gt; Dict[str, Any]:\n    \"\"\"Integrates CSV data replacement into a system model.\n\n    This function supports two modes (all handlers must use the same mode):\n    1. \"interceptor\" (default): Creates interceptor models between submodels and system.\n    2. \"replacement\": Directly modifies submodels to use CSV data.\n\n    Args:\n        package_path: The file path to the Modelica package. For multi-file packages,\n            this should be the path to `package.mo`. For single-file packages,\n            this should be the path to the `.mo` file containing the package.\n        model_name: The full name of the system model to be modified.\n        interception_configs: A list of dictionaries, each defining an interception task.\n            All configs must have the same 'mode' field. Each dict should contain\n            'submodel_name', 'csv_uri', 'instance_name', 'output_placeholder', and\n            optionally 'mode' (defaults to 'interceptor').\n\n    Returns:\n        A dictionary containing the paths to modified models. Structure varies by mode:\n            - interceptor mode: interceptor_model_paths, system_model_path\n            - replacement mode: replaced_models, system_model_path\n\n    Raises:\n        ValueError: If interception_configs is empty or if mixed modes are detected.\n        FileNotFoundError: If package_path is invalid or package.mo not found.\n\n    Note:\n        Mode is determined from the first config's 'mode' field. All configs must use\n        the same mode or ValueError is raised. Automatically detects single-file vs\n        multi-file package structure and routes to appropriate handler.\n    \"\"\"\n    if not interception_configs:\n        raise ValueError(\"interception_configs cannot be empty\")\n\n    # Get mode from first config (all should be the same)\n    mode = interception_configs[0].get(\"mode\", \"interceptor\")\n\n    # Validate that all configs use the same mode\n    for config in interception_configs:\n        config_mode = config.get(\"mode\", \"interceptor\")\n        if config_mode != mode:\n            raise ValueError(\n                f\"Mixed modes are not supported. All handlers must use the same mode. \"\n                f\"Expected '{mode}', but found '{config_mode}' in config for '{config.get('submodel_name')}'\"\n            )\n\n    logger.info(\n        \"Integrating CSV data replacement\",\n        extra={\n            \"mode\": mode,\n            \"num_submodels\": len(interception_configs),\n        },\n    )\n\n    # Route to appropriate handler based on mode\n    if mode == \"replacement\":\n        return _integrate_replacement(package_path, model_name, interception_configs)\n    else:  # mode == \"interceptor\"\n        # Determine package type and route to appropriate handler\n        if os.path.isdir(package_path):\n            package_file = os.path.join(package_path, \"package.mo\")\n            if os.path.exists(package_file):\n                return _integrate_interceptor_multi_file(\n                    package_file, model_name, interception_configs\n                )\n            else:\n                raise FileNotFoundError(\n                    f\"No package.mo found in directory: {package_path}\"\n                )\n        elif os.path.isfile(package_path) and package_path.endswith(\"package.mo\"):\n            return _integrate_interceptor_multi_file(\n                package_path, model_name, interception_configs\n            )\n        elif os.path.isfile(package_path):\n            return _integrate_interceptor_single_file(\n                package_path, model_name, interception_configs\n            )\n        else:\n            raise FileNotFoundError(f\"Invalid package path: {package_path}\")\n</code></pre>"},{"location":"api/tricys_core.html#tricys.core.interceptor.replace_submodels_with_csv","title":"<code>replace_submodels_with_csv(package_path, replacement_configs)</code>","text":"<p>Replaces multiple submodels with CSV data sources.</p> <p>Parameters:</p> Name Type Description Default <code>package_path</code> <code>str</code> <p>Path to the Modelica package directory or package.mo file.</p> required <code>replacement_configs</code> <code>list[Dict[str, Any]]</code> <p>A list of dictionaries, each defining a replacement task: - submodel_name: Full name of the submodel (e.g., 'MyPackage.MyModel') - output_ports: List of output port definitions - csv_file: Path to the CSV file</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A dictionary containing: - replaced_models: List of results from each replacement - package_path: Original package path</p> Note <p>Automatically determines if package is directory-based or single-file. Continues processing remaining models if one fails, but re-raises the error after logging. Each submodel file is identified by splitting the full name and locating {ModelName}.mo in the package directory.</p> Source code in <code>tricys/core/interceptor.py</code> <pre><code>def replace_submodels_with_csv(\n    package_path: str,\n    replacement_configs: list[Dict[str, Any]],\n) -&gt; Dict[str, Any]:\n    \"\"\"Replaces multiple submodels with CSV data sources.\n\n    Args:\n        package_path: Path to the Modelica package directory or package.mo file.\n        replacement_configs: A list of dictionaries, each defining a replacement task:\n            - submodel_name: Full name of the submodel (e.g., 'MyPackage.MyModel')\n            - output_ports: List of output port definitions\n            - csv_file: Path to the CSV file\n\n    Returns:\n        A dictionary containing:\n            - replaced_models: List of results from each replacement\n            - package_path: Original package path\n\n    Note:\n        Automatically determines if package is directory-based or single-file.\n        Continues processing remaining models if one fails, but re-raises the error\n        after logging. Each submodel file is identified by splitting the full name\n        and locating {ModelName}.mo in the package directory.\n    \"\"\"\n    logger.info(\n        \"Starting batch submodel replacement\",\n        extra={\"num_configs\": len(replacement_configs)},\n    )\n\n    # Determine package directory\n    if os.path.isdir(package_path):\n        package_dir = package_path\n    elif os.path.isfile(package_path) and package_path.endswith(\"package.mo\"):\n        package_dir = os.path.dirname(package_path)\n    elif os.path.isfile(package_path):\n        package_dir = os.path.dirname(package_path)\n    else:\n        raise FileNotFoundError(f\"Invalid package path: {package_path}\")\n\n    replaced_models = []\n\n    for config in replacement_configs:\n        submodel_name = config[\"submodel_name\"]\n        output_ports = config[\"output_ports\"]\n        csv_file = config[\"csv_file\"]\n\n        # Construct submodel file path\n        model_simple_name = submodel_name.split(\".\")[-1]\n        submodel_file = os.path.join(package_dir, f\"{model_simple_name}.mo\")\n\n        if not os.path.exists(submodel_file):\n            logger.warning(\n                \"Submodel file not found, skipping\",\n                extra={\"submodel_name\": submodel_name, \"expected_path\": submodel_file},\n            )\n            continue\n\n        try:\n            result = _replace_submodel_with_csv(\n                submodel_path=submodel_file,\n                output_ports=output_ports,\n                csv_file=csv_file,\n            )\n            result[\"submodel_name\"] = submodel_name\n            replaced_models.append(result)\n\n            logger.info(\n                \"Successfully replaced submodel\",\n                extra={\"submodel_name\": submodel_name},\n            )\n\n        except Exception as e:\n            logger.error(\n                \"Failed to replace submodel\",\n                extra={\"submodel_name\": submodel_name, \"error\": str(e)},\n            )\n            raise\n\n    logger.info(\n        \"Batch replacement completed\",\n        extra={\"num_replaced\": len(replaced_models)},\n    )\n\n    return {\n        \"replaced_models\": replaced_models,\n        \"package_path\": package_path,\n    }\n</code></pre>"},{"location":"api/tricys_handlers.html","title":"API \u53c2\u8003 - \u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers)","text":"<p>\u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers)</p> <p>\u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers) \u63d0\u4f9b\u4e86\u7528\u4e8e\u4e0e\u5916\u90e8\u4eff\u771f\u5de5\u5177\uff08\u5982 Aspen Plus\uff09\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u548c\u534f\u540c\u4eff\u771f\u7684\u63a5\u53e3\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> DIV HandlerI_ISS Handler"},{"location":"api/tricys_handlers.html#tricys.handlers.div_handler.run_div_simulation","title":"<code>run_div_simulation(temp_input_csv, temp_output_csv, **kwargs)</code>","text":"<p>Runs a simulation based on fake divertor data.</p> <p>Reads data from a source CSV, selects specific columns, and writes them to a temporary output CSV.</p> <p>Parameters:</p> Name Type Description Default <code>temp_input_csv</code> <code>str</code> <p>Path to the temporary input CSV file (unused).</p> required <code>temp_output_csv</code> <code>str</code> <p>Path to the temporary output CSV file.</p> required <code>**kwargs</code> <p>Additional keyword arguments (unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>A placeholder dictionary with output variable mappings.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the source CSV file cannot be found.</p> <code>ValueError</code> <p>If the source CSV is missing required columns.</p> Note <p>The temp_input_csv parameter is kept for interface consistency but not used. Reads from div_handler.csv in the same directory as this module. Returns a placeholder dict with format {\"to_CL\": \"{1,2,3,4,5,6}\"}.</p> Source code in <code>tricys/handlers/div_handler.py</code> <pre><code>def run_div_simulation(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"Runs a simulation based on fake divertor data.\n\n    Reads data from a source CSV, selects specific columns, and writes them\n    to a temporary output CSV.\n\n    Args:\n        temp_input_csv: Path to the temporary input CSV file (unused).\n        temp_output_csv: Path to the temporary output CSV file.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        A placeholder dictionary with output variable mappings.\n\n    Raises:\n        FileNotFoundError: If the source CSV file cannot be found.\n        ValueError: If the source CSV is missing required columns.\n\n    Note:\n        The temp_input_csv parameter is kept for interface consistency but not used.\n        Reads from div_handler.csv in the same directory as this module. Returns\n        a placeholder dict with format {\"to_CL\": \"{1,2,3,4,5,6}\"}.\n    \"\"\"\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"div_handler.csv\")\n\n    try:\n        source_df = pd.read_csv(source_csv_path)\n    except FileNotFoundError:\n        pd.DataFrame({\"time\": []}).to_csv(temp_output_csv, index=False)\n        raise\n\n    columns_to_select = [\n        \"time\",\n        \"div.to_CL[1]\",\n        \"div.to_CL[2]\",\n        \"div.to_CL[3]\",\n        \"div.to_CL[4]\",\n        \"div.to_CL[5]\",\n    ]\n\n    if not all(col in source_df.columns for col in columns_to_select):\n        missing_cols = [\n            col for col in columns_to_select if col not in source_df.columns\n        ]\n        raise ValueError(\n            f\"The source file {source_csv_path} is missing required columns: \"\n            f\"{missing_cols}\"\n        )\n\n    output_df = source_df[columns_to_select].copy()\n\n    output_df.to_csv(temp_output_csv, index=False)\n\n    output_placeholder = {\"to_CL\": \"{1,2,3,4,5,6}\"}\n\n    return output_placeholder\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced","title":"<code>AspenEnhanced</code>","text":"<p>A helper class to encapsulate interactions with an Aspen Plus COM server.</p> <p>Attributes:</p> Name Type Description <code>aspen</code> <p>The Aspen Plus COM object instance.</p> <code>M_T</code> <p>Molar mass of Tritium (3.016 g/mol).</p> <code>M_D</code> <p>Molar mass of Deuterium (2.014 g/mol).</p> <code>M_H</code> <p>Molar mass of Hydrogen (1.008 g/mol).</p> Note <p>Requires Aspen Plus COM interface to be available on the system. Sets visibility to 0 and suppresses dialogs for automation.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>class AspenEnhanced:\n    \"\"\"A helper class to encapsulate interactions with an Aspen Plus COM server.\n\n    Attributes:\n        aspen: The Aspen Plus COM object instance.\n        M_T: Molar mass of Tritium (3.016 g/mol).\n        M_D: Molar mass of Deuterium (2.014 g/mol).\n        M_H: Molar mass of Hydrogen (1.008 g/mol).\n\n    Note:\n        Requires Aspen Plus COM interface to be available on the system.\n        Sets visibility to 0 and suppresses dialogs for automation.\n    \"\"\"\n\n    def __init__(self, bkp_path: str) -&gt; None:\n        \"\"\"Initialize Aspen connection and define molar masses.\n\n        Args:\n            bkp_path: Path to the Aspen backup file (.bkp).\n\n        Note:\n            Converts path to absolute before loading. Suppresses Aspen GUI and dialogs.\n            COM object version \"Apwn.Document.40.0\" may need adjustment for different\n            Aspen Plus versions.\n        \"\"\"\n        logger.info(\"Dispatching Aspen COM object...\")\n        self.aspen = win32.Dispatch(\"Apwn.Document.40.0\")  # Adjust version if necessary\n        logger.info(f\"Loading Aspen backup file: {os.path.abspath(bkp_path)}\")\n        self.aspen.InitFromArchive2(os.path.abspath(bkp_path))\n        self.aspen.Visible = 0\n        self.aspen.SuppressDialogs = 1\n        logger.info(\"Aspen initialized successfully.\")\n\n        # \u5b9a\u4e49\u6469\u5c14\u8d28\u91cf (g/mol)\n        self.M_T, self.M_D, self.M_H = 3.016, 2.014, 1.008\n\n    def set_composition(self, ratios: list) -&gt; None:\n        \"\"\"Set six-component input composition.\n\n        Args:\n            ratios: List of 7 values [EH2, EHD, ED2, EHT, EDT, ET2, total_flow].\n\n        Note:\n            Updates Aspen stream FROMTEP with H2, HD, D2, HT, DT, T2 flows and total flow.\n            Total flow is divided by 2 when setting TOTFLOW/MIXED node.\n        \"\"\"\n        nodes = {\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\H2\": ratios[0],  # EH2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HD\": ratios[1],  # EHD\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\D2\": ratios[2],  # ED2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HT\": ratios[3],  # EHT\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\DT\": ratios[4],  # EDT\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\T2\": ratios[5],  # ET2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\TOTFLOW\\MIXED\": ratios[6] / 2,  # \u603b\u6d41\u91cf/2\n        }\n        for path, value in nodes.items():\n            self.aspen.Tree.FindNode(path).Value = value\n\n    def run_step(self) -&gt; None:\n        \"\"\"Execute single-step simulation and wait for completion.\n\n        Note:\n            Uses busy-wait polling with 0.1 second intervals to check if engine is running.\n            Blocks until simulation step completes.\n        \"\"\"\n        self.aspen.Engine.Run2()\n        while self.aspen.Engine.IsRunning:\n            time.sleep(0.1)\n\n    def get_stream_results(self) -&gt; dict:\n        \"\"\"Get H/D/T mass flow rates (g/h) from key streams.\n\n        Returns:\n            Dictionary mapping stream names to [H, D, T] mass flow lists.\n            Format: {\"WDS\": [H, D, T], \"SDST2\": [H, D, T], \"SDSD2\": [H, D, T]}.\n\n        Note:\n            Retrieves mole flows in kmol/h, converts to mol/h (*1000), then calculates\n            mass flows using isotope-specific molar masses. Streams mapped are:\n            WDS-&gt;S4, SDST2-&gt;S17, SDSD2-&gt;S16.\n        \"\"\"\n\n        def calc_stream(stream_name):\n            \"\"\"\u8ba1\u7b97\u5355\u4e2a\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf\"\"\"\n            nodes = self.aspen.Tree.FindNode(\n                rf\"\\Data\\Streams\\{stream_name}\\Output\\MOLEFLOW\\MIXED\"\n            )\n            Q1 = 1000 * nodes.FindNode(\"H2\").Value\n            Q2 = 1000 * nodes.FindNode(\"HD\").Value\n            Q3 = 1000 * nodes.FindNode(\"D2\").Value\n            Q4 = 1000 * nodes.FindNode(\"HT\").Value\n            Q5 = 1000 * nodes.FindNode(\"DT\").Value\n            Q6 = 1000 * nodes.FindNode(\"T2\").Value\n\n            H = (2 * Q1 + 1 * Q2 + 1 * Q4) * self.M_H\n            D = (1 * Q2 + 2 * Q3 + 1 * Q5) * self.M_D\n            T = (1 * Q4 + 1 * Q5 + 2 * Q6) * self.M_T\n            return [H, D, T]\n\n        streams = {\"WDS\": \"S4\", \"SDST2\": \"S17\", \"SDSD2\": \"S16\"}\n        return {name: calc_stream(path) for name, path in streams.items()}\n\n    def close(self) -&gt; None:\n        \"\"\"Closes the Aspen connection.\n\n        Note:\n            Should always be called to properly clean up COM resources.\n            Typically used in finally block to ensure cleanup even on errors.\n        \"\"\"\n        if self.aspen:\n            self.aspen.Close()\n            logger.info(\"Closed Aspen session.\")\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.__init__","title":"<code>__init__(bkp_path)</code>","text":"<p>Initialize Aspen connection and define molar masses.</p> <p>Parameters:</p> Name Type Description Default <code>bkp_path</code> <code>str</code> <p>Path to the Aspen backup file (.bkp).</p> required Note <p>Converts path to absolute before loading. Suppresses Aspen GUI and dialogs. COM object version \"Apwn.Document.40.0\" may need adjustment for different Aspen Plus versions.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def __init__(self, bkp_path: str) -&gt; None:\n    \"\"\"Initialize Aspen connection and define molar masses.\n\n    Args:\n        bkp_path: Path to the Aspen backup file (.bkp).\n\n    Note:\n        Converts path to absolute before loading. Suppresses Aspen GUI and dialogs.\n        COM object version \"Apwn.Document.40.0\" may need adjustment for different\n        Aspen Plus versions.\n    \"\"\"\n    logger.info(\"Dispatching Aspen COM object...\")\n    self.aspen = win32.Dispatch(\"Apwn.Document.40.0\")  # Adjust version if necessary\n    logger.info(f\"Loading Aspen backup file: {os.path.abspath(bkp_path)}\")\n    self.aspen.InitFromArchive2(os.path.abspath(bkp_path))\n    self.aspen.Visible = 0\n    self.aspen.SuppressDialogs = 1\n    logger.info(\"Aspen initialized successfully.\")\n\n    # \u5b9a\u4e49\u6469\u5c14\u8d28\u91cf (g/mol)\n    self.M_T, self.M_D, self.M_H = 3.016, 2.014, 1.008\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.close","title":"<code>close()</code>","text":"<p>Closes the Aspen connection.</p> Note <p>Should always be called to properly clean up COM resources. Typically used in finally block to ensure cleanup even on errors.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the Aspen connection.\n\n    Note:\n        Should always be called to properly clean up COM resources.\n        Typically used in finally block to ensure cleanup even on errors.\n    \"\"\"\n    if self.aspen:\n        self.aspen.Close()\n        logger.info(\"Closed Aspen session.\")\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.get_stream_results","title":"<code>get_stream_results()</code>","text":"<p>Get H/D/T mass flow rates (g/h) from key streams.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary mapping stream names to [H, D, T] mass flow lists.</p> <code>Format</code> <code>dict</code> <p>{\"WDS\": [H, D, T], \"SDST2\": [H, D, T], \"SDSD2\": [H, D, T]}.</p> Note <p>Retrieves mole flows in kmol/h, converts to mol/h (*1000), then calculates mass flows using isotope-specific molar masses. Streams mapped are: WDS-&gt;S4, SDST2-&gt;S17, SDSD2-&gt;S16.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def get_stream_results(self) -&gt; dict:\n    \"\"\"Get H/D/T mass flow rates (g/h) from key streams.\n\n    Returns:\n        Dictionary mapping stream names to [H, D, T] mass flow lists.\n        Format: {\"WDS\": [H, D, T], \"SDST2\": [H, D, T], \"SDSD2\": [H, D, T]}.\n\n    Note:\n        Retrieves mole flows in kmol/h, converts to mol/h (*1000), then calculates\n        mass flows using isotope-specific molar masses. Streams mapped are:\n        WDS-&gt;S4, SDST2-&gt;S17, SDSD2-&gt;S16.\n    \"\"\"\n\n    def calc_stream(stream_name):\n        \"\"\"\u8ba1\u7b97\u5355\u4e2a\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf\"\"\"\n        nodes = self.aspen.Tree.FindNode(\n            rf\"\\Data\\Streams\\{stream_name}\\Output\\MOLEFLOW\\MIXED\"\n        )\n        Q1 = 1000 * nodes.FindNode(\"H2\").Value\n        Q2 = 1000 * nodes.FindNode(\"HD\").Value\n        Q3 = 1000 * nodes.FindNode(\"D2\").Value\n        Q4 = 1000 * nodes.FindNode(\"HT\").Value\n        Q5 = 1000 * nodes.FindNode(\"DT\").Value\n        Q6 = 1000 * nodes.FindNode(\"T2\").Value\n\n        H = (2 * Q1 + 1 * Q2 + 1 * Q4) * self.M_H\n        D = (1 * Q2 + 2 * Q3 + 1 * Q5) * self.M_D\n        T = (1 * Q4 + 1 * Q5 + 2 * Q6) * self.M_T\n        return [H, D, T]\n\n    streams = {\"WDS\": \"S4\", \"SDST2\": \"S17\", \"SDSD2\": \"S16\"}\n    return {name: calc_stream(path) for name, path in streams.items()}\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.run_step","title":"<code>run_step()</code>","text":"<p>Execute single-step simulation and wait for completion.</p> Note <p>Uses busy-wait polling with 0.1 second intervals to check if engine is running. Blocks until simulation step completes.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_step(self) -&gt; None:\n    \"\"\"Execute single-step simulation and wait for completion.\n\n    Note:\n        Uses busy-wait polling with 0.1 second intervals to check if engine is running.\n        Blocks until simulation step completes.\n    \"\"\"\n    self.aspen.Engine.Run2()\n    while self.aspen.Engine.IsRunning:\n        time.sleep(0.1)\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.AspenEnhanced.set_composition","title":"<code>set_composition(ratios)</code>","text":"<p>Set six-component input composition.</p> <p>Parameters:</p> Name Type Description Default <code>ratios</code> <code>list</code> <p>List of 7 values [EH2, EHD, ED2, EHT, EDT, ET2, total_flow].</p> required Note <p>Updates Aspen stream FROMTEP with H2, HD, D2, HT, DT, T2 flows and total flow. Total flow is divided by 2 when setting TOTFLOW/MIXED node.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def set_composition(self, ratios: list) -&gt; None:\n    \"\"\"Set six-component input composition.\n\n    Args:\n        ratios: List of 7 values [EH2, EHD, ED2, EHT, EDT, ET2, total_flow].\n\n    Note:\n        Updates Aspen stream FROMTEP with H2, HD, D2, HT, DT, T2 flows and total flow.\n        Total flow is divided by 2 when setting TOTFLOW/MIXED node.\n    \"\"\"\n    nodes = {\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\H2\": ratios[0],  # EH2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HD\": ratios[1],  # EHD\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\D2\": ratios[2],  # ED2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HT\": ratios[3],  # EHT\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\DT\": ratios[4],  # EDT\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\T2\": ratios[5],  # ET2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\TOTFLOW\\MIXED\": ratios[6] / 2,  # \u603b\u6d41\u91cf/2\n    }\n    for path, value in nodes.items():\n        self.aspen.Tree.FindNode(path).Value = value\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.run_aspen_simulation","title":"<code>run_aspen_simulation(temp_input_csv, temp_output_csv, bkp_path='example_aspenbkp/T2-Threetowers4.bkp', aspen_results_csv=None, base=20, retime=60, time_step=3, min_stable_steps=100, stable_threshold=1e-06)</code>","text":"<p>Runs an Aspen Plus simulation based on inputs from a Modelica simulation.</p> <p>Parameters:</p> Name Type Description Default <code>temp_input_csv</code> <code>str</code> <p>Path to the input CSV file with time-series data.</p> required <code>temp_output_csv</code> <code>str</code> <p>Path to save the final summarized output CSV.</p> required <code>bkp_path</code> <code>str</code> <p>Path to the Aspen backup file (.bkp). Defaults to example path.</p> <code>'example_aspenbkp/T2-Threetowers4.bkp'</code> <code>aspen_results_csv</code> <code>str</code> <p>Path to save detailed Aspen results. Defaults to None.</p> <code>None</code> <code>base</code> <code>float</code> <p>Minimum inventory (heel) to start simulation (mol). Defaults to 20.</p> <code>20</code> <code>retime</code> <code>int</code> <p>Lag time in minutes for output results. Defaults to 60.</p> <code>60</code> <code>time_step</code> <code>int</code> <p>Time step in minutes. Defaults to 3.</p> <code>3</code> <code>min_stable_steps</code> <code>int</code> <p>Consecutive stable steps to confirm stability. Defaults to 100.</p> <code>100</code> <code>stable_threshold</code> <code>float</code> <p>Relative difference threshold for stability. Defaults to 1e-6.</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary mapping output variable names to their final values,</p> <code>dict</code> <p>formatted as Modelica vector strings.</p> <code>dict</code> <p>e.g., {'to_SDS': '{v1,v2,v3}', 'to_WDS': '{v4,v5,v6}'}.</p> Note <p>Implements delayed feedback with retime lag. Skips simulation until inventory reaches base level. Stops early if system stabilizes (T_flow change &lt; threshold for min_stable_steps). Input CSV encoding is 'gbk'. Creates cumulative inventory tracking columns I_H, I_D, I_T. Output columns use 1-indexed array notation [1], [2], [3].</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_aspen_simulation(\n    temp_input_csv: str,\n    temp_output_csv: str,\n    bkp_path: str = r\"example_aspenbkp/T2-Threetowers4.bkp\",\n    aspen_results_csv: str = None,\n    base: float = 20,\n    retime: int = 60,\n    time_step: int = 3,\n    min_stable_steps: int = 100,\n    stable_threshold: float = 1e-6,\n) -&gt; dict:\n    \"\"\"Runs an Aspen Plus simulation based on inputs from a Modelica simulation.\n\n    Args:\n        temp_input_csv: Path to the input CSV file with time-series data.\n        temp_output_csv: Path to save the final summarized output CSV.\n        bkp_path: Path to the Aspen backup file (.bkp). Defaults to example path.\n        aspen_results_csv: Path to save detailed Aspen results. Defaults to None.\n        base: Minimum inventory (heel) to start simulation (mol). Defaults to 20.\n        retime: Lag time in minutes for output results. Defaults to 60.\n        time_step: Time step in minutes. Defaults to 3.\n        min_stable_steps: Consecutive stable steps to confirm stability. Defaults to 100.\n        stable_threshold: Relative difference threshold for stability. Defaults to 1e-6.\n\n    Returns:\n        A dictionary mapping output variable names to their final values,\n        formatted as Modelica vector strings.\n        e.g., {'to_SDS': '{v1,v2,v3}', 'to_WDS': '{v4,v5,v6}'}.\n\n    Note:\n        Implements delayed feedback with retime lag. Skips simulation until inventory\n        reaches base level. Stops early if system stabilizes (T_flow change &lt; threshold\n        for min_stable_steps). Input CSV encoding is 'gbk'. Creates cumulative inventory\n        tracking columns I_H, I_D, I_T. Output columns use 1-indexed array notation [1], [2], [3].\n    \"\"\"\n    aspen = None\n    all_results = []\n    output_placeholder = {}\n\n    try:\n        # 1. \u521d\u59cb\u5316Aspen\n        aspen = AspenEnhanced(bkp_path)\n\n        # 2. \u8bfb\u53d6OpenModelica\u6570\u636e\n        logger.info(f\"Reading input data from: {temp_input_csv}\")\n        df_input = pd.read_csv(temp_input_csv, encoding=\"gbk\")\n\n        time_step_h = time_step / 60\n        N = int(retime / time_step)\n\n        df_input = df_input[\n            (df_input[\"time\"] / time_step_h).apply(lambda x: round(x, 9).is_integer())\n        ].copy()\n        required_cols = [\n            \"time\",\n            \"tep_fcu.outflow[1]\",\n            \"tep_fcu.outflow[2]\",\n            \"tep_fcu.outflow[3]\",\n        ]\n        input_data = df_input[required_cols].values\n\n        prev_T_flow = None\n        stable_count = 0\n        I_stock = 0\n        count = 0\n\n        # 3. \u4e3b\u5faa\u73af\u5904\u7406\n        logger.info(\"Starting main simulation loop...\")\n        for time_val, T_flow, D_flow, H_flow in input_data:\n            time_aspen = time_val * time_step\n            M_T, M_D, M_H = 3.016, 2.014, 1.008\n            T_flow_mol, D_flow_mol, H_flow_mol = (\n                T_flow / M_T,\n                D_flow / M_D,\n                H_flow / M_H,\n            )\n            total_flow = T_flow_mol + D_flow_mol + H_flow_mol\n\n            if prev_T_flow is not None and abs(prev_T_flow) &gt; 1e-9:\n                relative_diff = abs(T_flow - prev_T_flow) / abs(prev_T_flow)\n                if relative_diff &lt; stable_threshold:\n                    stable_count += 1\n                else:\n                    stable_count = 0\n                if stable_count &gt;= min_stable_steps:\n                    logger.info(\n                        f\"System stabilized at Time={time_val:.1f}h. Stopping simulation.\"\n                    )\n                    break\n            prev_T_flow = T_flow\n\n            I_stock += total_flow * time_step_h\n            if I_stock &lt;= base:\n                # Record zeros and skip simulation until inventory builds up\n                record = {\n                    \"Time\": time_val,\n                    \"Time_Aspen\": time_aspen,\n                    \"Input_T\": T_flow,\n                    \"Input_D\": D_flow,\n                    \"Input_H\": H_flow,\n                }\n                # ... (add other zero-ed out columns for consistency)\n                all_results.append(record)\n                continue\n\n            if not count:\n                count += 1\n                I_input = (I_stock - base) / time_step_h\n                logger.info(\n                    f\"Inventory base reached. Effective input flow: {I_input:.2f} mol/h\"\n                )\n                ET, ED, EH = (\n                    T_flow_mol / total_flow,\n                    D_flow_mol / total_flow,\n                    H_flow_mol / total_flow,\n                )\n                ratios = [\n                    EH**2,\n                    2 * EH * ED,\n                    ED**2,\n                    2 * EH * ET,\n                    2 * ED * ET,\n                    ET**2,\n                    I_input,\n                ]\n            else:\n                ET, ED, EH = (\n                    T_flow_mol / total_flow,\n                    D_flow_mol / total_flow,\n                    H_flow_mol / total_flow,\n                )\n                ratios = [\n                    EH**2,\n                    2 * EH * ED,\n                    ED**2,\n                    2 * EH * ET,\n                    2 * ED * ET,\n                    ET**2,\n                    total_flow,\n                ]\n\n            aspen.set_composition(ratios)\n            aspen.run_step()\n            stream_results = aspen.get_stream_results()\n\n            record = {\n                \"Time\": time_val,\n                \"Time_Aspen\": time_aspen,\n                \"Input_T\": T_flow,\n                \"Input_D\": D_flow,\n                \"Input_H\": H_flow,\n                **{\n                    f\"Input_{comp}\": val\n                    for comp, val in zip(\n                        [\"EH2\", \"EHD\", \"ED2\", \"EHT\", \"EDT\", \"ET2\", \"TOTAL\"], ratios\n                    )\n                },\n                **{\n                    f\"{stream}_{iso}_raw\": values[i]\n                    for stream, values in stream_results.items()\n                    for i, iso in enumerate([\"H\", \"D\", \"T\"])\n                },\n            }\n            all_results.append(record)\n            logger.debug(\n                f\"Progress: {len(all_results)}/{len(input_data)} | Time={time_val:.1f}h\"\n            )\n\n        # 4. \u540e\u5904\u7406\n        logger.info(\"Simulation loop finished. Starting post-processing...\")\n        if not all_results:\n            logger.warning(\n                \"No results were generated. The simulation might have been skipped entirely.\"\n            )\n            return output_placeholder\n\n        df = pd.DataFrame(all_results).fillna(0)\n\n        raw_cols = [\n            f\"{stream}_{iso}_raw\"\n            for stream in [\"WDS\", \"SDST2\", \"SDSD2\"]\n            for iso in [\"H\", \"D\", \"T\"]\n        ]\n        for col in raw_cols:\n            stream, iso, _ = col.split(\"_\")\n            df[f\"{stream}_{iso}\"] = df[col].shift(N).fillna(0)\n\n        df[\"delta_I_H\"] = (\n            df[\"Input_H\"]\n            - df.get(\"WDS_H\", 0)\n            - df.get(\"SDST2_H\", 0)\n            - df.get(\"SDSD2_H\", 0)\n        ) * time_step_h\n        df[\"delta_I_D\"] = (\n            df[\"Input_D\"]\n            - df.get(\"WDS_D\", 0)\n            - df.get(\"SDST2_D\", 0)\n            - df.get(\"SDSD2_D\", 0)\n        ) * time_step_h\n        df[\"delta_I_T\"] = (\n            df[\"Input_T\"]\n            - df.get(\"WDS_T\", 0)\n            - df.get(\"SDST2_T\", 0)\n            - df.get(\"SDSD2_T\", 0)\n        ) * time_step_h\n        df[\"I_H\"] = df[\"delta_I_H\"].cumsum()\n        df[\"I_D\"] = df[\"delta_I_D\"].cumsum()\n        df[\"I_T\"] = df[\"delta_I_T\"].cumsum()\n\n        df[\"to_SDS[1]\"] = df.get(\"SDST2_T\", 0) + df.get(\"SDSD2_T\", 0)\n        df[\"to_SDS[2]\"] = df.get(\"SDST2_D\", 0) + df.get(\"SDSD2_D\", 0)\n        df[\"to_SDS[3]\"] = df.get(\"SDST2_H\", 0) + df.get(\"SDSD2_H\", 0)\n        df[\"to_WDS[1]\"] = df.get(\"WDS_T\", 0)\n        df[\"to_WDS[2]\"] = df.get(\"WDS_D\", 0)\n        df[\"to_WDS[3]\"] = df.get(\"WDS_H\", 0)\n\n        # 5. \u4fdd\u5b58\u8f93\u51fa\u6587\u4ef6\n        out_df = df[\n            [\n                \"Time\",\n                \"to_SDS[1]\",\n                \"to_SDS[2]\",\n                \"to_SDS[3]\",\n                \"to_WDS[1]\",\n                \"to_WDS[2]\",\n                \"to_WDS[3]\",\n            ]\n        ]\n        out_df.to_csv(temp_output_csv, index=False)\n        logger.info(f\"Summary output saved to {temp_output_csv}\")\n\n        if aspen_results_csv:\n            df.drop(columns=raw_cols, errors=\"ignore\").to_csv(\n                aspen_results_csv, index=False\n            )\n            logger.info(f\"Detailed results saved to {aspen_results_csv}\")\n\n        # 6. \u6784\u5efa\u8fd4\u56de\u5b57\u5178\n        output_placeholder = {\n            \"to_SDS\": \"{1,2,3,4,1,1}\",\n            \"to_WDS\": \"{1,5,6,7,1,1}\",\n        }\n        logger.info(f\"Returning final values: {output_placeholder}\")\n\n    except Exception as e:\n        logger.error(\n            f\"An error occurred during the Aspen simulation: {str(e)}\", exc_info=True\n        )\n    finally:\n        if aspen:\n            aspen.close()\n\n    return output_placeholder\n</code></pre>"},{"location":"api/tricys_handlers.html#tricys.handlers.i_iss_handler.run_dummy_simulation","title":"<code>run_dummy_simulation(temp_input_csv, temp_output_csv, **kwargs)</code>","text":"<p>Runs a simulation based on fake i_ISS data.</p> <p>Reads data from a source CSV, selects specific columns, and writes them to a temporary output CSV.</p> <p>Parameters:</p> Name Type Description Default <code>temp_input_csv</code> <code>str</code> <p>Path to the temporary input CSV file (unused).</p> required <code>temp_output_csv</code> <code>str</code> <p>Path to the temporary output CSV file.</p> required <code>**kwargs</code> <p>Additional keyword arguments (unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>A placeholder dictionary with output variable mappings.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the source CSV file cannot be found.</p> <code>ValueError</code> <p>If the source CSV is missing required columns.</p> Note <p>The temp_input_csv parameter is kept for interface consistency but not used. Reads from i_iss_handler.csv in the same directory as this module. Selects columns for to_SDS[1-5] and to_WDS[1-5]. Returns placeholder dict with format {\"to_SDS\": \"{1,2,3,4,5,6}\", \"to_WDS\": \"{1,7,8,9,10,11}\"}.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_dummy_simulation(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"Runs a simulation based on fake i_ISS data.\n\n    Reads data from a source CSV, selects specific columns, and writes them\n    to a temporary output CSV.\n\n    Args:\n        temp_input_csv: Path to the temporary input CSV file (unused).\n        temp_output_csv: Path to the temporary output CSV file.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        A placeholder dictionary with output variable mappings.\n\n    Raises:\n        FileNotFoundError: If the source CSV file cannot be found.\n        ValueError: If the source CSV is missing required columns.\n\n    Note:\n        The temp_input_csv parameter is kept for interface consistency but not used.\n        Reads from i_iss_handler.csv in the same directory as this module. Selects\n        columns for to_SDS[1-5] and to_WDS[1-5]. Returns placeholder dict with format\n        {\"to_SDS\": \"{1,2,3,4,5,6}\", \"to_WDS\": \"{1,7,8,9,10,11}\"}.\n    \"\"\"\n    import os\n\n    import pandas as pd\n\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"i_iss_handler.csv\")\n\n    try:\n        source_df = pd.read_csv(source_csv_path)\n    except FileNotFoundError:\n        pd.DataFrame({\"time\": []}).to_csv(temp_output_csv, index=False)\n        raise\n\n    columns_to_select = [\n        \"time\",\n        \"i_iss.to_SDS[1]\",\n        \"i_iss.to_SDS[2]\",\n        \"i_iss.to_SDS[3]\",\n        \"i_iss.to_SDS[4]\",\n        \"i_iss.to_SDS[5]\",\n        \"i_iss.to_WDS[1]\",\n        \"i_iss.to_WDS[2]\",\n        \"i_iss.to_WDS[3]\",\n        \"i_iss.to_WDS[4]\",\n        \"i_iss.to_WDS[5]\",\n    ]\n\n    if not all(col in source_df.columns for col in columns_to_select):\n        missing_cols = [\n            col for col in columns_to_select if col not in source_df.columns\n        ]\n        raise ValueError(\n            f\"The source file {source_csv_path} is missing required columns: \"\n            f\"{missing_cols}\"\n        )\n\n    output_df = source_df[columns_to_select].copy()\n\n    output_df.to_csv(temp_output_csv, index=False)\n\n    output_placeholder = {\n        \"to_SDS\": \"{1,2,3,4,5,6}\",\n        \"to_WDS\": \"{1,7,8,9,10,11}\",\n    }\n    return output_placeholder\n</code></pre>"},{"location":"api/tricys_postprocess.html","title":"API \u53c2\u8003 - \u540e\u5904\u7406\u6a21\u5757 (Post-processing)","text":"<p>\u540e\u5904\u7406\u6a21\u5757 (Post-processing)</p> <p>\u540e\u5904\u7406\u6a21\u5757 (Post-processing) \u63d0\u4f9b\u4e86\u5728\u4eff\u771f\u8fd0\u884c\u540e\u81ea\u52a8\u6267\u884c\u7684\u5206\u6790\u548c\u62a5\u544a\u529f\u80fd\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Baseline Analysis (\u57fa\u51c6\u5206\u6790)Rise Analysis (\u4e0a\u5347\u65f6\u95f4\u5206\u6790)Static Alarm (\u9759\u6001\u8b66\u62a5) <p>This module provides functions for plotting simulation results.</p>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.baseline_analysis","title":"<code>baseline_analysis(results_df, output_dir, **kwargs)</code>","text":"<p>Generates baseline analysis plots and reports.</p> <p>Creates three outputs: 1. A time-series plot with overall view and detailed zoom around turning point 2. A bar chart showing final values of all variables, sorted 3. An optional Markdown report with AI analysis (if 'ai' flag is True)</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>The combined DataFrame of simulation results.</p> required <code>output_dir</code> <code>str</code> <p>The directory to save the plots and report.</p> required <code>**kwargs</code> <p>Additional parameters from config, including 'ai' flag, 'detailed_var', 'glossary_path', and AI model settings.</p> <code>{}</code> Note <p>Removes duplicate rows before processing. Creates bilingual plots (English and Chinese). If AI analysis enabled, requires API_KEY, BASE_URL, and AI_MODELS/AI_MODEL environment variables. Generates both initial LLM analysis and academic summary.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def baseline_analysis(results_df: pd.DataFrame, output_dir: str, **kwargs) -&gt; None:\n    \"\"\"Generates baseline analysis plots and reports.\n\n    Creates three outputs:\n    1. A time-series plot with overall view and detailed zoom around turning point\n    2. A bar chart showing final values of all variables, sorted\n    3. An optional Markdown report with AI analysis (if 'ai' flag is True)\n\n    Args:\n        results_df: The combined DataFrame of simulation results.\n        output_dir: The directory to save the plots and report.\n        **kwargs: Additional parameters from config, including 'ai' flag, 'detailed_var',\n            'glossary_path', and AI model settings.\n\n    Note:\n        Removes duplicate rows before processing. Creates bilingual plots (English and\n        Chinese). If AI analysis enabled, requires API_KEY, BASE_URL, and AI_MODELS/AI_MODEL\n        environment variables. Generates both initial LLM analysis and academic summary.\n    \"\"\"\n    if \"time\" not in results_df.columns:\n        logger.error(\"Plotting failed: 'time' column not found in results DataFrame.\")\n        return\n\n    if \"glossary_path\" in kwargs:\n        load_glossary(kwargs[\"glossary_path\"])\n\n    os.removedirs(output_dir) if os.path.exists(output_dir) else None\n    p = Path(output_dir)\n    output_dir = p.parent / \"report\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    df = results_df.copy()\n    # Remove duplicate rows before processing\n    df.drop_duplicates(inplace=True)\n    df.reset_index(drop=True, inplace=True)\n\n    # Create a unified color map for all variables\n    all_plot_columns = sorted([col for col in df.columns if col != \"time\"])\n    colors = sns.color_palette(\"turbo\", len(all_plot_columns))\n    color_map = dict(zip(all_plot_columns, colors))\n\n    # Add the color map to kwargs to pass it to the helper functions\n    plot_kwargs = kwargs.copy()\n    plot_kwargs[\"color_map\"] = color_map\n\n    # Generate the time-series plot with zoom\n    _plot_time_series_with_zoom(df, output_dir, **plot_kwargs)\n\n    # Generate the bar chart of final values\n    _plot_final_values_bar_chart(df, output_dir, **plot_kwargs)\n\n    # --- Report Generation and AI Analysis ---\n    base_report_path, base_report_content = _generate_postprocess_report(\n        df, output_dir, **kwargs\n    )\n\n    if base_report_path and kwargs.get(\"ai\", False):\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        # Prioritize AI_MODELS, fallback to AI_MODEL\n        ai_models_str = os.environ.get(\"AI_MODELS\")\n        if not ai_models_str:\n            ai_models_str = os.environ.get(\"AI_MODEL\")\n\n        if not api_key or not base_url or not ai_models_str:\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODELS/AI_MODEL not found in environment variables. Skipping LLM analysis.\"\n            )\n            return\n\n        ai_models = [model.strip() for model in ai_models_str.split(\",\")]\n\n        for ai_model in ai_models:\n            logger.info(f\"Generating AI analysis for model: {ai_model}\")\n\n            sanitized_model_name = \"\".join(\n                c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n            ).rstrip()\n\n            model_report_filename = (\n                f\"analysis_report_baseline_condition_{sanitized_model_name}.md\"\n            )\n            model_report_path = os.path.join(output_dir, model_report_filename)\n\n            with open(model_report_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(base_report_content)\n\n            llm_analysis = _call_openai_for_postprocess_analysis(\n                api_key=api_key,\n                base_url=base_url,\n                ai_model=ai_model,\n                report_content=base_report_content,\n                **kwargs,\n            )\n\n            if llm_analysis:\n                with open(model_report_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(f\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd ({ai_model})\\n\\n\")\n                    f.write(\"```markdown\\n\")\n                    f.write(llm_analysis)\n                    f.write(\"\\n```\\n\")\n                logger.info(\n                    f\"Appended LLM analysis for model {ai_model} to {model_report_path}\"\n                )\n\n                # --- ADDED: Second AI call for academic summary ---\n                academic_kwargs = kwargs.copy()\n                academic_kwargs[\"report_filename\"] = model_report_filename\n                generate_academic_report(\n                    output_dir, ai_model=ai_model, **academic_kwargs\n                )\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.generate_academic_report","title":"<code>generate_academic_report(output_dir, ai_model, **kwargs)</code>","text":"<p>Generates a professional academic analysis summary by sending the existing report and a glossary of terms to an LLM.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def generate_academic_report(output_dir: str, ai_model: str, **kwargs) -&gt; None:\n    \"\"\"\n    Generates a professional academic analysis summary by sending the existing report\n    and a glossary of terms to an LLM.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Starting generation of the academic analysis summary for model {ai_model}.\"\n        )\n\n        # 1. Read the existing report\n        report_filename = kwargs.get(\n            \"report_filename\", \"baseline_condition_analysis_report.md\"\n        )\n        report_path = os.path.join(output_dir, report_filename)\n        if not os.path.exists(report_path):\n            logger.error(\n                f\"Cannot generate academic summary: Original report '{report_path}' not found.\"\n            )\n            return\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            original_report_content = f.read()\n\n        # 2. Read the glossary\n        glossary_path = kwargs.get(\"glossary_path\", \"sheets.csv\")\n        if not os.path.exists(glossary_path):\n            logger.error(\n                f\"Cannot generate academic summary: Glossary file '{glossary_path}' not found.\"\n            )\n            return\n        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n            glossary_content = f.read()\n\n        # 3. Check for API credentials\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        if not all([api_key, base_url, ai_model]):\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not found. Skipping academic summary generation.\"\n            )\n            return\n\n        # 4. Construct the prompt\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u7531\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7684\u521d\u6b65\u5206\u6790\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\"\"\"\n\n        # Find all plots to instruct the LLM to include them\n        all_plots = [f for f in os.listdir(output_dir) if f.endswith((\".svg\", \".png\"))]\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n        instructions_prompt = f\"\"\"**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `detailed_var`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\u4f8b\u5982\uff0c\u5e94\u5c06\u201c`sds`\u7684\u5e93\u5b58\u201d\u8868\u8ff0\u4e3a\u201c\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS) \u7684\u6c1a\u5e93\u5b58\u91cf (Tritium Inventory)\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\u907f\u514d\u4f7f\u7528\u201c\u770b\u8d77\u6765\u201d\u3001\u201c\u597d\u50cf\u201d\u7b49\u6a21\u7cca\u8bcd\u6c47\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u5173\u952e\u9636\u6bb5\u7684\u62bd\u6837\u6570\u636e\u6216\u6700\u7ec8\u503c\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u4e2a**\u57fa\u51c6\u5de5\u51b5\uff08Baseline Operating Condition\uff09**\u7684\u6a21\u62df\u5206\u6790\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21**\u57fa\u51c6\u5de5\u51b5**\u6a21\u62df\u7684\u76ee\u7684\u3001\u5173\u952e\u53d1\u73b0\u548c\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0**\u57fa\u51c6\u5de5\u51b5**\u6a21\u62df\u7684\u80cc\u666f\u548c\u76ee\u6807\uff0c\u63d0\u53ca\u5173\u952e\u7684\u8f93\u5165\u53c2\u6570\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n        *   \u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u6c1a\u81ea\u6301\u65f6\u95f4\u3001\u500d\u589e\u65f6\u95f4\u7b49\uff0c\u5982\u679c\u6570\u636e\u53ef\u7528\uff09\u7684\u603b\u4f53\u8d8b\u52bf\u3002\n        *   \u5bf9\u5173\u952e\u8f6c\u6298\u70b9\uff08\u4f8b\u5982\u6c1a\u5e93\u5b58\u7684\u6700\u4f4e\u70b9\uff09\u7684\u7269\u7406\u610f\u4e49\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002\n        *   \u8bc4\u4f30\u7cfb\u7edf\u5728\u6a21\u62df\u7ed3\u675f\u65f6\u7684\u6700\u7ec8\u72b6\u6001\uff0c\u5e76\u8ba8\u8bba\u6c1a\u5728\u5404\u5b50\u7cfb\u7edf\u4e2d\u7684\u5206\u5e03\u60c5\u51b5\u3002\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u6a21\u62df\u7814\u7a76\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\uff08\u5305\u62ec\u56fe\u8868\u548c\u8868\u683c\uff09\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n---\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a (`baseline_condition_analysis_report.md`)\n---\n{original_report_content}\n\n---\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868 (`sheets.csv`)\n---\n{glossary_content}\n\"\"\"\n\n        # 5. Call the API\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for academic summary for model {ai_model} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, instructions_prompt, analysis_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                academic_summary = response.choices[0].message.content\n\n                # 6. Save the result\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                summary_filename = (\n                    f\"academic_analysis_summary_{sanitized_model_name}.md\"\n                )\n                summary_path = os.path.join(output_dir, summary_filename)\n                with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(academic_summary)\n\n                logger.info(\n                    f\"Successfully generated academic analysis summary: {summary_path}\"\n                )\n                return  # Exit after success\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling OpenAI API for academic summary on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to generate academic summary for {ai_model} after {max_retries} attempts.\"\n                    )\n                    return  # Exit after all retries failed\n\n    except Exception as e:\n        logger.error(\n            f\"Error in generate_academic_report for model {ai_model}: {e}\",\n            exc_info=True,\n        )\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.load_glossary","title":"<code>load_glossary(glossary_path)</code>","text":"<p>Loads glossary data from the specified CSV path into global dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>glossary_path</code> <code>str</code> <p>Path to the glossary CSV file.</p> required Note <p>Expected columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\", \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Clears existing glossaries on error. Updates global _english_glossary_map and _chinese_glossary_map.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def load_glossary(glossary_path: str) -&gt; None:\n    \"\"\"Loads glossary data from the specified CSV path into global dictionaries.\n\n    Args:\n        glossary_path: Path to the glossary CSV file.\n\n    Note:\n        Expected columns: \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\", \"\u82f1\u6587\u672f\u8bed (English Term)\",\n        \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\". Clears existing glossaries on error.\n        Updates global _english_glossary_map and _chinese_glossary_map.\n    \"\"\"\n    global _english_glossary_map, _chinese_glossary_map\n\n    if not glossary_path or not os.path.exists(glossary_path):\n        logger.warning(\n            f\"Glossary file not found at {glossary_path}. No labels will be loaded.\"\n        )\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n        return\n\n    try:\n        df = pd.read_csv(glossary_path)\n        if (\n            \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\" in df.columns\n            and \"\u82f1\u6587\u672f\u8bed (English Term)\" in df.columns\n            and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\" in df.columns\n        ):\n            df.dropna(subset=[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"], inplace=True)\n            _english_glossary_map = pd.Series(\n                df[\"\u82f1\u6587\u672f\u8bed (English Term)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            _chinese_glossary_map = pd.Series(\n                df[\"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            logger.info(f\"Successfully loaded glossary from {glossary_path}.\")\n        else:\n            logger.warning(\"Glossary CSV does not contain expected columns.\")\n            _english_glossary_map = {}\n            _chinese_glossary_map = {}\n    except Exception as e:\n        logger.warning(f\"Failed to load or parse glossary file. Error: {e}\")\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.baseline_analysis.set_plot_language","title":"<code>set_plot_language(lang='en')</code>","text":"<p>Sets the preferred language for plot labels.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>'en' for English (default), 'cn' for Chinese.</p> <code>'en'</code> Note <p>For Chinese, sets font to SimHei and adjusts unicode_minus. For English, restores matplotlib defaults. Changes apply globally to all subsequent plots.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def set_plot_language(lang: str = \"en\") -&gt; None:\n    \"\"\"Sets the preferred language for plot labels.\n\n    Args:\n        lang: 'en' for English (default), 'cn' for Chinese.\n\n    Note:\n        For Chinese, sets font to SimHei and adjusts unicode_minus. For English,\n        restores matplotlib defaults. Changes apply globally to all subsequent plots.\n    \"\"\"\n    global _use_chinese_labels\n    _use_chinese_labels = lang.lower() == \"cn\"\n\n    if _use_chinese_labels:\n        # To display Chinese characters correctly, specify a list of fallback fonts.\n        plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # \u66ff\u6362\u6210\u4f60\u7535\u8111\u4e0a\u6709\u7684\u5b57\u4f53\n        plt.rcParams[\"axes.unicode_minus\"] = False  # To display minus sign correctly.\n        plt.rcParams[\"font.family\"] = \"sans-serif\"  # \u786e\u4fdd\u5b57\u4f53\u5bb6\u65cf\u8bbe\u7f6e\u751f\u6548\n    else:\n        # Restore default settings\n        plt.rcParams[\"font.sans-serif\"] = plt.rcParamsDefault[\"font.sans-serif\"]\n        plt.rcParams[\"axes.unicode_minus\"] = plt.rcParamsDefault[\"axes.unicode_minus\"]\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.rise_analysis.analyze_rise_dip","title":"<code>analyze_rise_dip(results_df, output_dir, **kwargs)</code>","text":"<p>Analyzes parameter sweep results to identify curves that fail to exhibit 'dip and rise' feature.</p> <p>A curve exhibits the 'dip and rise' feature if: 1. It has a clear minimum point (not at boundaries) 2. Values at both start and end are higher than the minimum (with tolerance)</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>The combined DataFrame of simulation results, including time and multiple parameter combinations.</p> required <code>output_dir</code> <code>str</code> <p>The directory to save the analysis report.</p> required <code>**kwargs</code> <p>Additional parameters from config, e.g., 'output_filename'.</p> <code>{}</code> Note <p>Uses 0.1% smoothing window to handle noisy data. Column names expected in format 'variable&amp;param1=v1&amp;param2=v2'. Logs ERROR for each curve without the feature. Always generates rise_report.json with analysis results for all curves, including 'rises' boolean flag.</p> Source code in <code>tricys/postprocess/rise_analysis.py</code> <pre><code>def analyze_rise_dip(results_df: pd.DataFrame, output_dir: str, **kwargs) -&gt; None:\n    \"\"\"Analyzes parameter sweep results to identify curves that fail to exhibit 'dip and rise' feature.\n\n    A curve exhibits the 'dip and rise' feature if:\n    1. It has a clear minimum point (not at boundaries)\n    2. Values at both start and end are higher than the minimum (with tolerance)\n\n    Args:\n        results_df: The combined DataFrame of simulation results, including time and\n            multiple parameter combinations.\n        output_dir: The directory to save the analysis report.\n        **kwargs: Additional parameters from config, e.g., 'output_filename'.\n\n    Note:\n        Uses 0.1% smoothing window to handle noisy data. Column names expected in\n        format 'variable&amp;param1=v1&amp;param2=v2'. Logs ERROR for each curve without\n        the feature. Always generates rise_report.json with analysis results for\n        all curves, including 'rises' boolean flag.\n    \"\"\"\n    logger.info(\"Starting post-processing: Analyzing curve rise/dip features...\")\n    all_curves_info = []\n    error_count = 0\n\n    # Iterate over each column of the DataFrame (except for the 'time' column)\n    for col_name in results_df.columns:\n        if col_name == \"time\":\n            continue\n\n        # Parse parameters from the column name 'variable&amp;param1=v1&amp;param2=v2'\n        try:\n            parts = col_name.split(\"&amp;\")\n            if len(parts) &lt; 2:  # Must have at least one variable name and one parameter\n                logger.warning(\n                    f\"Column name '{col_name}' has an incorrect format, skipping.\"\n                )\n                continue\n\n            # parts[0] is the variable name, parse parameters from parts[1:]\n            param_parts = parts[1:]\n            job_params = dict(item.split(\"=\") for item in param_parts)\n            job_params[\"variable\"] = parts[\n                0\n            ]  # Also add the original variable name to the info\n\n        except (ValueError, IndexError):\n            logger.warning(\n                f\"Could not parse parameters from column name '{col_name}', skipping.\"\n            )\n            continue\n\n        series = results_df[col_name]\n        rises = False\n        if len(series) &gt; 2:\n            # This logic is inspired by `time_of_turning_point` from `tricys/analysis/metric.py`.\n            # It uses a smoothed series to determine if there is a 'dip and rise' trend.\n            window_size = max(1, int(len(series) * 0.001))  # 0.1% smoothing window\n            smoothed = series.rolling(\n                window=window_size, center=True, min_periods=1\n            ).mean()\n\n            min_pos_index = smoothed.idxmin()\n            min_val = smoothed.loc[min_pos_index]\n\n            logger.info(\n                f\"Analyzing curve '{col_name}': min at index {min_pos_index} with value {min_val}\"\n            )\n\n            # Check if the minimum is at the beginning or end of the series\n            is_min_at_boundary = (min_pos_index == smoothed.index[0]) or (\n                min_pos_index == smoothed.index[-1]\n            )\n\n            if not is_min_at_boundary:\n                # Check if it dips from the start and rises to the end.\n                # A small tolerance is used to avoid issues with noise.\n                series_range = smoothed.max() - smoothed.min()\n                # Avoid division by zero or NaN tolerance if series is flat\n                if series_range &gt; 1e-9:\n                    tolerance = series_range * 0.001  # 0.1% of range as tolerance\n                else:\n                    tolerance = 0\n\n                start_val = smoothed.iloc[0]\n                end_val = smoothed.iloc[-1]\n\n                if start_val &gt; min_val + tolerance and end_val &gt; min_val + tolerance:\n                    rises = True\n\n        # Record the analysis result for every curve\n        info = job_params.copy()\n        info[\"rises\"] = bool(rises)\n        all_curves_info.append(info)\n\n        # If the feature is not detected, log it at the ERROR level\n        if not rises:\n            error_count += 1\n            logger.error(\n                f\"Feature not detected: 'Dip and rise' feature was not found for the curve with parameters {job_params}.\"\n            )\n\n    # Generate a report file with all information unconditionally\n    output_filename = kwargs.get(\"output_filename\", \"rise_report.json\")\n    report_path = os.path.join(output_dir, output_filename)\n\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(all_curves_info, f, indent=4, ensure_ascii=False)\n\n    if error_count &gt; 0:\n        logger.info(\n            f\"{error_count} curves did not exhibit the expected feature. See report for details: {report_path}\"\n        )\n    else:\n        logger.info(\n            f\"All curves exhibit the expected 'dip and rise' feature. Report generated at: {report_path}\"\n        )\n</code></pre>"},{"location":"api/tricys_postprocess.html#tricys.postprocess.static_alarm.check_thresholds","title":"<code>check_thresholds(results_df, output_dir, rules, **kwargs)</code>","text":"<p>Analyzes simulation results to check if specified columns fall within threshold ranges.</p> <p>Supports both single tasks (column name as 'var') and parameter sweep tasks (column name as 'var&amp;param=value').</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>Merged simulation results DataFrame.</p> required <code>output_dir</code> <code>str</code> <p>Directory for saving alert reports.</p> required <code>rules</code> <code>List[Dict[str, Any]]</code> <p>List of rules, where each rule defines columns and their min/max thresholds. Format: [{\"columns\": [\"var1\", \"var2\"], \"min\": value, \"max\": value}, ...]</p> required <code>**kwargs</code> <p>Additional parameters from configuration, such as 'output_filename'.</p> <code>{}</code> Note <p>Logs ERROR for each threshold violation with peak/dip values. Generates alarm_report.json with parsed parameter information and 'has_alarm' flags. For columns matching 'base_col_name&amp;param=value', extracts parameters into separate fields in the report. Reports total alarm count in logs.</p> Source code in <code>tricys/postprocess/static_alarm.py</code> <pre><code>def check_thresholds(\n    results_df: pd.DataFrame, output_dir: str, rules: List[Dict[str, Any]], **kwargs\n) -&gt; None:\n    \"\"\"Analyzes simulation results to check if specified columns fall within threshold ranges.\n\n    Supports both single tasks (column name as 'var') and parameter sweep tasks\n    (column name as 'var&amp;param=value').\n\n    Args:\n        results_df: Merged simulation results DataFrame.\n        output_dir: Directory for saving alert reports.\n        rules: List of rules, where each rule defines columns and their min/max thresholds.\n            Format: [{\"columns\": [\"var1\", \"var2\"], \"min\": value, \"max\": value}, ...]\n        **kwargs: Additional parameters from configuration, such as 'output_filename'.\n\n    Note:\n        Logs ERROR for each threshold violation with peak/dip values. Generates\n        alarm_report.json with parsed parameter information and 'has_alarm' flags.\n        For columns matching 'base_col_name&amp;param=value', extracts parameters into\n        separate fields in the report. Reports total alarm count in logs.\n    \"\"\"\n    logger.info(\"Starting post-processing: Checking thresholds...\")\n\n    # Use a dictionary to track the alarm status of each checked column\n    checked_columns_status = {}\n\n    for i, rule in enumerate(rules):\n        min_val = rule.get(\"min\")\n        max_val = rule.get(\"max\")\n        columns_to_check = rule.get(\"columns\", [])\n\n        if not columns_to_check:\n            logger.warning(f\"Rule {i+1} does not specify 'columns', skipping.\")\n            continue\n\n        # Iterate over each base column name specified in the rule\n        for base_col_name in columns_to_check:\n            # Iterate over all actual column names in the DataFrame to find matches\n            for df_col_name in results_df.columns:\n                if df_col_name == base_col_name or df_col_name.startswith(\n                    base_col_name + \"&amp;\"\n                ):\n\n                    # Initialize status for this column if it's the first time being checked\n                    if df_col_name not in checked_columns_status:\n                        checked_columns_status[df_col_name] = (\n                            False  # Default to no alarm\n                        )\n\n                    # Check for values exceeding the maximum threshold\n                    if max_val is not None:\n                        exceeded_max = results_df[results_df[df_col_name] &gt; max_val]\n                        if not exceeded_max.empty:\n                            peak_value = exceeded_max[df_col_name].max()\n                            logger.error(\n                                f\"ALARM: Column '{df_col_name}' exceeds maximum threshold (Threshold: {max_val}, Value: {peak_value})\"\n                            )\n                            checked_columns_status[df_col_name] = True\n\n                    # Check for values falling below the minimum threshold\n                    if min_val is not None:\n                        exceeded_min = results_df[results_df[df_col_name] &lt; min_val]\n                        if not exceeded_min.empty:\n                            dip_value = exceeded_min[df_col_name].min()\n                            logger.error(\n                                f\"ALARM: Column '{df_col_name}' is below minimum threshold (Threshold: {min_val}, Value: {dip_value})\"\n                            )\n                            checked_columns_status[df_col_name] = True\n\n    # Convert to the final report format, parsing column names to include parameters\n    final_report = []\n    for col, status in checked_columns_status.items():\n        try:\n            report_item = {}\n            parts = col.split(\"&amp;\")\n\n            # For single runs, the column name may not contain '&amp;'\n            if len(parts) == 1:\n                report_item[\"variable\"] = parts[0]\n            else:\n                variable_name = parts[0]\n                param_parts = parts[1:]\n                report_item = dict(item.split(\"=\") for item in param_parts)\n                report_item[\"variable\"] = variable_name\n\n            report_item[\"has_alarm\"] = status\n            final_report.append(report_item)\n\n        except (ValueError, IndexError):\n            logger.warning(\n                f\"Could not parse column name '{col}' for the report, using the original name as a fallback.\"\n            )\n            # Fallback to the old format if parsing fails\n            final_report.append({\"column\": col, \"has_alarm\": status})\n\n    output_filename = kwargs.get(\"output_filename\", \"alarm_report.json\")\n    report_path = os.path.join(output_dir, output_filename)\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(final_report, f, indent=4, ensure_ascii=False)\n\n    total_alarms = sum(1 for entry in final_report if entry[\"has_alarm\"])\n    if total_alarms &gt; 0:\n        logger.info(\n            f\"{total_alarms} columns with alarms were found. See logs for details. Report generated at: {report_path}\"\n        )\n    else:\n        logger.info(\n            f\"Threshold check complete. All checked columns are within their thresholds. Report generated at: {report_path}\"\n        )\n</code></pre>"},{"location":"api/tricys_simulation.html","title":"API \u53c2\u8003 - \u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation)","text":"<p>\u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation)</p> <p>\u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation) \u5305\u542b\u4e86 TRICYS \u7684\u4e3b\u8981\u6267\u884c\u811a\u672c\uff0c\u8d1f\u8d23\u542f\u52a8\u6807\u51c6\u4eff\u771f\u548c\u5206\u6790\u5de5\u4f5c\u6d41\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Standard Simulation (\u6807\u51c6\u4eff\u771f)Simulation Analysis (\u4eff\u771f\u5206\u6790)"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation.main","title":"<code>main(config_path)</code>","text":"<p>Main entry point for a standard simulation run.</p> <p>This function prepares the configuration, sets up logging, and calls the main <code>run_simulation</code> orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>The path to the JSON configuration file.</p> required Source code in <code>tricys/simulation/simulation.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point for a standard simulation run.\n\n    This function prepares the configuration, sets up logging, and calls\n    the main `run_simulation` orchestrator.\n\n    Args:\n        config_path (str): The path to the JSON configuration file.\n    \"\"\"\n    config, original_config = basic_prepare_config(config_path)\n    setup_logging(config, original_config)\n    logger.info(\n        \"Loading configuration\",\n        extra={\n            \"config_path\": os.path.abspath(config_path),\n        },\n    )\n    try:\n        run_simulation(config)\n        logger.info(\"Main execution completed successfully\")\n    except Exception as e:\n        logger.error(\n            \"Main execution failed\", exc_info=True, extra={\"exception\": str(e)}\n        )\n        sys.exit(1)\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation.run_simulation","title":"<code>run_simulation(config)</code>","text":"<p>Orchestrates the main simulation workflow.</p> <p>This function serves as the primary orchestrator for running simulations. It generates jobs from parameters, executes them (concurrently or sequentially, as standard or co-simulations), merges the results into a single DataFrame, and triggers any configured post-processing steps.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary for the run.</p> required Note <p>Supports concurrent (ThreadPoolExecutor) and sequential execution modes. Co-simulations use ProcessPoolExecutor for better isolation. Merges all job results into single CSV with parameter-labeled columns. Triggers post-processing tasks if configured. Results saved to paths.results_dir.</p> Source code in <code>tricys/simulation/simulation.py</code> <pre><code>def run_simulation(config: Dict[str, Any]) -&gt; None:\n    \"\"\"Orchestrates the main simulation workflow.\n\n    This function serves as the primary orchestrator for running simulations.\n    It generates jobs from parameters, executes them (concurrently or sequentially,\n    as standard or co-simulations), merges the results into a single DataFrame,\n    and triggers any configured post-processing steps.\n\n    Args:\n        config: The main configuration dictionary for the run.\n\n    Note:\n        Supports concurrent (ThreadPoolExecutor) and sequential execution modes.\n        Co-simulations use ProcessPoolExecutor for better isolation. Merges all job\n        results into single CSV with parameter-labeled columns. Triggers post-processing\n        tasks if configured. Results saved to paths.results_dir.\n    \"\"\"\n    jobs = generate_simulation_jobs(config.get(\"simulation_parameters\", {}))\n\n    try:\n        results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n    except KeyError as e:\n        logger.error(f\"Missing required path key in configuration file: {e}\")\n        sys.exit(1)\n\n    simulation_results = {}\n    use_concurrent = config[\"simulation\"].get(\"concurrent\", False)\n\n    try:\n        max_workers = config[\"simulation\"].get(\"max_workers\", os.cpu_count())\n        if config.get(\"co_simulation\") is None:\n            if use_concurrent:\n                logger.info(\n                    \"Starting simulation\",\n                    extra={\n                        \"mode\": \"CONCURRENT\",\n                        \"max_workers\": max_workers,\n                    },\n                )\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_single_job, config, job_params, i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            result_path = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n            else:\n                logger.info(\"Starting simulation\", extra={\"mode\": \"SEQUENTIAL\"})\n                result_paths = _run_sequential_sweep(config, jobs)\n                for i, result_path in enumerate(result_paths):\n                    if result_path:\n                        simulation_results[tuple(sorted(jobs[i].items()))] = result_path\n        else:\n            if use_concurrent:\n                logger.info(\n                    \"Starting co-simulation\",\n                    extra={\n                        \"mode\": \"CONCURRENT\",\n                        \"max_workers\": max_workers,\n                    },\n                )\n\n                with concurrent.futures.ProcessPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_co_simulation, config, job_params, job_id=i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            result_path = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                                logger.info(\n                                    \"Successfully finished co-simulation job\",\n                                    extra={\n                                        \"job_params\": job_params,\n                                    },\n                                )\n                            else:\n                                logger.warning(\n                                    \"Co-simulation job did not return a result path\",\n                                    extra={\n                                        \"job_params\": job_params,\n                                    },\n                                )\n                        except Exception as exc:\n                            logger.error(\n                                \"Co-simulation job generated an exception\",\n                                exc_info=True,\n                                extra={\n                                    \"job_params\": job_params,\n                                    \"exception\": str(exc),\n                                },\n                            )\n            else:\n                logger.info(\"Starting co-simulation\", extra={\"mode\": \"SEQUENTIAL\"})\n                for i, job_params in enumerate(jobs):\n                    job_id = i + 1\n                    logger.info(\n                        \"Starting Sequential Co-simulation Job\",\n                        extra={\n                            \"job_index\": f\"{job_id}/{len(jobs)}\",\n                        },\n                    )\n                    try:\n                        result_path = _run_co_simulation(\n                            config, job_params, job_id=job_id\n                        )\n                        if result_path:\n                            simulation_results[tuple(sorted(job_params.items()))] = (\n                                result_path\n                            )\n                            logger.info(\n                                \"Successfully finished co-simulation job\",\n                                extra={\n                                    \"job_params\": job_params,\n                                },\n                            )\n                        else:\n                            logger.warning(\n                                \"Co-simulation job did not return a result path\",\n                                extra={\n                                    \"job_params\": job_params,\n                                },\n                            )\n                    except Exception as exc:\n                        logger.error(\n                            \"Co-simulation job generated an exception\",\n                            exc_info=True,\n                            extra={\n                                \"job_params\": job_params,\n                                \"exception\": str(exc),\n                            },\n                        )\n                    logger.info(\n                        \"Finished Sequential Co-simulation Job\",\n                        extra={\n                            \"job_index\": f\"{job_id}/{len(jobs)}\",\n                        },\n                    )\n    except Exception as e:\n        raise RuntimeError(\"Failed to run simulation\", e)\n\n    # --- Result Handling ---\n    # The simulation_results dictionary now contains paths to results inside temporary job workspaces.\n    # The results_dir from the config is now the self-contained workspace's results folder.\n    run_results_dir = results_dir\n    os.makedirs(run_results_dir, exist_ok=True)\n\n    # Unified result processing for both single and multiple jobs\n    logger.info(\n        \"Processing jobs and combining results\",\n        extra={\n            \"num_jobs\": len(jobs),\n        },\n    )\n    combined_df = None\n\n    all_dfs = []\n    time_df_added = False\n\n    for job_params in jobs:\n        job_key = tuple(sorted(job_params.items()))\n        result_path = simulation_results.get(job_key)\n\n        if not result_path or not os.path.exists(result_path):\n            logger.warning(\n                \"Job produced no result file\",\n                extra={\n                    \"job_params\": job_params,\n                },\n            )\n            continue\n\n        # Read the current job's result file\n        df = pd.read_csv(result_path)\n\n        # From the very first valid DataFrame, grab the 'time' column\n        if not time_df_added and \"time\" in df.columns:\n            all_dfs.append(df[[\"time\"]])\n            time_df_added = True\n\n        # Prepare the parameter string for column renaming\n        param_string = \"&amp;\".join([f\"{k}={v}\" for k, v in job_params.items()])\n\n        # Isolate the data columns (everything except 'time')\n        data_columns = df.drop(columns=[\"time\"], errors=\"ignore\")\n\n        # Create a dictionary to map old column names to new ones\n        # e.g., {'voltage': 'voltage&amp;param1=A&amp;param2=B'}\n        rename_mapping = {\n            col: f\"{col}&amp;{param_string}\" if param_string else col\n            for col in data_columns.columns\n        }\n\n        # Rename the columns and add the resulting DataFrame to our list\n        all_dfs.append(data_columns.rename(columns=rename_mapping))\n\n    # Concatenate all the DataFrames in the list along the columns axis (axis=1)\n    if all_dfs:\n        combined_df = pd.concat(all_dfs, axis=1)\n    else:\n        combined_df = pd.DataFrame()  # Or None, as you had before\n\n    if combined_df is not None and not combined_df.empty:\n        if len(jobs) == 1:\n            # For single job, save as simulation_result.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"simulation_result.csv\"\n            )\n        else:\n            # For multiple jobs, save as sweep_results.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"sweep_results.csv\"\n            )\n\n        combined_df.to_csv(combined_csv_path, index=False)\n        logger.info(\n            \"Combined results saved\",\n            extra={\n                \"file_path\": combined_csv_path,\n            },\n        )\n    else:\n        logger.warning(\"No valid results found to combine\")\n\n    # --- Post-Processing ---\n    if combined_df is not None:\n        # Calculate the top-level post-processing directory\n        top_level_run_workspace = os.path.abspath(config[\"run_timestamp\"])\n        top_level_post_processing_dir = os.path.join(\n            top_level_run_workspace, \"post_processing\"\n        )\n        _run_post_processing(config, combined_df, top_level_post_processing_dir)\n    else:\n        logger.warning(\"No simulation results generated, skipping post-processing\")\n\n    # --- Final Cleanup ---\n    # The primary cleanup of job workspaces is handled by the `finally` block in `_run_co_simulation`.\n    # This is an additional safeguard.\n    if not config[\"simulation\"].get(\"keep_temp_files\", True):\n        temp_dir_path = os.path.abspath(config[\"paths\"].get(\"temp_dir\", \"temp\"))\n        logger.info(\n            \"Cleaning up temporary directory\",\n            extra={\n                \"directory\": temp_dir_path,\n            },\n        )\n        if os.path.exists(temp_dir_path):\n            try:\n                shutil.rmtree(temp_dir_path)\n                os.makedirs(temp_dir_path)  # Recreate for next run\n            except OSError as e:\n                logger.error(\n                    \"Error cleaning up temporary directory\",\n                    extra={\n                        \"directory\": temp_dir_path,\n                        \"error\": str(e),\n                    },\n                )\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation_analysis.main","title":"<code>main(config_path)</code>","text":"<p>Main entry point for a simulation analysis run.</p> <p>This function prepares the configuration for an analysis run, sets up logging, and calls the main <code>run_simulation</code> orchestrator for analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>The path to the JSON configuration file.</p> required Source code in <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point for a simulation analysis run.\n\n    This function prepares the configuration for an analysis run, sets up\n    logging, and calls the main `run_simulation` orchestrator for analysis.\n\n    Args:\n        config_path (str): The path to the JSON configuration file.\n    \"\"\"\n    config, original_config = analysis_prepare_config(config_path)\n    setup_logging(config, original_config)\n    logger.info(\n        \"Loading configuration\",\n        extra={\n            \"config_path\": os.path.abspath(config_path),\n        },\n    )\n    try:\n        run_simulation(config)\n        logger.info(\"Main execution completed successfully\")\n    except Exception as e:\n        logger.error(\n            \"Main execution failed\", exc_info=True, extra={\"exception\": str(e)}\n        )\n        sys.exit(1)\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation_analysis.retry_analysis","title":"<code>retry_analysis(timestamp)</code>","text":"<p>Retries a failed AI analysis for a given run timestamp.</p> <p>This function restores the configuration from the log file of a previous run and re-triggers the AI-dependent parts of the analysis, including report generation and consolidation.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>str</code> <p>The timestamp of the run to retry (e.g., \"20230101_120000\").</p> required Source code in <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def retry_analysis(timestamp: str) -&gt; None:\n    \"\"\"Retries a failed AI analysis for a given run timestamp.\n\n    This function restores the configuration from the log file of a previous\n    run and re-triggers the AI-dependent parts of the analysis, including\n    report generation and consolidation.\n\n    Args:\n        timestamp (str): The timestamp of the run to retry (e.g., \"20230101_120000\").\n    \"\"\"\n    config, original_config = restore_configs_from_log(timestamp)\n    if not config or not original_config:\n        # Error is printed inside the helper function\n        sys.exit(1)\n\n    config[\"run_timestamp\"] = timestamp\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        stream=sys.stdout,\n    )\n    logger = logging.getLogger(__name__)\n    logger.info(\n        f\"Successfully restored configuration for timestamp {timestamp} for retry.\"\n    )\n\n    logger.info(\"Starting in AI analysis retry mode...\")\n    if not analysis_validate_config(config):\n        sys.exit(1)\n\n    case_configs = analysis_setup_analysis_cases_workspaces(config)\n    if not case_configs:\n        logger.error(\"Could not set up case workspaces for retry. Aborting.\")\n        sys.exit(1)\n\n    retry_ai_analysis(case_configs, config)\n    consolidate_reports(case_configs, config)\n\n    logger.info(\"AI analysis retry and consolidation complete.\")\n</code></pre>"},{"location":"api/tricys_simulation.html#tricys.simulation.simulation_analysis.run_simulation","title":"<code>run_simulation(config)</code>","text":"<p>Orchestrates the simulation analysis workflow.</p> <p>This is the main orchestrator for a simulation analysis run. It handles different execution paths based on the configuration: - If 'analysis_cases' are defined, it sets up and executes each case,   potentially in parallel. - If a SALib analysis is defined, it delegates to the SALib workflow. - Otherwise, it runs a standard parameter sweep, merges results,   generates plots, and triggers sensitivity analysis and post-processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary for the run.</p> required Note <p>Supports three modes: multi-case analysis (analysis_cases), SALib analysis (independent_variable as list with analyzer), or standard parameter sweep. For multi-case mode, creates isolated workspaces and can run cases in parallel with ProcessPoolExecutor. Generates summary reports and handles AI analysis retries if configured.</p> Source code in <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def run_simulation(config: Dict[str, Any]) -&gt; None:\n    \"\"\"Orchestrates the simulation analysis workflow.\n\n    This is the main orchestrator for a simulation analysis run. It handles\n    different execution paths based on the configuration:\n    - If 'analysis_cases' are defined, it sets up and executes each case,\n      potentially in parallel.\n    - If a SALib analysis is defined, it delegates to the SALib workflow.\n    - Otherwise, it runs a standard parameter sweep, merges results,\n      generates plots, and triggers sensitivity analysis and post-processing.\n\n    Args:\n        config: The main configuration dictionary for the run.\n\n    Note:\n        Supports three modes: multi-case analysis (analysis_cases), SALib analysis\n        (independent_variable as list with analyzer), or standard parameter sweep.\n        For multi-case mode, creates isolated workspaces and can run cases in parallel\n        with ProcessPoolExecutor. Generates summary reports and handles AI analysis retries\n        if configured.\n    \"\"\"\n\n    # 1. Split analysis_cases and determine salib_analysis_case\n    has_analysis_cases = (\n        \"sensitivity_analysis\" in config\n        and \"analysis_cases\" in config[\"sensitivity_analysis\"]\n        and (\n            # Support list format\n            (\n                isinstance(config[\"sensitivity_analysis\"][\"analysis_cases\"], list)\n                and len(config[\"sensitivity_analysis\"][\"analysis_cases\"]) &gt; 0\n            )\n            or\n            # Support single object format\n            isinstance(config[\"sensitivity_analysis\"][\"analysis_cases\"], dict)\n        )\n    )\n\n    # Check if it's a SALib analysis case (and not a multi-case analysis)\n    sa_config = config.get(\"sensitivity_analysis\", {})\n    analysis_case = sa_config.get(\"analysis_case\")\n\n    has_salib_analysis_case = (\n        not has_analysis_cases\n        and isinstance(analysis_case, dict)\n        and isinstance(analysis_case.get(\"independent_variable\"), list)\n        and isinstance(analysis_case.get(\"independent_variable_sampling\"), dict)\n        and \"analyzer\" in analysis_case\n    )\n\n    if has_analysis_cases and not has_salib_analysis_case:\n        logger.info(\n            \"Detected analysis_cases field, starting to create independent working directories for each analysis case...\"\n        )\n\n        # Create independent working directories and configuration files for each analysis_case\n        case_configs = analysis_setup_analysis_cases_workspaces(config)\n\n        if not case_configs:\n            logger.error(\n                \"Unable to create analysis_cases working directories, stopping execution\"\n            )\n            return\n\n        logger.info(f\"Starting execution of {len(case_configs)} analysis cases...\")\n\n        sa_config = config.get(\"sensitivity_analysis\", {})\n        run_cases_concurrently = sa_config.get(\"concurrent_cases\", False)\n        successful_cases = 0\n\n        if run_cases_concurrently:\n            logger.info(\n                f\"Starting execution of {len(case_configs)} analysis cases in PARALLEL.\"\n            )\n            max_workers = sa_config.get(\"max_case_workers\", os.cpu_count())\n            logger.info(\n                f\"Using up to {max_workers} parallel processes for analysis cases.\"\n            )\n\n            with concurrent.futures.ProcessPoolExecutor(\n                max_workers=max_workers\n            ) as executor:\n                future_to_case = {\n                    executor.submit(_execute_analysis_case, case_info): case_info\n                    for case_info in case_configs\n                }\n                for future in concurrent.futures.as_completed(future_to_case):\n                    case_info = future_to_case[future]\n                    case_name = case_info[\"case_data\"].get(\"name\", case_info[\"index\"])\n                    try:\n                        if future.result():\n                            successful_cases += 1\n                            logger.info(\n                                f\"Parallel case '{case_name}' completed successfully.\"\n                            )\n                        else:\n                            logger.warning(\n                                f\"Parallel case '{case_name}' completed with errors.\"\n                            )\n                    except Exception as exc:\n                        logger.error(\n                            f\"Parallel case '{case_name}' failed in executor with: {exc}\",\n                            exc_info=True,\n                        )\n        else:\n            logger.info(\n                f\"Starting execution of {len(case_configs)} analysis cases SEQUENTIALLY.\"\n            )\n            for case_info in case_configs:\n                try:\n                    case_index = case_info[\"index\"]\n                    case_workspace = case_info[\"workspace\"]\n                    case_config = case_info[\"config\"]\n                    case_data = case_info[\"case_data\"]\n\n                    logger.info(\n                        f\"\\n=== Starting execution of analysis case {case_index + 1}/{len(case_configs)} ===\"\n                    )\n                    logger.info(\n                        f\"Case name: {case_data.get('name', f'Case{case_index+1}')}\"\n                    )\n                    logger.info(\n                        f\"Independent variable: {case_data['independent_variable']}\"\n                    )\n                    logger.info(f\"Working directory: {case_workspace}\")\n\n                    original_cwd = os.getcwd()\n                    os.chdir(case_workspace)\n\n                    try:\n                        setup_logging(case_config)\n                        run_simulation(case_config)\n                        successful_cases += 1\n                        logger.info(\n                            f\"\u2713 Analysis case {case_index + 1} executed successfully\"\n                        )\n                    except Exception as case_e:\n                        logger.error(\n                            f\"\u2717 Analysis case {case_index + 1} execution failed: {case_e}\",\n                            exc_info=True,\n                        )\n                    finally:\n                        os.chdir(original_cwd)\n                        setup_logging(config)\n\n                except Exception as e:\n                    logger.error(\n                        f\"\u2717 Error processing analysis case {case_index + 1}: {e}\",\n                        exc_info=True,\n                    )\n\n        logger.info(\"\\n=== Analysis Cases Execution Completed ===\")\n        logger.info(\n            f\"Successfully executed: {successful_cases}/{len(case_configs)} cases\"\n        )\n\n        generate_analysis_cases_summary(case_configs, config)\n\n        return  # End analysis_cases processing\n    elif has_salib_analysis_case:\n        logger.info(\"Detected SALib analysis case, diverting to SALib workflow...\")\n        run_salib_analysis(config)\n        return  # SALib workflow is self-contained, so we exit here.\n\n    # 2. Core operational logic\n    jobs = generate_simulation_jobs(config.get(\"simulation_parameters\", {}))\n\n    # --- START: Add baseline jobs based on default parameter values ---\n    analysis_case = config.get(\"sensitivity_analysis\", {}).get(\"analysis_case\", {})\n    default_values = analysis_case.get(\"default_simulation_values\")\n\n    if default_values:\n        logger.info(\n            \"Found default_simulation_values, generating additional baseline jobs.\"\n        )\n\n        # Prepare simulation parameters for the baseline run, starting with default values\n        baseline_params = default_values.copy()\n\n        # Add the main independent variable sweep to the baseline parameters\n        independent_var = analysis_case.get(\"independent_variable\")\n        independent_sampling = analysis_case.get(\"independent_variable_sampling\")\n\n        if independent_var and independent_sampling:\n            baseline_params[independent_var] = independent_sampling\n\n            # Generate the additional jobs using the baseline config\n            default_jobs = generate_simulation_jobs(baseline_params)\n\n            # Combine with existing jobs and deduplicate\n            combined_jobs = jobs + default_jobs\n\n            # Deduplicate the list of job dictionaries\n            seen = set()\n            unique_jobs = []\n            for job in combined_jobs:\n                job_tuple = tuple(sorted(job.items()))\n                if job_tuple not in seen:\n                    seen.add(job_tuple)\n                    unique_jobs.append(job)\n\n            logger.info(\n                f\"Original jobs: {len(jobs)}, Combined jobs: {len(combined_jobs)}, Unique jobs after deduplication: {len(unique_jobs)}\"\n            )\n            jobs = unique_jobs\n    # --- END: Add baseline jobs ---\n\n    try:\n        results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n    except KeyError as e:\n        logger.error(f\"Missing required path key in configuration file: {e}\")\n        sys.exit(1)\n\n    simulation_results = {}\n    use_concurrent = config[\"simulation\"].get(\"concurrent\", False)\n\n    try:\n        if config.get(\"co_simulation\") is None:\n            if use_concurrent:\n                logger.info(\"Starting simulation in CONCURRENT mode.\")\n                max_workers = config[\"simulation\"].get(\"max_workers\", os.cpu_count())\n                logger.info(f\"Using up to {max_workers} parallel workers.\")\n                final_results = []\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_single_job, config, job_params, i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            (\n                                optimal_params,\n                                optimal_values,\n                                result_path,\n                            ) = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n\n                if _get_optimization_tasks(config):\n                    results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n                    os.makedirs(results_dir, exist_ok=True)\n                    if final_results:\n                        final_df = pd.DataFrame(final_results)\n                        output_path = os.path.join(\n                            results_dir, \"requierd_tbr_summary.csv\"\n                        )\n                        final_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n                        logger.info(\n                            f\"Sweep optimization summary saved to: {output_path}\"\n                        )\n            else:\n                logger.info(\"Starting simulation in SEQUENTIAL mode.\")\n                result_paths = _run_sequential_sweep(config, jobs)\n                for i, result_path in enumerate(result_paths):\n                    if result_path:\n                        simulation_results[tuple(sorted(jobs[i].items()))] = result_path\n        else:\n            if use_concurrent:\n                logger.info(\"Starting co-simulation in CONCURRENT mode.\")\n                max_workers = config[\"simulation\"].get(\"max_workers\", 4)\n                logger.info(f\"Using up to {max_workers} parallel processes.\")\n\n                final_results = []\n\n                with concurrent.futures.ProcessPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_co_simulation, config, job_params, job_id=i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            (\n                                optimal_params,\n                                optimal_values,\n                                result_path,\n                            ) = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                                logger.info(\n                                    f\"Successfully finished job for params: {job_params}\"\n                                )\n                            else:\n                                logger.warning(\n                                    f\"Job for params {job_params} did not return a result path.\"\n                                )\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for params {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n            else:\n                logger.info(\"Starting co-simulation in SEQUENTIAL mode.\")\n                final_results = []\n                for i, job_params in enumerate(jobs):\n                    job_id = i + 1\n                    logger.info(f\"--- Starting Sequential Job {job_id}/{len(jobs)} ---\")\n                    try:\n                        (\n                            optimal_params,\n                            optimal_values,\n                            result_path,\n                        ) = _run_co_simulation(config, job_params, job_id=job_id)\n                        if result_path:\n                            simulation_results[tuple(sorted(job_params.items()))] = (\n                                result_path\n                            )\n                            logger.info(\n                                f\"Successfully finished job for params: {job_params}\"\n                            )\n                        else:\n                            logger.warning(\n                                f\"Job for params {job_params} did not return a result path.\"\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n                    except Exception as exc:\n                        logger.error(\n                            f\"Job for params {job_params} generated an exception: {exc}\",\n                            exc_info=True,\n                        )\n                    logger.info(f\"--- Finished Sequential Job {job_id}/{len(jobs)} ---\")\n\n            if _get_optimization_tasks(config):\n                results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n                os.makedirs(results_dir, exist_ok=True)\n                if final_results:\n                    final_df = pd.DataFrame(final_results)\n                    output_path = os.path.join(results_dir, \"requierd_tbr_summary.csv\")\n                    final_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n                    logger.info(f\"Sweep optimization summary saved to: {output_path}\")\n    except Exception as e:\n        raise RuntimeError(f\"Failed to run simualtion: {e}\")\n\n    # 3. Data merging and processing\n    run_results_dir = results_dir\n    os.makedirs(run_results_dir, exist_ok=True)\n\n    # Unified result processing for both single and multiple jobs\n    logger.info(f\"Processing {len(jobs)} job(s). Combining results.\")\n    combined_df = None\n\n    all_dfs = []\n    time_df_added = False\n\n    for job_params in jobs:\n        job_key = tuple(sorted(job_params.items()))\n        result_path = simulation_results.get(job_key)\n\n        if not result_path or not os.path.exists(result_path):\n            logger.warning(f\"Job {job_params} produced no result file. Skipping.\")\n            continue\n\n        # Read the current job's result file\n        df = pd.read_csv(result_path)\n\n        # From the very first valid DataFrame, grab the 'time' column\n        if not time_df_added and \"time\" in df.columns:\n            all_dfs.append(df[[\"time\"]])\n            time_df_added = True\n\n        # Prepare the parameter string for column renaming\n        param_string = \"&amp;\".join([f\"{k}={v}\" for k, v in job_params.items()])\n\n        # Isolate the data columns (everything except 'time')\n        data_columns = df.drop(columns=[\"time\"], errors=\"ignore\")\n\n        # Create a dictionary to map old column names to new ones\n        # e.g., {'voltage': 'voltage&amp;param1=A&amp;param2=B'}\n        rename_mapping = {\n            col: f\"{col}&amp;{param_string}\" if param_string else col\n            for col in data_columns.columns\n        }\n\n        # Rename the columns and add the resulting DataFrame to our list\n        all_dfs.append(data_columns.rename(columns=rename_mapping))\n\n    # Concatenate all the DataFrames in the list along the columns axis (axis=1)\n    if all_dfs:\n        combined_df = pd.concat(all_dfs, axis=1)\n    else:\n        combined_df = pd.DataFrame()  # Or None, as you had before\n\n    if combined_df is not None and not combined_df.empty:\n        if len(jobs) == 1:\n            # For single job, save as simulation_result.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"simulation_result.csv\"\n            )\n        else:\n            # For multiple jobs, save as sweep_results.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"sweep_results.csv\"\n            )\n\n        # Clean up rows where the 'time' column is blank, which often occurs as redundant rows at the end of the file.\n        combined_df.dropna(subset=[\"time\"], inplace=True)\n        combined_df.to_csv(combined_csv_path, index=False)\n        logger.info(f\"Combined results saved to: {combined_csv_path}\")\n    else:\n        logger.warning(\"No valid results found to combine.\")\n\n    # Check if sweep_time plotting is enabled\n    analysis_case = config[\"sensitivity_analysis\"].get(\"analysis_case\", {})\n    sweep_time_list = analysis_case.get(\"sweep_time\", None)\n    if sweep_time_list and len(sweep_time_list) &gt;= 1:\n        # Get parameters for plot_sweep_time_series\n        independent_var = analysis_case.get(\"independent_variable\")\n        dependent_vars = analysis_case.get(\"dependent_variables\", [])\n        independent_var_alias = analysis_case.get(\"independent_variable_alias\")\n\n        if (\n            independent_var\n            and dependent_vars\n            and combined_csv_path\n            and os.path.exists(combined_csv_path)\n        ):\n\n            try:\n                # Get default values if they exist to filter the plot\n                default_values = analysis_case.get(\"default_simulation_values\")\n\n                plot_path = plot_sweep_time_series(\n                    csv_path=combined_csv_path,\n                    save_dir=run_results_dir,\n                    y_var_name=sweep_time_list,\n                    independent_var_name=independent_var,\n                    independent_var_alias=independent_var_alias,\n                    default_params=default_values,  # Pass default values to the plot function\n                    glossary_path=config[\"sensitivity_analysis\"].get(\n                        \"glossary_path\", None\n                    ),\n                )\n                if plot_path:\n                    logger.info(f\"Sweep time series plot generated: {plot_path}\")\n                else:\n                    logger.warning(\"Failed to generate sweep time series plot\")\n            except Exception as e:\n                logger.error(f\"Error generating sweep time series plot: {e}\")\n\n    # 4. Sensitivity analysis\n    _run_sensitivity_analysis(config, run_results_dir, jobs)\n\n    # 5. Post-processing\n    if combined_df is not None:\n        # Calculate the top-level post-processing directory\n        top_level_run_workspace = os.path.abspath(\"post_processing\")\n        _run_post_processing(config, combined_df, top_level_run_workspace)\n    else:\n        logger.warning(\n            \"No simulation results were generated, skipping post-processing.\"\n        )\n\n    # 6. Intermediate data cleaning\n    if not config[\"simulation\"].get(\"keep_temp_files\", True):\n        logger.info(\"Cleaning up temporary directory...\")\n        temp_dir_path = os.path.abspath(config[\"paths\"].get(\"temp_dir\", \"temp\"))\n        if os.path.exists(temp_dir_path):\n            try:\n                shutil.rmtree(temp_dir_path)\n                os.makedirs(temp_dir_path)  # Recreate for next run\n            except OSError as e:\n                logger.error(f\"Error cleaning up temp directory: {e}\")\n</code></pre>"},{"location":"api/tricys_utils.html","title":"API \u53c2\u8003 - \u5de5\u5177\u51fd\u6570 (Utilities)","text":"<p>\u5de5\u5177\u51fd\u6570 (Utilities)</p> <p>\u5de5\u5177\u51fd\u6570 (Utilities) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u7528\u4e8e\u914d\u7f6e\u5904\u7406\u3001\u6587\u4ef6\u64cd\u4f5c\u3001\u65e5\u5fd7\u8bb0\u5f55\u548c\u6570\u636e\u5e93\u4ea4\u4e92\u7684\u8f85\u52a9\u51fd\u6570\u3002 \u8bf7\u5728\u4e0b\u65b9\u7684\u6807\u7b7e\u9875\u4e2d\u9009\u62e9\u60a8\u611f\u5174\u8da3\u7684\u7279\u5b9a\u6a21\u5757\u3002</p> Config Utils (\u914d\u7f6e\u5de5\u5177)File Utils (\u6587\u4ef6\u5de5\u5177)Log Utils (\u65e5\u5fd7\u5de5\u5177)SQLite Utils (\u6570\u636e\u5e93\u5de5\u5177) <p>Configuration utility functions for tricys.</p> <p>Utility functions for file and directory management.</p> <p>This module provides helper functions for creating unique filenames and managing log file rotation.</p> <p>Utilities for interacting with the simulation parameter SQLite database.</p> <p>This module provides functions to create, store, update, and retrieve simulation parameter data from a SQLite database file.</p>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_prepare_config","title":"<code>analysis_prepare_config(config_path)</code>","text":"<p>Loads, validates, and prepares the configuration from the given path.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_prepare_config(config_path: str) -&gt; tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Loads, validates, and prepares the configuration from the given path.\"\"\"\n    try:\n        config_path = os.path.abspath(config_path)\n        with open(config_path, \"r\") as f:\n            base_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        print(\n            f\"ERROR: Failed to load or parse config file {config_path}: {e}\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    original_config_dir = os.path.dirname(config_path)\n    absolute_config = convert_relative_paths_to_absolute(\n        base_config, original_config_dir\n    )\n\n    # Perform all validation on the config with absolute paths\n    analysis_validate_config(absolute_config)\n\n    config = json.loads(json.dumps(absolute_config))\n    config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    config[\"paths\"][\"log_dir\"] = run_workspace\n    if \"paths\" not in config:\n        config[\"paths\"] = {}\n\n    original_string = config[\"simulation\"][\"variableFilter\"]\n    config[\"simulation\"][\"variableFilter\"] = original_string.replace(\n        \"[\", \"\\\\[[\"\n    ).replace(\"]\", \"]\\\\]\")\n\n    return config, base_config\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_setup_analysis_cases_workspaces","title":"<code>analysis_setup_analysis_cases_workspaces(config)</code>","text":"<p>Set up independent working directories and configuration files for multiple analysis_cases</p> <p>This function will: 1. Create independent working directories for each analysis_case in the current working directory 2. Convert relative paths in the original configuration to absolute paths 3. Convert analysis_cases format to standard analysis_case format 4. Generate independent config.json files for each case</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary containing analysis_cases</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List containing information for each case, each element contains:</p> <code>List[Dict[str, Any]]</code> <ul> <li>index: Case index</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>workspace: Working directory path</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>config_path: Configuration file path</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>config: Configuration applicable to this case</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>case_data: Original case data</li> </ul> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_setup_analysis_cases_workspaces(\n    config: Dict[str, Any],\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Set up independent working directories and configuration files for multiple analysis_cases\n\n    This function will:\n    1. Create independent working directories for each analysis_case in the current working directory\n    2. Convert relative paths in the original configuration to absolute paths\n    3. Convert analysis_cases format to standard analysis_case format\n    4. Generate independent config.json files for each case\n\n    Args:\n        config: Original configuration dictionary containing analysis_cases\n\n    Returns:\n        List containing information for each case, each element contains:\n        - index: Case index\n        - workspace: Working directory path\n        - config_path: Configuration file path\n        - config: Configuration applicable to this case\n        - case_data: Original case data\n    \"\"\"\n\n    analysis_cases_raw = config[\"sensitivity_analysis\"][\"analysis_cases\"]\n\n    # Unified processing into list format\n    if isinstance(analysis_cases_raw, dict):\n        # Single analysis_case object\n        analysis_cases = [analysis_cases_raw]\n        logger.info(\n            \"Detected single analysis_case object, converting to list format for processing\"\n        )\n    else:\n        # Already in list format\n        analysis_cases = analysis_cases_raw\n\n    # The main run workspace is the timestamped directory, already created by initialize_run.\n    # We will create the case workspaces inside it.\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    # Determine the main log file path to be shared with all cases\n    main_log_file_name = f\"simulation_{config['run_timestamp']}.log\"\n    main_log_path = os.path.join(run_workspace, main_log_file_name)\n\n    logger.info(\n        f\"Detected {len(analysis_cases)} analysis cases, creating independent workspaces inside: {run_workspace}\"\n    )\n\n    case_configs = []\n\n    for i, analysis_case in enumerate(analysis_cases):\n        try:\n            # Generate case working directory name\n            workspace_name = analysis_case.get(\"name\", f\"case_{i}\")\n            # Create the case workspace directly inside the main run workspace\n            case_workspace = os.path.join(run_workspace, workspace_name)\n            os.makedirs(case_workspace, exist_ok=True)\n\n            # Create standard configuration (inlined from _create_standard_config_for_case)\n            base_config = config\n            original_config_dir = os.path.dirname(\n                base_config.get(\"paths\", {}).get(\"package_path\", os.getcwd())\n            )\n            absolute_config = convert_relative_paths_to_absolute(\n                base_config, original_config_dir\n            )\n            standard_config = json.loads(json.dumps(absolute_config))\n\n            # if analysis_case.get(\"name\") == \"SALib_Analysis\":\n            if isinstance(\n                analysis_case.get(\"independent_variable\"), list\n            ) and isinstance(analysis_case.get(\"independent_variable_sampling\"), dict):\n                sensitivity_analysis = standard_config[\"sensitivity_analysis\"]\n                if \"analysis_cases\" in sensitivity_analysis:\n                    del sensitivity_analysis[\"analysis_cases\"]\n                sensitivity_analysis[\"analysis_case\"] = analysis_case.copy()\n            else:\n                # Get independent variable and sampling from the current analysis case\n                independent_var = analysis_case[\"independent_variable\"]\n                independent_sampling = analysis_case[\"independent_variable_sampling\"]\n                logger.debug(\n                    f\"independent_sampling configuration: {independent_sampling}\"\n                )\n\n                # Ensure simulation_parameters exists at the top level\n                if \"simulation_parameters\" not in standard_config:\n                    standard_config[\"simulation_parameters\"] = {}\n\n                # If the specific analysis_case has its own simulation_parameters, merge them into the top-level ones\n                # This allows for case-specific parameter overrides or additions\n                if \"simulation_parameters\" in analysis_case:\n                    case_sim_params = analysis_case.get(\"simulation_parameters\", {})\n\n                    # Identify and handle virtual parameters (e.g., Required_TBR) used for metric configuration\n                    virtual_params = {\n                        k: v\n                        for k, v in case_sim_params.items()\n                        if k.startswith(\"Required_\") and isinstance(v, dict)\n                    }\n\n                    if virtual_params:\n                        # Merge virtual parameter config into the case's metrics_definition\n                        metrics_def = standard_config.setdefault(\n                            \"sensitivity_analysis\", {}\n                        ).setdefault(\"metrics_definition\", {})\n                        for key, value in virtual_params.items():\n                            if key in metrics_def:\n                                metrics_def[key].update(value)\n                            else:\n                                metrics_def[key] = value\n\n                    # Get real parameters by excluding virtual ones\n                    real_params = {\n                        k: v\n                        for k, v in case_sim_params.items()\n                        if k not in virtual_params\n                    }\n\n                    # Update standard_config's simulation_parameters with only real parameters for job generation\n                    standard_config[\"simulation_parameters\"].update(real_params)\n\n                # Fetch default values for both independent and simulation parameters\n                omc = None\n                try:\n                    # Get all sim params from the case, which may include virtual parameters\n                    all_case_sim_params = analysis_case.get(\"simulation_parameters\", {})\n                    # Filter out virtual parameters before fetching default values\n                    sim_param_keys = [\n                        k\n                        for k, v in all_case_sim_params.items()\n                        if not (k.startswith(\"Required_\") and isinstance(v, dict))\n                    ]\n                    # Ensure independent_var is a list for consistent processing, as it can be a list in SALib cases\n                    ind_param_keys = (\n                        [independent_var]\n                        if isinstance(independent_var, str)\n                        else independent_var\n                    )\n\n                    param_keys_to_fetch = sim_param_keys + ind_param_keys\n\n                    if param_keys_to_fetch:\n                        logger.info(\n                            f\"Fetching default values for parameters: {param_keys_to_fetch}\"\n                        )\n                        omc = get_om_session()\n                        if load_modelica_package(\n                            omc,\n                            Path(standard_config[\"paths\"][\"package_path\"]).as_posix(),\n                        ):\n                            all_defaults = get_model_default_parameters(\n                                omc, standard_config[\"simulation\"][\"model_name\"]\n                            )\n\n                            # Helper function to handle array access like 'param[1]'\n                            def get_specific_default(key, defaults):\n                                if key in defaults:\n                                    return defaults[key]\n                                if \"[\" in key and key.endswith(\"]\"):\n                                    try:\n                                        base_name, index_str = key.rsplit(\"[\", 1)\n                                        # Modelica is 1-based, Python is 0-based\n                                        index = int(index_str[:-1]) - 1\n                                        if base_name in defaults:\n                                            default_array = defaults[base_name]\n                                            if isinstance(\n                                                default_array, list\n                                            ) and 0 &lt;= index &lt; len(default_array):\n                                                return default_array[index]\n                                    except (ValueError, IndexError):\n                                        pass  # Malformed index or out of bounds\n                                return \"N/A\"\n\n                            # Get defaults for simulation_parameters\n                            default_sim_values = {\n                                p: get_specific_default(p, all_defaults)\n                                for p in sim_param_keys\n                            }\n                            analysis_case[\"default_simulation_values\"] = (\n                                default_sim_values\n                            )\n\n                            # Get defaults for independent_variable\n                            default_ind_values = {\n                                p: get_specific_default(p, all_defaults)\n                                for p in ind_param_keys\n                            }\n                            analysis_case[\"default_independent_values\"] = (\n                                default_ind_values\n                            )\n\n                except Exception as e:\n                    logger.warning(\n                        f\"Could not fetch default parameter values. Defaults will be empty. Error: {e}\"\n                    )\n                    analysis_case[\"default_simulation_values\"] = {}\n                    analysis_case[\"default_independent_values\"] = {}\n                finally:\n                    if omc:\n                        omc.sendExpression(\"quit()\")\n\n                # Add the primary independent_variable_sampling for the current analysis case\n                standard_config[\"simulation_parameters\"][\n                    independent_var\n                ] = independent_sampling\n\n                # Update sensitivity_analysis configuration\n                sensitivity_analysis = standard_config[\"sensitivity_analysis\"]\n\n                # Remove analysis_cases and replace with single analysis_case\n                if \"analysis_cases\" in sensitivity_analysis:\n                    del sensitivity_analysis[\"analysis_cases\"]\n\n                sensitivity_analysis[\"analysis_case\"] = analysis_case.copy()\n\n            # Update paths in configuration to be relative to case working directory\n            case_config = standard_config.copy()\n            case_config[\"paths\"][\"results_dir\"] = os.path.join(\n                case_workspace, \"results\"\n            )\n            case_config[\"paths\"][\"temp_dir\"] = os.path.join(case_workspace, \"temp\")\n            case_config[\"paths\"][\"db_path\"] = os.path.join(\n                case_workspace, \"data\", \"parameters.db\"\n            )\n\n            # If there's logging configuration, also update log directory\n            if \"paths\" in case_config and \"log_dir\" in case_config[\"paths\"]:\n                case_config[\"paths\"][\"log_dir\"] = os.path.join(case_workspace, \"log\")\n                # Inject the main log path for dual logging\n                if \"logging\" in case_config:\n                    case_config[\"logging\"][\"main_log_path\"] = main_log_path\n\n            # Save standard configuration file to case working directory\n            config_file_path = os.path.join(case_workspace, \"config.json\")\n            with open(config_file_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(standard_config, f, indent=4, ensure_ascii=False)\n\n            # Record case information\n            case_info = {\n                \"index\": i,\n                \"workspace\": case_workspace,\n                \"config_path\": config_file_path,\n                \"config\": case_config,\n                \"case_data\": analysis_case,\n            }\n            case_configs.append(case_info)\n\n            logger.info(\n                f\"Workspace for case {i+1} created successfully\",\n                extra={\n                    \"case_index\": i,\n                    \"case_name\": analysis_case.get(\"name\", f\"case_{i}\"),\n                    \"workspace\": case_workspace,\n                    \"config_path\": config_file_path,\n                },\n            )\n\n        except Exception as e:\n            logger.error(f\"\u2717 Error processing case {i}: {e}\", exc_info=True)\n            continue\n\n    logger.info(\n        f\"Successfully created independent working directories for {len(case_configs)} analysis cases\"\n    )\n    return case_configs\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_validate_analysis_cases_config","title":"<code>analysis_validate_analysis_cases_config(config)</code>","text":"<p>Validates analysis_cases configuration format supporting both list and single object.</p> <p>This function validates: 1. Basic structure and required fields of analysis_cases 2. Simulation parameters compatibility (single job requirement) 3. Required_TBR configuration completeness if used in dependent_variables</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to validate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if configuration is valid, False otherwise.</p> Note <p>Supports both single analysis_case dict or list of cases. Required fields per case: name, independent_variable, independent_variable_sampling. Validates simulation_parameters contain only single job (no sweep). Checks Required_TBR completeness in metrics_definition.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_validate_analysis_cases_config(config: Dict[str, Any]) -&gt; bool:\n    \"\"\"Validates analysis_cases configuration format supporting both list and single object.\n\n    This function validates:\n    1. Basic structure and required fields of analysis_cases\n    2. Simulation parameters compatibility (single job requirement)\n    3. Required_TBR configuration completeness if used in dependent_variables\n\n    Args:\n        config: Configuration dictionary to validate.\n\n    Returns:\n        True if configuration is valid, False otherwise.\n\n    Note:\n        Supports both single analysis_case dict or list of cases. Required fields per case:\n        name, independent_variable, independent_variable_sampling. Validates simulation_parameters\n        contain only single job (no sweep). Checks Required_TBR completeness in metrics_definition.\n    \"\"\"\n    if \"sensitivity_analysis\" not in config:\n        logger.error(\"Missing sensitivity_analysis\")\n        return False\n\n    sensitivity_analysis = config[\"sensitivity_analysis\"]\n    if \"analysis_cases\" not in sensitivity_analysis:\n        logger.error(\"Missing analysis_cases\")\n        return False\n\n    analysis_cases = sensitivity_analysis[\"analysis_cases\"]\n\n    # Support both single object and list formats\n    if isinstance(analysis_cases, dict):\n        # Single analysis_case object\n        cases_to_check = [analysis_cases]\n    elif isinstance(analysis_cases, list) and len(analysis_cases) &gt; 0:\n        # analysis_cases list\n        cases_to_check = analysis_cases\n    else:\n        logger.error(\"analysis_cases must be a non-empty list or a single object\")\n        return False\n\n    # Check required fields for each analysis_case\n    required_fields = [\"name\", \"independent_variable\", \"independent_variable_sampling\"]\n    for i, case in enumerate(cases_to_check):\n        if not isinstance(case, dict):\n            logger.error(f\"analysis_cases[{i}] must be an object\")\n            return False\n        for field in required_fields:\n            if field not in case:\n                logger.error(f\"Missing required field '{field}' in analysis_cases[{i}]\")\n                return False\n\n    # Check if top-level simulation_parameters are used, which is disallowed in analysis_cases mode\n    if config.get(\"simulation_parameters\"):\n        logger.error(\n            \"The top-level 'simulation_parameters' field cannot be used when 'analysis_cases' is defined. \"\n            \"Please move any shared or case-specific parameters into the 'simulation_parameters' field \"\n            \"inside each object within the 'analysis_cases' list.\"\n        )\n        return False\n\n    # Check Required_TBR configuration completeness if it exists in dependent_variables\n    metrics_definition = sensitivity_analysis.get(\"metrics_definition\", {})\n    for i, case in enumerate(cases_to_check):\n        dependent_vars = case.get(\"dependent_variables\", [])\n        if \"Required_TBR\" in dependent_vars:\n            # Check if Required_TBR exists in metrics_definition\n            if \"Required_TBR\" not in metrics_definition:\n                logger.error(\n                    f\"Required_TBR is in dependent_variables of analysis_cases[{i}] but missing from metrics_definition\"\n                )\n                return False\n\n            # Check if Required_TBR configuration is complete\n            required_tbr_config = metrics_definition[\"Required_TBR\"]\n            required_fields = [\n                \"method\",\n                \"parameter_to_optimize\",\n                \"search_range\",\n                \"tolerance\",\n                \"max_iterations\",\n            ]\n            missing_fields = [\n                field for field in required_fields if field not in required_tbr_config\n            ]\n            if missing_fields:\n                logger.error(\n                    f\"Required_TBR configuration in metrics_definition is incomplete. Missing fields: {missing_fields}\"\n                )\n                return False\n\n    return True\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.analysis_validate_config","title":"<code>analysis_validate_config(config, required_keys=ANALYSIS_REQUIRED_CONFIG_KEYS, parent_key='')</code>","text":"<p>Recursively validates the configuration's structure and values.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_validate_config(\n    config: Dict[str, Any],\n    required_keys: Dict = ANALYSIS_REQUIRED_CONFIG_KEYS,\n    parent_key: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Recursively validates the configuration's structure and values.\n    \"\"\"\n    # --- Structural Validation ---\n    for key, expected in required_keys.items():\n        full_key_path = f\"{parent_key}.{key}\" if parent_key else key\n        if key not in config:\n            print(\n                f\"ERROR: Missing required configuration key: '{full_key_path}'\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if isinstance(expected, dict):\n            if not isinstance(config[key], dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' must be a dictionary.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            analysis_validate_config(config[key], expected, parent_key=full_key_path)\n        elif not isinstance(config[key], expected):\n            print(\n                f\"ERROR: Configuration key '{full_key_path}' has incorrect type. Expected {expected}, got {type(config[key])}.\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n    # 2. Validate variableFilter format\n    variable_filter = config.get(\"simulation\", {}).get(\"variableFilter\")\n    if variable_filter:\n        # Regex for a valid Modelica identifier (simplified)\n        ident = r\"[a-zA-Z_][a-zA-Z0-9_]*\"\n        # Regex for a valid substring in the filter:\n        # - time\n        # - class.name\n        # - class.name[index]\n        # - class.name[start-end]\n        valid_substring_re = re.compile(rf\"^time$|^{ident}\\.{ident}(\\[\\d+(-\\d+)?\\])?$\")\n\n        substrings = variable_filter.split(\"|\")\n        for sub in substrings:\n            if not valid_substring_re.match(sub):\n                print(\n                    f\"ERROR: Invalid format in 'simulation.variableFilter'. Substring '{sub}' does not match required format. \"\n                    f\"Valid formats are 'time', 'classname.typename', 'classname.typename[1]', or 'classname.typename[1-5]'.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    # --- Value and Conditional Validation (only on top-level call) ---\n    if not parent_key:\n        # Check for package_path existence\n        package_path = config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            print(\n                f\"ERROR: File specified in 'paths.package_path' not found: {package_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        # Analysis-specific validation\n        sa_config = config.get(\"sensitivity_analysis\", {})\n        if sa_config.get(\"enabled\", False):\n            has_sim_params = (\n                \"simulation_parameters\" in config and config[\"simulation_parameters\"]\n            )\n            has_analysis_cases = (\n                \"analysis_cases\" in sa_config and sa_config[\"analysis_cases\"]\n            )\n\n            if not has_sim_params and not has_analysis_cases:\n                print(\n                    \"ERROR: When 'sensitivity_analysis' is enabled, either 'simulation_parameters' or 'sensitivity_analysis.analysis_cases' must be defined.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n            if has_analysis_cases:\n                if not analysis_validate_analysis_cases_config(config):\n                    # The original function uses a logger which is not yet configured.\n                    # Add a print statement to ensure the user sees an error.\n                    print(\n                        \"ERROR: 'analysis_cases' configuration is invalid. See previous logs for details.\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n\n        check_ai_config(config)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.basic_prepare_config","title":"<code>basic_prepare_config(config_path)</code>","text":"<p>Loads and prepares the configuration from the given path.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to the JSON configuration file.</p> required <p>Returns:</p> Type Description <code>tuple[Dict[str, Any], Dict[str, Any]]</code> <p>A tuple of (runtime_config, original_config).</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If config file loading/parsing fails or validation fails.</p> Note <p>Converts relative paths to absolute, validates config structure, adds run_timestamp, creates workspace directories, and processes variableFilter for regex escaping. Sets up log_dir, temp_dir, and results_dir within run workspace.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def basic_prepare_config(config_path: str) -&gt; tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Loads and prepares the configuration from the given path.\n\n    Args:\n        config_path: Path to the JSON configuration file.\n\n    Returns:\n        A tuple of (runtime_config, original_config).\n\n    Raises:\n        SystemExit: If config file loading/parsing fails or validation fails.\n\n    Note:\n        Converts relative paths to absolute, validates config structure, adds run_timestamp,\n        creates workspace directories, and processes variableFilter for regex escaping.\n        Sets up log_dir, temp_dir, and results_dir within run workspace.\n    \"\"\"\n    try:\n        config_path = os.path.abspath(config_path)\n        with open(config_path, \"r\") as f:\n            base_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        # Logger is not set up yet, so print directly to stderr\n        print(\n            f\"ERROR: Failed to load or parse config file {config_path}: {e}\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    original_config_dir = os.path.dirname(config_path)\n\n    absolute_config = convert_relative_paths_to_absolute(\n        base_config, original_config_dir\n    )\n\n    # Perform all validation on the config with absolute paths\n    basic_validate_config(absolute_config)\n\n    config = json.loads(json.dumps(absolute_config))\n    config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    if \"paths\" not in config:\n        config[\"paths\"] = {}\n\n    original_string = config[\"simulation\"][\"variableFilter\"]\n    config[\"simulation\"][\"variableFilter\"] = original_string.replace(\n        \"[\", \"\\\\[[\"\n    ).replace(\"]\", \"]\\\\]\")\n\n    config[\"paths\"][\"log_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"log_dir\", \"log\")\n    )\n    config[\"paths\"][\"temp_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"temp_dir\", \"temp\")\n    )\n    config[\"paths\"][\"results_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"results_dir\", \"results\")\n    )\n\n    os.makedirs(config[\"paths\"][\"log_dir\"], exist_ok=True)\n    os.makedirs(config[\"paths\"][\"temp_dir\"], exist_ok=True)\n    os.makedirs(config[\"paths\"][\"results_dir\"], exist_ok=True)\n\n    return config, base_config\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.basic_validate_config","title":"<code>basic_validate_config(config, required_keys=BASIC_REQUIRED_CONFIG_KEYS, parent_key='')</code>","text":"<p>Recursively validates the configuration against required structure.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to validate.</p> required <code>required_keys</code> <code>Dict</code> <p>Dictionary defining required keys and their expected types.</p> <code>BASIC_REQUIRED_CONFIG_KEYS</code> <code>parent_key</code> <code>str</code> <p>Parent key path for nested validation (used internally).</p> <code>''</code> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If validation fails (exits with code 1).</p> Note <p>Performs structural validation (required keys and types) and value validation (path existence, variableFilter format). Uses regex to validate variableFilter against Modelica identifier patterns. Only validates values on top-level call.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def basic_validate_config(\n    config: Dict[str, Any],\n    required_keys: Dict = BASIC_REQUIRED_CONFIG_KEYS,\n    parent_key: str = \"\",\n) -&gt; None:\n    \"\"\"Recursively validates the configuration against required structure.\n\n    Args:\n        config: Configuration dictionary to validate.\n        required_keys: Dictionary defining required keys and their expected types.\n        parent_key: Parent key path for nested validation (used internally).\n\n    Raises:\n        SystemExit: If validation fails (exits with code 1).\n\n    Note:\n        Performs structural validation (required keys and types) and value validation\n        (path existence, variableFilter format). Uses regex to validate variableFilter\n        against Modelica identifier patterns. Only validates values on top-level call.\n    \"\"\"\n    # --- Structural Validation ---\n    for key, expected_type_or_dict in required_keys.items():\n        full_key_path = f\"{parent_key}.{key}\" if parent_key else key\n\n        if key not in config:\n            print(\n                f\"ERROR: Missing required configuration key: '{full_key_path}'\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if isinstance(expected_type_or_dict, dict):\n            if not isinstance(config[key], dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' must be a dictionary.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            # Recurse for nested dictionaries\n            basic_validate_config(\n                config[key], expected_type_or_dict, parent_key=full_key_path\n            )\n        else:\n            # Perform type checking for leaf keys\n            if not isinstance(config[key], expected_type_or_dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' has incorrect type. \"\n                    f\"Expected {expected_type_or_dict}, but got {type(config[key])}.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    # --- Value Validation (only on top-level call) ---\n    if not parent_key:\n        # 1. Check if package_path exists\n        package_path = config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            print(\n                f\"ERROR: File specified in 'paths.package_path' not found: {package_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        # 2. Validate variableFilter format\n        variable_filter = config.get(\"simulation\", {}).get(\"variableFilter\")\n        if variable_filter:\n            # Regex for a valid Modelica identifier (simplified)\n            ident = r\"[a-zA-Z_][a-zA-Z0-9_]*\"\n            # Regex for a valid substring in the filter:\n            # - time\n            # - class.name\n            # - class.name[index]\n            # - class.name[start-end]\n            valid_substring_re = re.compile(\n                rf\"^time$|^{ident}\\.{ident}(\\[\\d+(-\\d+)?\\])?$\"\n            )\n\n            substrings = variable_filter.split(\"|\")\n            for sub in substrings:\n                if not valid_substring_re.match(sub):\n                    print(\n                        f\"ERROR: Invalid format in 'simulation.variableFilter'. Substring '{sub}' does not match required format. \"\n                        f\"Valid formats are 'time', 'classname.typename', 'classname.typename[1]', or 'classname.typename[1-5]'.\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n\n        check_ai_config(config)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.check_ai_config","title":"<code>check_ai_config(config)</code>","text":"<p>Checks for AI-related environment variables if 'ai: true' is found in the config.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The configuration dictionary.</p> required <p>Raises:</p> Type Description <code>SystemExit</code> <p>If AI is enabled in the config but required environment         variables are missing.</p> Note <p>If any part of the configuration contains <code>\"ai\": true</code>, this function verifies that <code>API_KEY</code>, <code>BASE_URL</code>, and either <code>AI_MODEL</code> or <code>AI_MODELS</code> are set as environment variables.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def check_ai_config(config: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Checks for AI-related environment variables if 'ai: true' is found in the config.\n\n    Args:\n        config: The configuration dictionary.\n\n    Raises:\n        SystemExit: If AI is enabled in the config but required environment\n                    variables are missing.\n\n    Note:\n        If any part of the configuration contains `\"ai\": true`, this function verifies\n        that `API_KEY`, `BASE_URL`, and either `AI_MODEL` or `AI_MODELS` are set as\n        environment variables.\n    \"\"\"\n    if _search_dict(config, \"ai\", True):\n        logger.info(\n            \"AI feature enabled in config, checking for required environment variables...\"\n        )\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n        ai_model = os.environ.get(\"AI_MODEL\")\n        ai_models = os.environ.get(\"AI_MODELS\")\n\n        missing_vars = []\n        if not api_key:\n            missing_vars.append(\"API_KEY\")\n        if not base_url:\n            missing_vars.append(\"BASE_URL\")\n        if not ai_model and not ai_models:\n            missing_vars.append(\"AI_MODEL or AI_MODELS\")\n\n        if missing_vars:\n            print(\n                f\"ERROR: 'ai: true' is set in the configuration, but the following required environment variables are missing: {', '.join(missing_vars)}. \"\n                \"Please set them in your environment or a .env file.\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n        else:\n            logger.info(\"All required AI environment variables are present.\")\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.config_utils.convert_relative_paths_to_absolute","title":"<code>convert_relative_paths_to_absolute(config, base_dir)</code>","text":"<p>Recursively converts relative paths to absolute paths in configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to process.</p> required <code>base_dir</code> <code>str</code> <p>Base directory path for resolving relative paths.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Configuration dictionary with converted absolute paths.</p> Note <p>Processes path keys including package_path, db_path, results_dir, temp_dir, log_dir, glossary_path, and any key ending with '_path'. Converts relative paths to absolute using base_dir. Handles nested dictionaries and lists recursively.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def convert_relative_paths_to_absolute(\n    config: Dict[str, Any], base_dir: str\n) -&gt; Dict[str, Any]:\n    \"\"\"Recursively converts relative paths to absolute paths in configuration.\n\n    Args:\n        config: Configuration dictionary to process.\n        base_dir: Base directory path for resolving relative paths.\n\n    Returns:\n        Configuration dictionary with converted absolute paths.\n\n    Note:\n        Processes path keys including package_path, db_path, results_dir, temp_dir,\n        log_dir, glossary_path, and any key ending with '_path'. Converts relative\n        paths to absolute using base_dir. Handles nested dictionaries and lists recursively.\n    \"\"\"\n\n    def _process_value(value, key_name=\"\", parent_dict=None):\n        if isinstance(value, dict):\n            return {k: _process_value(v, k, value) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [_process_value(item, parent_dict=parent_dict) for item in value]\n        elif isinstance(value, str):\n            # Check if it's a path-related key name (extended support for more path fields)\n            path_keys = [\n                \"package_path\",\n                \"db_path\",\n                \"results_dir\",\n                \"temp_dir\",\n                \"log_dir\",\n                \"glossary_path\",\n            ]\n\n            if key_name.endswith(\"_path\") or key_name in path_keys:\n                # If it's a relative path, convert to absolute path\n                if not os.path.isabs(value) and value:\n                    abs_path = os.path.abspath(os.path.join(base_dir, value))\n                    logger.debug(\n                        \"Converted path\",\n                        extra={\n                            \"key_name\": key_name,\n                            \"original_value\": value,\n                            \"absolute_path\": abs_path,\n                        },\n                    )\n                    return abs_path\n            return value\n        else:\n            return value\n\n    return _process_value(config)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.file_utils.archive_run","title":"<code>archive_run(timestamp)</code>","text":"<p>Archives a run (simulation or analysis) based on its configuration.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>str</code> <p>The timestamp directory name of the run to archive.</p> required Note <p>Determines run type (analysis vs simulation) from configuration. Delegates to _archive_run() with appropriate run_type. Extracts configuration from log files using restore_configs_from_log().</p> Source code in <code>tricys/utils/file_utils.py</code> <pre><code>def archive_run(timestamp: str) -&gt; None:\n    \"\"\"Archives a run (simulation or analysis) based on its configuration.\n\n    Args:\n        timestamp: The timestamp directory name of the run to archive.\n\n    Note:\n        Determines run type (analysis vs simulation) from configuration. Delegates\n        to _archive_run() with appropriate run_type. Extracts configuration from\n        log files using restore_configs_from_log().\n    \"\"\"\n\n    configs = restore_configs_from_log(timestamp)\n    if not configs:\n        return\n    runtime_config, original_config = configs\n    logger.info(\"Successfully extracted both runtime and original configurations.\")\n\n    is_analysis = \"sensitivity_analysis\" in original_config and original_config.get(\n        \"sensitivity_analysis\", {}\n    ).get(\"enabled\", False)\n\n    if is_analysis:\n        _archive_run(timestamp, \"analysis\")\n    else:\n        _archive_run(timestamp, \"simulation\")\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.file_utils.get_unique_filename","title":"<code>get_unique_filename(base_path, filename)</code>","text":"<p>Generates a unique filename by appending a counter if the file already exists.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>The directory path where the file will be saved.</p> required <code>filename</code> <code>str</code> <p>The desired filename, including the extension.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A unique, non-existing file path.</p> Note <p>Appends _1, _2, etc. before the extension until a non-existing filename is found. Example: if \"data.csv\" exists, returns \"data_1.csv\", then \"data_2.csv\", etc.</p> Source code in <code>tricys/utils/file_utils.py</code> <pre><code>def get_unique_filename(base_path: str, filename: str) -&gt; str:\n    \"\"\"Generates a unique filename by appending a counter if the file already exists.\n\n    Args:\n        base_path: The directory path where the file will be saved.\n        filename: The desired filename, including the extension.\n\n    Returns:\n        A unique, non-existing file path.\n\n    Note:\n        Appends _1, _2, etc. before the extension until a non-existing filename is found.\n        Example: if \"data.csv\" exists, returns \"data_1.csv\", then \"data_2.csv\", etc.\n    \"\"\"\n    base_name, ext = os.path.splitext(filename)\n    counter = 0\n    new_filename = filename\n    new_filepath = os.path.join(base_path, new_filename)\n\n    while os.path.exists(new_filepath):\n        counter += 1\n        new_filename = f\"{base_name}_{counter}{ext}\"\n        new_filepath = os.path.join(base_path, new_filename)\n\n    return new_filepath\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.file_utils.unarchive_run","title":"<code>unarchive_run(zip_file)</code>","text":"<p>Unarchives a simulation run from a zip file.</p> <p>Parameters:</p> Name Type Description Default <code>zip_file</code> <code>str</code> <p>Path to the zip file to extract.</p> required <p>Raises:</p> Type Description <code>SystemExit</code> <p>If zip file not found or extraction fails.</p> Note <p>Extracts to current directory if empty, otherwise creates new directory named after the zip file. Sets up basic logging for the unarchive process. Handles BadZipFile exceptions gracefully.</p> Source code in <code>tricys/utils/file_utils.py</code> <pre><code>def unarchive_run(zip_file: str) -&gt; None:\n    \"\"\"Unarchives a simulation run from a zip file.\n\n    Args:\n        zip_file: Path to the zip file to extract.\n\n    Raises:\n        SystemExit: If zip file not found or extraction fails.\n\n    Note:\n        Extracts to current directory if empty, otherwise creates new directory\n        named after the zip file. Sets up basic logging for the unarchive process.\n        Handles BadZipFile exceptions gracefully.\n    \"\"\"\n    # Basic logging setup for unarchive command\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        stream=sys.stdout,\n    )\n    logger = logging.getLogger(__name__)\n\n    if not os.path.isfile(zip_file):\n        logger.error(f\"Archive file not found: {zip_file}\")\n        sys.exit(1)\n\n    target_dir = \".\"\n    if os.listdir(\".\"):  # If the list of CWD contents is not empty\n        dir_name = os.path.splitext(os.path.basename(zip_file))[0]\n        target_dir = dir_name\n        logger.info(\n            f\"Current directory is not empty. Extracting to new directory: {target_dir}\"\n        )\n        os.makedirs(target_dir, exist_ok=True)\n    else:\n        logger.info(\"Current directory is empty. Extracting to current directory.\")\n\n    # Unzip the file\n    try:\n        with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n            zip_ref.extractall(target_dir)\n        logger.info(\n            f\"Successfully unarchived '{zip_file}' to '{os.path.abspath(target_dir)}'\"\n        )\n    except zipfile.BadZipFile:\n        logger.error(f\"Error: '{zip_file}' is not a valid zip file.\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"An error occurred during unarchiving: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.delete_old_logs","title":"<code>delete_old_logs(log_path, max_files)</code>","text":"<p>Deletes the oldest log files in a directory to meet a specified limit.</p> <p>Checks the number of <code>.log</code> files in the given directory and removes the oldest ones based on modification time until the file count matches the <code>max_files</code> limit.</p> <p>Parameters:</p> Name Type Description Default <code>log_path</code> <code>str</code> <p>The path to the directory containing log files.</p> required <code>max_files</code> <code>int</code> <p>The maximum number of <code>.log</code> files to retain.</p> required Note <p>Only processes files with .log extension. Sorts by modification time (oldest first) before deletion. Does nothing if current count &lt;= max_files.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def delete_old_logs(log_path: str, max_files: int) -&gt; None:\n    \"\"\"Deletes the oldest log files in a directory to meet a specified limit.\n\n    Checks the number of `.log` files in the given directory and removes the\n    oldest ones based on modification time until the file count matches the\n    `max_files` limit.\n\n    Args:\n        log_path: The path to the directory containing log files.\n        max_files: The maximum number of `.log` files to retain.\n\n    Note:\n        Only processes files with .log extension. Sorts by modification time\n        (oldest first) before deletion. Does nothing if current count &lt;= max_files.\n    \"\"\"\n    log_files = [\n        os.path.join(log_path, f) for f in os.listdir(log_path) if f.endswith(\".log\")\n    ]\n\n    if len(log_files) &gt; max_files:\n        # Sort by modification time, oldest first\n        log_files.sort(key=os.path.getmtime)\n\n        # Calculate how many files to delete\n        files_to_delete_count = len(log_files) - max_files\n\n        # Delete the oldest files\n        for i in range(files_to_delete_count):\n            os.remove(log_files[i])\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.log_execution_time","title":"<code>log_execution_time(func)</code>","text":"<p>A decorator to log the execution time of a function.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The function to be decorated.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>The wrapped function that logs execution time.</p> Note <p>Measures execution time using time.perf_counter(). Logs function name, module, and duration in milliseconds. Uses structured logging with extra fields.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def log_execution_time(func: Callable) -&gt; Callable:\n    \"\"\"A decorator to log the execution time of a function.\n\n    Args:\n        func: The function to be decorated.\n\n    Returns:\n        The wrapped function that logs execution time.\n\n    Note:\n        Measures execution time using time.perf_counter(). Logs function name,\n        module, and duration in milliseconds. Uses structured logging with extra fields.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        duration_ms = (end_time - start_time) * 1000\n\n        logger.info(\n            \"Function executed\",\n            extra={\n                \"function_name\": func.__name__,\n                \"function_module\": func.__module__,\n                \"duration_ms\": round(duration_ms, 2),\n            },\n        )\n        return result\n\n    return wrapper\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.restore_configs_from_log","title":"<code>restore_configs_from_log(timestamp)</code>","text":"<p>Finds the log file for a given timestamp and restores configurations.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>str</code> <p>The timestamp directory name to search for log files.</p> required <p>Returns:</p> Type Description <code>tuple[Dict[str, Any] | None, Dict[str, Any] | None]</code> <p>A tuple of (runtime_config, original_config) or (None, None) if not found.</p> Note <p>Searches in timestamp/simulation_{timestamp}.log and timestamp/log/ directory. Parses JSON log entries to find \"Runtime Configuration\" and \"Original Configuration\" messages. Returns parsed configurations as dictionaries.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def restore_configs_from_log(\n    timestamp: str,\n) -&gt; tuple[Dict[str, Any] | None, Dict[str, Any] | None]:\n    \"\"\"Finds the log file for a given timestamp and restores configurations.\n\n    Args:\n        timestamp: The timestamp directory name to search for log files.\n\n    Returns:\n        A tuple of (runtime_config, original_config) or (None, None) if not found.\n\n    Note:\n        Searches in timestamp/simulation_{timestamp}.log and timestamp/log/ directory.\n        Parses JSON log entries to find \"Runtime Configuration\" and \"Original Configuration\"\n        messages. Returns parsed configurations as dictionaries.\n    \"\"\"\n    log_file_path = None\n    # Define potential locations for the log file\n    search_paths = [\n        os.path.join(timestamp, f\"simulation_{timestamp}.log\"),  # analysis style\n        os.path.join(timestamp, \"log\"),  # simulation style\n    ]\n\n    for path in search_paths:\n        if os.path.isfile(path):\n            log_file_path = path\n            break\n        if os.path.isdir(path):\n            for f in os.listdir(path):\n                if f.startswith(\"simulation_\") and f.endswith(\".log\"):\n                    log_file_path = os.path.join(path, f)\n                    break\n            if log_file_path:\n                break\n\n    if not log_file_path:\n        print(\n            f\"ERROR: Main log file not found for timestamp {timestamp}\", file=sys.stderr\n        )\n        return None, None\n\n    runtime_config_str = None\n    original_config_str = None\n    try:\n        with open(log_file_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                try:\n                    log_entry = json.loads(line)\n                    if \"message\" in log_entry:\n                        if log_entry[\"message\"].startswith(\n                            \"Runtime Configuration (compact JSON):\"\n                        ):\n                            runtime_config_str = log_entry[\"message\"].replace(\n                                \"Runtime Configuration (compact JSON): \", \"\"\n                            )\n                        elif log_entry[\"message\"].startswith(\n                            \"Original Configuration (compact JSON):\"\n                        ):\n                            original_config_str = log_entry[\"message\"].replace(\n                                \"Original Configuration (compact JSON): \", \"\"\n                            )\n                    if runtime_config_str and original_config_str:\n                        break\n                except json.JSONDecodeError:\n                    continue\n    except Exception as e:\n        print(f\"ERROR: Failed to read log file {log_file_path}: {e}\", file=sys.stderr)\n        return None, None\n\n    if not runtime_config_str or not original_config_str:\n        print(\n            \"ERROR: Could not find runtime and/or original configuration in log file.\",\n            file=sys.stderr,\n        )\n        return None, None\n\n    try:\n        runtime_config = json.loads(runtime_config_str)\n        original_config = json.loads(original_config_str)\n        return runtime_config, original_config\n    except json.JSONDecodeError as e:\n        print(\n            f\"ERROR: Failed to parse configuration from log file: {e}\", file=sys.stderr\n        )\n        return None, None\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.log_utils.setup_logging","title":"<code>setup_logging(config, original_config=None)</code>","text":"<p>Configures the logging module based on the application configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary containing logging settings.</p> required <code>original_config</code> <code>Dict[str, Any]</code> <p>Optional original configuration for additional logging.</p> <code>None</code> Note <p>Sets up JSON formatted logging to console and/or file. Manages log file rotation via delete_old_logs(). Supports main_log_path for analysis cases. Logs both runtime and original configurations in compact JSON format. Clears existing handlers to prevent duplicates.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def setup_logging(\n    config: Dict[str, Any], original_config: Dict[str, Any] = None\n) -&gt; None:\n    \"\"\"Configures the logging module based on the application configuration.\n\n    Args:\n        config: The main configuration dictionary containing logging settings.\n        original_config: Optional original configuration for additional logging.\n\n    Note:\n        Sets up JSON formatted logging to console and/or file. Manages log file rotation\n        via delete_old_logs(). Supports main_log_path for analysis cases. Logs both\n        runtime and original configurations in compact JSON format. Clears existing\n        handlers to prevent duplicates.\n    \"\"\"\n    log_config = config.get(\"logging\", {})\n    log_level_str = log_config.get(\"log_level\", \"INFO\").upper()\n    log_level = getattr(logging, log_level_str, logging.INFO)\n    log_to_console = log_config.get(\"log_to_console\", True)\n    run_timestamp = config.get(\"run_timestamp\")\n\n    log_dir_path = config.get(\"paths\", {}).get(\"log_dir\")\n    log_count = log_config.get(\"log_count\", 5)\n\n    root_logger = logging.getLogger()\n    root_logger.setLevel(log_level)\n\n    # Clear any existing handlers to prevent duplicate logs\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n        handler.close()\n\n    formatter = jsonlogger.JsonFormatter(\n        \"%(asctime)s %(name)s %(levelname)s %(message)s\"\n    )\n\n    if log_to_console:\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setFormatter(formatter)\n        root_logger.addHandler(console_handler)\n\n    if log_dir_path:\n        abs_log_dir = os.path.abspath(log_dir_path)\n        os.makedirs(abs_log_dir, exist_ok=True)\n        delete_old_logs(abs_log_dir, log_count)\n        log_file_path = os.path.join(abs_log_dir, f\"simulation_{run_timestamp}.log\")\n\n        file_handler = logging.FileHandler(log_file_path, mode=\"a\", encoding=\"utf-8\")\n        file_handler.setFormatter(formatter)\n        root_logger.addHandler(file_handler)\n\n        # If a main log path is provided (for analysis cases), add it as an additional handler\n        main_log_path = log_config.get(\"main_log_path\")\n        if main_log_path:\n            try:\n                # Ensure the directory for the main log exists, just in case\n                os.makedirs(os.path.dirname(main_log_path), exist_ok=True)\n\n                main_log_handler = logging.FileHandler(\n                    main_log_path, mode=\"a\", encoding=\"utf-8\"\n                )\n                main_log_handler.setFormatter(formatter)\n                root_logger.addHandler(main_log_handler)\n                logger.info(f\"Also logging to main log file: {main_log_path}\")\n            except Exception as e:\n                logger.warning(\n                    f\"Failed to attach main log handler for {main_log_path}: {e}\"\n                )\n\n        logger.info(f\"Logging to file: {log_file_path}\")\n        # Log the full runtime configuration in a compact JSON format\n        logger.info(\n            f\"Runtime Configuration (compact JSON): {json.dumps(config, separators=(',', ':'), ensure_ascii=False)}\"\n        )\n        if original_config:\n            logger.info(\n                f\"Original Configuration (compact JSON): {json.dumps(original_config, separators=(',', ':'), ensure_ascii=False)}\"\n            )\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.create_parameters_table","title":"<code>create_parameters_table(db_path)</code>","text":"<p>Creates the parameters table in the database if it does not exist.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If a database error occurs during table creation.</p> Note <p>Creates parent directories if they don't exist. Table schema includes: name (TEXT PRIMARY KEY), type, default_value, sweep_values, description, dimensions. Uses CREATE TABLE IF NOT EXISTS for safe repeated calls.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def create_parameters_table(db_path: str) -&gt; None:\n    \"\"\"Creates the parameters table in the database if it does not exist.\n\n    Args:\n        db_path: The path to the SQLite database file.\n\n    Raises:\n        sqlite3.Error: If a database error occurs during table creation.\n\n    Note:\n        Creates parent directories if they don't exist. Table schema includes:\n        name (TEXT PRIMARY KEY), type, default_value, sweep_values, description, dimensions.\n        Uses CREATE TABLE IF NOT EXISTS for safe repeated calls.\n    \"\"\"\n    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n    logger.debug(f\"Ensuring 'parameters' table exists in {db_path}\")\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS parameters (\n                    name TEXT PRIMARY KEY,\n                    type TEXT,\n                    default_value TEXT,\n                    sweep_values TEXT,\n                    description TEXT,\n                    dimensions TEXT\n                )\n            \"\"\"\n            )\n            conn.commit()\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while creating table: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.get_parameters_from_db","title":"<code>get_parameters_from_db(db_path)</code>","text":"<p>Retrieves parameter details from the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>A list of parameter dictionaries, each containing the name, default_value,</p> <code>List[Dict[str, Any]]</code> <p>description, and sweep_values.</p> Note <p>JSON-decodes stored values. Returns empty string for sweep_values if None. Result dict keys: name, default_value, description, sweep_values.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def get_parameters_from_db(db_path: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"Retrieves parameter details from the database.\n\n    Args:\n        db_path: The path to the SQLite database file.\n\n    Returns:\n        A list of parameter dictionaries, each containing the name, default_value,\n        description, and sweep_values.\n\n    Note:\n        JSON-decodes stored values. Returns empty string for sweep_values if None.\n        Result dict keys: name, default_value, description, sweep_values.\n    \"\"\"\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(\n            \"SELECT name, default_value, description, sweep_values FROM parameters\"\n        )\n        params = []\n        for name, default_value, description, sweep_values in cursor.fetchall():\n            params.append(\n                {\n                    \"name\": name,\n                    \"default_value\": json.loads(default_value),\n                    \"description\": description,\n                    \"sweep_values\": json.loads(sweep_values) if sweep_values else \"\",\n                }\n            )\n    return params\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.store_parameters_in_db","title":"<code>store_parameters_in_db(db_path, params_data)</code>","text":"<p>Stores or replaces a list of parameter details in the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <code>params_data</code> <code>List[Dict[str, Any]]</code> <p>A list of dictionaries, where each dictionary contains details for a single parameter.</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If a database error occurs during insertion.</p> Note <p>Uses INSERT OR REPLACE for upsert behavior. JSON-encodes defaultValue and stores dimensions with '()' default. Skips parameters without names. Expected param dict keys: name, type, defaultValue, comment, dimensions.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def store_parameters_in_db(db_path: str, params_data: List[Dict[str, Any]]) -&gt; None:\n    \"\"\"Stores or replaces a list of parameter details in the database.\n\n    Args:\n        db_path: The path to the SQLite database file.\n        params_data: A list of dictionaries, where each dictionary contains\n            details for a single parameter.\n\n    Raises:\n        sqlite3.Error: If a database error occurs during insertion.\n\n    Note:\n        Uses INSERT OR REPLACE for upsert behavior. JSON-encodes defaultValue\n        and stores dimensions with '()' default. Skips parameters without names.\n        Expected param dict keys: name, type, defaultValue, comment, dimensions.\n    \"\"\"\n    logger.info(f\"Storing {len(params_data)} parameters into '{db_path}'\")\n    if not params_data:\n        logger.warning(\"Parameter data is empty, nothing to store.\")\n        return\n\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            for param in params_data:\n                name = param.get(\"name\")\n                if not name:\n                    continue\n\n                value_json = json.dumps(param.get(\"defaultValue\"))\n                dimensions = param.get(\n                    \"dimensions\", \"()\"\n                )  # Default to '()' if not present\n\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO parameters (name, type, default_value, sweep_values, description, dimensions)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        name,\n                        param.get(\"type\", \"Real\"),\n                        value_json,\n                        None,\n                        param.get(\"comment\", \"\"),\n                        dimensions,\n                    ),\n                )\n            conn.commit()\n        logger.info(\"Successfully stored/updated parameters in the database.\")\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while storing parameters: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"api/tricys_utils.html#tricys.utils.sqlite_utils.update_sweep_values_in_db","title":"<code>update_sweep_values_in_db(db_path, param_sweep)</code>","text":"<p>Updates the 'sweep_values' for specified parameters in the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <code>param_sweep</code> <code>Dict[str, Any]</code> <p>A dictionary where keys are parameter names and values are the corresponding sweep values (e.g., a list).</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If a database error occurs during the update.</p> Note <p>Converts numpy arrays to lists before JSON encoding. Warns if parameter not found in database. Uses UPDATE statement so parameters must exist before calling this function.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def update_sweep_values_in_db(db_path: str, param_sweep: Dict[str, Any]) -&gt; None:\n    \"\"\"Updates the 'sweep_values' for specified parameters in the database.\n\n    Args:\n        db_path: The path to the SQLite database file.\n        param_sweep: A dictionary where keys are parameter names and values are\n            the corresponding sweep values (e.g., a list).\n\n    Raises:\n        sqlite3.Error: If a database error occurs during the update.\n\n    Note:\n        Converts numpy arrays to lists before JSON encoding. Warns if parameter\n        not found in database. Uses UPDATE statement so parameters must exist\n        before calling this function.\n    \"\"\"\n    logger.info(f\"Updating sweep values in '{db_path}'\")\n    if not param_sweep:\n        logger.warning(\"param_sweep dictionary is empty. No values to update.\")\n        return\n\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            for param_name, sweep_values in param_sweep.items():\n                if isinstance(sweep_values, np.ndarray):\n                    sweep_values = sweep_values.tolist()\n\n                sweep_values_json = json.dumps(sweep_values)\n\n                cursor.execute(\n                    \"\"\"\n                    UPDATE parameters SET sweep_values = ? WHERE name = ?\n                \"\"\",\n                    (sweep_values_json, param_name),\n                )\n\n                if cursor.rowcount == 0:\n                    logger.warning(\n                        f\"Parameter '{param_name}' not found in database. No sweep value updated.\"\n                    )\n            conn.commit()\n        logger.info(\"Sweep values updated successfully.\")\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while updating sweep values: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"explanation/architecture.html","title":"\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1","text":""},{"location":"explanation/architecture.html#1","title":"1. \u6574\u4f53\u67b6\u6784","text":"<p>TRICYS \u91c7\u7528\u5206\u5c42\u67b6\u6784\u8bbe\u8ba1\uff0c\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u51e0\u5c42\uff1a</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u7528\u6237\u754c\u9762\u5c42             \n\u2502 tricys basic, tricys analysis, tricys gui       \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u4eff\u771f\u6267\u884c\u5c42                     \n\u2502     simulation, simulation_analysis    \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u6838\u5fc3\u529f\u80fd\u5c42                     \n\u2502      Jobs, Modelica, Interceptor            \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             \u5206\u6790\u4e0e\u540e\u5904\u7406\u5c42                   \n\u2502       Metric, Plot, Report, SALib           \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               \u5de5\u5177\u51fd\u6570\u5c42                     \n\u2502      Config, File, Log, SQLite Utils        \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                \u5916\u90e8\u4f9d\u8d56\u5c42                    \n\u2502     OpenModelica, Pandas, NumPy, SALib      \n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"explanation/architecture.html#2","title":"2. \u7a0b\u5e8f\u5206\u5c42","text":""},{"location":"explanation/architecture.html#21","title":"2.1. \u7528\u6237\u754c\u9762\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/main.py</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u63d0\u4f9b\u547d\u4ee4\u884c\u63a5\u53e3\uff08CLI\uff09\u548c\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u4e24\u79cd\u4ea4\u4e92\u65b9\u5f0f</li> <li>\u89e3\u6790\u7528\u6237\u8f93\u5165\u7684\u547d\u4ee4\u884c\u53c2\u6570\u548c\u5b50\u547d\u4ee4\uff08<code>basic</code>, <code>analysis</code>, <code>gui</code>, <code>example</code>, <code>archive</code>, <code>unarchive</code>\uff09</li> <li>\u8def\u7531\u8bf7\u6c42\u5230\u76f8\u5e94\u7684\u4eff\u771f\u6267\u884c\u5c42\u6a21\u5757</li> <li>\u7ba1\u7406\u7528\u6237\u4f1a\u8bdd\u548c\u914d\u7f6e\u6587\u4ef6\u52a0\u8f7d</li> </ul> <p>\u5173\u952e\u529f\u80fd\uff1a</p> <ul> <li>CLI \u547d\u4ee4\u5206\u53d1\uff1a\u6839\u636e\u5b50\u547d\u4ee4\u6216\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9\u81ea\u52a8\u8bc6\u522b\u8fd0\u884c\u6a21\u5f0f</li> <li>GUI \u4ea4\u4e92\u754c\u9762\uff1a\u63d0\u4f9b\u53ef\u89c6\u5316\u7684\u53c2\u6570\u8bbe\u7f6e\u3001\u4eff\u771f\u542f\u52a8\u548c\u7ed3\u679c\u67e5\u770b\u529f\u80fd</li> <li>\u793a\u4f8b\u8fd0\u884c\u5668\uff1a\u96c6\u6210\u4ea4\u4e92\u5f0f\u793a\u4f8b\u9009\u62e9\u548c\u8fd0\u884c\u529f\u80fd</li> </ul>"},{"location":"explanation/architecture.html#22","title":"2.2. \u4eff\u771f\u6267\u884c\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/simulation/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u57fa\u7840\u4eff\u771f\u6a21\u5f0f (<code>simulation.py</code>)\uff1a\u6267\u884c\u5355\u6b21\u6216\u53c2\u6570\u626b\u63cf\u4eff\u771f\u4efb\u52a1</li> <li>\u7075\u654f\u5ea6\u5206\u6790\u6a21\u5f0f (<code>simulation_analysis.py</code>)\uff1a\u6267\u884c\u591a\u79cd\u654f\u611f\u6027\u5206\u6790\u5de5\u4f5c\u6d41</li> <li>\u7ba1\u7406\u4eff\u771f\u4efb\u52a1\u7684\u5b8c\u6574\u751f\u547d\u5468\u671f\uff08\u521d\u59cb\u5316\u3001\u6267\u884c\u3001\u540e\u5904\u7406\uff09</li> <li>\u534f\u8c03\u6838\u5fc3\u529f\u80fd\u5c42\u3001\u5206\u6790\u5c42\u548c\u540e\u5904\u7406\u5c42\u7684\u8c03\u7528</li> </ul> <p>\u8be6\u89c1\uff1a\u4eff\u771f\u6267\u884c\u6d41\u7a0b \u548c \u81ea\u52a8\u5206\u6790\u6d41\u7a0b</p>"},{"location":"explanation/architecture.html#23","title":"2.3. \u6838\u5fc3\u529f\u80fd\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/core/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>Modelica \u4ea4\u4e92 (<code>modelica.py</code>)\uff1a\u901a\u8fc7 OMPython \u4e0e OpenModelica \u5f15\u64ce\u901a\u4fe1</li> <li>\u4efb\u52a1\u751f\u6210 (<code>jobs.py</code>)\uff1a\u6839\u636e\u914d\u7f6e\u751f\u6210\u53c2\u6570\u626b\u63cf\u4efb\u52a1\u548c\u4eff\u771f\u4f5c\u4e1a</li> <li>\u62e6\u622a\u5668\u673a\u5236 (<code>interceptor.py</code>)\uff1a\u751f\u6210\u548c\u96c6\u6210\u62e6\u622a\u5668\u6a21\u578b\uff0c\u5b9e\u73b0\u534f\u540c\u4eff\u771f</li> </ul> <p>\u8be6\u89c1\uff1aAPI \u53c2\u8003 - \u6838\u5fc3\u6a21\u5757 (Core)</p>"},{"location":"explanation/architecture.html#24","title":"2.4. \u5206\u6790\u4e0e\u540e\u5904\u7406\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/analysis/</code>, <code>tricys/postprocess/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u6027\u80fd\u6307\u6807\u8ba1\u7b97 (<code>analysis/metric.py</code>)\uff1a\u8ba1\u7b97\u542f\u52a8\u76d8\u5b58\u3001\u500d\u589e\u65f6\u95f4\u3001\u8f6c\u6298\u70b9\u7b49\u5173\u952e\u6307\u6807</li> <li>\u6570\u636e\u53ef\u89c6\u5316 (<code>analysis/plot.py</code>)\uff1a\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u56fe\u3001\u53c2\u6570\u626b\u63cf\u56fe\u3001\u5bf9\u6bd4\u56fe\u7b49</li> <li>\u7075\u654f\u5ea6\u5206\u6790 (<code>analysis/salib.py</code>)\uff1a\u96c6\u6210 SALib \u5e93\u6267\u884c\u591a\u79cd\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5</li> <li>\u5206\u6790\u62a5\u544a\u751f\u6210 (<code>analysis/report.py</code>)\uff1a\u81ea\u52a8\u751f\u6210 Markdown \u683c\u5f0f\u7684\u5206\u6790\u62a5\u544a\uff0c\u652f\u6301 AI \u589e\u5f3a</li> <li>\u540e\u5904\u7406\u6a21\u5757 (<code>postprocess/</code>)\uff1a\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6570\u636e\u540e\u5904\u7406\u529f\u80fd</li> </ul> <p>\u8be6\u89c1\uff1aAPI \u53c2\u8003 - \u5206\u6790\u6a21\u5757 (Analysis)</p>"},{"location":"explanation/architecture.html#25","title":"2.5. \u5de5\u5177\u51fd\u6570\u5c42","text":"<p>\u4f4d\u7f6e\uff1a<code>tricys/utils/</code></p> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u914d\u7f6e\u7ba1\u7406 (<code>config_utils.py</code>)\uff1a\u914d\u7f6e\u6587\u4ef6\u52a0\u8f7d\u3001\u9a8c\u8bc1\u548c\u9884\u5904\u7406</li> <li>\u6587\u4ef6\u64cd\u4f5c (<code>file_utils.py</code>)\uff1a\u6587\u4ef6\u8def\u5f84\u5904\u7406\u3001\u552f\u4e00\u6587\u4ef6\u540d\u751f\u6210\u3001\u5f52\u6863\u7ba1\u7406</li> <li>\u65e5\u5fd7\u7cfb\u7edf (<code>log_utils.py</code>)\uff1a\u7ed3\u6784\u5316\u65e5\u5fd7\u8bb0\u5f55\u548c\u914d\u7f6e\u6062\u590d</li> <li>\u6570\u636e\u5e93\u64cd\u4f5c (<code>sqlite_utils.py</code>)\uff1aSQLite \u6570\u636e\u5b58\u50a8\u548c\u67e5\u8be2</li> </ul> <p>\u8be6\u89c1\uff1aAPI \u53c2\u8003 - \u5de5\u5177\u51fd\u6570 (Utilities)</p>"},{"location":"explanation/architecture.html#26","title":"2.6. \u5916\u90e8\u4f9d\u8d56\u5c42","text":"<p>\u4e3b\u8981\u4f9d\u8d56\uff1a</p> <ul> <li>OpenModelica\uff1aModelica \u6a21\u578b\u7f16\u8bd1\u548c\u4eff\u771f\u6267\u884c\u5f15\u64ce</li> <li>OMPython\uff1aPython \u4e0e OpenModelica \u7684\u63a5\u53e3\u5e93</li> <li>SALib\uff1a\u654f\u611f\u6027\u5206\u6790\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5e93</li> <li>Pandas/NumPy\uff1a\u6570\u636e\u5904\u7406\u548c\u6570\u503c\u8ba1\u7b97</li> <li>Matplotlib/Seaborn\uff1a\u6570\u636e\u53ef\u89c6\u5316</li> <li>OpenAI\uff08\u53ef\u9009\uff09\uff1aAI \u589e\u5f3a\u7684\u5206\u6790\u62a5\u544a\u751f\u6210</li> </ul> <p>\u804c\u8d23\uff1a</p> <ul> <li>\u63d0\u4f9b\u5e95\u5c42\u7684\u4eff\u771f\u5f15\u64ce\u3001\u6570\u503c\u8ba1\u7b97\u548c\u79d1\u5b66\u8ba1\u7b97\u652f\u6301</li> <li>\u786e\u4fdd\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u80fd\u529b</li> </ul>"},{"location":"explanation/architecture.html#3","title":"3. \u8bbe\u8ba1\u539f\u5219","text":"<ol> <li>\u6a21\u5757\u5316\uff1a\u6bcf\u4e2a\u529f\u80fd\u6a21\u5757\u804c\u8d23\u5355\u4e00\uff0c\u76f8\u4e92\u72ec\u7acb</li> <li>\u53ef\u6269\u5c55\uff1a\u6613\u4e8e\u6dfb\u52a0\u65b0\u7684\u540e\u5904\u7406\u6a21\u5757\u3001\u6027\u80fd\u6307\u6807\u548c\u534f\u540c\u4eff\u771f\u5904\u7406\u5668</li> <li>\u914d\u7f6e\u9a71\u52a8\uff1a\u6240\u6709\u4eff\u771f\u4efb\u52a1\u901a\u8fc7 JSON \u914d\u7f6e\u6587\u4ef6\u5b9a\u4e49</li> <li>\u81ea\u52a8\u5316\uff1a\u4ece\u4eff\u771f\u5230\u5206\u6790\u62a5\u544a\u751f\u6210\u7684\u5168\u6d41\u7a0b\u81ea\u52a8\u5316</li> <li>\u5f00\u653e\u6027\uff1a\u5f00\u6e90\u8bbe\u8ba1\uff0c\u652f\u6301\u793e\u533a\u8d21\u732e</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_flow.html","title":"\u81ea\u52a8\u5206\u6790\u6d41\u7a0b","text":"<p><code>tricys</code> \u7684\u5206\u6790\u5de5\u4f5c\u6d41 (<code>simulation_analysis.py</code>) \u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u4ee5\u5206\u6790\u4e3a\u5bfc\u5411\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u3002\u5b83\u5728\u6838\u5fc3\u4eff\u771f\u529f\u80fd\u4e4b\u4e0a\uff0c\u6784\u5efa\u4e86\u590d\u6742\u7684\u591a\u6a21\u5f0f\u8c03\u5ea6\u3001\u76ee\u6807\u5bfb\u4f18\u548c\u62a5\u544a\u751f\u6210\u80fd\u529b\u3002\u672c\u7bc7\u6587\u6863\u5c06\u8be6\u7ec6\u89e3\u6790\u5176\u5185\u90e8\u7684\u5b8c\u6574\u5de5\u4f5c\u6d41\u7a0b\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_flow.html#1","title":"1. \u6838\u5fc3\u6d41\u7a0b\u56fe","text":"<p>\u4e0b\u9762\u662f <code>tricys</code> \u5206\u6790\u5de5\u4f5c\u6d41\u7684\u5b8c\u6574\u6d41\u7a0b\u56fe\u3002\u5b83\u4ece\u8bfb\u53d6\u914d\u7f6e\u5f00\u59cb\uff0c\u667a\u80fd\u5730\u9009\u62e9\u4e09\u79cd\u4e3b\u8981\u64cd\u4f5c\u6a21\u5f0f\u4e4b\u4e00\uff0c\u5e76\u6267\u884c\u76f8\u5e94\u7684\u4efb\u52a1\u76f4\u5230\u7ed3\u675f\u3002</p> <pre><code>graph TD\n    %% === 1. \u542f\u52a8\u9636\u6bb5 ===\n    subgraph Sub_A [\"A. \u542f\u52a8\u4e0e\u6a21\u5f0f\u9009\u62e9\"]\n        A1[\u5f00\u59cb: main config.json] --&gt; A2[\"\u51c6\u5907\u914d\u7f6e\u4e0e\u65e5\u5fd7&lt;br&gt;analysis_prepare_config()\"]\n        A2 --&gt; A3{\"&lt;font size=4&gt;&lt;b&gt;\u8fd0\u884c\u6a21\u5f0f\u5224\u65ad&lt;/b&gt;&lt;/font&gt;&lt;br&gt;\u5728 run_simulation() \u5185\u90e8\"}\n    end\n\n    %% \u6a21\u5f0f\u5224\u5b9a\u903b\u8f91\n    A3 --&gt; B_GROUP{analysis_cases \u662f\u5426\u5b58\u5728?}\n    B_GROUP -- \u662f --&gt; C1\n    B_GROUP -- \u5426 --&gt; D_GROUP{\u662f\u5426\u4e3a SALib \u5206\u6790?}\n\n    D_GROUP -- \u662f --&gt; E1\n    D_GROUP -- \u5426 --&gt; F1\n\n    %% === 2. \u6a21\u5f0f\u4e00 ===\n    subgraph Sub_C [\"C. \u6a21\u5f0f\u4e00: \u591a\u6848\u4f8b\u5206\u6790\"]\n        direction TB\n        C1[\"&lt;b&gt;\u6a21\u5f0f\u4e00: \u591a\u6848\u4f8b\u5206\u6790&lt;/b&gt;\"]\n        C1 --&gt; C2[\u4e3a\u6bcf\u4e2a\u6848\u4f8b\u521b\u5efa&lt;br&gt;\u72ec\u7acb\u5de5\u4f5c\u76ee\u5f55\u548c\u914d\u7f6e]\n        C2 --&gt; C3{\u5e76\u884c\u6267\u884c\u6848\u4f8b?&lt;br&gt;concurrent_cases}\n\n        C3 -- \u662f --&gt; C4[\u4f7f\u7528 &lt;b&gt;ProcessPoolExecutor&lt;/b&gt;&lt;br&gt;\u5e76\u884c\u8c03\u7528 _execute_analysis_case]\n        C3 -- \u5426 --&gt; C5[\u4e32\u884c\u5faa\u73af&lt;br&gt;\u9010\u4e2a\u8c03\u7528 _execute_analysis_case]\n\n        %% \u5b50\u56fe\uff1a\u5355\u4e2a\u6848\u4f8b\u6267\u884c\n        subgraph Sub_C6 [\"C6. \u5355\u4e2a\u6848\u4f8b\u7684\u6267\u884c _execute_analysis_case\"]\n            direction TB\n            C6_1[\u8fdb\u5165\u72ec\u7acb\u5de5\u4f5c\u76ee\u5f55] --&gt; C6_2[\"&lt;b&gt;\u9012\u5f52\u8c03\u7528 run_simulation&lt;br&gt;(\u7981\u7528\u5185\u90e8\u5e76\u53d1)&lt;/b&gt;\"] \n            C6_2 --&gt; C6_3[\u6267\u884c\u6a21\u5f0f\u4e09\u7684\u5b8c\u6574\u6d41\u7a0b]\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u7684\u7b2c\u4e00\u4e2a\u8282\u70b9 C6_1\uff0c\u800c\u4e0d\u662f\u5b50\u56fe\u672c\u8eab\n        C4 --&gt; C6_1\n        C5 --&gt; C6_1\n\n        C6_3 --&gt; C7[\u6240\u6709\u6848\u4f8b\u6267\u884c\u5b8c\u6bd5]\n        C7 --&gt; C8[\"\u6c47\u603b\u6240\u6709\u6848\u4f8b\u7684\u62a5\u544a&lt;br&gt;consolidate_reports()\"]\n        C8 --&gt; Z1[\u7ed3\u675f]\n    end\n\n    %% === 3. \u6a21\u5f0f\u4e8c ===\n    subgraph Sub_E [\"E. \u6a21\u5f0f\u4e8c: SALib \u5206\u6790\"]\n        direction TB\n        E1[\"&lt;b&gt;\u6a21\u5f0f\u4e8c: SALib \u5206\u6790&lt;/b&gt;\"] --&gt; E2[\u8c03\u7528 run_salib_analysis]\n\n        %% \u5b50\u56fe\uff1aSALib \u6d41\u7a0b\n        subgraph Sub_E3 [\"E3. SALib \u5185\u90e8\u6d41\u7a0b\"]\n            direction TB\n            E3_1[1. \u4f7f\u7528 SALib \u751f\u6210\u53c2\u6570\u6837\u672c] --&gt; E3_2[2. \u4e3a\u6bcf\u4e2a\u6837\u672c\u8fd0\u884c\u4eff\u771f] \n            E3_2 --&gt; E3_3[3. \u6536\u96c6\u7ed3\u679c\u5e76\u8ba1\u7b97\u654f\u611f\u5ea6\u6307\u6570]\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u8282\u70b9 E3_1\n        E2 --&gt; E3_1\n        E3_3 --&gt; Z2[\u7ed3\u675f]\n    end\n\n    %% === 4. \u6a21\u5f0f\u4e09 ===\n    subgraph Sub_F [\"F. \u6a21\u5f0f\u4e09: \u6807\u51c6\u626b\u63cf\u4e0e\u5206\u6790\"]\n        direction TB\n        F1[\"&lt;b&gt;\u6a21\u5f0f\u4e09: \u6807\u51c6\u626b\u63cf\u4e0e\u5206\u6790&lt;/b&gt;\"] --&gt; F2[\u751f\u6210\u4eff\u771f\u4efb\u52a1\u5217\u8868 jobs]\n        F2 --&gt; F3{\u5e76\u884c\u6267\u884c\u4efb\u52a1?&lt;br&gt;concurrent}\n\n        F3 -- \u662f --&gt; F4[\"\u4f7f\u7528 &lt;b&gt;ThreadPoolExecutor (\u6807\u51c6)&lt;/b&gt;&lt;br&gt;\u6216 &lt;b&gt;ProcessPoolExecutor (\u534f\u540c)&lt;/b&gt;&lt;br&gt;\u5e76\u884c\u6267\u884c\u6bcf\u4e2a\u4efb\u52a1\"]\n        F3 -- \u5426 --&gt; F5[\"\u4e32\u884c\u6267\u884c&lt;br&gt;_run_sequential_sweep()\"]\n\n        %% \u5b50\u56fe\uff1a\u5355\u4e2a\u4efb\u52a1\u6267\u884c\n        subgraph Sub_F6 [\"F6. \u5355\u4e2a\u4efb\u52a1\u7684\u6267\u884c _run_..._job\"]\n            direction TB\n            F6_1[1. \u5728\u9694\u79bb\u76ee\u5f55\u4e2d\u8fd0\u884c\u4eff\u771f] --&gt; F6_2{2. \u662f\u5426\u914d\u7f6e\u4e86\u4f18\u5316\u76ee\u6807?&lt;br&gt;Required_...}\n\n            F6_2 -- \u662f --&gt; F6_3[\"&lt;b&gt;\u4f18\u5316\u5b50\u6d41\u7a0b&lt;/b&gt;&lt;br&gt;\u8c03\u7528 _run_bisection_search_for_job\"]\n\n            %% \u5d4c\u5957\u5b50\u56fe\uff1a\u4e8c\u5206\u641c\u7d22\n            subgraph Sub_F6_4 [\"F6_4. \u4e8c\u5206\u641c\u7d22\u5faa\u73af\"]\n                F6_4_1[a. \u5728\u641c\u7d22\u8303\u56f4\u5185&lt;br&gt;\u8fed\u4ee3\u6267\u884c\u4eff\u771f] --&gt; F6_4_2[b. \u68c0\u67e5\u6307\u6807\u662f\u5426\u6ee1\u8db3\u6761\u4ef6] \n                F6_4_2 --&gt; F6_4_3[c. \u7f29\u5c0f\u641c\u7d22\u8303\u56f4]\n                F6_4_3 --&gt; F6_4_1\n            end\n\n            F6_3 --&gt; F6_4_1\n            F6_4_2 -- \u6ee1\u8db3\u6216\u7ed3\u675f --&gt; F6_5\n\n            F6_5[\"3. \u8fd4\u56de\u4eff\u771f\u7ed3\u679c\u8def\u5f84&lt;br&gt;\u548c&lt;b&gt;\u4f18\u5316\u7ed3\u679c&lt;/b&gt;\"]\n            F6_2 -- \u5426 --&gt; F6_5\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u8282\u70b9 F6_1\n        F4 --&gt; F6_1\n        F5 --&gt; F6_1\n\n        F6_5 --&gt; F7[\u6240\u6709\u4efb\u52a1\u6267\u884c\u5b8c\u6bd5]\n        F7 --&gt; F8[\"&lt;b&gt;\u7ed3\u679c\u805a\u5408\u4e0e\u540e\u5904\u7406&lt;/b&gt;\"]\n\n        %% \u5b50\u56fe\uff1a\u540e\u7eed\u6b65\u9aa4\n        subgraph Sub_F9 [\"F9. \u540e\u7eed\u6b65\u9aa4\"]\n            direction TB\n            F9_1[a. \u5408\u5e76\u4eff\u771f\u7ed3\u679c\u5230 sweep_results.csv] --&gt; F9_2[b. \u5408\u5e76\u4f18\u5316\u7ed3\u679c\u5230 requierd_tbr_summary.csv]\n            F9_2 --&gt; F9_3[\"c. \u6267\u884c\u654f\u611f\u6027\u5206\u6790&lt;br&gt;_run_sensitivity_analysis()&lt;br&gt;(\u63d0\u53d6\u6307\u6807\u3001\u751f\u6210\u56fe\u8868)\"]\n            F9_3 --&gt; F9_4[\"d. \u6267\u884c\u81ea\u5b9a\u4e49\u540e\u5904\u7406&lt;br&gt;_run_post_processing()\"]\n        end\n\n        %% \u4fee\u590d\u70b9\uff1a\u8fde\u63a5\u5230\u5b50\u56fe\u5185\u90e8\u8282\u70b9 F9_1\n        F8 --&gt; F9_1\n        F9_4 --&gt; Z3[\u7ed3\u675f]\n    end\n\n    %% \u6837\u5f0f\u5b9a\u4e49\n    style C1 fill:#e3f2fd,stroke:#333,stroke-width:2px\n    style E1 fill:#e8f5e9,stroke:#333,stroke-width:2px\n    style F1 fill:#fbe9e7,stroke:#333,stroke-width:2px</code></pre>"},{"location":"explanation/tricys_analysis/analysis_flow.html#2","title":"2. \u6d41\u7a0b\u6b65\u9aa4\u8be6\u89e3","text":""},{"location":"explanation/tricys_analysis/analysis_flow.html#21","title":"2.1. \u542f\u52a8\u4e0e\u6a21\u5f0f\u9009\u62e9","text":"<p>\u6574\u4e2a\u6d41\u7a0b\u59cb\u4e8e <code>main</code> \u51fd\u6570\uff0c\u5b83\u8d1f\u8d23\u52a0\u8f7d\u548c\u9884\u5904\u7406\u914d\u7f6e\u6587\u4ef6 (<code>analysis_prepare_config</code>) \u5e76\u8bbe\u7f6e\u65e5\u5fd7\u7cfb\u7edf\u3002\u6838\u5fc3\u903b\u8f91\u4f4d\u4e8e <code>run_simulation</code> \u51fd\u6570\u4e2d\uff0c\u5b83\u9996\u5148\u4f1a\u8fdb\u884c\u6a21\u5f0f\u5224\u65ad\uff0c\u4ee5\u51b3\u5b9a\u63a5\u4e0b\u6765\u6267\u884c\u54ea\u4e2a\u6838\u5fc3\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_flow.html#22","title":"2.2. \u6a21\u5f0f\u4e00\uff1a\u591a\u6848\u4f8b\u5206\u6790","text":"<p>\u5f53\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u4e86 <code>analysis_cases</code> \u65f6\uff0c\u6b64\u6a21\u5f0f\u88ab\u6fc0\u6d3b\u3002\u5b83\u7528\u4e8e\u6267\u884c\u4e00\u7cfb\u5217\u72ec\u7acb\u7684\u3001\u53ef\u5bf9\u6bd4\u7684\u5206\u6790\u7814\u7a76\u3002</p> <ol> <li>\u73af\u5883\u8bbe\u7f6e\uff1a\u6846\u67b6\u4f1a\u4e3a <code>analysis_cases</code> \u4e2d\u7684\u6bcf\u4e00\u4e2a\u6848\u4f8b\u521b\u5efa\u4e00\u4e2a\u5b8c\u5168\u72ec\u7acb\u7684\u5b50\u5de5\u4f5c\u76ee\u5f55\uff0c\u5e76\u4e3a\u5176\u751f\u6210\u4e00\u4efd\u5b9a\u5236\u5316\u7684\u914d\u7f6e\u6587\u4ef6\u3002\u8fd9\u786e\u4fdd\u4e86\u6bcf\u4e2a\u6848\u4f8b\u7684\u8fd0\u884c\u73af\u5883\uff08\u5305\u62ec\u6a21\u578b\u4fee\u6539\u3001\u4e34\u65f6\u6587\u4ef6\u548c\u7ed3\u679c\uff09\u90fd\u662f\u9694\u79bb\u7684\u3002</li> <li>\u5e76\u53d1\u6267\u884c\uff1a\u5982\u679c\u914d\u7f6e\u4e86 <code>\"concurrent_cases\": true</code>\uff0c<code>tricys</code> \u4f1a\u542f\u52a8\u4e00\u4e2a\u8fdb\u7a0b\u6c60 (<code>ProcessPoolExecutor</code>) \u6765\u5e76\u884c\u6267\u884c\u6240\u6709\u6848\u4f8b\u3002\u4f7f\u7528\u8fdb\u7a0b\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6848\u4f8b\u90fd\u662f\u4e00\u4e2a\u5b8c\u6574\u7684 <code>tricys</code> \u8fd0\u884c\u5b9e\u4f8b\uff0c\u9700\u8981\u72ec\u7acb\u7684\u5185\u5b58\u7a7a\u95f4\u548c\u6587\u4ef6\u7cfb\u7edf\u6743\u9650\u4ee5\u907f\u514d\u51b2\u7a81\u3002</li> <li>\u9012\u5f52\u8c03\u7528\uff1a\u6bcf\u4e2a\u6848\u4f8b\u7684\u6267\u884c\u7531 <code>_execute_analysis_case</code> \u51fd\u6570\u5305\u88f9\uff0c\u8be5\u51fd\u6570\u4f1a\u9012\u5f52\u5730\u8c03\u7528 <code>run_simulation</code>\uff0c\u5e76\u5f3a\u5236\u7981\u7528\u5185\u90e8\u7684\u5e76\u53d1\u6267\u884c\uff08\u9632\u6b62\u8fdb\u7a0b\u6c60\u5d4c\u5957\uff09\u3002\u8fd9\u610f\u5473\u7740\u6bcf\u4e2a\u6848\u4f8b\u5185\u90e8\u4f1a\u5b8c\u6574\u5730\u6267\u884c\u4e00\u904d\u201c\u6a21\u5f0f\u4e09\u201d\u7684\u6d41\u7a0b\u3002</li> <li>\u62a5\u544a\u6c47\u603b\uff1a\u6240\u6709\u6848\u4f8b\u6267\u884c\u5b8c\u6bd5\u540e\uff0c\u6846\u67b6\u4f1a\u8c03\u7528 <code>consolidate_reports</code> \u7b49\u51fd\u6570\uff0c\u4ece\u6240\u6709\u5b50\u5de5\u4f5c\u76ee\u5f55\u4e2d\u6536\u96c6\u5206\u6790\u7ed3\u679c\u548c\u62a5\u544a\uff0c\u5e76\u751f\u6210\u4e00\u4efd\u9876\u5c42\u7684\u6c47\u603b\u62a5\u544a\uff0c\u65b9\u4fbf\u7528\u6237\u8fdb\u884c\u8de8\u6848\u4f8b\u7684\u6bd4\u8f83\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_flow.html#23-salib","title":"2.3. \u6a21\u5f0f\u4e8c\uff1aSALib \u5168\u5c40\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5982\u679c\u914d\u7f6e\u6307\u5411\u4e00\u4e2a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff08GSA\uff09\u4efb\u52a1\uff08\u901a\u8fc7 <code>independent_variable_sampling</code> \u548c <code>analyzer</code> \u7b49\u5173\u952e\u5b57\u8bc6\u522b\uff09\uff0c<code>tricys</code> \u4f1a\u5c06\u63a7\u5236\u6743\u79fb\u4ea4\u7ed9\u4e13\u95e8\u7684 SALib \u5de5\u4f5c\u6d41\u3002</p> <ol> <li>\u8c03\u7528 <code>run_salib_analysis</code>\uff1a\u8fd9\u662f SALib \u6d41\u7a0b\u7684\u5165\u53e3\u3002</li> <li>\u53c2\u6570\u91c7\u6837\uff1a\u4f7f\u7528 SALib \u5e93\uff08\u5982 <code>saltelli.sample</code>\uff09\u6839\u636e\u914d\u7f6e\u7684\u53c2\u6570\u5206\u5e03\u751f\u6210\u5927\u91cf\u7684\u53c2\u6570\u6837\u672c\u96c6\u3002</li> <li>\u6279\u91cf\u4eff\u771f\uff1a\u4e3a\u6bcf\u4e00\u4e2a\u53c2\u6570\u6837\u672c\u8fd0\u884c\u4e00\u6b21 Modelica \u4eff\u771f\u3002</li> <li>\u7ed3\u679c\u5206\u6790\uff1a\u6536\u96c6\u6240\u6709\u4eff\u771f\u7ed3\u679c\uff0c\u5e76\u4f7f\u7528 SALib \u7684\u5206\u6790\u5668\uff08\u5982 <code>sobol.analyze</code>\uff09\u8ba1\u7b97\u6bcf\u4e2a\u53c2\u6570\u7684\u4e00\u9636\u3001\u4e8c\u9636\u548c\u603b\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1, S2, ST\uff09\u3002</li> <li>\u8f93\u51fa\u62a5\u544a\uff1a\u5c06\u654f\u611f\u6027\u6307\u6570\u548c\u76f8\u5173\u56fe\u8868\u8f93\u51fa\u4e3a\u6700\u7ec8\u7684\u5206\u6790\u62a5\u544a\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_flow.html#24","title":"2.4. \u6a21\u5f0f\u4e09\uff1a\u6807\u51c6\u626b\u63cf\u4e0e\u5206\u6790","text":"<p>\u8fd9\u662f\u6700\u57fa\u7840\u4e5f\u662f\u6700\u6838\u5fc3\u7684\u5de5\u4f5c\u6d41\uff0c\u5f53\u4ee5\u4e0a\u4e24\u79cd\u6a21\u5f0f\u7684\u6761\u4ef6\u90fd\u4e0d\u6ee1\u8db3\u65f6\uff0c\u5c31\u4f1a\u6267\u884c\u6b64\u6d41\u7a0b\u3002</p> <ol> <li>\u751f\u6210\u4efb\u52a1\uff1a\u6839\u636e <code>simulation_parameters</code> \u751f\u6210\u4eff\u771f\u4efb\u52a1\u5217\u8868 <code>jobs</code>\u3002</li> <li>\u6267\u884c\u4eff\u771f\u4efb\u52a1\uff1a<ul> <li>\u6839\u636e <code>concurrent</code> \u914d\u7f6e\uff0c\u9009\u62e9\u5e76\u884c\u6216\u4e32\u884c\u6267\u884c\u6240\u6709 <code>jobs</code>\u3002</li> <li>\u6bcf\u4e2a\u4efb\u52a1\u7684\u6267\u884c\u7531 <code>_run_single_job</code> \u6216 <code>_run_co_simulation</code> \u7b49\u51fd\u6570\u5904\u7406\u3002</li> </ul> </li> <li>\u4f18\u5316\u5b50\u6d41\u7a0b\uff08\u6838\u5fc3\u7279\u8272\uff09\uff1a\u5728\u5355\u6b21\u4eff\u771f\u4efb\u52a1\u6267\u884c\u5b8c\u6bd5\u540e\uff0c\u7cfb\u7edf\u4f1a\u68c0\u67e5\u662f\u5426\u914d\u7f6e\u4e86\u4f18\u5316\u76ee\u6807\uff08\u4ee5 <code>Required_</code> \u4e3a\u524d\u7f00\u7684\u6307\u6807\uff09\u3002<ul> <li>\u5982\u679c\u5b58\u5728\uff0c\u7cfb\u7edf\u4f1a\u7acb\u5373\u8c03\u7528 <code>_run_bisection_search_for_job</code>\uff0c\u542f\u52a8\u4e00\u4e2a\u4e8c\u5206\u641c\u7d22\u5faa\u73af\u3002</li> <li>\u8be5\u5faa\u73af\u4f1a\u4e3a\u4e86\u5bfb\u627e\u4e00\u4e2a\u80fd\u6ee1\u8db3\u9884\u8bbe\u6307\u6807\uff08\u4f8b\u5982\uff0c\u6c1a\u589e\u6b96\u6bd4TBR &gt; 1.05\uff09\u7684\u6700\u4f18\u53c2\u6570\u503c\uff0c\u800c\u8fed\u4ee3\u5730\u8fd0\u884c\u591a\u6b21\u4eff\u771f\uff0c\u5e76\u6839\u636e\u6bcf\u6b21\u7684\u7ed3\u679c\u52a8\u6001\u8c03\u6574\u53c2\u6570\uff0c\u76f4\u5230\u627e\u5230\u89e3\u6216\u8fbe\u5230\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002</li> </ul> </li> <li>\u7ed3\u679c\u805a\u5408\uff1a<ul> <li>\u6240\u6709\u4efb\u52a1\uff08\u5305\u62ec\u4f18\u5316\u5b50\u6d41\u7a0b\u4e2d\u7684\u6240\u6709\u4eff\u771f\uff09\u5b8c\u6210\u540e\uff0c\u6846\u67b6\u4f1a\u805a\u5408\u4e24\u7c7b\u6570\u636e\uff1a<ul> <li>\u6240\u6709\u4eff\u771f\u7684\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5408\u5e76\u5230 <code>sweep_results.csv</code>\u3002</li> <li>\u6240\u6709\u4f18\u5316\u4efb\u52a1\u7684\u6700\u7ec8\u7ed3\u679c\uff08\u4f8b\u5982\uff0c<code>TBR&gt;1.05</code> \u5bf9\u5e94\u7684\u6700\u4f18 <code>enrichment</code> \u662f <code>0.85</code>\uff09\uff0c\u5408\u5e76\u5230 <code>requierd_tbr_summary.csv</code>\u3002</li> </ul> </li> </ul> </li> <li>\u6700\u7ec8\u5206\u6790\u4e0e\u540e\u5904\u7406\uff1a<ul> <li>\u8c03\u7528 <code>_run_sensitivity_analysis</code>\uff0c\u5b83\u4f1a\u52a0\u8f7d\u805a\u5408\u540e\u7684\u6570\u636e\uff0c\u8ba1\u7b97\u6700\u7ec8\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPI\uff09\uff0c\u5e76\u751f\u6210\u5206\u6790\u56fe\u8868\u548c\u6458\u8981\u3002</li> <li>\u8c03\u7528 <code>_run_post_processing</code>\uff0c\u6267\u884c\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u4efb\u4f55\u6700\u7ec8\u5904\u7406\u811a\u672c\uff08\u4f8b\u5982\uff0c\u751f\u6210\u7279\u5b9a\u7684\u62a5\u544a\u683c\u5f0f\uff09\u3002</li> </ul> </li> </ol>"},{"location":"explanation/tricys_analysis/analysis_report.html","title":"\u751f\u6210\u5206\u6790\u62a5\u544a","text":"<p>TRICYS \u4e0d\u4ec5\u662f\u4e00\u4e2a\u4eff\u771f\u6267\u884c\u6846\u67b6\uff0c\u66f4\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u81ea\u52a8\u5316\u5206\u6790\u4e0e\u62a5\u544a\u5e73\u53f0\u3002\u5b83\u80fd\u591f\u5c06\u590d\u6742\u7684\u4eff\u771f\u7ed3\u679c\u81ea\u52a8\u5904\u7406\u6210\u7ed3\u6784\u6e05\u6670\u3001\u5185\u5bb9\u4e30\u5bcc\u3001\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u7684\u5206\u6790\u62a5\u544a\u3002\u5176\u62a5\u544a\u751f\u6210\u6d41\u7a0b\u91c7\u7528\u521b\u65b0\u7684\u5206\u5c42\u8bbe\u8ba1\uff0c\u4ece\u6570\u636e\u9a71\u52a8\u7684\u56fe\u8868\u751f\u6210\uff0c\u5230\u53ef\u9009\u7684\u3001\u7531\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u6df1\u5ea6\u5206\u6790\u4e0e\u5b66\u672f\u7ea7\u62a5\u544a\u64b0\u5199\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#1","title":"1. \u4e13\u4e1a\u672f\u8bed\u4e0e\u56fd\u9645\u5316\u56fe\u8868","text":"<p>\u4e3a\u4e86\u4f7f\u751f\u6210\u7684\u56fe\u8868\u5177\u6709\u4e13\u4e1a\u6027\u548c\u53ef\u8bfb\u6027\uff0cTRICYS \u5f15\u5165\u4e86\u4e00\u5957\u57fa\u4e8e\u5916\u90e8\u672f\u8bed\u8868\u7684\u6807\u7b7e\u6620\u5c04\u673a\u5236\uff0c\u5e76\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u5207\u6362\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#11","title":"1.1 \u5de5\u4f5c\u539f\u7406","text":"<p>\u8be5\u529f\u80fd\u7531 <code>tricys/analysis/plot.py</code> \u6a21\u5757\u5b9e\u73b0\u3002</p> <ol> <li>\u52a0\u8f7d\u672f\u8bed\u8868\uff1a\u7a0b\u5e8f\u542f\u52a8\u65f6\uff0c<code>load_glossary()</code> \u51fd\u6570\u4f1a\u8bfb\u53d6\u4e00\u4e2a\u7528\u6237\u6307\u5b9a\u7684 CSV \u6587\u4ef6\uff08<code>glossary_path</code>\uff09\u3002\u8be5 CSV \u6587\u4ef6\u5b9a\u4e49\u4e86\u5185\u90e8\u6a21\u578b\u53d8\u91cf\u540d\u4e0e\u5176\u4e2d\u82f1\u6587\u4e13\u4e1a\u672f\u8bed\u7684\u5bf9\u5e94\u5173\u7cfb\u3002</li> <li>\u8bbe\u7f6e\u8bed\u8a00\uff1a\u901a\u8fc7\u8c03\u7528 <code>set_plot_language('cn')</code> \u6216 <code>set_plot_language('en')</code>\uff0c\u53ef\u4ee5\u5168\u5c40\u5207\u6362\u56fe\u8868\u7684\u663e\u793a\u8bed\u8a00\u3002\u5207\u6362\u81f3\u4e2d\u6587\u65f6\uff0c\u4f1a\u81ea\u52a8\u542f\u7528\u652f\u6301\u4e2d\u6587\u7684\u5b57\u4f53\uff08\u5982\u201cSimHei\u201d\uff09\u3002</li> <li>\u6807\u7b7e\u683c\u5f0f\u5316\uff1a\u5728\u7ed8\u5236\u56fe\u8868\u65f6\uff0c\u6240\u6709\u539f\u59cb\u7684\u53d8\u91cf\u540d\uff08\u5982 <code>Startup_Inventory</code>, <code>sds.I[1]</code>\uff09\u90fd\u4f1a\u7ecf\u8fc7 <code>_format_label()</code> \u51fd\u6570\u5904\u7406\u3002\u8be5\u51fd\u6570\u4f1a\uff1a<ul> <li>\u9996\u5148\uff0c\u6839\u636e\u5f53\u524d\u8bbe\u7f6e\u7684\u8bed\u8a00\uff0c\u5728\u52a0\u8f7d\u7684\u672f\u8bed\u8868\u4e2d\u67e5\u627e\u5bf9\u5e94\u7684\u4e2d\u6587\u6216\u82f1\u6587\u4e13\u4e1a\u672f\u8bed\u3002</li> <li>\u5982\u679c\u67e5\u627e\u5230\uff0c\u5219\u4f7f\u7528\u8be5\u4e13\u4e1a\u672f\u8bed\u4f5c\u4e3a\u56fe\u8868\u6807\u7b7e\uff08\u4f8b\u5982\uff0c\u56fe\u4f8b\u3001\u5750\u6807\u8f74\u6807\u9898\uff09\u3002</li> <li>\u5982\u679c\u672a\u627e\u5230\uff0c\u5219\u6267\u884c\u9ed8\u8ba4\u7684\u683c\u5f0f\u5316\uff08\u4f8b\u5982\uff0c\u5c06\u4e0b\u5212\u7ebf\u66ff\u6362\u4e3a\u7a7a\u683c\uff09\uff0c\u4fdd\u8bc1\u6807\u7b7e\u7684\u57fa\u672c\u53ef\u8bfb\u6027\u3002</li> </ul> </li> <li>\u5355\u4f4d\u6620\u5c04\uff1a\u9664\u4e86\u672f\u8bed\uff0c\u5750\u6807\u8f74\u7684\u5355\u4f4d\u4e5f\u652f\u6301\u901a\u8fc7 <code>unit_map</code> \u914d\u7f6e\u8fdb\u884c\u8f6c\u6362\u548c\u663e\u793a\uff0c\u5e76\u540c\u6837\u652f\u6301\u56fd\u9645\u5316\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_report.html#12","title":"1.2 \u672f\u8bed\u8868\u683c\u5f0f\u793a\u4f8b","text":"<p>\u8be5 CSV \u6587\u4ef6\u5fc5\u987b\u5305\u542b\u4ee5\u4e0b\u4e09\u5217\uff1a</p> \u6a21\u578b\u53c2\u6570 (Model Parameter) \u82f1\u6587\u672f\u8bed (English Term) \u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation) <code>Startup_Inventory</code> Startup Inventory \u542f\u52a8\u5e93\u5b58 <code>Doubling_Time</code> Doubling Time \u500d\u589e\u65f6\u95f4 <code>sds.I[1]</code> Tritium Inventory in SDS \u8d2e\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf\u6c1a\u5e93\u5b58 <p>\u901a\u8fc7\u8fd9\u79cd\u673a\u5236\uff0cTRICYS \u80fd\u591f\u5c06\u5185\u90e8\u53d8\u91cf <code>Startup_Inventory</code> \u5728\u751f\u6210\u56fe\u8868\u65f6\u81ea\u52a8\u7f8e\u5316\u4e3a\u201cStartup Inventory (kg)\u201d\u6216\u201c\u542f\u52a8\u5e93\u5b58 (\u5343\u514b)\u201d\u3002</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#2","title":"2. \u6838\u5fc3\u56fe\u8868\u7c7b\u578b","text":"<p><code>tricys/analysis/plot.py</code> \u4e2d\u7684 <code>generate_analysis_plots()</code> \u51fd\u6570\u662f\u6240\u6709\u5206\u6790\u56fe\u8868\u7684\u603b\u5165\u53e3\uff0c\u5b83\u4f1a\u6839\u636e\u5206\u6790\u4efb\u52a1\u7684\u7c7b\u578b\u751f\u6210\u4ee5\u4e0b\u51e0\u7c7b\u6838\u5fc3\u56fe\u8868\uff1a</p>"},{"location":"explanation/tricys_analysis/analysis_report.html#21","title":"2.1 \u4e3b\u8d8b\u52bf\u56fe","text":"<ul> <li>\u7528\u9014\uff1a\u5c55\u793a\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u56e0\u53d8\u91cf\uff09\u5982\u4f55\u968f\u72ec\u7acb\u626b\u63cf\u53d8\u91cf\u7684\u53d8\u5316\u800c\u53d8\u5316\u3002</li> <li>\u7279\u70b9\uff1a<ul> <li>\u5f53\u5b58\u5728\u591a\u4e2a\u80cc\u666f\u626b\u63cf\u53c2\u6570\uff08<code>simulation_parameters</code>\uff09\u65f6\uff0c\u4f1a\u81ea\u52a8\u4f7f\u7528\u4e0d\u540c\u7684\u989c\u8272\u3001\u7ebf\u578b\u548c\u6807\u8bb0\u6765\u7ed8\u5236\u591a\u6761\u66f2\u7ebf\uff0c\u5e76\u751f\u6210\u56fe\u4f8b\u3002</li> <li>\u5982\u679c\u66f2\u7ebf\u6570\u91cf\u4e0d\u591a\uff0c\u4f1a\u81ea\u52a8\u5728\u6570\u636e\u70b9\u4e0a\u6807\u6ce8\u6570\u503c\uff0c\u65b9\u4fbf\u7cbe\u786e\u8bfb\u6570\u3002</li> <li>\u652f\u6301\u5c06\u591a\u4e2a\u6307\u6807\u7ed8\u5236\u5728\u540c\u4e00\u5f20\u56fe\u7684\u591a\u4e2a\u5b50\u56fe\u4e2d\uff08<code>_generate_combined_plots</code>\uff09\uff0c\u6216\u4e3a\u6bcf\u4e2a\u6307\u6807\u751f\u6210\u72ec\u7acb\u7684\u56fe\u8868\u6587\u4ef6\uff08<code>_generate_individual_plots</code>\uff09\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_analysis/analysis_report.html#22","title":"2.2 \u7ea6\u675f\u6c42\u89e3\u5206\u6790\u56fe","text":"<ul> <li>\u7528\u9014\uff1a\u4e13\u95e8\u7528\u4e8e\u53ef\u89c6\u5316\u201c\u76ee\u6807\u5bfb\u4f18\u201d\u4efb\u52a1\u7684\u7ed3\u679c\uff08\u5373 <code>Required_</code> \u5f00\u5934\u7684\u6307\u6807\uff09\u3002</li> <li>\u7279\u70b9\uff1a<ul> <li>\u7531 <code>_generate_multi_required_plot()</code> \u51fd\u6570\u751f\u6210\uff0c\u901a\u5e38\u91c7\u7528\u591a\u5b50\u56fe\u5e03\u5c40\u3002</li> <li>\u6bcf\u4e2a\u5b50\u56fe\u4ee3\u8868\u4e00\u7ec4\u7279\u5b9a\u7684\u80cc\u666f\u53c2\u6570\u7ec4\u5408\uff0c\u6e05\u6670\u5730\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u573a\u666f\u4e0b\uff0c\u4e3a\u4e86\u8fbe\u6210\u67d0\u4e2a\u7ea6\u675f\u6761\u4ef6\uff08\u4f8b\u5982\uff0c\u500d\u589e\u65f6\u95f4\u5c0f\u4e8e10\u5e74\uff09\uff0c\u9700\u8981\u4ed8\u51fa\u7684\u201c\u4ee3\u4ef7\u201d\uff08\u5373\u88ab\u4f18\u5316\u7684\u53c2\u6570\u503c\uff09\u3002</li> <li>\u8fd9\u79cd\u56fe\u5bf9\u4e8e\u7406\u89e3\u591a\u53d8\u91cf\u6743\u8861\uff08Trade-offs\uff09\u5173\u7cfb\u81f3\u5173\u91cd\u8981\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_analysis/analysis_report.html#23","title":"2.3 \u626b\u63cf\u8fc7\u7a0b\u65f6\u5e8f\u56fe","text":"<ul> <li>\u7528\u9014\uff1a\u5f53\u9700\u8981\u89c2\u5bdf\u67d0\u4e2a\u52a8\u6001\u53d8\u91cf\u5728\u4e0d\u540c\u53c2\u6570\u626b\u63cf\u4e0b\u7684\u5b8c\u6574\u65f6\u95f4\u6f14\u5316\u8fc7\u7a0b\u65f6\uff0c\u751f\u6210\u6b64\u56fe\u3002</li> <li>\u7279\u70b9\uff1a<ul> <li>\u7531 <code>plot_sweep_time_series()</code> \u51fd\u6570\u751f\u6210\uff0c\u5305\u542b\u4e24\u4e2a\u5b50\u56fe\uff1a<ol> <li>\u5168\u5c40\u89c6\u56fe (Overall View)\uff1a\u5c55\u793a\u4ece <code>t=0</code> \u5230\u4eff\u771f\u7ed3\u675f\u7684\u5b8c\u6574\u65f6\u95f4\u66f2\u7ebf\u3002\u4e3a\u4e86\u7a81\u51fa\u65e9\u671f\u5173\u952e\u884c\u4e3a\uff0c\u6b64\u89c6\u56fe\u4f1a\u81ea\u52a8\u9690\u85cf\u8d85\u8fc7\u521d\u59cb\u503c\u4e24\u500d\u7684\u6570\u636e\u70b9\u3002</li> <li>\u7ec6\u8282\u89c6\u56fe (Detailed View)\uff1a\u81ea\u52a8\u805a\u7126\u4e8e\u6240\u6709\u66f2\u7ebf\u4e2d\u9996\u6b21\u8fbe\u5230\u6700\u5c0f\u503c\u7684\u533a\u57df\uff0c\u5e76\u653e\u5927\u663e\u793a\u3002\u8fd9\u5bf9\u4e8e\u89c2\u5bdf\u7cfb\u7edf\u542f\u52a8\u521d\u671f\u7684\u52a8\u6001\u7279\u6027\uff08\u5982\u5e93\u5b58\u7684\u201c\u4e0b\u8dcc-\u56de\u5347\u201d\u8f6c\u6298\u70b9\uff09\u975e\u5e38\u6709\u7528\u3002</li> </ol> </li> <li>\u4e00\u4e2a\u7ea2\u8272\u7684\u865a\u7ebf\u6846\u4f1a\u81ea\u52a8\u7ed8\u5236\u5728\u201c\u5168\u5c40\u89c6\u56fe\u201d\u4e0a\uff0c\u4ee5\u6807\u793a\u201c\u7ec6\u8282\u89c6\u56fe\u201d\u6240\u5bf9\u5e94\u7684\u533a\u57df\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_analysis/analysis_report.html#3","title":"3. \u591a\u9636\u6bb5\u62a5\u544a\u751f\u6210\u903b\u8f91","text":"<p>TRICYS \u7684\u62a5\u544a\u751f\u6210\u5206\u4e3a\u4e24\u4e2a\u6838\u5fc3\u9636\u6bb5\uff0c\u7531 <code>tricys/analysis/report.py</code> \u6a21\u5757\u8c03\u5ea6\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5c06\u539f\u59cb\u6570\u636e\u4e0e AI \u89e3\u8bfb\u5206\u79bb\uff0c\u4fdd\u8bc1\u4e86\u7ed3\u679c\u7684\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u3002</p> <pre><code>graph TD\n    A[\u5f00\u59cb] --&gt; B[\u6267\u884c\u6240\u6709\u4eff\u771f\u4e0e\u5206\u6790\u4efb\u52a1];\n    B --&gt; C[\"&lt;b&gt;\u9636\u6bb5\u4e00\uff1a\u751f\u6210\u57fa\u7840\u6570\u636e\u62a5\u544a&lt;/b&gt;&lt;br&gt;`generate_prompt_templates()`\"];\n    C --&gt; D{AI \u5206\u6790\u662f\u5426\u542f\u7528?};\n    D -- \u5426 --&gt; E[\u7ed3\u675f: \u4ec5\u5305\u542b\u6570\u636e\u548c\u56fe\u8868\u7684\u57fa\u7840\u62a5\u544a];\n    D -- \u662f --&gt; F[\"&lt;b&gt;\u9636\u6bb5\u4e8c\uff1a\u751f\u6210 AI \u589e\u5f3a\u62a5\u544a&lt;/b&gt;\"];\n\n    subgraph F\n        direction LR\n        F1[\"\u7b2c\u4e00\u6b21\u8c03\u7528 LLM:&lt;br&gt;\u539f\u59cb\u6570\u636e\u5206\u6790&lt;br&gt;`call_openai_analysis_api`\"] --&gt; F2[\"\u7b2c\u4e8c\u6b21\u8c03\u7528 LLM:&lt;br&gt;\u5b66\u672f\u62a5\u544a\u64b0\u5199&lt;br&gt;`generate_sensitivity_academic_report`\"];\n    end\n    F --&gt; G[\u7ed3\u675f: \u751f\u6210\u5305\u542b\u6df1\u5ea6\u5206\u6790\u7684\u5b66\u672f\u7ea7\u62a5\u544a];</code></pre>"},{"location":"explanation/tricys_analysis/analysis_report.html#31","title":"3.1. \u9636\u6bb5\u4e00\uff1a\u57fa\u7840\u6570\u636e\u62a5\u544a","text":"<p>\u6b64\u9636\u6bb5\u7531 <code>generate_prompt_templates()</code> \u51fd\u6570\u6267\u884c\uff0c\u5176\u6838\u5fc3\u804c\u8d23\u662f\u521b\u5efa\u4e00\u4e2a\u5185\u5bb9\u8be6\u5c3d\u3001\u7eaf\u6570\u636e\u9a71\u52a8\u7684 Markdown \u6587\u4ef6\u3002\u8fd9\u4efd\u6587\u4ef6\u662f\u540e\u7eed\u6240\u6709\u5206\u6790\u7684\u201c\u4e8b\u5b9e\u6839\u57fa\u201d\uff0c\u5305\u542b\uff1a</p> <ol> <li>\u914d\u7f6e\u8be6\u60c5\uff1a\u672c\u6b21\u5206\u6790\u7684\u6240\u6709\u914d\u7f6e\u53c2\u6570\uff0c\u5982\u72ec\u7acb/\u56e0\u53d8\u91cf\u3001\u626b\u63cf\u8303\u56f4\u3001\u4f18\u5316\u8bbe\u7f6e\u7b49\u3002</li> <li>\u6570\u636e\u8868\u683c\uff1a\u5c06 <code>sensitivity_analysis_summary.csv</code> \u548c <code>requierd_tbr_summary.csv</code> \u4e2d\u7684\u6570\u636e\u683c\u5f0f\u5316\u4e3a\u7f8e\u89c2\u7684 Markdown \u8868\u683c\u3002</li> <li>\u56fe\u8868\u5d4c\u5165\uff1a\u5c06 <code>plot.py</code> \u751f\u6210\u7684\u6240\u6709 <code>.svg</code> \u56fe\u8868\u6587\u4ef6\u901a\u8fc7 <code>![\u6807\u9898](\u6587\u4ef6\u540d.svg)</code> \u7684\u8bed\u6cd5\u5d4c\u5165\u62a5\u544a\u4e2d\u3002</li> <li>\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u5982\u679c\u9002\u7528\uff0c\u8fd8\u4f1a\u4ece <code>sweep_results.csv</code> \u4e2d\u63d0\u53d6\u5173\u952e\u52a8\u6001\u8fc7\u7a0b\uff08\u5982\u521d\u59cb\u3001\u8f6c\u6298\u70b9\u3001\u7ed3\u675f\u9636\u6bb5\uff09\u7684\u6570\u636e\u5207\u7247\uff0c\u4ee5\u8868\u683c\u5f62\u5f0f\u5448\u73b0\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/analysis_report.html#32","title":"3.2. \u9636\u6bb5\u4e8c\uff1a\u539f\u59cb\u6570\u636e\u5206\u6790","text":"<ul> <li>\u6267\u884c\u8005\uff1a<code>call_openai_analysis_api()</code></li> <li>\u76ee\u7684\uff1a\u5bf9\u7eaf\u6570\u636e\u8868\u683c\u8fdb\u884c\u6df1\u5ea6\u91cf\u5316\u5206\u6790\uff0c\u53d1\u6398\u6570\u636e\u80cc\u540e\u7684\u8d8b\u52bf\u4e0e\u5173\u8054\u3002</li> <li>\u8fc7\u7a0b\uff1a<ol> <li>\u5c06\u9636\u6bb5\u4e00\u751f\u6210\u7684\u57fa\u7840\u62a5\u544a\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u5e76\u9644\u52a0\u4e0a\u4e00\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5206\u6790\u6307\u4ee4\uff08\u89c1\u4e0b\u4e00\u8282\uff09\u3002</li> <li>\u4e00\u4e2a\u5173\u952e\u6307\u4ee4\u662f\u5ffd\u7565\u56fe\u8868\uff0c\u53ea\u5206\u6790\u8868\u683c\uff0c\u8fd9\u5f3a\u5236\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u800c\u975e\u5b9a\u6027\u7684\u5206\u6790\u3002</li> <li>LLM \u8fd4\u56de\u7684\u5206\u6790\u7ed3\u679c\u4f1a\u88ab\u8ffd\u52a0\u5230\u57fa\u7840\u62a5\u544a\u7684\u672b\u5c3e\uff0c\u5f62\u6210\u4e00\u4efd\u5305\u542b\u201c\u539f\u59cb\u6570\u636e+AI\u521d\u6b65\u89e3\u8bfb\u201d\u7684\u5b8c\u6574\u62a5\u544a\u3002</li> </ol> </li> </ul> \u6570\u636e\u5206\u6790\u5e08\u63d0\u793a\u8bcd <pre><code>**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u805a\u53d8\u53cd\u5e94\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u7684\u4e13\u5bb6\u3002\n**\u4efb\u52a1\uff1a** \u8bf7**\u5b8c\u5168\u57fa\u4e8e**\u4e0b\u65b9\u63d0\u4f9b\u7684**\u4e24\u7c7b\u6570\u636e\u8868\u683c**\uff0c\u5bf9\u805a\u53d8\u5806\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684**\u654f\u611f\u6027\u5206\u6790**\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\u3002\n**\u5206\u6790\u8981\u70b9 (\u5fc5\u987b\u4e25\u683c\u4f9d\u636e\u6570\u636e\u8868\u683c\u4f5c\u7b54)\uff1a**\n1.  **\u5168\u5c40\u654f\u611f\u6027\u5206\u6790:**\n    *   \u5206\u6790\u6027\u80fd\u6307\u6807\u603b\u8868\u5448\u73b0\u51fa\u600e\u6837\u7684**\u603b\u4f53\u8d8b\u52bf**\uff1f\n    *   \u54ea\u4e2a\u6027\u80fd\u6307\u6807\u5bf9\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u7684\u53d8\u5316\u6700\u4e3a\u654f\u611f\uff1f\n2.  **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a**\n    *   \u5206\u6790\u72ec\u7acb\u53d8\u91cf\u4e0e\u80cc\u666f\u626b\u63cf\u53c2\u6570\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\u3002\n3.  **\u52a8\u6001\u8fc7\u7a0b\u5206\u6790:**\n    *   \u89c2\u5bdf\u8fc7\u7a0b\u6570\u636e\u5207\u7247\uff1a\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u9636\u6bb5\u201d\u548c\u201c\u7ed3\u675f\u9636\u6bb5\u201d\u7684\u884c\u4e3a\u6709\u4f55\u4e0d\u540c\uff1f\n    *   \u8f6c\u6298\u70b9\u9636\u6bb5\u7684\u6570\u636e\u63ed\u793a\u4e86\u4ec0\u4e48\u7269\u7406\u8fc7\u7a0b\uff1f\n4.  **\u7efc\u5408\u7ed3\u8bba\uff1a**\n    *   \u603b\u7ed3\u8c03\u6574 `{independent_variable}` \u5bf9\u7cfb\u7edf\u7684\u7efc\u5408\u5f71\u54cd\u548c\u5229\u5f0a\u6743\u8861\u3002\n    *   \u53ef\u4ee5\u5f97\u51fa\u54ea\u4e9b\u5173\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\u6216\u8fd0\u884c\u4f18\u5316\u7684\u521d\u6b65\u5efa\u8bae\uff1f\n</code></pre>"},{"location":"explanation/tricys_analysis/analysis_report.html#33","title":"3.3. \u9636\u6bb5\u4e09\uff1a\u5b66\u672f\u62a5\u544a\u64b0\u5199","text":"<ul> <li>\u6267\u884c\u8005\uff1a<code>generate_sensitivity_academic_report()</code></li> <li>\u76ee\u7684\uff1a\u5c06\u4e00\u4efd\u5305\u542b\u6570\u636e\u3001\u56fe\u8868\u548c\u521d\u6b65\u5206\u6790\u7684\u6df7\u5408\u62a5\u544a\uff0c\u201c\u5347\u683c\u201d\u4e3a\u4e00\u7bc7\u7ed3\u6784\u4e25\u8c28\u3001\u8bed\u8a00\u4e13\u4e1a\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</li> <li>\u8fc7\u7a0b\uff1a<ol> <li>\u5c06\u66f4\u65b0\u540e\u7684\u62a5\u544a\uff08\u5df2\u5305\u542b\u7b2c\u4e00\u6b21AI\u5206\u6790\uff09\u548c\u672f\u8bed\u8868 (<code>glossary.csv</code>) \u4e00\u540c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u3002</li> <li>\u9644\u52a0\u4e0a\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u6307\u4ee4\uff0c\u8981\u6c42\u6a21\u578b\u626e\u6f14\u201c\u8d44\u6df1\u79d1\u5b66\u5bb6\u201d\u89d2\u8272\uff0c\u5e76\u4e25\u683c\u9075\u5faa\u5b66\u672f\u89c4\u8303\u3002</li> <li>LLM \u4f1a\u5229\u7528\u672f\u8bed\u8868\u5c06\u62a5\u544a\u4e2d\u7684\u5185\u90e8\u53d8\u91cf\u66ff\u6362\u4e3a\u4e13\u4e1a\u672f\u8bed\uff0c\u5e76\u6309\u7167\u6807\u51c6\u7684\u5b66\u672f\u7ed3\u6784\uff08\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\uff09\u91cd\u65b0\u7ec4\u7ec7\u548c\u64b0\u5199\u6240\u6709\u5185\u5bb9\u3002</li> <li>\u6700\u7ec8\u7ed3\u679c\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u5168\u65b0\u7684\u3001\u53ef\u76f4\u63a5\u4f7f\u7528\u7684\u5b66\u672f\u62a5\u544a\u6587\u4ef6 (<code>academic_report_....md</code>)\u3002</li> </ol> </li> </ul> \u8d44\u6df1\u79d1\u5b66\u5bb6\u63d0\u793a\u8bcd <pre><code>**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n**\u6307\u4ee4\uff1a**\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u4e13\u4e1a\u672f\u8bed\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u60a8**\u5fc5\u987b**\u4f7f\u7528 Markdown \u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6807\u9898 (Title):** ...\n    *   **\u6458\u8981 (Abstract):** ...\n    *   **\u5f15\u8a00 (Introduction):** ...\n    *   **\u65b9\u6cd5 (Methodology):** ...\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** ...\n    *   **\u7ed3\u8bba (Conclusion):** ...\n</code></pre>"},{"location":"explanation/tricys_analysis/performance_metrics.html","title":"\u6838\u5fc3\u6027\u80fd\u6307\u6807","text":"<p>\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u7684\u6a21\u62df\u4e0e\u5206\u6790\u4e2d\uff0c\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ecf\u6d4e\u6027\u548c\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\u3002<code>tricys</code> \u5185\u7f6e\u4e86\u4e00\u7cfb\u5217\u6838\u5fc3\u6027\u80fd\u6307\u6807\uff08Key Performance Indicators, KPIs\uff09\uff0c\u7528\u4e8e\u4ece\u52a8\u6001\u4eff\u771f\u7ed3\u679c\u4e2d\u91cf\u5316\u8bc4\u4f30\u7cfb\u7edf\u7684\u5173\u952e\u7279\u6027\u3002</p>"},{"location":"explanation/tricys_analysis/performance_metrics.html#1","title":"1. \u542f\u52a8\u5e93\u5b58","text":"<ul> <li>\u8ba1\u7b97\u51fd\u6570: <code>calculate_startup_inventory</code></li> <li>\u7269\u7406\u610f\u4e49: \u542f\u52a8\u5e93\u5b58\u662f\u6307\u5728\u53cd\u5e94\u5806\u542f\u52a8\u521d\u671f\uff0c\u4e3a\u4e86\u7ef4\u6301\u8fde\u7eed\u8fd0\u884c\u76f4\u81f3\u7cfb\u7edf\u8fbe\u5230\u6c1a\u81ea\u6301\uff08\u5373\u6c1a\u7684\u589e\u6b96\u901f\u7387\u7b49\u4e8e\u6216\u8d85\u8fc7\u5176\u6d88\u8017\u901f\u7387\uff09\u800c\u5fc5\u987b\u9884\u5148\u6295\u5165\u7684\u6c1a\u91cf\u3002\u5728\u6c1a\u5e93\u5b58\u968f\u65f6\u95f4\u53d8\u5316\u7684\u66f2\u7ebf\u4e0a\uff0c\u8fd9\u8868\u73b0\u4e3a\u4ece\u521d\u59cb\u5e93\u5b58\u4e0b\u964d\u5230\u6700\u4f4e\u70b9\uff08\u62d0\u70b9\uff09\u7684\u5782\u76f4\u8ddd\u79bb\u3002</li> <li> <p>\u8ba1\u7b97\u65b9\u6cd5:</p> <ol> <li>\u5728\u4eff\u771f\u65f6\u95f4\u5e8f\u5217\u4e2d\uff0c\u627e\u5230\u6c1a\u5e93\u5b58\u7684\u6700\u4f4e\u70b9\uff08Turning Point\uff09\uff0c\u8fd9\u4e2a\u70b9\u901a\u5e38\u4ee3\u8868\u7cfb\u7edf\u4ece\u51c0\u6d88\u8017\u8f6c\u4e3a\u51c0\u589e\u6b96\u7684\u65f6\u523b\u3002</li> <li>\u542f\u52a8\u5e93\u5b58\u88ab\u8ba1\u7b97\u4e3a \u521d\u59cb\u5e93\u5b58 \u4e0e \u6700\u4f4e\u5e93\u5b58 \u4e4b\u95f4\u7684\u5dee\u503c\u3002</li> </ol> <p><code>Startup Inventory = Initial Inventory - Minimum Inventory</code> - \u89e3\u8bfb: \u542f\u52a8\u5e93\u5b58\u662f\u4e00\u4e2a\u5173\u952e\u7684\u7ecf\u6d4e\u6027\u6307\u6807\u3002\u8f83\u4f4e\u7684\u542f\u52a8\u5e93\u5b58\u610f\u5473\u7740\u7cfb\u7edf\u80fd\u66f4\u5feb\u5730\u8fbe\u5230\u81ea\u6301\uff0c\u51cf\u5c11\u4e86\u5bf9\u5916\u90e8\u6c1a\u6e90\u7684\u4f9d\u8d56\u548c\u524d\u671f\u6295\u5165\u6210\u672c\uff0c\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u8bbe\u8ba1\u7684\u4f18\u5316\u76ee\u6807\u4e4b\u4e00\u3002</p> </li> </ul>"},{"location":"explanation/tricys_analysis/performance_metrics.html#2","title":"2. \u81ea\u6301\u65f6\u95f4","text":"<ul> <li>\u8ba1\u7b97\u51fd\u6570: <code>time_of_turning_point</code></li> <li>\u7269\u7406\u610f\u4e49: \u81ea\u6301\u65f6\u95f4\u662f\u6307\u7cfb\u7edf\u4ece\u542f\u52a8\u5f00\u59cb\uff0c\u5230\u5176\u603b\u6c1a\u5e93\u5b58\u91cf\u8fbe\u5230\u6700\u4f4e\u70b9\u5e76\u5f00\u59cb\u56de\u5347\u7684\u65f6\u523b\u3002\u8fd9\u4e2a\u65f6\u95f4\u70b9\u6807\u5fd7\u7740\u7cfb\u7edf\u5185\u90e8\u7684\u6c1a\u589e\u6b96\u901f\u7387\u5f00\u59cb\u8d85\u8fc7\u6d88\u8017\u548c\u635f\u5931\u901f\u7387\uff0c\u7cfb\u7edf\u5728\u7406\u8bba\u4e0a\u5b9e\u73b0\u4e86\u201c\u81ea\u7ed9\u81ea\u8db3\u201d\u3002</li> <li>\u8ba1\u7b97\u65b9\u6cd5:<ol> <li>\u8be5\u51fd\u6570\u9996\u5148\u5bf9\u5e93\u5b58\u6570\u636e\u8fdb\u884c\u5e73\u6ed1\u5904\u7406\uff0c\u4ee5\u6d88\u9664\u566a\u58f0\u5e72\u6270\uff0c\u5224\u65ad\u662f\u5426\u5b58\u5728\u4e00\u4e2a\u771f\u5b9e\u7684\u201c\u62d0\u70b9\u201d\u3002</li> <li>\u5982\u679c\u5e93\u5b58\u66f2\u7ebf\u662f\u5355\u8c03\u4e0b\u964d\u7684\uff08\u610f\u5473\u7740\u5728\u6574\u4e2a\u4eff\u771f\u65f6\u95f4\u5185\u90fd\u672a\u8fbe\u5230\u81ea\u6301\uff09\uff0c\u5219\u8fd4\u56de <code>NaN</code> (Not a Number)\u3002</li> <li>\u5426\u5219\uff0c\u5b83\u4f1a\u8fd4\u56de\u539f\u59cb\uff08\u672a\u5e73\u6ed1\u7684\uff09\u6570\u636e\u4e2d\u5e93\u5b58\u91cf\u8fbe\u5230\u6700\u5c0f\u503c\u7684\u7cbe\u786e\u65f6\u95f4\u70b9\u3002</li> </ol> </li> <li>\u89e3\u8bfb: \u81ea\u6301\u65f6\u95f4\u76f4\u63a5\u53cd\u6620\u4e86\u7cfb\u7edf\u8fbe\u5230\u6c1a\u5e73\u8861\u7684\u901f\u5ea6\u3002\u66f4\u77ed\u7684\u81ea\u6301\u65f6\u95f4\u662f\u7406\u60f3\u7684\uff0c\u56e0\u4e3a\u5b83\u8868\u660e\u7cfb\u7edf\u80fd\u66f4\u5feb\u5730\u6446\u8131\u5bf9\u542f\u52a8\u5e93\u5b58\u7684\u6d88\u8017\uff0c\u5e76\u5f00\u59cb\u79ef\u7d2f\u6c1a\uff0c\u8fd9\u5bf9\u5feb\u901f\u542f\u52a8\u5546\u4e1a\u805a\u53d8\u7535\u7ad9\u81f3\u5173\u91cd\u8981\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/performance_metrics.html#3","title":"3. \u500d\u589e\u65f6\u95f4","text":"<ul> <li>\u8ba1\u7b97\u51fd\u6570: <code>calculate_doubling_time</code></li> <li>\u7269\u7406\u610f\u4e49: \u500d\u589e\u65f6\u95f4\u662f\u6307\u5728\u8fbe\u5230\u6c1a\u81ea\u6301\u4e4b\u540e\uff0c\u7cfb\u7edf\u5185\u603b\u6c1a\u5e93\u5b58\u91cf\u7ffb\u500d\uff08\u5373\u8fbe\u5230\u521d\u59cb\u5e93\u5b58\u91cf\u7684\u4e24\u500d\uff09\u6240\u9700\u7684\u65f6\u95f4\u3002</li> <li>\u8ba1\u7b97\u65b9\u6cd5:<ol> <li>\u9996\u5148\uff0c\u786e\u5b9a\u7cfb\u7edf\u7684\u201c\u62d0\u70b9\u201d\uff08\u5e93\u5b58\u6700\u4f4e\u70b9\uff09\u3002</li> <li>\u7136\u540e\uff0c\u5728\u62d0\u70b9\u4e4b\u540e\u7684\u5e93\u5b58\u6570\u636e\u4e2d\uff0c\u5bfb\u627e\u7b2c\u4e00\u4e2a\u65f6\u95f4\u70b9\uff0c\u8be5\u70b9\u5e93\u5b58\u91cf\u5927\u4e8e\u6216\u7b49\u4e8e \u521d\u59cb\u5e93\u5b58\u7684\u4e24\u500d\u3002</li> <li>\u500d\u589e\u65f6\u95f4\u5c31\u662f\u8fd9\u4e2a\u65f6\u95f4\u70b9\u4e0e\u4eff\u771f\u5f00\u59cb\u65f6\u95f4\u4e4b\u5dee\u3002\u5982\u679c\u5e93\u5b58\u4ece\u672a\u8fbe\u5230\u521d\u59cb\u503c\u7684\u4e24\u500d\uff0c\u5219\u8fd4\u56de <code>NaN</code>\u3002</li> </ol> </li> <li>\u89e3\u8bfb: \u500d\u589e\u65f6\u95f4\u662f\u8861\u91cf\u6c1a\u589e\u6b96\u7cfb\u7edf\u201c\u76c8\u5229\u80fd\u529b\u201d\u7684\u6838\u5fc3\u6307\u6807\u3002\u4e00\u4e2a\u6709\u9650\u4e14\u5408\u7406\u7684\u500d\u589e\u65f6\u95f4\uff0c\u610f\u5473\u7740\u8be5\u805a\u53d8\u7535\u7ad9\u4e0d\u4ec5\u80fd\u81ea\u6211\u7ef4\u6301\uff0c\u8fd8\u80fd\u4e3a\u542f\u52a8\u65b0\u7684\u7535\u7ad9\u63d0\u4f9b\u989d\u5916\u7684\u6c1a\u71c3\u6599\u3002\u8fd9\u662f\u5b9e\u73b0\u805a\u53d8\u80fd\u6e90\u89c4\u6a21\u5316\u53d1\u5c55\u7684\u5173\u952e\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/performance_metrics.html#4","title":"4. \u7ea6\u675f\u6c42\u89e3\u6307\u6807","text":"<ul> <li>\u8ba1\u7b97\u65b9\u6cd5: <code>bisection_search</code> (\u5728 <code>tricys.simulation.simulation_analysis</code> \u4e2d\u5b9e\u73b0)</li> <li>\u7269\u7406\u610f\u4e49: \u5728\u8bb8\u591a\u8bbe\u8ba1\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u5173\u5fc3\u7684\u4e0d\u662f\u5728\u56fa\u5b9a\u7684\u6c1a\u589e\u6b96\u6bd4\uff08Tritium Breeding Ratio, TBR\uff09\u4e0b\u7cfb\u7edf\u7684\u6027\u80fd\u5982\u4f55\uff0c\u800c\u662f\u53cd\u8fc7\u6765\uff1a\u4e3a\u4e86\u8fbe\u5230\u67d0\u4e2a\u7279\u5b9a\u7684\u5de5\u7a0b\u76ee\u6807\uff08\u4f8b\u5982\uff0c\u500d\u589e\u65f6\u95f4\u5c0f\u4e8e10\u5e74\uff09\uff0c\u6211\u4eec\u6240\u9700\u8981\u7684\u6700\u4f4eTBR\u662f\u591a\u5c11\uff1f</li> <li>\u7ea6\u675f\u6c42\u89e3\u4efb\u52a1\u3002<ul> <li>\u5f53\u60a8\u5728 <code>dependent_variables</code> \u4e2d\u5305\u542b\u5b83\u65f6\uff0c<code>tricys</code> \u4f1a\u542f\u7528\u4e00\u4e2a\u4f18\u5316\u7b97\u6cd5\uff08\u5982\u4e8c\u5206\u67e5\u627e <code>bisection_search</code>\uff09\u3002</li> <li>\u8be5\u7b97\u6cd5\u4f1a\u4ee5 <code>parameter_to_optimize</code>\uff08\u901a\u5e38\u662f\u6a21\u578b\u4e2d\u7684 <code>TBR</code> \u53c2\u6570\uff09\u4e3a\u53d8\u91cf\uff0c\u5728\u7ed9\u5b9a\u7684 <code>search_range</code> \u5185\u53cd\u590d\u8fed\u4ee3\u8fd0\u884c\u4eff\u771f\u3002</li> <li>\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\uff0c\u5b83\u4f1a\u68c0\u67e5\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u4f8b\u5982 <code>Doubling_Time</code>\uff09\u662f\u5426\u6ee1\u8db3\u9884\u8bbe\u7684\u7ea6\u675f\u6761\u4ef6\uff08\u4f8b\u5982\u5c0f\u4e8e\u67d0\u4e2a <code>metric_max_value</code>\uff09\u3002</li> <li>\u6700\u7ec8\uff0c\u7b97\u6cd5\u4f1a\u6536\u655b\u5e76\u8f93\u51fa\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u7684\u6700\u5c0fTBR\u503c\u3002</li> </ul> </li> <li>\u89e3\u8bfb: \u8fd9\u4e2a\u201c\u53cd\u5411\u201d\u6c42\u89e3\u7684\u80fd\u529b\u975e\u5e38\u5f3a\u5927\u3002\u5b83\u5c06\u8bbe\u8ba1\u95ee\u9898\u4ece\u201c\u6b63\u5411\u9a8c\u8bc1\u201d\u8f6c\u53d8\u4e3a\u201c\u9006\u5411\u5bfb\u4f18\u201d\uff0c\u5e2e\u52a9\u5de5\u7a0b\u5e08\u5feb\u901f\u786e\u5b9a\u5b9e\u73b0\u5173\u952e\u6027\u80fd\u76ee\u6807\u6240\u9700\u7684\u6700\u4f4e\u8bbe\u8ba1\u8981\u6c42\uff0c\u6781\u5927\u5730\u52a0\u901f\u4e86\u8bbe\u8ba1\u8fed\u4ee3\u8fc7\u7a0b\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html","title":"SALIB\u96c6\u6210\u65b9\u6cd5","text":"<p>TRICYS \u6df1\u5ea6\u96c6\u6210\u4e86\u4e1a\u754c\u9886\u5148\u7684\u654f\u611f\u6027\u5206\u6790\u5e93 SALib\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u5957\u5f3a\u5927\u3001\u81ea\u52a8\u5316\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff08Global Sensitivity Analysis, GSA\uff09\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08Uncertainty Quantification, UQ\uff09\u5de5\u4f5c\u6d41\u3002\u672c\u7bc7\u6587\u6863\u5c06\u4ecb\u7ecd SALib \u53ca\u5176\u6838\u5fc3\u65b9\u6cd5\uff0c\u5e76\u8be6\u7ec6\u89e3\u6790 TRICYS \u662f\u5982\u4f55\u901a\u8fc7\u4e00\u4e2a\u4e09\u6b65\u6d41\u7a0b\u4e0e SALib \u534f\u540c\u5de5\u4f5c\u7684\u3002</p>"},{"location":"explanation/tricys_analysis/salib_integration.html#1-salib","title":"1. SALib \u5e93\u53ca\u5176\u5206\u6790\u65b9\u6cd5\u7b80\u4ecb","text":""},{"location":"explanation/tricys_analysis/salib_integration.html#11-salib","title":"1.1. \u4ec0\u4e48\u662f SALib\uff1f","text":"<p>SALib \u662f\u4e00\u4e2a\u7528 Python \u7f16\u5199\u7684\u5f00\u6e90\u5e93\uff0c\u4e13\u95e8\u7528\u4e8e\u6267\u884c\u654f\u611f\u6027\u5206\u6790\u3002\u654f\u611f\u6027\u5206\u6790\u65e8\u5728\u7814\u7a76\u4e00\u4e2a\u6a21\u578b\u7684\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u5f52\u56e0\u4e8e\u5176\u4e0d\u540c\u8f93\u5165\u6e90\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7b80\u5355\u6765\u8bf4\uff0c\u5b83\u5e2e\u52a9\u6211\u4eec\u56de\u7b54\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u201c\u6a21\u578b\u4e2d\u7684\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u5bf9\u8f93\u51fa\u7ed3\u679c\u7684\u5f71\u54cd\u6700\u5927\uff1f\u201d</p> <p>\u5bf9\u4e8e\u50cf TRICYS \u8fd9\u6837\u7684\u590d\u6742\u4eff\u771f\u6a21\u578b\uff0cGSA \u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\uff1a</p> <ul> <li>\u8bc6\u522b\u5173\u952e\u53c2\u6570\uff1a\u5728\u4f17\u591a\u53c2\u6570\u4e2d\uff0c\u627e\u5230\u5bf9\u7cfb\u7edf\u6027\u80fd\uff08\u5982\u542f\u52a8\u5e93\u5b58\u3001\u500d\u589e\u65f6\u95f4\uff09\u5f71\u54cd\u6700\u5927\u7684\u5c11\u6570\u51e0\u4e2a\u3002</li> <li>\u7406\u89e3\u53c2\u6570\u4ea4\u4e92\uff1a\u63ed\u793a\u53c2\u6570\u4e4b\u95f4\u662f\u5426\u5b58\u5728\u590d\u6742\u7684\u975e\u7ebf\u6027\u6216\u4ea4\u4e92\u6548\u5e94\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#12-salib","title":"1.2. \u6838\u5fc3 SALib \u65b9\u6cd5","text":"<p>TRICYS \u7684 <code>TricysSALibAnalyzer</code> \u7c7b\u96c6\u6210\u4e86 SALib \u4e2d\u51e0\u79cd\u6700\u5e38\u7528\u548c\u6700\u5f3a\u5927\u7684\u5206\u6790\u65b9\u6cd5\uff1a</p>"},{"location":"explanation/tricys_analysis/salib_integration.html#sobol","title":"Sobol \u5206\u6790 (\u65b9\u5dee\u5206\u6790\u6cd5)","text":"<ul> <li>\u7c7b\u578b\uff1a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (GSA)\uff0c\u57fa\u4e8e\u65b9\u5dee\u5206\u89e3\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a<ul> <li>\u4e00\u9636\u6307\u6570 (S1)\uff1a\u8861\u91cf\u5355\u4e2a\u53c2\u6570\u53d8\u5316\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u76f4\u63a5\u8d21\u732e\uff0c\u5373\u201c\u4e3b\u6548\u5e94\u201d\u3002S1 \u503c\u8d8a\u9ad8\uff0c\u8be5\u53c2\u6570\u7684\u72ec\u7acb\u5f71\u54cd\u8d8a\u5927\u3002</li> <li>\u603b\u9636\u6307\u6570 (ST)\uff1a\u8861\u91cf\u5355\u4e2a\u53c2\u6570\u672c\u8eab\u53ca\u5176\u4e0e\u5176\u4ed6\u53c2\u6570\u6240\u6709\u4ea4\u4e92\u6548\u5e94\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u603b\u8d21\u732e\u3002</li> </ul> </li> <li>\u89e3\u8bfb\uff1a\u5982\u679c\u4e00\u4e2a\u53c2\u6570\u7684 <code>ST</code> \u503c\u8fdc\u5927\u4e8e\u5176 <code>S1</code> \u503c\uff0c\u5219\u8868\u660e\u8be5\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u975e\u7ebf\u6027\u6548\u5e94\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u6709\u663e\u8457\u7684\u4ea4\u4e92\u4f5c\u7528\u3002</li> <li>\u7279\u70b9\uff1a\u7ed3\u679c\u975e\u5e38\u53ef\u9760\u548c\u5168\u9762\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u7684\u6837\u672c\u91cf\u901a\u5e38\u5f88\u5927\uff08<code>N * (2D + 2)</code>\uff0c\u5176\u4e2d D \u662f\u53c2\u6570\u6570\u91cf\uff09\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#morris","title":"Morris \u5206\u6790 (\u7b5b\u9009\u6cd5)","text":"<ul> <li>\u7c7b\u578b\uff1a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff0c\u57fa\u4e8e\u8f68\u8ff9\u7684\u7b5b\u9009\u65b9\u6cd5\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a<ul> <li>\u03bc* (mu_star)\uff1a\u8861\u91cf\u53c2\u6570\u5bf9\u8f93\u51fa\u5f71\u54cd\u7684\u603b\u4f53\u5927\u5c0f\uff0c\u662f\u6548\u5e94\u7684\u7edd\u5bf9\u503c\u7684\u5747\u503c\u3002\u03bc* \u8d8a\u9ad8\uff0c\u53c2\u6570\u8d8a\u91cd\u8981\u3002</li> <li>\u03c3 (sigma)\uff1a\u8861\u91cf\u53c2\u6570\u6548\u5e94\u7684\u6807\u51c6\u5dee\u3002\u03c3 \u8d8a\u9ad8\uff0c\u8868\u660e\u53c2\u6570\u7684\u5f71\u54cd\u662f\u975e\u7ebf\u6027\u7684\uff0c\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u4ea4\u4e92\u3002</li> </ul> </li> <li>\u7279\u70b9\uff1a\u8ba1\u7b97\u6548\u7387\u975e\u5e38\u9ad8\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6709\u5927\u91cf\u8f93\u5165\u53c2\u6570\uff08\u9ad8\u7ef4\u6a21\u578b\uff09\u7684\u65e9\u671f\u63a2\u7d22\u9636\u6bb5\uff0c\u7528\u4e8e\u5feb\u901f\u7b5b\u9009\u51fa\u5c11\u6570\u51e0\u4e2a\u6700\u91cd\u8981\u7684\u53c2\u6570\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#fast","title":"FAST \u5206\u6790 (\u5085\u91cc\u53f6\u5e45\u5ea6\u654f\u611f\u6027\u68c0\u9a8c)","text":"<ul> <li>\u7c7b\u578b\uff1a\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff0c\u57fa\u4e8e\u9891\u7387\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a\u4e0e Sobol \u7c7b\u4f3c\uff0c\u8ba1\u7b97\u4e00\u9636\u6307\u6570 (S1) \u548c\u603b\u9636\u6307\u6570 (ST)\u3002</li> <li>\u7279\u70b9\uff1a\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5b83\u6bd4 Sobol \u65b9\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0c\u4f46\u5bf9\u6a21\u578b\u7684\u9002\u7528\u6027\u6709\u4e00\u5b9a\u8981\u6c42\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#lhs","title":"\u62c9\u4e01\u8d85\u7acb\u65b9\u62bd\u6837 (LHS) \u4e0e\u4e0d\u786e\u5b9a\u6027\u5206\u6790","text":"<ul> <li>\u7c7b\u578b\uff1a\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (UQ)\u3002</li> <li>\u76ee\u7684\uff1aLHS \u672c\u8eab\u662f\u4e00\u79cd\u5148\u8fdb\u7684\u53c2\u6570\u91c7\u6837\u65b9\u6cd5\uff0c\u65e8\u5728\u9ad8\u6548\u5730\u8986\u76d6\u6574\u4e2a\u53c2\u6570\u7a7a\u95f4\u3002\u5f53\u4e0e TRICYS \u7ed3\u5408\u7528\u4e8e\u5206\u6790\u65f6\uff0c\u5176\u76ee\u7684\u4e0d\u662f\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\uff0c\u800c\u662f\u7814\u7a76\u5f53\u8f93\u5165\u53c2\u6570\u5728\u7ed9\u5b9a\u8303\u56f4\u5185\u4e0d\u786e\u5b9a\u65f6\uff0c\u8f93\u51fa\u6307\u6807\u7684\u7edf\u8ba1\u5206\u5e03\u7279\u6027\u3002</li> <li>\u6838\u5fc3\u6307\u6807\uff1a<ul> <li>\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5927/\u6700\u5c0f\u503c\u3002</li> <li>\u767e\u5206\u4f4d\u6570\uff08\u5982 5% \u548c 95%\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u8f93\u51fa\u7ed3\u679c\u7684\u7f6e\u4fe1\u533a\u95f4\u3002</li> </ul> </li> <li>\u89e3\u8bfb\uff1a\u901a\u8fc7 LHS \u5206\u6790\uff0c\u6211\u4eec\u53ef\u4ee5\u4e86\u89e3\u6a21\u578b\u8f93\u51fa\u7684\u7a33\u5b9a\u6027\u548c\u6ce2\u52a8\u8303\u56f4\uff0c\u8bc4\u4f30\u5176\u5728\u9762\u5bf9\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u65f6\u7684\u98ce\u9669\u3002</li> </ul>"},{"location":"explanation/tricys_analysis/salib_integration.html#2","title":"2. \u4e09\u6b65\u96c6\u6210\u6d41\u7a0b","text":"<p>TRICYS \u5c06\u590d\u6742\u7684 GSA \u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e00\u4e2a\u6e05\u6670\u3001\u81ea\u52a8\u5316\u7684\u4e09\u6b65\u5de5\u4f5c\u6d41\u3002<code>TricysSALibAnalyzer</code> \u7c7b\u8d1f\u8d23\u8c03\u5ea6\u6574\u4e2a\u6d41\u7a0b\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u201cSALib \u8d1f\u8d23\u62bd\u6837\u4e0e\u5206\u6790\uff0cTRICYS \u8d1f\u8d23\u6267\u884c\u8ba1\u7b97\u201d\uff0c\u4e24\u8005\u901a\u8fc7 CSV \u6587\u4ef6\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u3002</p> <pre><code>graph TD\n    subgraph \"A. SALib \u7aef\"\n        A1[\"&lt;b&gt;\u6b65\u9aa4\u4e00\uff1a\u53c2\u6570\u91c7\u6837&lt;/b&gt;&lt;br&gt;\u5728 salib.py \u4e2d\u6267\u884c\"]\n        A1 --&gt; B1[\"1. \u5b9a\u4e49\u95ee\u9898 (`define_problem`)&lt;br&gt;\u6307\u5b9a\u53c2\u6570\u53ca\u5176\u8303\u56f4\"]\n        B1 --&gt; B2[\"2. \u751f\u6210\u6837\u672c (`generate_samples`)&lt;br&gt;\u9009\u62e9 Sobol/Morris \u7b49\u65b9\u6cd5\"]\n        B2 --&gt; B3[\"3. \u5bfc\u51fa\u6837\u672c (`run_tricys_simulations`)&lt;br&gt;\u751f\u6210 &lt;b&gt;salib_sampling.csv&lt;/b&gt; \u6587\u4ef6\"]\n    end\n\n    subgraph \"B. TRICYS \u7aef\"\n        C1[\"&lt;b&gt;\u6b65\u9aa4\u4e8c\uff1a\u6279\u91cf\u4eff\u771f&lt;/b&gt;&lt;br&gt;\u5728 simulation_analysis.py \u4e2d\u6267\u884c\"]\n        C1 --&gt; D1[\"1. \u751f\u6210\u7279\u5b9a\u914d\u7f6e\u6587\u4ef6&lt;br&gt;\u8ba9 TRICYS \u8bfb\u53d6 CSV\"]\n        D1 --&gt; D2[\"2. TRICYS \u542f\u52a8&lt;br&gt;\u5c06 CSV \u6bcf\u4e00\u884c\u4f5c\u4e3a\u72ec\u7acb\u7684\u4eff\u771f\u4efb\u52a1\"]\n        D2 --&gt; D3[\"3. \u6267\u884c\u6240\u6709\u4eff\u771f&lt;br&gt;\u5e76\u5c06\u6240\u6709\u4efb\u52a1\u7684\u7ed3\u679c\u6307\u6807&lt;br&gt;\u6c47\u603b\u5230 &lt;b&gt;sensitivity_analysis_summary.csv&lt;/b&gt;\"]\n    end\n\n    subgraph \"C. SALib \u7aef (\u518d\u6b21)\"\n        E1[\"&lt;b&gt;\u6b65\u9aa4\u4e09\uff1a\u7ed3\u679c\u5206\u6790&lt;/b&gt;&lt;br&gt;\u8fd4\u56de salib.py \u4e2d\u6267\u884c\"]\n        E1 --&gt; F1[\"1. \u52a0\u8f7d\u7ed3\u679c (`load_tricys_results`)&lt;br&gt;\u8bfb\u53d6 &lt;b&gt;sensitivity_analysis_summary.csv&lt;/b&gt;\"]\n        F1 --&gt; F2[\"2. \u8ba1\u7b97\u6307\u6570 (`analyze_sobol`\u7b49)&lt;br&gt;SALib \u5206\u6790\u4eff\u771f\u7ed3\u679c\"]\n        F2 --&gt; F3[\"3. \u751f\u6210\u62a5\u544a (`plot_results`, `save_report`)&lt;br&gt;\u8f93\u51fa\u56fe\u8868\u3001\u8868\u683c\u548c\u6700\u7ec8\u5206\u6790\u62a5\u544a\"]\n    end\n\n    B3 -- \"\u4f5c\u4e3a\u8f93\u5165\" --&gt; C1\n    D3 -- \"\u4f5c\u4e3a\u8f93\u5165\" --&gt; E1\n</code></pre>"},{"location":"explanation/tricys_analysis/salib_integration.html#salib-csv","title":"\u6b65\u9aa4\u4e00\uff1a\u53c2\u6570\u91c7\u6837 (SALib -&gt; CSV)","text":"<p>\u6b64\u9636\u6bb5\u5b8c\u5168\u5728 <code>salib.py</code> \u7684 <code>TricysSALibAnalyzer</code> \u7c7b\u4e2d\u5b8c\u6210\uff0c\u76ee\u6807\u662f\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6240\u6709\u53c2\u6570\u7ec4\u5408\u7684 CSV \u6587\u4ef6\u3002</p> <ol> <li>\u5b9a\u4e49\u95ee\u9898\uff1a\u901a\u8fc7\u8c03\u7528 <code>define_problem()</code>\uff0c\u7528\u6237\u9700\u8981\u63d0\u4f9b\u4e00\u4e2a\u5305\u542b\u6240\u6709\u5f85\u5206\u6790\u53c2\u6570\u53ca\u5176\u53d6\u503c\u8303\u56f4\uff08bounds\uff09\u7684\u5b57\u5178\u3002</li> <li>\u751f\u6210\u6837\u672c\uff1a\u8c03\u7528 <code>generate_samples()</code>\uff0c\u5e76\u6307\u5b9a\u91c7\u6837\u65b9\u6cd5\uff08\u5982 <code>'sobol'</code>\uff09\u548c\u6837\u672c\u6570\u91cf <code>N</code>\u3002SALib \u4f1a\u6839\u636e\u6240\u9009\u65b9\u6cd5\u5728\u5b9a\u4e49\u7684\u53c2\u6570\u7a7a\u95f4\u4e2d\u751f\u6210\u4e00\u7cfb\u5217\u53c2\u6570\u70b9\u3002</li> <li>\u5bfc\u51fa\u6587\u4ef6\uff1a\u8c03\u7528 <code>run_tricys_simulations()</code> \u51fd\u6570\uff08\u6ce8\u610f\uff1a\u6b64\u51fd\u6570\u540d\u867d\u6709\u201csimulation\u201d\uff0c\u4f46\u5b83\u4e0d\u6267\u884c\u4eff\u771f\uff09\uff0c\u8be5\u51fd\u6570\u4f1a\u5c06\u4e0a\u4e00\u6b65\u751f\u6210\u7684\u6240\u6709\u53c2\u6570\u6837\u672c\u5199\u5165\u4e00\u4e2a\u540d\u4e3a <code>salib_sampling.csv</code> \u7684\u6587\u4ef6\u4e2d\u3002\u8fd9\u4e2a\u6587\u4ef6\u662f\u8fde\u63a5 SALib \u548c TRICYS \u7684\u6865\u6881\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/salib_integration.html#tricys-csv","title":"\u6b65\u9aa4\u4e8c\uff1a\u6279\u91cf\u4eff\u771f (TRICYS \u8bfb\u53d6 CSV)","text":"<p>\u6b64\u9636\u6bb5\u7531 <code>simulation_analysis.py</code> \u4e2d\u7684 <code>run_salib_analysis()</code> \u51fd\u6570\u8c03\u5ea6\uff0c\u5b83\u4f1a\u8c03\u7528 TRICYS \u7684\u6838\u5fc3\u4eff\u771f\u5f15\u64ce\u6765\u6267\u884c\u8ba1\u7b97\u3002</p> <ol> <li>\u751f\u6210\u7279\u5b9a\u914d\u7f6e\uff1a<code>salib.py</code> \u4e2d\u7684 <code>generate_tricys_config()</code> \u4f1a\u521b\u5efa\u4e00\u4e2a\u4e34\u65f6\u7684 TRICYS \u914d\u7f6e\u6587\u4ef6\u3002\u8fd9\u4e2a\u914d\u7f6e\u6587\u4ef6\u7684\u5173\u952e\u4e4b\u5904\u5728\u4e8e\uff0c\u5b83\u5c06 <code>simulation_parameters</code> \u6307\u5411\u4e86\u4e0a\u4e00\u6b65\u751f\u6210\u7684 <code>salib_sampling.csv</code> \u6587\u4ef6\u3002     <pre><code>\"simulation_parameters\": {\n  \"file\": \"/path/to/salib_sampling.csv\"\n}\n</code></pre></li> <li>TRICYS \u542f\u52a8\u4e0e\u6267\u884c\uff1a\u5f53 <code>simulation_analysis.py</code> \u4f7f\u7528\u8fd9\u4e2a\u7279\u6b8a\u914d\u7f6e\u542f\u52a8\u65f6\uff0c\u5b83\u4f1a\u8bc6\u522b\u51fa\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u6587\u4ef6\u7684\u4efb\u52a1\u3002TRICYS \u4f1a\u9010\u884c\u8bfb\u53d6 <code>salib_sampling.csv</code>\uff0c\u5e76\u5c06\u6bcf\u4e00\u884c\uff08\u5373\u4e00\u7ec4\u5b8c\u6574\u7684\u53c2\u6570\uff09\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u4eff\u771f\u4efb\u52a1\u6765\u6267\u884c\u3002</li> <li>\u6c47\u603b\u7ed3\u679c\uff1aTRICYS \u4f1a\uff08\u5e76\u884c\u6216\u4e32\u884c\u5730\uff09\u6267\u884c\u6240\u6709\u4eff\u771f\u4efb\u52a1\u3002\u5f85\u6240\u6709\u4efb\u52a1\u5b8c\u6210\u540e\uff0c\u5b83\u4f1a\u5c06\u6bcf\u4e2a\u4efb\u52a1\u8ba1\u7b97\u51fa\u7684\u6027\u80fd\u6307\u6807\uff08\u5982 <code>Startup_Inventory</code>\uff09\u6c47\u603b\u8d77\u6765\uff0c\u5e76\u751f\u6210\u4e00\u4e2a\u540d\u4e3a <code>sensitivity_analysis_summary.csv</code> \u7684\u7ed3\u679c\u6587\u4ef6\u3002\u6b64\u6587\u4ef6\u7684\u6bcf\u4e00\u884c\u5bf9\u5e94 <code>salib_sampling.csv</code> \u4e2d\u7684\u4e00\u884c\u8f93\u5165\uff0c\u4ece\u800c\u5b8c\u7f8e\u5730\u5c06\u8f93\u5165\u53c2\u6570\u4e0e\u8f93\u51fa\u7ed3\u679c\u5bf9\u5e94\u8d77\u6765\u3002</li> </ol>"},{"location":"explanation/tricys_analysis/salib_integration.html#salib","title":"\u6b65\u9aa4\u4e09\uff1a\u7ed3\u679c\u5206\u6790\u4e0e\u62a5\u544a (SALib \u8bfb\u53d6\u7ed3\u679c)","text":"<p>\u4eff\u771f\u5b8c\u6210\u540e\uff0c\u63a7\u5236\u6743\u518d\u6b21\u56de\u5230 <code>salib.py</code>\uff0c\u8fdb\u884c\u6700\u540e\u7684\u5206\u6790\u548c\u62a5\u544a\u751f\u6210\u3002</p> <ol> <li>\u52a0\u8f7d\u7ed3\u679c\uff1a<code>load_tricys_results()</code> \u51fd\u6570\u4f1a\u8bfb\u53d6 <code>sensitivity_analysis_summary.csv</code>\uff0c\u5c06 TRICYS \u7684\u8ba1\u7b97\u7ed3\u679c\u52a0\u8f7d\u5230\u5185\u5b58\u4e2d\u3002</li> <li>\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\uff1a\u6839\u636e\u7528\u6237\u9009\u62e9\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u8c03\u7528\u5bf9\u5e94\u7684\u5206\u6790\u51fd\u6570\uff0c\u5982 <code>analyze_sobol()</code>\u3002\u8be5\u51fd\u6570\u4f1a\u5c06\u53c2\u6570\u6837\u672c\u548c\u4eff\u771f\u7ed3\u679c\u4e00\u540c\u9001\u5165 SALib \u7684\u5206\u6790\u5f15\u64ce\uff0c\u8ba1\u7b97\u51fa S1\u3001ST \u7b49\u654f\u611f\u6027\u6307\u6570\u3002</li> <li>\u751f\u6210\u62a5\u544a\uff1a\u6700\u540e\uff0c<code>plot_*_results()</code> \u548c <code>_save_sensitivity_report()</code> \u7b49\u51fd\u6570\u4f1a\u5229\u7528\u8ba1\u7b97\u51fa\u7684\u6307\u6570\uff0c\u751f\u6210\u4e00\u7cfb\u5217\u53ef\u89c6\u5316\u7684\u56fe\u8868\uff08\u5982\u6761\u5f62\u56fe\u3001\u03bc*-\u03c3 \u56fe\uff09\u3001\u6570\u636e\u8868\u683c\u548c\u4e00\u4efd\u5b8c\u6574\u7684 Markdown \u5206\u6790\u62a5\u544a\uff08\u540c\u6837\u652f\u6301 AI \u589e\u5f3a\u7684\u6df1\u5ea6\u89e3\u8bfb\uff09\u3002</li> </ol> <p>\u901a\u8fc7\u8fd9\u4e09\u4e2a\u6e05\u6670\u7684\u6b65\u9aa4\uff0cTRICYS \u6210\u529f\u5730\u5c06 SALib \u5f3a\u5927\u7684\u91c7\u6837\u548c\u5206\u6790\u80fd\u529b\u4e0e\u81ea\u8eab\u9ad8\u6548\u7684\u4eff\u771f\u6267\u884c\u80fd\u529b\u89e3\u8026\u5e76\u96c6\u6210\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u95ee\u9898\u5b9a\u4e49\u5230\u6700\u7ec8\u62a5\u544a\u7684\u5168\u81ea\u52a8\u5316 GSA \u5de5\u4f5c\u6d41\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html","title":"\u534f\u540c\u4eff\u771f\u539f\u7406","text":"<p>\u5728\u534f\u540c\u4eff\u771f\u4e2d\uff0cTRICYS \u63d0\u4f9b\u4e86\u4e24\u79cd\u5c06\u5916\u90e8\u6570\u636e\u6ce8\u5165 Modelica \u6a21\u578b\u7684\u65b9\u6cd5\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#1","title":"1. \u62e6\u622a\u5668\u6a21\u5f0f","text":""},{"location":"explanation/tricys_basic/co_simulation.html#11","title":"1.1. \u5de5\u4f5c\u539f\u7406","text":"<p>\u62e6\u622a\u5668\u6a21\u5f0f\u662f\u4e00\u79cd\u975e\u4fb5\u5165\u5f0f\u7684\u6570\u636e\u6ce8\u5165\u65b9\u6cd5\u3002\u5b83\u4e0d\u4f1a\u4fee\u6539\u4efb\u4f55\u539f\u59cb\u7684\u6a21\u578b\u6587\u4ef6\uff0c\u800c\u662f\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u65b0\u6a21\u578b\u7684\u65b9\u5f0f\u6765\u5b9e\u73b0\u3002</p> <p>\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5728\u539f\u59cb\u5b50\u6a21\u578b\u548c\u4e0b\u6e38\u7ec4\u4ef6\u4e4b\u95f4\u52a8\u6001\u63d2\u5165\u4e00\u4e2a\u65b0\u5efa\u7684\u201c\u62e6\u622a\u5668\u201d\u6a21\u578b\u3002\u6b64\u62e6\u622a\u5668\u50cf\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u5f00\u5173\uff0c\u5b83\u540c\u65f6\u63a5\u6536\u6765\u81ea\u539f\u59cb\u5b50\u6a21\u578b\u7684\u5b9e\u65f6\u8f93\u51fa\u4fe1\u53f7\u548c\u6765\u81ea CSV \u6587\u4ef6\u7684\u9884\u5b9a\u4e49\u6570\u636e\u3002\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u8bbe\u7f6e\u6a21\u578b\u53c2\u6570\uff0c\u60a8\u53ef\u4ee5\u7cbe\u786e\u63a7\u5236\u6bcf\u4e2a\u8f93\u51fa\u4fe1\u53f7\u662f\u9009\u62e9\u201c\u76f4\u901a\u201d\uff08Passthrough\uff09\u4e0a\u6e38\u7684\u5b9e\u65f6\u4fe1\u53f7\uff0c\u8fd8\u662f\u201c\u8986\u76d6\u201d\uff08Override\uff09\u4e3a\u4f7f\u7528 CSV \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u3002</p> <p>\u8fd9\u79cd\u6a21\u5f0f\u7684\u4f18\u52bf\u5728\u4e8e\u5b83\u7684\u5b89\u5168\u6027\u548c\u7075\u6d3b\u6027\uff0c\u6240\u6709\u4fee\u6539\u90fd\u662f\u5728\u81ea\u52a8\u751f\u6210\u7684\u526f\u672c\u4e0a\u8fdb\u884c\u7684\uff08\u4f8b\u5982 <code>_Intercepted.mo</code>\uff09\uff0c\u539f\u59cb\u6a21\u578b\u548c\u7cfb\u7edf\u8bbe\u8ba1\u4fdd\u6301\u4e0d\u53d8\uff0c\u975e\u5e38\u9002\u5408\u7528\u4e8e\u201cwhat-if\u201d\u5206\u6790\u3001\u6545\u969c\u6ce8\u5165\u6216\u4e34\u65f6\u66ff\u6362\u90e8\u5206\u7cfb\u7edf\u884c\u4e3a\u7684\u573a\u666f\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#12","title":"1.2. \u67b6\u6784\u56fe","text":"<pre><code>\u539f\u7cfb\u7edf\u7ed3\u6784\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n\n\u62e6\u622a\u5668\u6a21\u5f0f\u7ed3\u6784\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b] --&gt; [\u62e6\u622a\u5668] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n                               \u2191\n                           [CSV \u6570\u636e]\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#13","title":"1.3. \u5b9e\u73b0\u6b65\u9aa4","text":"<p><code>tricys</code> \u4f1a\u81ea\u52a8\u5b8c\u6210\u4ee5\u4e0b\u6b65\u9aa4\u6765\u5b9e\u73b0\u62e6\u622a\u5668\u6a21\u5f0f\uff1a</p> <pre><code>graph TD\n    A[\u5f00\u59cb] --&gt; B{\u8bfb\u53d6\u534f\u540c\u4eff\u771f\u914d\u7f6e};\n    B --&gt; C[\u901a\u8fc7 OMCSession \u5206\u6790&lt;br&gt;\u76ee\u6807\u5b50\u6a21\u578b\u4ee5\u83b7\u53d6\u6240\u6709\u8f93\u51fa\u7aef\u53e3];\n    C --&gt; D[\u4e3a\u5b50\u6a21\u578b\u52a8\u6001\u751f\u6210\u4e00\u4e2a&lt;br&gt;\u5bf9\u5e94\u7684 '..._Interceptor.mo' \u6a21\u578b\u6587\u4ef6];\n    D --&gt; E[\u8bfb\u53d6\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u7684\u4ee3\u7801];\n    E --&gt; F{\u5728\u7cfb\u7edf\u6a21\u578b\u4e2d&lt;br&gt;\u91cd\u6784\u8fde\u63a5\u5173\u7cfb};\n    F --&gt; G[1. \u58f0\u660e\u5e76\u5b9e\u4f8b\u5316\u62e6\u622a\u5668\u6a21\u578b];\n    F --&gt; H[2. \u4fee\u6539 connect \u8bed\u53e5&lt;br&gt;\u5c06\u539f\u8fde\u63a5\u91cd\u5b9a\u5411\u81f3\u62e6\u622a\u5668];\n    G &amp; H --&gt; I[\u5c06\u4fee\u6539\u540e\u7684\u7cfb\u7edf\u6a21\u578b&lt;br&gt;\u53e6\u5b58\u4e3a '..._Intercepted.mo' \u6587\u4ef6];\n    I --&gt; J[\u7ed3\u675f];\n\n    style C fill:#f9f,stroke:#333,stroke-width:2px;\n    style D fill:#ccf,stroke:#333,stroke-width:2px;\n    style F fill:#f9f,stroke:#333,stroke-width:2px;\n    style I fill:#ccf,stroke:#333,stroke-width:2px;</code></pre> <p>\u5177\u4f53\u6b65\u9aa4\u5206\u89e3\u5982\u4e0b\uff1a 1.  \u5206\u6790\u6a21\u578b\uff1a<code>tricys</code> \u9996\u5148\u4f7f\u7528 OpenModelica (OMC) \u5de5\u5177\u94fe\u5206\u6790\u76ee\u6807\u5b50\u6a21\u578b\uff0c\u81ea\u52a8\u8bc6\u522b\u51fa\u5176\u6240\u6709\u7684\u8f93\u51fa\u7aef\u53e3\u3001\u7ef4\u5ea6\u7b49\u5143\u4fe1\u606f\u3002 2.  \u751f\u6210\u62e6\u622a\u5668\uff1a\u6839\u636e\u4e0a\u4e00\u6b65\u83b7\u53d6\u7684\u7aef\u53e3\u4fe1\u606f\uff0c\u52a8\u6001\u751f\u6210\u4e00\u4e2a\u65b0\u7684 Modelica \u6a21\u578b\uff08<code>..._Interceptor.mo</code>\uff09\u3002\u8be5\u6a21\u578b\u5185\u90e8\u5305\u542b\u4e86 <code>CombiTimeTable</code> \u7ec4\u4ef6\uff08\u7528\u4e8e\u8bfb\u53d6CSV\uff09\u548c\u6570\u636e\u9009\u62e9\u903b\u8f91\u3002 3.  \u4fee\u6539\u7cfb\u7edf\uff1a<code>tricys</code> \u8bfb\u53d6\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u7684\u4ee3\u7801\uff0c\u5e76\u6267\u884c\u4ee5\u4e0b\u4fee\u6539\uff1a     *   \u5b9e\u4f8b\u5316\u62e6\u622a\u5668\uff1a\u5728 <code>equation</code> \u90e8\u5206\u4e4b\u524d\u6dfb\u52a0\u5bf9\u65b0\u751f\u6210\u7684\u62e6\u622a\u5668\u6a21\u578b\u7684\u5b9e\u4f8b\u58f0\u660e\u3002     *   \u91cd\u5b9a\u5411\u8fde\u63a5\uff1a\u901a\u8fc7\u6b63\u5219\u8868\u8fbe\u5f0f\u81ea\u52a8\u67e5\u627e\u5e76\u4fee\u6539 <code>connect</code> \u8bed\u53e5\u3002\u539f\u672c\u4ece\u5b50\u6a21\u578b\u8f93\u51fa\u7aef\u53e3\u5230\u4e0b\u6e38\u7ec4\u4ef6\u7684\u8fde\u63a5\u88ab\u65ad\u5f00\uff0c\u8f6c\u800c\u901a\u8fc7\u62e6\u622a\u5668\u8fdb\u884c\u8def\u7531\uff1a         *   <code>\u5b50\u6a21\u578b.\u8f93\u51fa\u7aef\u53e3</code> -&gt; <code>\u62e6\u622a\u5668.\u7269\u7406\u8f93\u5165\u7aef\u53e3</code>         *   <code>\u62e6\u622a\u5668.\u6700\u7ec8\u8f93\u51fa\u7aef\u53e3</code> -&gt; <code>\u4e0b\u6e38\u7ec4\u4ef6.\u8f93\u5165\u7aef\u53e3</code> 4.  \u4fdd\u5b58\u65b0\u7cfb\u7edf\uff1a\u5c06\u4fee\u6539\u540e\u7684\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u5185\u5bb9\u4fdd\u5b58\u4e3a\u4e00\u4e2a\u65b0\u7684\u6587\u4ef6\uff0c\u5e76\u6dfb\u52a0 <code>_Intercepted</code> \u540e\u7f00\uff0c\u786e\u4fdd\u539f\u59cb\u7cfb\u7edf\u6a21\u578b\u6587\u4ef6\u4e0d\u53d7\u5f71\u54cd\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#14","title":"1.4. \u62e6\u622a\u5668\u6a21\u578b\u793a\u4f8b","text":"<pre><code>within example_model;\n\nmodel Plasma_Interceptor\n  // \u63a5\u6536\u539f\u6a21\u578b\u8f93\u51fa\n  Modelica.Blocks.Interfaces.RealInput physical_to_Pump[5];\n\n  // \u6700\u7ec8\u8f93\u51fa\n  Modelica.Blocks.Interfaces.RealOutput final_to_Pump[5];\n\n  protected\n    parameter String fileName = \"plasma_data.csv\";\n\n    // \u5217\u6620\u5c04\u53c2\u6570\uff1a[time, y1, y2, y3, y4, y5]\n    // \u5982\u679c\u67d0\u5217\u8bbe\u4e3a 1\uff0c\u8868\u793a\u4f7f\u7528\u7269\u7406\u6570\u636e\u800c\u975e CSV\n    parameter Integer columns_to_Pump[6] = {1, 2, 3, 4, 5, 6};\n\n    // CSV \u8bfb\u53d6\u5668\n    Modelica.Blocks.Sources.CombiTimeTable table_to_Pump(\n      tableName=\"csv_data_to_Pump\",\n      fileName=fileName,\n      columns=columns_to_Pump,\n      tableOnFile=true\n    );\n\n  equation\n    // \u9010\u5143\u7d20\u9009\u62e9\u6570\u636e\u6e90\n    for i in 1:5 loop\n      final_to_Pump[i] = if columns_to_Pump[i+1] &lt;&gt; 1 \n                         then table_to_Pump.y[i]   // \u4f7f\u7528 CSV\n                         else physical_to_Pump[i]; // \u4f7f\u7528\u7269\u7406\u6570\u636e\n    end for;\n\nend Plasma_Interceptor;\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#2","title":"2. \u76f4\u63a5\u66ff\u6362\u6a21\u5f0f","text":""},{"location":"explanation/tricys_basic/co_simulation.html#21","title":"2.1. \u5de5\u4f5c\u539f\u7406","text":"<p>\u76f4\u63a5\u66ff\u6362\u6a21\u5f0f\u662f\u4e00\u79cd\u4fb5\u5165\u5f0f\u4f46\u9ad8\u6548\u7684\u65b9\u6cd5\u3002\u5b83\u4f1a\u76f4\u63a5\u4fee\u6539\u76ee\u6807\u5b50\u6a21\u578b\u7684\u6587\u4ef6\uff0c\u7528\u4e00\u4e2a\u201c\u6570\u636e\u64ad\u653e\u5668\u201d\u6765\u5b8c\u5168\u66ff\u4ee3\u5176\u539f\u6709\u7684\u5185\u90e8\u903b\u8f91\u3002</p> <p>\u5de5\u4f5c\u6d41\u7a0b\u662f\uff0c<code>tricys</code> \u9996\u5148\u4f1a\u4e3a\u76ee\u6807\u5b50\u6a21\u578b\u521b\u5efa\u4e00\u4e2a\u5907\u4efd\u6587\u4ef6\uff08<code>.bak</code>\uff09\u3002\u7136\u540e\uff0c\u5b83\u4f1a\u201c\u6e05\u7a7a\u201d\u539f\u59cb\u6a21\u578b\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u5185\u90e8\u65b9\u7a0b\u548c\u53d8\u91cf\uff0c\u4ec5\u4fdd\u7559\u5176\u8f93\u5165/\u8f93\u51fa\u7aef\u53e3\u7684\u58f0\u660e\u3002\u63a5\u7740\uff0c\u5b83\u5411\u8be5\u6a21\u578b\u4e2d\u6dfb\u52a0 <code>CombiTimeTable</code> \u7ec4\u4ef6\uff0c\u5e76\u5c06\u8f93\u51fa\u7aef\u53e3\u76f4\u63a5\u8fde\u63a5\u5230\u8fd9\u4e9b\u7ec4\u4ef6\u7684\u6570\u636e\u8f93\u51fa\u4e0a\u3002</p> <p>\u6700\u7ec8\uff0c\u8be5\u5b50\u6a21\u578b\u53d8\u6210\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u6570\u636e\u6e90\uff0c\u5176\u884c\u4e3a\u5b8c\u5168\u7531\u5916\u90e8 CSV \u6587\u4ef6\u5b9a\u4e49\u3002\u8fd9\u79cd\u6a21\u5f0f\u9002\u7528\u4e8e\u5f53\u4f60\u9700\u8981\u7528\u4e00\u4e2a\u56fa\u5b9a\u7684\u6570\u636e\u96c6\uff08\u4f8b\u5982\uff0c\u6765\u81ea\u9ad8\u7cbe\u5ea6\u4eff\u771f\u7684\u7ed3\u679c\u6216\u5b9e\u9a8c\u6570\u636e\uff09\u6765\u6c38\u4e45\u6216\u534a\u6c38\u4e45\u5730\u66ff\u6362\u4e00\u4e2a\u8ba1\u7b97\u6602\u8d35\u6216\u6682\u4e0d\u53ef\u7528\u7684\u5b50\u6a21\u578b\u65f6\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#22","title":"2.2. \u67b6\u6784\u56fe","text":"<pre><code>\u539f\u7cfb\u7edf\u7ed3\u6784\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n\n\u76f4\u63a5\u66ff\u6362\u6a21\u5f0f\uff1a\n  [\u4e0a\u6e38\u6a21\u578b] --&gt; [\u5b50\u6a21\u578b(CSV\u7248)] --&gt; [\u4e0b\u6e38\u6a21\u578b]\n                     \u2191\n                 [CSV \u6570\u636e]\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#23","title":"2.3. \u5b9e\u73b0\u6b65\u9aa4","text":"<p><code>tricys</code> \u901a\u8fc7\u4ee5\u4e0b\u81ea\u52a8\u5316\u6d41\u7a0b\u5b9e\u73b0\u76f4\u63a5\u66ff\u6362\uff1a</p> <pre><code>graph TD\n    A[\u5f00\u59cb] --&gt; B{\u8bfb\u53d6\u534f\u540c\u4eff\u771f\u914d\u7f6e};\n    B --&gt; C[\u5b9a\u4f4d\u5230\u76ee\u6807\u5b50\u6a21\u578b\u7684 '.mo' \u6587\u4ef6];\n    C --&gt; D[\u521b\u5efa\u8be5\u6587\u4ef6\u7684\u5907\u4efd&lt;br&gt;\u4f8b\u5982 'SubModel.mo' -&gt; 'SubModel.bak'];\n    D --&gt; E[\u8bfb\u53d6\u6a21\u578b\u4ee3\u7801&lt;br&gt;\u4ec5\u4fdd\u7559\u7aef\u53e3\u58f0\u660e\u548c\u6a21\u578b\u6846\u67b6];\n    E --&gt; F[\u751f\u6210\u65b0\u7684\u6a21\u578b\u5185\u5bb9];\n    F --&gt; G[1. \u6dfb\u52a0 CombiTimeTable \u7ec4\u4ef6&lt;br&gt;\u7528\u4e8e\u8bfb\u53d6 CSV \u6570\u636e];\n    F --&gt; H[2. \u521b\u5efa\u65b0\u7684 equation&lt;br&gt;\u5c06\u8f93\u51fa\u7aef\u53e3\u76f4\u63a5\u8fde\u63a5\u5230 Table \u7684\u8f93\u51fa];\n    G &amp; H --&gt; I[\u4f7f\u7528\u65b0\u751f\u6210\u7684\u4ee3\u7801&lt;br&gt;\u8986\u76d6\u539f\u59cb\u7684 '.mo' \u6587\u4ef6];\n    I --&gt; J[\u7ed3\u675f];\n\n    style D fill:#f9f,stroke:#333,stroke-width:2px;\n    style F fill:#f9f,stroke:#333,stroke-width:2px;\n    style I fill:#ccf,stroke:#333,stroke-width:2px;</code></pre> <p>\u5177\u4f53\u6b65\u9aa4\u5206\u89e3\u5982\u4e0b\uff1a 1.  \u5b9a\u4f4d\u4e0e\u5907\u4efd\uff1a<code>tricys</code> \u6839\u636e <code>submodel_name</code> \u5728\u9879\u76ee\u76ee\u5f55\u4e2d\u627e\u5230\u5bf9\u5e94\u7684 <code>.mo</code> \u6587\u4ef6\uff0c\u5e76\u7acb\u5373\u521b\u5efa\u4e00\u4e2a <code>.bak</code> \u540e\u7f00\u7684\u5907\u4efd\u6587\u4ef6\u4ee5\u9632\u6570\u636e\u4e22\u5931\u3002 2.  \u89e3\u6790\u4e0e\u6e05\u7a7a\uff1a\u7a0b\u5e8f\u8bfb\u53d6\u539f\u59cb\u6a21\u578b\u4ee3\u7801\uff0c\u5e76\u89e3\u6790\u51fa\u5176\u5b8c\u6574\u7684\u8f93\u5165/\u8f93\u51fa\u7aef\u53e3\u58f0\u660e\u3002\u7136\u540e\uff0c\u5b83\u4f1a\u4e22\u5f03\u6a21\u578b\u4e2d\u6240\u6709\u5176\u4ed6\u5185\u5bb9\uff0c\u5982 <code>parameter</code>, <code>protected</code> \u90e8\u5206\u7684\u53d8\u91cf\u4ee5\u53ca <code>equation</code> \u90e8\u5206\u7684\u6240\u6709\u65b9\u7a0b\u3002 3.  \u751f\u6210\u65b0\u4ee3\u7801\uff1a<code>tricys</code> \u57fa\u4e8e\u89e3\u6790\u51fa\u7684\u7aef\u53e3\u4fe1\u606f\u751f\u6210\u5168\u65b0\u7684\u6a21\u578b\u4ee3\u7801\uff1a     *   \u4fdd\u7559\u539f\u59cb\u7684\u7aef\u53e3\u58f0\u660e\uff0c\u786e\u4fdd\u5176\u5bf9\u5916\u63a5\u53e3\u4e0d\u53d8\u3002     *   \u4e3a\u6bcf\u4e2a\u9700\u8981\u88ab CSV \u6570\u636e\u9a71\u52a8\u7684\u8f93\u51fa\u7aef\u53e3\uff0c\u6dfb\u52a0\u4e00\u4e2a <code>CombiTimeTable</code> \u5b9e\u4f8b\uff0c\u5e76\u914d\u7f6e\u597d <code>fileName</code> \u548c <code>columns</code> \u7b49\u53c2\u6570\u3002     *   \u521b\u5efa\u4e00\u4e2a\u65b0\u7684 <code>equation</code> \u90e8\u5206\uff0c\u7528\u7b80\u5355\u7684\u6620\u5c04\u8bed\u53e5 <code>output_port = table.y</code> \u5c06\u8f93\u51fa\u7aef\u53e3\u76f4\u63a5\u8fde\u63a5\u5230 <code>CombiTimeTable</code> \u7684\u6570\u636e\u8f93\u51fa\u4e0a\u3002 4.  \u8986\u76d6\u6587\u4ef6\uff1a\u6700\u540e\uff0c<code>tricys</code> \u7528\u65b0\u751f\u6210\u7684\u4ee3\u7801\u5b8c\u5168\u8986\u76d6\u539f\u59cb\u7684 <code>.mo</code> \u6587\u4ef6\uff0c\u5b8c\u6210\u66ff\u6362\u8fc7\u7a0b\u3002\u7531\u4e8e\u5b50\u6a21\u578b\u7684\u63a5\u53e3\uff08\u7aef\u53e3\uff09\u6ca1\u6709\u6539\u53d8\uff0c\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u65e0\u9700\u4efb\u4f55\u4fee\u6539\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#24","title":"2.4. \u66ff\u6362\u540e\u6a21\u578b\u793a\u4f8b","text":"<pre><code>within example_model;\n\nmodel Plasma\n  // \u539f\u6709\u7aef\u53e3\u58f0\u660e\u4fdd\u6301\u4e0d\u53d8\n  Modelica.Blocks.Interfaces.RealInput pulseInput;\n  Modelica.Blocks.Interfaces.RealOutput from_Fueling_System[5];\n  Modelica.Blocks.Interfaces.RealOutput to_FW[5];\n  Modelica.Blocks.Interfaces.RealOutput to_Div[5];\n  Modelica.Blocks.Interfaces.RealOutput to_Pump[5];\n\nprotected\n  parameter String fileName = \"plasma_data.csv\";\n\n  // CSV \u6570\u636e\u6e90\n  Modelica.Blocks.Sources.CombiTimeTable table_to_Pump(\n    tableName=\"csv_data_to_Pump\",\n    fileName=fileName,\n    columns={1, 2, 3, 4, 5, 6},  // time + 5 data columns\n    tableOnFile=true\n  );\n\n  Modelica.Blocks.Sources.CombiTimeTable table_to_FW(\n    tableName=\"csv_data_to_FW\",\n    fileName=fileName,\n    columns={1, 7, 8, 9, 10, 11},\n    tableOnFile=true\n  );\n\n  // ... \u5176\u4ed6\u7aef\u53e3\u7684 table \u5b9a\u4e49 ...\n\nequation\n  // \u76f4\u63a5\u6620\u5c04 CSV \u5230\u8f93\u51fa\uff08\u5ffd\u7565\u8f93\u5165\uff09\n  for i in 1:5 loop\n    to_Pump[i] = table_to_Pump.y[i];\n    to_FW[i] = table_to_FW.y[i];\n    to_Div[i] = table_to_Div.y[i];\n    from_Fueling_System[i] = table_from_Fueling_System.y[i];\n  end for;\n\nend Plasma;\n</code></pre>"},{"location":"explanation/tricys_basic/co_simulation.html#3","title":"3. \u7f16\u5199\u60a8\u81ea\u5df1\u7684\u5904\u7406\u5668","text":"<p>\u9664\u4e86\u4f7f\u7528\u5185\u7f6e\u7684\u5904\u7406\u5668\uff0c<code>tricys</code> \u534f\u540c\u4eff\u771f\u6846\u67b6\u6700\u5f3a\u5927\u7684\u529f\u80fd\u662f\u5141\u8bb8\u60a8\u7f16\u5199\u81ea\u5df1\u7684 Python \u51fd\u6570\uff08\u5904\u7406\u5668\uff09\u6765\u52a8\u6001\u751f\u6210\u6ce8\u5165\u5230 Modelica \u6a21\u578b\u4e2d\u7684\u6570\u636e\u3002\u8fd9\u610f\u5473\u7740\u60a8\u53ef\u4ee5\u96c6\u6210\u4efb\u4f55\u590d\u6742\u7684\u5916\u90e8\u6a21\u578b\u3001\u7b97\u6cd5\u6216\u6570\u636e\u6e90\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#31","title":"3.1. \u5904\u7406\u5668\u914d\u7f6e","text":"<p>\u5728 <code>config.json</code> \u7684 <code>co_simulation.handlers</code> \u5217\u8868\u4e2d\uff0c\u6bcf\u4e00\u4e2a\u5904\u7406\u5668\u5bf9\u8c61\u90fd\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u6765\u5b9a\u4e49\u5176\u884c\u4e3a\uff1a</p> <ul> <li> <p><code>handler_module</code> \u6216 <code>handler_script_path</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b\u4e4b\u4e00):</p> <ul> <li><code>handler_module</code>: \u6307\u5b9a\u5904\u7406\u5668\u51fd\u6570\u6240\u5728\u7684 Python \u6a21\u5757 \u7684\u5b8c\u6574\u8def\u5f84\u3002\u9002\u7528\u4e8e\u4ee3\u7801\u662f\u6807\u51c6 Python \u5305\u4e00\u90e8\u5206\u7684\u573a\u666f\u3002</li> <li><code>handler_script_path</code>: \u6307\u5b9a\u5305\u542b\u5904\u7406\u5668\u51fd\u6570\u7684 Python \u811a\u672c\u6587\u4ef6 \u7684\u8def\u5f84\u3002\u8fd9\u66f4\u52a0\u7075\u6d3b\uff0c\u9002\u7528\u4e8e\u72ec\u7acb\u7684\u811a\u672c\u6587\u4ef6\u3002</li> </ul> </li> <li> <p><code>handler_function</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</p> <ul> <li>\u63cf\u8ff0: \u8981\u5728\u6307\u5b9a\u6a21\u5757\u6216\u811a\u672c\u4e2d\u8c03\u7528\u7684\u51fd\u6570\u540d\u3002</li> </ul> </li> <li> <p><code>params</code> (\u5b57\u5178, \u9009\u586b):</p> <ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5305\u542b\u8981\u4f20\u9012\u7ed9\u5904\u7406\u5668\u51fd\u6570\u7684\u4efb\u610f\u5173\u952e\u5b57\u53c2\u6570\u7684\u5b57\u5178\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_basic/co_simulation.html#32","title":"3.2. \u51fd\u6570\u7b7e\u540d\u4e0e\u804c\u8d23","text":"<p>\u4e3a\u4e86\u80fd\u88ab <code>tricys</code> \u6846\u67b6\u6b63\u786e\u8c03\u7528\uff0c\u60a8\u7684\u5904\u7406\u5668\u51fd\u6570\u5fc5\u987b\u9075\u5faa\u7279\u5b9a\u7684\u7b7e\u540d\u3002\u6846\u67b6\u4f1a\u81ea\u52a8\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570\u4f20\u5165\u4e24\u4e2a\u6838\u5fc3\u8def\u5f84\uff0c\u60a8\u7684\u51fd\u6570\u9700\u8981\u5b9a\u4e49\u5e76\u63a5\u6536\u5b83\u4eec\uff1a</p> <pre><code>def my_handler(temp_input_csv: str, temp_output_csv: str, **kwargs) -&gt; dict:\n    \"\"\"\n    \u4e00\u4e2a\u6807\u51c6\u7684\u5904\u7406\u5668\u51fd\u6570\u7b7e\u540d\u3002\n\n    Args:\n        temp_input_csv (str): \u4e00\u4e2a CSV \u6587\u4ef6\u7684\u8def\u5f84\uff0c\u5305\u542b\u4e0a\u6e38\u6a21\u578b\u7684\u8f93\u51fa\u7ed3\u679c\u3002\n                              \u60a8\u53ef\u4ee5\u8bfb\u53d6\u6b64\u6587\u4ef6\u6765\u83b7\u53d6\u9a71\u52a8\u60a8\u8ba1\u7b97\u7684\u8f93\u5165\u3002\n        temp_output_csv (str): \u4e00\u4e2a\u76ee\u6807 CSV \u6587\u4ef6\u7684\u8def\u5f84\uff0c\u60a8\u9700\u8981\u5c06\u8ba1\u7b97\u7ed3\u679c\u5199\u5165\u6b64\u6587\u4ef6\u3002\n                               tricys \u4f1a\u5c06\u6b64\u6587\u4ef6\u63d0\u4f9b\u7ed9 Modelica \u7684 CombiTimeTable\u3002\n        **kwargs: \u7528\u4e8e\u63a5\u6536\u6765\u81ea JSON \u914d\u7f6e\u4e2d \"params\" \u7684\u6240\u6709\u81ea\u5b9a\u4e49\u53c2\u6570\u3002\n\n    Returns:\n        dict: \u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u4e8e\u914d\u7f6e Modelica CombiTimeTable \u7684\u5217\u6620\u5c04\u3002\n    \"\"\"\n    # ... \u60a8\u7684\u4ee3\u7801\u903b\u8f91 ...\n</code></pre> <p>\u6838\u5fc3\u804c\u8d23: 1.  \u8bfb\u53d6\u8f93\u5165 (\u53ef\u9009): \u4f7f\u7528 Pandas \u6216\u5176\u4ed6\u5e93\u8bfb\u53d6 <code>temp_input_csv</code> \u6587\u4ef6\uff0c\u83b7\u53d6\u4e0a\u6e38\u6a21\u578b\u7684\u52a8\u6001\u8f93\u51fa\u3002 2.  \u6267\u884c\u8ba1\u7b97: \u8fd0\u884c\u60a8\u7684\u6a21\u578b\u3001\u7b97\u6cd5\u6216\u4efb\u4f55\u5176\u4ed6\u903b\u8f91\u3002 3.  \u5199\u5165\u8f93\u51fa: \u5c06\u60a8\u7684\u8ba1\u7b97\u7ed3\u679c\uff08\u5fc5\u987b\u5305\u542b <code>time</code> \u5217\uff09\u4fdd\u5b58\u4e3a CSV \u683c\u5f0f\u5230 <code>temp_output_csv</code> \u6307\u5b9a\u7684\u8def\u5f84\u3002</p>"},{"location":"explanation/tricys_basic/co_simulation.html#33","title":"3.3. \u8fd4\u56de\u503c","text":"<p>\u5904\u7406\u5668\u51fd\u6570\u5fc5\u987b\u8fd4\u56de\u4e00\u4e2a\u5b57\u5178\u3002\u8fd9\u4e2a\u5b57\u5178\u7684\u952e\u5bf9\u5e94 Modelica \u5b50\u6a21\u578b\u7684\u8f93\u51fa\u7aef\u53e3\u540d\uff0c\u503c\u662f\u4e00\u4e2a\u5b57\u7b26\u4e32\uff0c\u7528\u4e8e\u914d\u7f6e <code>CombiTimeTable</code> \u7684 <code>columns</code> \u53c2\u6570\uff0c\u5b9a\u4e49\u4e86\u5982\u4f55\u4ece\u60a8\u751f\u6210\u7684 CSV \u6587\u4ef6\u4e2d\u8bfb\u53d6\u6570\u636e\u5217\u3002</p> <ul> <li>\u793a\u4f8b: <code>return {\"to_CL\": \"{1,2,3,4,5,6}\"}</code></li> <li>\u8fd9\u544a\u8bc9 <code>tricys</code>\uff0c\u5bf9\u4e8e\u540d\u4e3a <code>to_CL</code> \u7684\u8f93\u51fa\u7aef\u53e3\uff0c\u751f\u6210\u7684 <code>CombiTimeTable</code> \u5e94\u8be5\u4f7f\u7528\u60a8\u5728 <code>temp_output_csv</code> \u4e2d\u5199\u5165\u7684\u7b2c 1 \u5230\u7b2c 6 \u5217\u6570\u636e\uff08\u5176\u4e2d\u7b2c 1 \u5217\u901a\u5e38\u662f <code>time</code>\uff09\u3002</li> </ul>"},{"location":"explanation/tricys_basic/co_simulation.html#34","title":"3.4. \u5b8c\u6574\u793a\u4f8b","text":"<p>\u4ee5\u5185\u7f6e\u7684 <code>div_handler.py</code> \u4e3a\u4f8b\uff0c\u5b83\u6a21\u62df\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u5916\u90e8\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4e0d\u4f9d\u8d56\u4e0a\u6e38\u8f93\u5165\uff0c\u800c\u662f\u81ea\u5df1\u751f\u6210\u6570\u636e\u3002</p> <p>\u6b65\u9aa4 1: \u521b\u5efa\u5904\u7406\u5668\u811a\u672c</p> <pre><code># tricys/handlers/div_handler.py\n\nimport os\nimport pandas as pd\n\ndef run_div_simulation(temp_input_csv, temp_output_csv, **kwargs):\n    \"\"\"\n    \u4e00\u4e2a\u7b80\u5355\u7684\u5904\u7406\u5668\uff0c\u5b83\u8bfb\u53d6\u4e00\u4e2a\u9884\u5b9a\u4e49\u7684 CSV \u6587\u4ef6\u5e76\u5c06\u5176\u5185\u5bb9\n    \u5199\u5165\u5230\u6846\u67b6\u6307\u5b9a\u7684\u76ee\u6807\u8f93\u51fa\u8def\u5f84\u3002\n    \"\"\"\n    # \u83b7\u53d6\u5f53\u524d\u6587\u4ef6\u6240\u5728\u76ee\u5f55\uff0c\u4ee5\u5b9a\u4f4d\u6570\u636e\u6587\u4ef6\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"div_handler.csv\")\n\n    # \u8bfb\u53d6\u6e90\u6570\u636e\n    source_df = pd.read_csv(source_csv_path)\n\n    # \u5b9a\u4e49\u9700\u8981\u8f93\u51fa\u5230 Modelica \u7684\u5217\n    columns_to_select = [\n        \"time\",\n        \"div.to_CL[1]\", \"div.to_CL[2]\", \"div.to_CL[3]\",\n        \"div.to_CL[4]\", \"div.to_CL[5]\",\n    ]\n    output_df = source_df[columns_to_select].copy()\n\n    # \u5c06\u5904\u7406\u540e\u7684\u6570\u636e\u5199\u5165\u6846\u67b6\u6307\u5b9a\u7684\u76ee\u6807 CSV \u6587\u4ef6\n    output_df.to_csv(temp_output_csv, index=False)\n\n    # \u8fd4\u56de\u7aef\u53e3\u4e0e\u5217\u7684\u6620\u5c04\u5173\u7cfb\n    output_placeholder = {\"to_CL\": \"{1,2,3,4,5,6}\"}\n    return output_placeholder\n</code></pre> <p>\u6b65\u9aa4 2: \u5728 <code>config.json</code> \u4e2d\u914d\u7f6e</p> <pre><code>\"co_simulation\": {\n    \"mode\": \"interceptor\",\n    \"handlers\": [\n        {\n            \"submodel_name\": \"example_model.DIV\",\n            \"instance_name\": \"div\",\n            \"handler_module\": \"tricys.handlers.div_handler\",\n            \"handler_function\": \"run_div_simulation\",\n            \"params\": {}\n        }\n    ]\n}\n</code></pre> <p>\u5728\u8fd9\u4e2a\u914d\u7f6e\u4e2d\uff0c<code>tricys</code> \u4f1a: 1.  \u5bfc\u5165 <code>tricys.handlers.div_handler</code> \u6a21\u5757\u3002 2.  \u8c03\u7528 <code>run_div_simulation</code> \u51fd\u6570\u3002 3.  \u51fd\u6570\u6267\u884c\u540e\uff0c\u751f\u6210\u4e00\u4e2a\u65b0\u7684 CSV \u6587\u4ef6\u3002 4.  \u4f7f\u7528\u51fd\u6570\u8fd4\u56de\u7684 <code>{\"to_CL\": \"{1,2,3,4,5,6}\"}</code> \u6765\u914d\u7f6e\u6ce8\u5165\u5230 Modelica \u4eff\u771f\u4e2d\u7684 <code>CombiTimeTable</code>\u3002</p>"},{"location":"explanation/tricys_basic/concurrency.html","title":"TRICYS \u5e76\u53d1\u6267\u884c","text":"<p>TRICYS \u65e8\u5728\u5145\u5206\u5229\u7528\u73b0\u4ee3\u591a\u6838\u5904\u7406\u5668\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u901a\u8fc7\u5e76\u53d1\u6267\u884c\u6765\u663e\u8457\u7f29\u77ed\u53c2\u6570\u626b\u63cf\u548c\u6279\u91cf\u4eff\u771f\u7684\u603b\u8017\u65f6\u3002\u6839\u636e\u4eff\u771f\u7c7b\u578b\u7684\u4e0d\u540c\uff0cTRICYS \u4f1a\u667a\u80fd\u5730\u91c7\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u5e76\u53d1\u7b56\u7565\uff1a\u591a\u7ebf\u7a0b\uff08\u7528\u4e8e\u6807\u51c6\u4eff\u771f\uff09\u548c\u591a\u8fdb\u7a0b\uff08\u7528\u4e8e\u534f\u540c\u4eff\u771f\uff09\u3002</p> <p>\u60a8\u53ef\u4ee5\u5728 <code>config.json</code> \u4e2d\u901a\u8fc7\u4ee5\u4e0b\u53c2\u6570\u6765\u63a7\u5236\u5e76\u53d1\u884c\u4e3a\uff1a</p> <pre><code>\"simulation\": {\n  \"concurrent\": true,  // \u8bbe\u7f6e\u4e3a true \u6765\u5f00\u542f\u5e76\u53d1\u6a21\u5f0f\n  \"max_workers\": 8     // \u8bbe\u7f6e\u6700\u5927\u5e76\u53d1\u5de5\u4f5c\u5355\u5143\u6570\uff0c\u9ed8\u8ba4\u4e3a CPU \u6838\u5fc3\u6570\n}\n</code></pre>"},{"location":"explanation/tricys_basic/concurrency.html#1","title":"1. \u6807\u51c6\u4eff\u771f\uff1a\u591a\u7ebf\u7a0b\u5e76\u53d1","text":"<p>\u5bf9\u4e8e\u4e0d\u6d89\u53ca\u534f\u540c\u4eff\u771f\u7684\u6807\u51c6\u53c2\u6570\u626b\u63cf\u4efb\u52a1\uff0cTRICYS \u9ed8\u8ba4\u4f7f\u7528\u591a\u7ebf\u7a0b\u6a21\u578b\u3002</p>"},{"location":"explanation/tricys_basic/concurrency.html#11","title":"1.1. \u5de5\u4f5c\u539f\u7406","text":"<p>TRICYS \u4f7f\u7528 Python \u7684 <code>concurrent.futures.ThreadPoolExecutor</code> \u6765\u7ba1\u7406\u4e00\u4e2a\u5de5\u4f5c\u7ebf\u7a0b\u6c60\u3002\u6bcf\u4e2a\u4eff\u771f\u4efb\u52a1\uff08\u5373\u4e00\u7ec4\u7279\u5b9a\u7684\u53c2\u6570\uff09\u4f1a\u88ab\u63d0\u4ea4\u5230\u7ebf\u7a0b\u6c60\u4e2d\uff0c\u7531\u4e00\u4e2a\u7a7a\u95f2\u7684\u7ebf\u7a0b\u6765\u6267\u884c\u3002</p> <pre><code># \u7b80\u5316\u7248\u539f\u7406\u4ee3\u7801\nfrom concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=8) as executor:\n    # _run_single_job \u662f\u6bcf\u4e2a\u7ebf\u7a0b\u8981\u6267\u884c\u7684\u4efb\u52a1\n    futures = [executor.submit(_run_single_job, config, params, i) for i, params in enumerate(jobs)]\n    # ... \u7b49\u5f85\u5e76\u6536\u96c6\u7ed3\u679c ...\n</code></pre>"},{"location":"explanation/tricys_basic/concurrency.html#12","title":"1.2. \u4e3a\u4f55\u4f7f\u7528\u591a\u7ebf\u7a0b\uff1f","text":"<p>\u867d\u7136 Python \u5b58\u5728\u5168\u5c40\u89e3\u91ca\u5668\u9501\uff08GIL\uff09\uff0c\u4f7f\u5f97\u5728\u5355\u4e2a\u8fdb\u7a0b\u4e2d\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684 CPU \u5bc6\u96c6\u578b\u4ee3\u7801\u5e76\u884c\uff0c\u4f46\u5bf9\u4e8e\u6807\u51c6 Modelica \u4eff\u771f\u573a\u666f\uff0c\u591a\u7ebf\u7a0b\u4ecd\u7136\u662f\u9ad8\u6548\u7684\u9009\u62e9\u3002\u539f\u56e0\u5982\u4e0b\uff1a</p> <ul> <li>I/O \u5bc6\u96c6\u578b\uff1a\u8c03\u7528 <code>OMPython</code> \u8fd0\u884c\u4eff\u771f\u672c\u8d28\u4e0a\u662f\u542f\u52a8\u4e00\u4e2a\u5916\u90e8\u7684 <code>simulate.exe</code> \u53ef\u6267\u884c\u6587\u4ef6\u3002Python \u7ebf\u7a0b\u5728\u6b64\u671f\u95f4\u4e3b\u8981\u5904\u4e8e\u7b49\u5f85\u72b6\u6001\uff08I/O-bound\uff09\uff0c\u7b49\u5f85\u5916\u90e8\u8fdb\u7a0b\u5b8c\u6210\u8ba1\u7b97\u5e76\u5199\u56de\u7ed3\u679c\u6587\u4ef6\u3002GIL \u5728\u6b64\u671f\u95f4\u4f1a\u88ab\u91ca\u653e\uff0c\u5141\u8bb8\u5176\u4ed6\u7ebf\u7a0b\u8fd0\u884c\u3002</li> <li>\u4f4e\u5f00\u9500\uff1a\u7ebf\u7a0b\u6bd4\u8fdb\u7a0b\u66f4\u8f7b\u91cf\uff0c\u521b\u5efa\u548c\u9500\u6bc1\u7684\u901f\u5ea6\u66f4\u5feb\uff0c\u5360\u7528\u7684\u7cfb\u7edf\u8d44\u6e90\u4e5f\u66f4\u5c11\u3002\u5bf9\u4e8e\u6570\u91cf\u4f17\u591a\u4f46\u6bcf\u6b21\u4eff\u771f\u8017\u65f6\u4e0d\u662f\u7279\u522b\u957f\u7684\u4efb\u52a1\uff0c\u4f7f\u7528\u7ebf\u7a0b\u53ef\u4ee5\u51cf\u5c11\u4efb\u52a1\u8c03\u5ea6\u7684\u989d\u5916\u5f00\u9500\u3002</li> </ul>"},{"location":"explanation/tricys_basic/concurrency.html#2","title":"2. \u534f\u540c\u4eff\u771f\uff1a\u591a\u8fdb\u7a0b\u5e76\u53d1","text":"<p>\u5bf9\u4e8e\u590d\u6742\u7684\u534f\u540c\u4eff\u771f\u4efb\u52a1\uff0cTRICYS \u5219\u5207\u6362\u5230\u66f4\u5065\u58ee\u7684\u591a\u8fdb\u7a0b\u6a21\u578b\u3002</p>"},{"location":"explanation/tricys_basic/concurrency.html#21","title":"2.1. \u5de5\u4f5c\u539f\u7406","text":"<p>TRICYS \u4f7f\u7528 <code>concurrent.futures.ProcessPoolExecutor</code> \u6765\u521b\u5efa\u4e00\u4e2a\u8fdb\u7a0b\u6c60\u3002\u6bcf\u4e2a\u534f\u540c\u4eff\u771f\u4efb\u52a1\uff08<code>_run_co_simulation</code>\uff09\u90fd\u5728\u4e00\u4e2a\u5b8c\u5168\u72ec\u7acb\u7684\u5b50\u8fdb\u7a0b\u4e2d\u8fd0\u884c\u3002</p> <pre><code># \u7b80\u5316\u7248\u539f\u7406\u4ee3\u7801\nfrom concurrent.futures import ProcessPoolExecutor\n\nwith ProcessPoolExecutor(max_workers=8) as executor:\n    # _run_co_simulation \u5728\u4e00\u4e2a\u72ec\u7acb\u7684\u8fdb\u7a0b\u4e2d\u6267\u884c\n    futures = [executor.submit(_run_co_simulation, config, params, i) for i, params in enumerate(jobs)]\n    # ... \u7b49\u5f85\u5e76\u6536\u96c6\u7ed3\u679c ...\n</code></pre>"},{"location":"explanation/tricys_basic/concurrency.html#22","title":"2.2. \u4e3a\u4f55\u5fc5\u987b\u4f7f\u7528\u591a\u8fdb\u7a0b\uff1f","text":"<p>\u534f\u540c\u4eff\u771f\u7684\u5de5\u4f5c\u6d41\u7a0b\u6d89\u53ca\u5230\u5bf9\u6587\u4ef6\u7cfb\u7edf\u7684\u5927\u91cf\u8bfb\u5199\u548c\u4fee\u6539\uff0c\u8fd9\u662f\u5176\u5fc5\u987b\u4f7f\u7528\u591a\u8fdb\u7a0b\u7684\u6838\u5fc3\u539f\u56e0\uff1a</p> <ul> <li>\u73af\u5883\u9694\u79bb\uff1a\u6bcf\u4e2a\u534f\u540c\u4eff\u771f\u4efb\u52a1\u90fd\u9700\u8981\u4e00\u4e2a\u7eaf\u51c0\u3001\u72ec\u7acb\u7684\u8fd0\u884c\u73af\u5883\u3002\u5b83\u4f1a\u5c06\u539f\u59cb Modelica \u6a21\u578b\u5305\u590d\u5236\u5230\u4e00\u4e2a\u4e34\u65f6\u76ee\u5f55\uff0c\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u4fee\u6539\uff08\u4f8b\u5982\uff0c\u751f\u6210\u62e6\u622a\u5668\u6216\u76f4\u63a5\u66ff\u6362\u6a21\u578b\uff09\u3002\u5982\u679c\u4f7f\u7528\u591a\u7ebf\u7a0b\uff0c\u591a\u4e2a\u4efb\u52a1\u4f1a\u540c\u65f6\u4fee\u6539\u5171\u4eab\u7684\u6a21\u578b\u6587\u4ef6\uff0c\u5bfc\u81f4\u6587\u4ef6\u635f\u574f\u548c\u7ed3\u679c\u9519\u4e71\u3002</li> <li>\u65e0\u72b6\u6001\u51b2\u7a81\uff1a\u8fdb\u7a0b\u62e5\u6709\u72ec\u7acb\u7684\u5185\u5b58\u7a7a\u95f4\u548c\u6587\u4ef6\u53e5\u67c4\u3002\u8fd9\u786e\u4fdd\u4e86\u4e00\u4e2a\u4efb\u52a1\u5bf9\u6a21\u578b\u4ee3\u7801\u7684\u4fee\u6539\u3001\u5916\u90e8 Python \u5904\u7406\u5668\uff08handler\uff09\u7684\u8fd0\u884c\u4ee5\u53ca\u751f\u6210\u7684\u6240\u6709\u4e2d\u95f4\u6587\u4ef6\uff0c\u90fd\u4e0d\u4f1a\u5bf9\u5176\u4ed6\u5e76\u884c\u4efb\u52a1\u4ea7\u751f\u4efb\u4f55\u5e72\u6270\u3002</li> <li>\u89c4\u907f GIL\uff1a\u534f\u540c\u4eff\u771f\u4e2d\u7684 Python \u5904\u7406\u5668\uff08handler\uff09\u672c\u8eab\u53ef\u80fd\u662f\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684\u3002\u5728\u591a\u8fdb\u7a0b\u6a21\u578b\u4e0b\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u6709\u81ea\u5df1\u7684 Python \u89e3\u91ca\u5668\u548c GIL\uff0c\u53ef\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u5e76\u884c\u8ba1\u7b97\uff0c\u5145\u5206\u5229\u7528\u6240\u6709 CPU \u6838\u5fc3\u3002</li> </ul>"},{"location":"explanation/tricys_basic/concurrency.html#3","title":"3. \u6027\u80fd\u4e0e\u5b9e\u8df5\u5efa\u8bae","text":"<ul> <li> <p>\u5408\u7406\u8bbe\u7f6e <code>max_workers</code>\uff1a</p> <ul> <li>\u5bf9\u4e8e I/O \u5bc6\u96c6\u578b\u7684\u6807\u51c6\u4eff\u771f\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u6bd4 CPU \u6838\u5fc3\u6570\u7a0d\u591a\u7684 <code>max_workers</code>\uff08\u4f8b\u5982\uff0c\u6838\u5fc3\u6570 * 1.5\uff09\u3002</li> <li>\u5bf9\u4e8e CPU \u5bc6\u96c6\u578b\u7684\u534f\u540c\u4eff\u771f\uff0c<code>max_workers</code> \u901a\u5e38\u8bbe\u7f6e\u4e3a\u7b49\u4e8e\u6216\u7565\u5c0f\u4e8e\u60a8\u7684 CPU \u6838\u5fc3\u6570\uff0c\u4ee5\u907f\u514d\u8fc7\u5ea6\u7684\u4e0a\u4e0b\u6587\u5207\u6362\u5f00\u9500\u3002</li> <li>\u59cb\u7ec8\u8981\u8003\u8651\u5185\u5b58\u9650\u5236\u3002\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u4f1a\u6d88\u8017\u76f8\u5f53\u6570\u91cf\u7684\u5185\u5b58\uff0c\u5982\u679c <code>max_workers</code> \u8bbe\u7f6e\u5f97\u592a\u9ad8\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u5185\u5b58\u8017\u5c3d\u3002</li> </ul> </li> <li> <p>\u4efb\u52a1\u7c92\u5ea6\uff1a</p> <ul> <li>\u5e76\u53d1\u6267\u884c\u672c\u8eab\u6709\u5f00\u9500\u3002\u5982\u679c\u5355\u6b21\u4eff\u771f\u8017\u65f6\u975e\u5e38\u77ed\uff08\u4f8b\u5982\uff0c\u5c11\u4e8e 1 \u79d2\uff09\uff0c\u5e76\u53d1\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u53ef\u80fd\u8fd8\u4e0d\u8db3\u4ee5\u62b5\u6d88\u4efb\u52a1\u8c03\u5ea6\u7684\u5f00\u9500\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e32\u884c\u6267\u884c (<code>\"concurrent\": false</code>) \u53ef\u80fd\u66f4\u5feb\u3002</li> </ul> </li> <li> <p>\u76d1\u63a7\u7cfb\u7edf\u8d44\u6e90\uff1a</p> <ul> <li>\u5728\u8fd0\u884c\u5927\u89c4\u6a21\u5e76\u53d1\u4efb\u52a1\u65f6\uff0c\u5efa\u8bae\u4f7f\u7528\u7cfb\u7edf\u76d1\u63a7\u5de5\u5177\uff08\u5982\u4efb\u52a1\u7ba1\u7406\u5668\u6216 <code>htop</code>\uff09\u6765\u89c2\u5bdf CPU \u548c\u5185\u5b58\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u4ee5\u4fbf\u8c03\u6574 <code>max_workers</code> \u5230\u6700\u4f73\u503c\u3002</li> </ul> </li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html","title":"\u4eff\u771f\u6267\u884c\u6d41\u7a0b","text":""},{"location":"explanation/tricys_basic/simulation_flow.html#1","title":"1. \u4eff\u771f\u6267\u884c\u6d41\u7a0b","text":"<p><code>tricys</code> \u7684\u6838\u5fc3\u4eff\u771f\u6d41\u7a0b\u7531 <code>tricys/simulation/simulation.py</code> \u811a\u672c\u9a71\u52a8\u3002\u5b83\u88ab\u8bbe\u8ba1\u4e3a\u4e00\u4e2a\u9ad8\u5ea6\u53ef\u914d\u7f6e\u7684\u3001\u5065\u58ee\u7684\u4eff\u771f\u4e1a\u52a1\u6d41\u7a0b\u534f\u8c03\u7a0b\u5e8f\uff0c\u80fd\u591f\u5904\u7406\u4ece\u7b80\u5355\u7684\u5355\u6b21\u8fd0\u884c\u5230\u590d\u6742\u7684\u591a\u53c2\u6570\u3001\u591a\u6a21\u5f0f\uff08\u6807\u51c6/\u534f\u540c\uff09\u4eff\u771f\u3002</p> <p>\u4ee5\u4e0b\u662f\u5b8c\u6574\u7684\u6267\u884c\u6d41\u7a0b\u56fe\u548c\u8be6\u7ec6\u6b65\u9aa4\u89e3\u91ca\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#2","title":"2. \u8be6\u7ec6\u6d41\u7a0b\u56fe","text":"<pre><code>graph TD\n    %% 1. \u521d\u59cb\u5316\u9636\u6bb5\n    subgraph S1 [\"1. \u521d\u59cb\u5316\"]\n        A[\u5f00\u59cb: \u63d0\u4f9b\u914d\u7f6e\u6587\u4ef6] --&gt; B[\u8bfb\u53d6\u548c\u51c6\u5907\u914d\u7f6e]\n        B --&gt; C[\u8bbe\u7f6e\u65e5\u5fd7\u8bb0\u5f55]\n    end\n\n    %% 2. \u4f5c\u4e1a\u751f\u6210\u9636\u6bb5\n    subgraph S2 [\"2. \u4f5c\u4e1a\u751f\u6210\"]\n        C --&gt; D[\u6839\u636e simulation_parameters \u751f\u6210\u4eff\u771f\u4f5c\u4e1a]\n    end\n\n    %% 3. \u51b3\u7b56\u9636\u6bb5\n    subgraph S3 [\"3. \u6267\u884c\u6a21\u5f0f\u51b3\u7b56\"]\n        D --&gt; E{\u68c0\u6d4b\u5230 co_simulation \u914d\u7f6e?}\n        E -- \u662f --&gt; F[\u534f\u540c\u4eff\u771f\u6d41\u7a0b]\n        E -- \u5426 --&gt; G[\u6807\u51c6\u4eff\u771f\u6d41\u7a0b]\n\n        G --&gt; H{\u4f7f\u7528 concurrent \u5e76\u884c\u6a21\u5f0f?}\n        H -- \u662f --&gt; I[\u5e76\u884c\u6267\u884c\u591a\u4e2a _run_single_job]\n        H -- \u5426 --&gt; J[\u987a\u5e8f\u6267\u884c _run_sequential_sweep]\n\n        F --&gt; K{\u4f7f\u7528 concurrent \u5e76\u884c\u6a21\u5f0f?}\n        K -- \u662f --&gt; L[\u5e76\u884c\u6267\u884c\u591a\u4e2a _run_co_simulation]\n        K -- \u5426 --&gt; M[\u987a\u5e8f\u6267\u884c\u591a\u4e2a _run_co_simulation]\n    end\n\n    %% 4. \u5faa\u73af\u8282\u70b9 (\u8fde\u63a5\u70b9)\n    subgraph S4 [\"4. \u4f5c\u4e1a\u6267\u884c\u5165\u53e3\"]\n        J --&gt; N((\u6807\u51c6\u4eff\u771f\u5faa\u73af))\n        I --&gt; N\n\n        M --&gt; O((\u534f\u540c\u4eff\u771f\u5faa\u73af))\n        L --&gt; O\n    end\n\n    %% \u8be6\u7ec6\u6d41\u7a0b - \u6807\u51c6\u4eff\u771f\n    subgraph S5 [\"\u6807\u51c6\u4eff\u771f (_run_single_job / _run_sequential_sweep)\"]\n        N --&gt; N1[\u521b\u5efa\u72ec\u7acb\u5de5\u4f5c\u533a - \u5e76\u884c\u6a21\u5f0f]\n        N1 --&gt; N2[\u83b7\u53d6OMPython\u4f1a\u8bdd]\n        N2 --&gt; N3[\u52a0\u8f7dModelica\u6a21\u578b]\n        N3 --&gt; N4[\u8bbe\u7f6e\u4eff\u771f\u53c2\u6570]\n        N4 --&gt; N5[\u6267\u884c simulate]\n        N5 --&gt; N6[\u6e05\u7406\u5e76\u4fdd\u5b58\u7ed3\u679cCSV]\n        N6 --&gt; P[\u8fd4\u56de\u7ed3\u679c\u6587\u4ef6\u8def\u5f84]\n    end\n\n    %% \u8be6\u7ec6\u6d41\u7a0b - \u534f\u540c\u4eff\u771f\n    subgraph S6 [\"\u534f\u540c\u4eff\u771f (_run_co_simulation)\"]\n        O --&gt; O1[1. \u521b\u5efa\u72ec\u7acb\u5de5\u4f5c\u533a]\n        O1 --&gt; O2[2. \u590d\u5236\u6a21\u578b\u548c\u8d44\u4ea7\u6587\u4ef6]\n        O2 --&gt; O3[3. \u9636\u6bb5\u4e00: \u8fd0\u884c\u521d\u6b65\u4eff\u771f\u4ee5\u751f\u6210\u5904\u7406\u5668\u8f93\u5165]\n        O3 --&gt; O4[4. \u52a8\u6001\u52a0\u8f7dPython\u5904\u7406\u5668 Handler \u51fd\u6570]\n        O4 --&gt; O5[5. \u6267\u884c\u5904\u7406\u5668, \u751f\u6210\u5916\u90e8\u6570\u636eCSV]\n        O5 --&gt; O6[6. \u521b\u5efa\u5e76\u96c6\u6210\u62e6\u622a\u5668 Interceptor \u6a21\u578b]\n        O6 --&gt; O7[7. \u9636\u6bb5\u4e8c: \u4f7f\u7528\u62e6\u622a\u5668\u6a21\u578b\u8fd0\u884c\u6700\u7ec8\u4eff\u771f]\n        O7 --&gt; O8[8. \u6e05\u7406\u5e76\u4fdd\u5b58\u6700\u7ec8\u7ed3\u679cCSV]\n        O8 --&gt; P\n    end\n\n    %% 5. \u7ed3\u679c\u805a\u5408\n    subgraph S7 [\"5. \u7ed3\u679c\u805a\u5408\"]\n        P --&gt; Q{\u6536\u96c6\u6240\u6709\u4f5c\u4e1a\u7684\u7ed3\u679c\u8def\u5f84}\n        Q --&gt; R[\u8bfb\u53d6\u6bcf\u4e2a\u7ed3\u679cCSV]\n        R --&gt; S[\"\u4e3a\u53d8\u91cf\u5217\u540d\u9644\u52a0\u53c2\u6570 (e.g., 'var&amp;p1=v1')\"]\n        S --&gt; T[\u5408\u5e76\u6240\u6709\u7ed3\u679c\u4e3a\u4e00\u4e2aDataFrame]\n        T --&gt; U[\u4fdd\u5b58\u4e3a 'sweep_results.csv']\n    end\n\n    %% 6. \u540e\u5904\u7406\n    subgraph S8 [\"6. \u540e\u5904\u7406\"]\n        U --&gt; V{\u68c0\u6d4b\u5230 post_processing \u914d\u7f6e?}\n        V -- \u662f --&gt; W[\u52a8\u6001\u52a0\u8f7d\u5e76\u6267\u884c\u540e\u5904\u7406\u51fd\u6570]\n        V -- \u5426 --&gt; X[\u8df3\u8fc7\u540e\u5904\u7406]\n    end\n\n    %% 7. \u7ed3\u675f\n    subgraph S9 [\"7. \u6e05\u7406\u4e0e\u7ed3\u675f\"]\n        W --&gt; Y[\u6e05\u7406\u4e34\u65f6\u6587\u4ef6\u548c\u76ee\u5f55]\n        X --&gt; Y\n        Y --&gt; Z[\u7ed3\u675f]\n    end</code></pre>"},{"location":"explanation/tricys_basic/simulation_flow.html#3","title":"3. \u6d41\u7a0b\u6b65\u9aa4\u8be6\u89e3","text":""},{"location":"explanation/tricys_basic/simulation_flow.html#31","title":"3.1. \u521d\u59cb\u5316","text":"<ul> <li>\u8bfb\u53d6\u548c\u51c6\u5907\u914d\u7f6e: \u6d41\u7a0b\u4ece\u4e00\u4e2aJSON\u914d\u7f6e\u6587\u4ef6\u5f00\u59cb\u3002<code>tricys</code>\u4f1a\u8bfb\u53d6\u6b64\u6587\u4ef6\uff0c\u89e3\u6790\u6240\u6709\u8def\u5f84\u3001\u4eff\u771f\u8bbe\u7f6e\u548c\u53c2\u6570\uff0c\u5e76\u51c6\u5907\u4e00\u4e2a\u5185\u90e8\u4f7f\u7528\u7684\u914d\u7f6e\u5bf9\u8c61\u3002</li> <li>\u8bbe\u7f6e\u65e5\u5fd7\u8bb0\u5f55: \u6839\u636e\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u65e5\u5fd7\u8bbe\u7f6e\uff0c\u521d\u59cb\u5316\u5168\u5c40\u65e5\u5fd7\u8bb0\u5f55\u5668\uff0c\u4ee5\u4fbf\u5728\u6574\u4e2a\u6d41\u7a0b\u4e2d\u8bb0\u5f55\u8be6\u7ec6\u7684\u6b65\u9aa4\u3001\u8b66\u544a\u548c\u9519\u8bef\u3002</li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html#32","title":"3.2. \u4f5c\u4e1a\u751f\u6210","text":"<ul> <li><code>tricys</code>\u4f1a\u68c0\u67e5\u914d\u7f6e\u4e2d\u7684 <code>simulation_parameters</code> \u90e8\u5206\u3002\u5982\u679c\u5b9a\u4e49\u4e86\u53c2\u6570\u626b\u63cf\uff08\u4f8b\u5982\uff0c\u4e00\u4e2a\u53c2\u6570\u6709\u591a\u4e2a\u503c\uff09\uff0c\u5b83\u4f1a\u4e3a\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u751f\u6210\u4e00\u4e2a\u72ec\u7acb\u7684\u201c\u4f5c\u4e1a\u201d\u3002\u5982\u679c\u672a\u5b9a\u4e49\u53c2\u6570\u626b\u63cf\uff0c\u5219\u53ea\u4f1a\u751f\u6210\u4e00\u4e2a\u9ed8\u8ba4\u4f5c\u4e1a\u3002</li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html#33","title":"3.3. \u6267\u884c\u6a21\u5f0f\u51b3\u7b56","text":"<p>\u8fd9\u662f\u6d41\u7a0b\u7684\u4e00\u4e2a\u5173\u952e\u5206\u652f\u70b9\uff0c<code>tricys</code>\u4f1a\u6839\u636e\u914d\u7f6e\u51b3\u5b9a\u5982\u4f55\u6267\u884c\u751f\u6210\u7684\u4f5c\u4e1a\uff1a - \u6807\u51c6\u4eff\u771f vs \u534f\u540c\u4eff\u771f: \u9996\u5148\u68c0\u67e5\u662f\u5426\u5b58\u5728 <code>co_simulation</code> \u914d\u7f6e\u5757\u3002\u5982\u679c\u5b58\u5728\uff0c\u5c06\u8fdb\u5165\u534f\u540c\u4eff\u771f\u6d41\u7a0b\uff1b\u5426\u5219\uff0c\u8fdb\u5165\u6807\u51c6\u4eff\u771f\u6d41\u7a0b\u3002 - \u5e76\u884c vs \u987a\u5e8f: \u63a5\u7740\uff0c\u68c0\u67e5 <code>simulation.concurrent</code> \u6807\u5fd7\u3002\u5982\u679c\u4e3a <code>true</code>\uff0c<code>tricys</code>\u4f1a\u4f7f\u7528\u5e76\u53d1\u6a21\u5f0f\uff08\u591a\u7ebf\u7a0b\u6216\u591a\u8fdb\u7a0b\uff09\u540c\u65f6\u6267\u884c\u591a\u4e2a\u4f5c\u4e1a\u3002\u5982\u679c\u4e3a <code>false</code>\uff0c\u5219\u4f1a\u6309\u987a\u5e8f\u9010\u4e2a\u6267\u884c\u4f5c\u4e1a\u3002</p> <p>\u8fd9\u56db\u4e2a\u7ec4\u5408\uff08\u6807\u51c6/\u987a\u5e8f, \u6807\u51c6/\u5e76\u884c, \u534f\u540c/\u987a\u5e8f, \u534f\u540c/\u5e76\u884c\uff09\u5206\u522b\u5bf9\u5e94\u4e0d\u540c\u7684\u6267\u884c\u51fd\u6570\uff0c\u4ee5\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u548c\u9694\u79bb\u6027\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#34","title":"3.4. \u4f5c\u4e1a\u6267\u884c","text":"<p>\u6bcf\u4e2a\u4f5c\u4e1a\u90fd\u5728\u4e00\u4e2a\u72ec\u7acb\u7684\u3001\u9694\u79bb\u7684\u5de5\u4f5c\u533a\u4e2d\u6267\u884c\uff0c\u4ee5\u9632\u6b62\u6587\u4ef6\u51b2\u7a81\u3002</p> <ul> <li>\u6807\u51c6\u4eff\u771f\u6d41\u7a0b (<code>_run_single_job</code> / <code>_run_sequential_sweep</code>):</li> <li>\u83b7\u53d6\u4e00\u4e2a <code>OMPython</code> \u4f1a\u8bdd\u3002</li> <li>\u52a0\u8f7d\u6307\u5b9a\u7684 Modelica \u6a21\u578b\u5305\u3002</li> <li>\u5c06\u5f53\u524d\u4f5c\u4e1a\u7684\u53c2\u6570\u5e94\u7528\u5230\u6a21\u578b\u4e2d\u3002   4.\u8c03\u7528 <code>simulate()</code> \u6267\u884c\u4eff\u771f\u3002</li> <li> <p>\u5bf9\u751f\u6210\u7684 <code>_res.csv</code> \u7ed3\u679c\u6587\u4ef6\u8fdb\u884c\u6e05\u7406\uff08\u4f8b\u5982\uff0c\u53bb\u9664\u91cd\u590d\u7684\u65f6\u95f4\u70b9\uff09\uff0c\u5e76\u8fd4\u56de\u5176\u8def\u5f84\u3002</p> </li> <li> <p>\u534f\u540c\u4eff\u771f\u6d41\u7a0b (<code>_run_co_simulation</code>):   \u8fd9\u662f\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u591a\u9636\u6bb5\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5c06 Modelica \u6a21\u578b\u4e0e\u5916\u90e8 Python \u903b\u8f91\uff08\u79f0\u4e3a\"Handler\"\uff09\u96c6\u6210\uff1a</p> </li> <li>\u521b\u5efa\u5de5\u4f5c\u533a: \u4e3a\u4f5c\u4e1a\u521b\u5efa\u4e00\u4e2a\u5b8c\u5168\u9694\u79bb\u7684\u4e34\u65f6\u76ee\u5f55\u3002</li> <li>\u590d\u5236\u8d44\u4ea7: \u5c06\u6a21\u578b\u6587\u4ef6\uff08<code>.mo</code>\uff09\u4ee5\u53caHandler\u53ef\u80fd\u9700\u8981\u7684\u4efb\u4f55\u5916\u90e8\u6587\u4ef6\uff08\u5982CSV\u3001\u67e5\u627e\u8868\u7b49\uff09\u590d\u5236\u5230\u5de5\u4f5c\u533a\u3002</li> <li>\u9636\u6bb5\u4e00\uff1a\u521d\u6b65\u4eff\u771f: \u8fd0\u884c\u4e00\u6b21\u521d\u6b65\u4eff\u771f\u3002\u8fd9\u6b21\u4eff\u771f\u7684\u76ee\u7684\u4e0d\u662f\u5f97\u5230\u6700\u7ec8\u7ed3\u679c\uff0c\u800c\u662f\u4e3a\u4e86\u751f\u6210Handler\u6240\u9700\u8981\u7684\u8f93\u5165\u4fe1\u53f7\u3002\u4f8b\u5982\uff0c\u4e00\u4e2a\u5916\u90e8\u63a7\u5236\u5668\u9700\u8981\u77e5\u9053\u5f53\u524d\u7cfb\u7edf\u7684\u6e29\u5ea6\u548c\u538b\u529b\uff0c\u8fd9\u6b21\u4eff\u771f\u5c31\u4f1a\u628a\u8fd9\u4e9b\u53d8\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u5bfc\u51fa\u5230 <code>primary_inputs.csv</code>\u3002</li> <li>\u6267\u884cHandler: <code>tricys</code>\u52a8\u6001\u52a0\u8f7d\u914d\u7f6e\u6587\u4ef6\u4e2d\u6307\u5b9a\u7684Python Handler\u51fd\u6570\u3002</li> <li>\u751f\u6210\u5916\u90e8\u6570\u636e: \u8c03\u7528Handler\u51fd\u6570\uff0c\u5b83\u4f1a\u8bfb\u53d6 <code>primary_inputs.csv</code>\uff0c\u6267\u884c\u5176\u5185\u90e8\u903b\u8f91\uff08\u4f8b\u5982\uff0c\u4e00\u4e2aPID\u7b97\u6cd5\u6216\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff09\uff0c\u7136\u540e\u751f\u6210\u4e00\u4efd\u8f93\u51faCSV\u6587\u4ef6\uff08\u4f8b\u5982 <code>handler_outputs.csv</code>\uff09\u3002</li> <li>\u96c6\u6210\u62e6\u622a\u5668: <code>tricys</code>\u4f1a\u751f\u6210\u4e00\u4e2a\u65b0\u7684Modelica\u6a21\u578b\uff08\u79f0\u4e3a\u62e6\u622a\u5668\u6a21\u578b\uff09\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u8bfb\u53d6 <code>handler_outputs.csv</code> \u7684\u6570\u636e\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8f93\u5165\u6ce8\u5165\u5230\u4e3b\u6a21\u578b\u4e2d\uff0c\u4ece\u800c\u53d6\u4ee3\u6216\"\u62e6\u622a\"\u539f\u59cb\u6a21\u578b\u7684\u67d0\u4e2a\u90e8\u5206\u3002</li> <li>\u9636\u6bb5\u4e8c\uff1a\u6700\u7ec8\u4eff\u771f: \u4f7f\u7528\u8fd9\u4e2a\u88ab\u4fee\u6539\u548c\u62e6\u622a\u8fc7\u7684\u65b0\u6a21\u578b\u8fd0\u884c\u6700\u7ec8\u7684\u3001\u5b8c\u6574\u7684\u4eff\u771f\u3002</li> <li>\u4fdd\u5b58\u7ed3\u679c: \u6e05\u7406\u6700\u7ec8\u7684\u4eff\u771f\u7ed3\u679c\u5e76\u8fd4\u56de\u5176\u8def\u5f84\u3002</li> </ul>"},{"location":"explanation/tricys_basic/simulation_flow.html#35","title":"3.5. \u7ed3\u679c\u805a\u5408","text":"<p>\u6240\u6709\u4f5c\u4e1a\u6267\u884c\u5b8c\u6bd5\u540e\uff1a 1. <code>tricys</code>\u6536\u96c6\u6bcf\u4e2a\u6210\u529f\u4f5c\u4e1a\u7684\u7ed3\u679c\u6587\u4ef6\u8def\u5f84\u3002 2. \u5b83\u9010\u4e2a\u8bfb\u53d6\u8fd9\u4e9bCSV\u6587\u4ef6\uff0c\u5e76\u5c06\u5b83\u4eec\u5408\u5e76\u6210\u4e00\u4e2a\u5927\u7684 Pandas DataFrame\u3002 3. \u4e3a\u4e86\u533a\u5206\u6765\u81ea\u4e0d\u540c\u4f5c\u4e1a\u7684\u6570\u636e\uff0c\u5b83\u4f1a\u5c06\u53d8\u91cf\u5217\u91cd\u547d\u540d\uff0c\u9644\u52a0\u4ea7\u751f\u8be5\u6570\u636e\u7684\u53c2\u6570\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4e00\u4e2a\u4f5c\u4e1a\u7684\u53c2\u6570\u662f <code>{\"freq\": 10}</code>\uff0c\u90a3\u4e48\u539f\u59cb\u7684 <code>voltage</code> \u5217\u4f1a\u53d8\u4e3a <code>voltage&amp;freq=10</code>\u3002 4. \u6700\u7ec8\uff0c\u8fd9\u4e2a\u5408\u5e76\u540e\u7684 DataFrame \u88ab\u4fdd\u5b58\u4e3a <code>sweep_results.csv</code>\uff08\u7528\u4e8e\u53c2\u6570\u626b\u63cf\uff09\u6216 <code>simulation_result.csv</code>\uff08\u7528\u4e8e\u5355\u6b21\u8fd0\u884c\uff09\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#36","title":"3.6. \u540e\u5904\u7406","text":"<p>\u5982\u679c\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u4e86 <code>post_processing</code> \u4efb\u52a1\uff0c<code>tricys</code>\u4f1a\u5728\u6b64\u65f6\u6267\u884c\u5b83\u4eec\u3002\u5b83\u4f1a\u52a8\u6001\u52a0\u8f7d\u6307\u5b9a\u7684Python\u51fd\u6570\uff0c\u5e76\u5c06\u4e0a\u4e00\u6b65\u751f\u6210\u7684\u5408\u5e76\u7ed3\u679cDataFrame\u4f5c\u4e3a\u8f93\u5165\u4f20\u9012\u7ed9\u5b83\u3002\u8fd9\u5141\u8bb8\u7528\u6237\u65e0\u7f1d\u5730\u5bf9\u63a5\u81ea\u5b9a\u4e49\u7684\u5206\u6790\u3001\u7ed8\u56fe\u6216\u62a5\u544a\u751f\u6210\u811a\u672c\u3002</p>"},{"location":"explanation/tricys_basic/simulation_flow.html#37","title":"3.7. \u6e05\u7406\u4e0e\u7ed3\u675f","text":"<ul> <li>\u9664\u975e\u5728\u914d\u7f6e\u4e2d\u8bbe\u7f6e\u4e86 <code>keep_temp_files: true</code>\uff0c\u5426\u5219 <code>tricys</code> \u4f1a\u81ea\u52a8\u5220\u9664\u6240\u6709\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u521b\u5efa\u7684\u4e34\u65f6\u5de5\u4f5c\u533a\u548c\u6587\u4ef6\u3002</li> <li>\u6d41\u7a0b\u7ed3\u675f\u3002</li> </ul>"},{"location":"guides/quickstart.html","title":"\u5feb\u901f\u5f00\u59cb","text":"<p>\u672c\u6307\u5357\u5c06\u5f15\u5bfc\u60a8\u5b8c\u6210 Windows \u73af\u5883\u4e0b <code>tricys</code> \u7684\u5b89\u88c5\u8fc7\u7a0b\uff0c\u5e76\u8fd0\u884c\u4e00\u4e2a\u57fa\u672c\u7684\u547d\u4ee4\u884c\u4eff\u771f\u3002</p>"},{"location":"guides/quickstart.html#1","title":"1. \u73af\u5883\u8981\u6c42","text":"<p>\u5728\u5f00\u59cb\u4e4b\u524d\uff0c\u8bf7\u786e\u4fdd\u60a8\u7684\u7cfb\u7edf\u6ee1\u8db3\u4ee5\u4e0b\u8981\u6c42\uff1a</p> <ul> <li>Python: \u7248\u672c 3.8 \u6216\u66f4\u9ad8\u3002</li> <li>Git: \u7528\u4e8e\u514b\u9686\u9879\u76ee\u4ed3\u5e93\u3002</li> <li>OpenModelica: \u9700\u8981\u5b89\u88c5 OpenModelica\uff0c\u5e76\u786e\u4fdd\u5176\u547d\u4ee4\u884c\u5de5\u5177 (<code>omc.exe</code>) \u5df2\u6dfb\u52a0\u5230\u7cfb\u7edf\u7684 <code>PATH</code> \u73af\u5883\u53d8\u91cf\u4e2d\u3002</li> </ul> <p>\u63d0\u793a</p> <p>\u5728 Windows \u4e0a\u5b89\u88c5 Python \u65f6\uff0c\u8bf7\u52a1\u5fc5\u52fe\u9009 \"Add Python to PATH\" \u9009\u9879\uff0c\u4ee5\u786e\u4fdd <code>python</code> \u548c <code>pip</code> \u547d\u4ee4\u5728\u7ec8\u7aef\u4e2d\u53ef\u7528\u3002</p>"},{"location":"guides/quickstart.html#2","title":"2. \u5b89\u88c5\u6b65\u9aa4","text":""},{"location":"guides/quickstart.html#a","title":"a. \u514b\u9686\u9879\u76ee\u4ed3\u5e93","text":"<p>\u6253\u5f00\u60a8\u7684\u7ec8\u7aef\uff08\u5982 PowerShell \u6216 Cmd\uff09\uff0c\u4f7f\u7528 <code>git</code> \u514b\u9686 <code>tricys</code> \u7684\u6e90\u4ee3\u7801\u3002</p> <pre><code>git clone https://github.com/asipp-neutronics/tricys.git\ncd tricys\n</code></pre>"},{"location":"guides/quickstart.html#b","title":"b. \u521b\u5efa\u5e76\u6fc0\u6d3b\u865a\u62df\u73af\u5883","text":"<p>\u5728\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\uff0c\u521b\u5efa\u4e00\u4e2a\u72ec\u7acb\u7684 Python \u865a\u62df\u73af\u5883\uff0c\u4ee5\u9694\u79bb\u9879\u76ee\u4f9d\u8d56\u3002</p> <pre><code># \u521b\u5efa\u865a\u62df\u73af\u5883\npython -m venv venv\n\n# \u6fc0\u6d3b\u865a\u62df\u73af\u5883\n.\\venv\\Scripts\\activate\n</code></pre> <p>\u6fc0\u6d3b\u540e\uff0c\u60a8\u4f1a\u770b\u5230\u7ec8\u7aef\u63d0\u793a\u7b26\u524d\u51fa\u73b0 <code>(venv)</code> \u5b57\u6837\u3002</p>"},{"location":"guides/quickstart.html#c","title":"c. \u5b89\u88c5\u9879\u76ee\u4f9d\u8d56","text":"<p>\u4f7f\u7528 <code>pip</code> \u5b89\u88c5 <code>tricys</code> \u53ca\u5176\u6240\u6709\u5f00\u53d1\u4f9d\u8d56\u9879\u3002<code>-e</code> \u53c2\u6570\u8868\u793a\u4ee5\u201c\u53ef\u7f16\u8f91\u201d\u6a21\u5f0f\u5b89\u88c5\uff0c\u8fd9\u610f\u5473\u7740\u60a8\u5bf9\u6e90\u4ee3\u7801\u7684\u4efb\u4f55\u4fee\u6539\u90fd\u4f1a\u7acb\u5373\u751f\u6548\u3002</p> <pre><code>pip install -e \".[win]\"\n\nor # \u6216\u4f7f\u7528Makefile.bat\u811a\u672c\u5b89\u88c5\u4f9d\u8d56\n\nMakefile.bat win-install\n</code></pre>"},{"location":"guides/quickstart.html#3","title":"3. \u8fd0\u884c\u793a\u4f8b","text":"<p><code>tricys</code> \u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7684\u793a\u4f8b\u8fd0\u884c\u5668\uff0c\u53ef\u4ee5\u5e2e\u52a9\u60a8\u5feb\u901f\u63a2\u7d22\u548c\u8fd0\u884c\u6240\u6709\u53ef\u7528\u7684\u793a\u4f8b\uff0c\u5305\u62ec\u57fa\u7840\u4eff\u771f\u548c\u9ad8\u7ea7\u5206\u6790\u4efb\u52a1\u3002\u8fd9\u662f\u9a8c\u8bc1\u5b89\u88c5\u5e76\u4e86\u89e3 <code>tricys</code> \u529f\u80fd\u7684\u6700\u7b80\u5355\u65b9\u6cd5\u3002</p>"},{"location":"guides/quickstart.html#a_1","title":"a. \u542f\u52a8\u793a\u4f8b\u8fd0\u884c\u5668","text":"<p>\u5728\u6fc0\u6d3b\u4e86\u865a\u62df\u73af\u5883\u7684\u7ec8\u7aef\u4e2d\uff0c\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\u6765\u542f\u52a8\u793a\u4f8b\u8fd0\u884c\u5668\uff1a</p> <pre><code>tricys example\n</code></pre>"},{"location":"guides/quickstart.html#b_1","title":"b. \u9009\u62e9\u5e76\u8fd0\u884c\u793a\u4f8b","text":"<p>\u8be5\u547d\u4ee4\u4f1a\u542f\u52a8\u4e00\u4e2a\u7edf\u4e00\u7684\u793a\u4f8b\u8fd0\u884c\u5668\uff0c\u626b\u63cf\u5e76\u5217\u51fa <code>example/basic</code> \u548c <code>example/analysis</code> \u76ee\u5f55\u4e0b\u7684\u6240\u6709\u53ef\u7528\u793a\u4f8b\u3002</p> <p>\u60a8\u4f1a\u770b\u5230\u4e00\u4e2a\u7c7b\u4f3c\u4e0b\u9762\u7684\u83dc\u5355\uff1a</p> <pre><code>============================================================\n         TRICYS \u7edf\u4e00\u793a\u4f8b\u8fd0\u884c\u5668\n============================================================\n\n  1. [BASIC] Basic Configuration\n     \u63cf\u8ff0: A basic simulation with a single run\n     \u914d\u7f6e: basic_configuration.json\n\n  2. [BASIC] Parameter Sweep\n     \u63cf\u8ff0: A multi-run simulation with parameter sweeps\n     \u914d\u7f6e: parameter_sweep.json\n\n  ...\n\n  6. [ANALYSIS] Baseline Condition Analysis\n     \u63cf\u8ff0: Baseline condition analysis for TBR search\n     \u914d\u7f6e: baseline_condition_analysis.json\n\n  ...\n\n  0. \u9000\u51fa\u7a0b\u5e8f\n  h. \u663e\u793a\u5e2e\u52a9\u4fe1\u606f\n  s. \u91cd\u65b0\u626b\u63cf\u793a\u4f8b\u76ee\u5f55\n\n============================================================\n</code></pre> <ul> <li>\u8f93\u5165\u6570\u5b57 (\u4f8b\u5982 <code>1</code>) \u5e76\u6309\u56de\u8f66\uff0c\u5373\u53ef\u8fd0\u884c\u5bf9\u5e94\u7684\u793a\u4f8b\u3002</li> <li>\u7a0b\u5e8f\u4f1a\u81ea\u52a8\u5c06\u793a\u4f8b\u6587\u4ef6\u590d\u5236\u5230\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\u7684 <code>test_example</code> \u6587\u4ef6\u5939\u4e2d\uff0c\u5e76\u5728\u8be5\u76ee\u5f55\u4e2d\u6267\u884c\u4efb\u52a1\u3002</li> <li>\u8fd9\u79cd\u8bbe\u8ba1\u53ef\u4ee5\u786e\u4fdd\u539f\u59cb\u793a\u4f8b\u6587\u4ef6\u4e0d\u88ab\u4fee\u6539\uff0c\u5e76\u4fdd\u6301\u5de5\u4f5c\u533a\u6574\u6d01\u3002</li> </ul>"},{"location":"guides/quickstart.html#c_1","title":"c. \u67e5\u770b\u7ed3\u679c","text":"<p>\u4efb\u52a1\u5b8c\u6210\u540e\uff0c\u7ed3\u679c\u5c06\u4fdd\u5b58\u5728 <code>test_example</code> \u76ee\u5f55\u4e2d\uff0c\u4f4d\u4e8e\u76f8\u5e94\u793a\u4f8b\u7684\u5b50\u6587\u4ef6\u5939\u5185\u3002</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u8fd0\u884c\u4e86 <code>Basic Configuration</code> \u793a\u4f8b\uff0c\u7ed3\u679c\u5c06\u4f4d\u4e8e <code>test_example/basic/1_basic_configuration/</code> \u76ee\u5f55\u4e0b\u3002\u60a8\u53ef\u4ee5\u5728\u5176\u4e2d\u627e\u5230\uff1a</p> <ul> <li><code>simulation_result.csv</code>: \u5305\u542b\u6240\u6709\u8f93\u51fa\u53d8\u91cf\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6570\u636e\u3002</li> <li><code>simualtion_{timestamp}.log</code>: \u672c\u6b21\u8fd0\u884c\u7684\u8be6\u7ec6\u65e5\u5fd7\u6587\u4ef6\u3002</li> <li><code>basic_configuation.json</code>: \u672c\u6b21\u8fd0\u884c\u6240\u4f7f\u7528\u7684\u5b8c\u6574\u914d\u7f6e\u7684\u5907\u4efd\u3002</li> </ul>"},{"location":"guides/quickstart.html#4-gui","title":"4. \u8fd0\u884c\u56fe\u5f62\u7528\u6237\u754c\u9762 (GUI)","text":"<p>\u5982\u679c\u60a8\u66f4\u559c\u6b22\u56fe\u5f62\u5316\u64cd\u4f5c\uff0c\u53ef\u4ee5\u542f\u52a8 <code>tricys</code> \u7684 GUI\u3002</p> <pre><code>tricys gui\n</code></pre> <p>GUI \u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u754c\u9762\uff0c\u7528\u4e8e\u52a0\u8f7d\u6a21\u578b\u3001\u8bbe\u7f6e\u53c2\u6570\u3001\u5b9a\u4e49\u626b\u63cf\u8303\u56f4\u548c\u542f\u52a8\u4eff\u771f\u3002</p>"},{"location":"guides/quickstart.html#5-tricys","title":"5. TRICYS \u76f8\u5173\u547d\u4ee4","text":"<p>\u606d\u559c\uff01\u60a8\u5df2\u7ecf\u6210\u529f\u5b89\u88c5\u5e76\u8fd0\u884c\u4e86 <code>tricys</code>\u3002\u63a5\u4e0b\u6765\uff0c\u60a8\u53ef\u4ee5\u63a2\u7d22\u66f4\u9ad8\u7ea7\u7684\u529f\u80fd\uff0c\u4f8b\u5982\u53c2\u6570\u626b\u63cf\u6216\u534f\u540c\u4eff\u771f\u3002</p>"},{"location":"guides/models/cycle.html","title":"\u6c1a\u71c3\u6599\u5faa\u73af 0 \u7ef4\u7cfb\u7edf\u6a21\u578b","text":""},{"location":"guides/models/cycle.html#1","title":"1. \u6c1a\u5faa\u73af\u7cfb\u7edf\u4ecb\u7ecd","text":"<p>\u805a\u53d8\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u5728\u67b6\u6784\u4e0a\u5206\u4e3a\u4e24\u4e2a\u9ad8\u5ea6\u8026\u5408\u7684\u7cfb\u7edf\uff1a\u5185\u90e8\u71c3\u6599\u5faa\u73af\u548c\u5916\u90e8\u71c3\u6599\u5faa\u73af\u3002</p> <p></p>"},{"location":"guides/models/cycle.html#11","title":"1.1. \u5185\u90e8\u71c3\u6599\u5faa\u73af","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u5904\u7406\u672a\u71c3\u71c3\u6599\u7684\u9ad8\u901a\u91cf\u3001\u5feb\u901f\u95ed\u73af\u56de\u8def \u3002\u5176\u7269\u8d28\u6d41\u8def\u5f84\u5982\u4e0b\uff1a</p> <p>1)  \u6ce8\u5165 (Fuelling): \u5faa\u73af\u59cb\u4e8e\u71c3\u6599\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS)\u3002\u9ad8\u7eaf D-T \u71c3\u6599\u7ecf\u7531\u52a0\u6599\u7cfb\u7edf (FS) \u6ce8\u5165\u6258\u5361\u9a6c\u514b\u771f\u7a7a\u5ba4 (Plasma) \u3002</p> <p>2)  \u6392\u51fa (Exhaust): \u5728\u7b49\u79bb\u5b50\u4f53\u4e2d\uff0c\u4ec5\u6709\u5c11\u91cf\u71c3\u6599\u53d1\u751f\u805a\u53d8, \u5927\u90e8\u5206\u672a\u71c3\u71c3\u6599\u3001\u805a\u53d8\u4ea7\u7269\uff08\u6c26\u7070\uff09\u53ca\u6742\u8d28\u88ab\u5f15\u5bfc\u81f3\u504f\u6ee4\u5668 (Divertor) \u533a\u57df \u3002</p> <p>3)  \u6cf5\u9001 (Pumping): \u771f\u7a7a\u6cf5\u7cfb\u7edf (Pump_System) \u5c06\u8fd9\u4e9b\u6392\u51fa\u7684\u9ad8\u6e29\u5e9f\u6c14\u62bd\u51fa \u3002</p> <p>4)  \u51c0\u5316 (TEP): \u5e9f\u6c14\u88ab\u9001\u81f3\u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406\u7cfb\u7edf (TEP)\u3002TEP \u5728\u6b64\u8fdb\u884c\u5173\u952e\u7684\u5316\u5b66\u51c0\u5316\uff0c\u4ee5\u4ece\u6742\u8d28\uff08\u5982\u6c1a\u5316\u6c34 Q2O \u548c\u6c1a\u5316\u7532\u70f7 CQ4\uff09\u4e2d\u56de\u6536\u6c22\u540c\u4f4d\u7d20 \u3002</p> <p>5)  \u5206\u79bb (ISS): \u51c0\u5316\u540e\u7684\u6c22\u540c\u4f4d\u7d20 (Q2) \u6df7\u5408\u6c14\u6d41\u88ab\u9001\u81f3\u5185\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf (I-ISS)\uff0c\u901a\u5e38\u901a\u8fc7\u4f4e\u6e29\u7cbe\u998f\u6280\u672f\u8fdb\u884c\u540c\u4f4d\u7d20\u5206\u79bb \u3002</p> <p>6) \u56de\u6d41 (Return): \u6700\u7ec8\uff0c\u5206\u79bb\u51fa\u7684\u9ad8\u7eaf\u5ea6 D2 \u548c T2 \u71c3\u6599\u88ab\u9001\u56de SDS\uff0c\u5b9e\u73b0\u71c3\u6599\u7684\u518d\u5faa\u73af\uff0c\u5b8c\u6210\u5185\u90e8\u95ed\u73af \u3002</p>"},{"location":"guides/models/cycle.html#12","title":"1.2. \u5916\u90e8\u71c3\u6599\u5faa\u73af","text":"<p>\u8fd9\u662f\u4e00\u4e2a\u8d1f\u8d23\u751f\u4ea7\u65b0\u71c3\u6599\u4ee5\u5b9e\u73b0\u6c1a\u81ea\u6301\u7684\u4f4e\u901a\u91cf\u3001\u6162\u901f\u56de\u8def \u3002\u5176\u7269\u8d28\u6d41\u8def\u5f84\u5982\u4e0b\uff1a</p> <p>1)  \u589e\u6b96 (Breeding): \u805a\u53d8\u4ea7\u751f\u7684\u9ad8\u80fd\u4e2d\u5b50\u8fdb\u5165\u589e\u6b96\u5305\u5c42 (Blanket)\uff0c\u4e0e\u5305\u5c42\u4e2d\u7684\u9502 (Li) \u53d1\u751f\u6838\u53cd\u5e94\u4ee5\u589e\u6b96\u65b0\u7684\u6c1a \u3002</p> <p>2)  \u63d0\u53d6 (Extraction): \u65b0\u751f\u7684\u6c1a\u901a\u8fc7\u589e\u6b96\u5242\u6c1a\u63d0\u53d6\u7cfb\u7edf (TES) \u4ece\u5305\u5c42\u6750\u6599\u4e2d\u79fb\u51fa \u3002</p> <p>3)  \u6cc4\u6f0f\u4e0e\u51c0\u5316 (Permeation &amp; Purification): \u4e0e\u6b64\u540c\u65f6\uff0c\u5c11\u91cf\u6c1a\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u6e17\u900f\u8fdb\u5165\u51b7\u5374\u5242\u56de\u8def (CL) \u3002\u51b7\u5374\u5242\u51c0\u5316\u7cfb\u7edf (CPS) \u8d1f\u8d23\u4ece\u51b7\u5374\u5242\u4e2d\u6355\u83b7\u5e76\u56de\u6536\u8fd9\u90e8\u5206\u6e17\u900f\u7684\u6c1a \u3002</p> <p>4)  \u6c47\u96c6\u4e0e\u5206\u79bb (Collection &amp; Separation): \u6765\u81ea TES \u7684\u5bcc\u6c1a\u6d41\uff08\u4f8b\u5982\uff0c\u56fa\u6001\u5305\u5c42\u7684\u6c26\u6c14\u5439\u626b\u6c14\u6216\u6db2\u6001\u5305\u5c42\u7684\u6e17\u900f\u5668\u4ea7\u6c14 \uff09\u4e0e\u6765\u81ea CPS \u7684\u56de\u6536\u6c1a\u6d41\u6c47\u5408\uff0c\u4e00\u540c\u88ab\u8f93\u9001\u81f3\u5916\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf (O-ISS) \u8fdb\u884c\u63d0\u7eaf\u3002</p> <p>5)  \u8865\u5145 (Replenish): O-ISS \u5c06\u6c26\u6c14\u53ca\u5176\u4ed6\u6742\u8d28\u53bb\u9664\u540e\uff0c\u628a\u9ad8\u7eaf\u5ea6\u6c1a\u9001\u5165 SDS\uff0c\u8865\u5145\u5230\u4e3b\u71c3\u6599\u5faa\u73af\u4e2d\uff0c\u5b8c\u6210\u5168\u5382\u7684\u71c3\u6599\u95ed\u73af \u3002</p>"},{"location":"guides/models/cycle.html#2-modelica","title":"2. Modelica\u793a\u4f8b\u6a21\u578b","text":"<p>TRICYS \u7684\u6838\u5fc3\u662f\u4e00\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af 0 \u7ef4\u7cfb\u7edf\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u805a\u53d8\u5806\u7684\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u62bd\u8c61\u4e3a\u4e00\u7cfb\u5217\u76f8\u4e92\u8fde\u63a5\u7684\u5b50\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u5b50\u7cfb\u7edf\u4ee3\u8868\u5b9e\u9645\u5de5\u5382\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u529f\u80fd\u6a21\u5757\u3002</p> <p>0 \u7ef4\u6a21\u578b\u610f\u5473\u7740\u6211\u4eec\u5173\u6ce8\u7684\u662f\u7cfb\u7edf\u7ea7\u7684\u7269\u8d28\u6d41\u52a8\u548c\u5e93\u5b58\u53d8\u5316\uff0c\u800c\u4e0d\u662f\u8be6\u7ec6\u7684\u7a7a\u95f4\u5206\u5e03\u3002\u8fd9\u79cd\u5efa\u6a21\u65b9\u6cd5\u7279\u522b\u9002\u5408\u7528\u4e8e\uff1a</p> <ul> <li>\u7cfb\u7edf\u7ea7\u7684\u6c1a\u5e93\u5b58\u5206\u6790</li> <li>\u71c3\u6599\u81ea\u6301\u65f6\u95f4\u8bc4\u4f30</li> <li>\u8bbe\u8ba1\u53c2\u6570\u4f18\u5316</li> <li>\u8fd0\u884c\u7b56\u7565\u7814\u7a76</li> <li>\u5b89\u5168\u6027\u8bc4\u4f30</li> </ul> <p></p> \u6a21\u578b\u7f29\u5199 (Abbreviation) \u4e2d\u6587\u5168\u79f0 (Chinese Full Name) \u82f1\u6587\u5168\u79f0 (English Full Name) <code>Plasma</code> \u7b49\u79bb\u5b50\u4f53 Plasma <code>Fueling_System</code> \u71c3\u6599\u6ce8\u5165\u7cfb\u7edf Fueling System <code>Pump_System</code> \u771f\u7a7a\u6cf5\u7cfb\u7edf Vacuum Pumping System <code>TEP_FEP</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u524d\u7aef Tokamak Exhaust Processing - Front-End Processing <code>TEP_IP</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u4e2d\u95f4\u5904\u7406 Tokamak Exhaust Processing - Intermediate Processing <code>TEP_FCU</code> \u6258\u5361\u9a6c\u514b\u6392\u6c14\u5904\u7406 - \u6700\u7ec8\u51c0\u5316\u5355\u5143 Tokamak Exhaust Processing - Final Cleanup Unit <code>I_ISS</code> \u5185\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf Inner Isotope Separation System <code>SDS</code> \u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf Storage and Delivery System <code>Blanket</code> \u589e\u6b96\u5305\u5c42 Breeding Blanket <code>TES</code> \u6c1a\u63d0\u53d6\u7cfb\u7edf Tritium Extraction System <code>O_ISS</code> \u5916\u90e8\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf Outer Isotope Separation System <code>FW</code> \u7b2c\u4e00\u58c1 First Wall <code>DIV</code> \u504f\u6ee4\u5668 Divertor <code>Coolant_Pipe</code> \u51b7\u5374\u5242\u56de\u8def Coolant Pipe <code>CPS</code> \u51b7\u5374\u5242\u51c0\u5316\u7cfb\u7edf Coolant Purification System <code>WDS</code> \u6c34\u53bb\u6c1a\u7cfb\u7edf Water Detritiation System"},{"location":"guides/models/cycle.html#3","title":"3. \u8fdb\u4e00\u6b65\u5b66\u4e60","text":"<ul> <li>\u5feb\u901f\u5f00\u59cb\uff1a\u8fd0\u884c\u60a8\u7684\u7b2c\u4e00\u4e2a\u4eff\u771f</li> <li>\u57fa\u7840\u914d\u7f6e\uff1a\u4e86\u89e3\u5982\u4f55\u914d\u7f6e\u6a21\u578b\u53c2\u6570</li> <li>\u53c2\u6570\u626b\u63cf\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u53c2\u6570\u7a7a\u95f4</li> <li>\u654f\u611f\u6027\u5206\u6790\uff1a\u8bc6\u522b\u5173\u952e\u53c2\u6570</li> </ul>"},{"location":"guides/tricys_analysis/index.html","title":"\u81ea\u52a8\u5206\u6790 (TRICYS ANALYSIS)","text":"<p><code>TRICYS ANALYSIS</code> \u662f <code>tricys</code> \u7684\u9ad8\u7ea7\u5206\u6790\u6a21\u5757\uff0c\u65e8\u5728\u5c06\u4e00\u7cfb\u5217\u590d\u6742\u7684\u4eff\u771f\u3001\u540e\u5904\u7406\u548c\u62a5\u544a\u751f\u6210\u4efb\u52a1\u81ea\u52a8\u5316\u3002\u4e0e\u6267\u884c\u5355\u6b21\u4eff\u771f\u7684 <code>TRICYS BASIC</code> \u4e0d\u540c\uff0c<code>ANALYSIS</code> \u6a21\u5757\u901a\u8fc7\u4e00\u4e2a\u7edf\u4e00\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u53ef\u4ee5\u6267\u884c\u4ece\u53c2\u6570\u626b\u63cf\u3001\u654f\u611f\u6027\u5206\u6790\u5230\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b49\u591a\u79cd\u9ad8\u7ea7\u5206\u6790\u4efb\u52a1\u3002</p> <p>\u672c\u7ae0\u8282\u5c06\u9996\u5148\u4ecb\u7ecd\u5404\u7c7b\u5206\u6790\u4efb\u52a1\u4e2d\u901a\u7528\u7684\u6838\u5fc3\u914d\u7f6e\u9879\uff0c\u7136\u540e\u5206\u8282\u8be6\u7ec6\u4ecb\u7ecd\u6bcf\u4e00\u79cd\u5177\u4f53\u7684\u5206\u6790\u6a21\u5f0f\u3002</p>"},{"location":"guides/tricys_analysis/index.html#1","title":"1. \u901a\u7528\u914d\u7f6e\u9879","text":"<p>\u5728 <code>tricys</code> \u7684\u5206\u6790\u914d\u7f6e\u6587\u4ef6\u4e2d\uff0c<code>sensitivity_analysis</code> \u5bf9\u8c61\u662f\u6240\u6709\u5206\u6790\u4efb\u52a1\u7684\u6838\u5fc3\u3002\u4ee5\u4e0b\u662f\u5176\u4e2d\u8de8\u591a\u79cd\u5206\u6790\u7c7b\u578b\u901a\u7528\u7684\u5173\u952e\u5b57\u6bb5\u3002</p>"},{"location":"guides/tricys_analysis/index.html#11","title":"1.1. \u591a\u6848\u4f8b\u5e76\u53d1\u6267\u884c","text":"<ul> <li> <p><code>analysis_cases</code> (\u5206\u6790\u6848\u4f8b\u5217\u8868)</p> <ul> <li>\u63cf\u8ff0: \u8fd9\u662f\u4e00\u4e2a\u6570\u7ec4\uff0c\u4e5f\u662f <code>TRICYS ANALYSIS</code> \u6a21\u5f0f\u7684\u6838\u5fc3\u3002\u5b83\u5141\u8bb8\u60a8\u5728\u4e00\u4e2a\u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u591a\u4e2a\u72ec\u7acb\u7684\u5206\u6790\u4efb\u52a1\u3002\u6bcf\u4e2a\u6570\u7ec4\u5143\u7d20\u90fd\u662f\u4e00\u4e2a\u5b8c\u6574\u7684\u5206\u6790\u6848\u4f8b\u5bf9\u8c61\uff0c\u53ef\u4ee5\u6709\u5404\u81ea\u72ec\u7acb\u7684 <code>name</code>\u3001<code>independent_variable</code>\u3001<code>dependent_variables</code> \u7b49\u3002<code>tricys</code> \u4f1a\u4f9d\u6b21\u6267\u884c\u8fd9\u4e2a\u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u6848\u4f8b\u3002</li> <li>\u5e94\u7528: \u5f53\u60a8\u9700\u8981\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\u7248\u672c\u3001\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u6216\u4e0d\u540c\u5206\u6790\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c\u5728\u540c\u4e00\u6279\u6b21\u4e2d\u8fd0\u884c\u4e00\u4e2a\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u548c\u4e00\u4e2aSOBOL\u5206\u6790\uff09\u65f6\uff0c\u6b64\u529f\u80fd\u975e\u5e38\u6709\u7528\u3002</li> </ul> </li> <li> <p><code>concurrent_cases</code> (\u5e76\u53d1\u6267\u884c\u6848\u4f8b)</p> <ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5e03\u5c14\u503c (<code>true</code> \u6216 <code>false</code>)\uff0c\u9ed8\u8ba4\u4e3a <code>false</code>\u3002\u5f53\u8bbe\u7f6e\u4e3a <code>true</code> \u65f6\uff0c<code>tricys</code> \u4f1a\u542f\u7528\u591a\u8fdb\u7a0b\u5e76\u884c\u8ba1\u7b97\uff0c\u540c\u65f6\u6267\u884c <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u591a\u4e2a\u6848\u4f8b\u3002</li> <li>\u5e94\u7528: \u5bf9\u4e8e\u5305\u542b\u5927\u91cf\u72ec\u7acb\u5206\u6790\u6848\u4f8b\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u5f00\u542f\u6b64\u9009\u9879\u53ef\u4ee5\u5229\u7528\u591a\u6838CPU\u7684\u4f18\u52bf\uff0c\u663e\u8457\u7f29\u77ed\u603b\u5206\u6790\u65f6\u95f4\u3002</li> </ul> </li> <li> <p><code>max_case_workers</code> (\u6700\u5927\u5e76\u53d1\u8fdb\u7a0b\u6570)</p> <ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u6574\u6570\uff0c\u4ec5\u5728 <code>concurrent_cases</code> \u4e3a <code>true</code> \u65f6\u751f\u6548\u3002\u7528\u4e8e\u6307\u5b9a\u5e76\u884c\u6267\u884c\u7684\u6700\u5927\u8fdb\u7a0b\u6570\u3002</li> <li>\u9ed8\u8ba4\u503c: \u5982\u679c\u4e0d\u8bbe\u7f6e\uff0c<code>tricys</code> \u4f1a\u9ed8\u8ba4\u4f7f\u7528\u60a8\u673a\u5668\u4e0a\u7684CPU\u6838\u5fc3\u6570\u3002</li> <li>\u5efa\u8bae: \u5efa\u8bae\u8bbe\u7f6e\u4e3a\u4e0d\u8d85\u8fc7\u60a8\u8ba1\u7b97\u673a\u7684\u7269\u7406CPU\u6838\u5fc3\u6570\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/index.html#12-metrics_definition","title":"1.2. <code>metrics_definition</code> (\u6307\u6807\u5b9a\u4e49)","text":"<p>\u8fd9\u662f\u6700\u5173\u952e\u7684\u90e8\u5206\uff0c\u7528\u4e8e\u5b9a\u4e49\u60a8\u5173\u5fc3\u7684\u6027\u80fd\u6307\u6807 (KPIs)\uff0c\u4e5f\u5c31\u662f\u5206\u6790\u7ed3\u679c\u4e2d\u7684\u56e0\u53d8\u91cf\u3002</p> <ul> <li>\u7ed3\u6784: \u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u4e2d\u6bcf\u4e2a\u952e\u90fd\u662f\u60a8\u4e3a\u6307\u6807\u8d4b\u4e88\u7684\u552f\u4e00\u540d\u79f0\uff08\u5982 <code>Startup_Inventory</code>\uff09\u3002</li> <li>\u503c: \u4e00\u4e2a\u63cf\u8ff0\u5982\u4f55\u8ba1\u7b97\u8be5\u6307\u6807\u7684\u5bf9\u8c61\u3002<ul> <li><code>source_column</code>: \u7528\u4e8e\u8ba1\u7b97\u7684\u539f\u59cb\u6570\u636e\u6765\u6e90\uff0c\u5373\u4eff\u771f\u7ed3\u679c (<code>.csv</code>) \u4e2d\u7684\u5217\u540d\u3002</li> <li><code>method</code>: <code>tricys.analysis.metric</code> \u6a21\u5757\u4e2d\u7528\u4e8e\u8ba1\u7b97\u7684\u51fd\u6570\u540d\u3002</li> </ul> </li> <li>\u8be6\u89e3: <code>tricys</code> \u5185\u7f6e\u4e86\u591a\u79cd\u5e38\u7528\u6307\u6807\u8ba1\u7b97\u51fd\u6570\u3002\u5173\u4e8e\u5185\u7f6e\u6838\u5fc3\u6027\u80fd\u6307\u6807\uff08\u5982 <code>Startup_Inventory</code>, <code>Doubling_Time</code> \u7b49\uff09\u7684\u8be6\u7ec6\u7269\u7406\u610f\u4e49\u548c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605 \u6838\u5fc3\u6027\u80fd\u6307\u6807\u8be6\u89e3\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#13-glossary_path","title":"1.3. <code>glossary_path</code> (\u672f\u8bed\u8868)","text":"<ul> <li>\u63cf\u8ff0: \u6307\u5411\u4e00\u4e2a\u201c\u672f\u8bed\u8868\u201d CSV \u6587\u4ef6\u7684\u8def\u5f84\u3002\u63d0\u4f9b\u6b64\u6587\u4ef6\u53ef\u4ee5\u6781\u5927\u5730\u589e\u5f3a\u62a5\u544a\u7684\u53ef\u8bfb\u6027\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5c06\u4ee3\u7801\u4e2d\u7b80\u5199\u7684\u53d8\u91cf\u540d\uff08\u5982 <code>sds.I[1]</code>\uff09\u6620\u5c04\u4e3a\u6613\u4e8e\u7406\u89e3\u7684\u4e2d\u6587\u540d\u79f0\u548c\u63cf\u8ff0\u3002</li> <li>\u683c\u5f0f: \u8fd9\u662f\u4e00\u4e2a\u6807\u51c6\u7684 CSV \u6587\u4ef6\uff0c\u5176\u5217\u5934\u5e94\u5305\u542b <code>\u6a21\u578b\u53c2\u6570 (Model Parameter)</code> (\u5fc5\u586b), <code>\u82f1\u6587\u672f\u8bed (English Term)</code>, <code>\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)</code> \u7b49\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#14-unit_map","title":"1.4. <code>unit_map</code> (\u5355\u4f4d\u6620\u5c04)","text":"<ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u4e8e\u81ea\u5b9a\u4e49\u62a5\u544a\u56fe\u8868\u4e2d\u7684\u5355\u4f4d\uff0c\u4f7f\u7ed3\u679c\u66f4\u76f4\u89c2\u3002</li> <li>\u952e: \u53d8\u91cf\u540d\u6216\u6307\u6807\u540d\u3002</li> <li>\u503c: \u5305\u542b <code>unit</code> (\u5355\u4f4d\u5b57\u7b26\u4e32) \u548c <code>conversion_factor</code> (\u4ece\u539f\u59cb\u4eff\u771f\u5355\u4f4d\u5230\u76ee\u6807\u5355\u4f4d\u7684\u6362\u7b97\u7cfb\u6570) \u7684\u5bf9\u8c61\u3002\u4f8b\u5982\uff0c\u5982\u679c\u4eff\u771f\u65f6\u95f4\u5355\u4f4d\u662f\u5c0f\u65f6\uff0c\u901a\u8fc7 <code>\"conversion_factor\": 24</code> \u53ef\u4ee5\u5c06 <code>Doubling_Time</code> \u7684\u5355\u4f4d\u6362\u7b97\u4e3a\u5929\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#15-ai-ai-true","title":"1.5. AI \u589e\u5f3a\u5206\u6790 (<code>\"ai\": true</code>)","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u5185\u7f6e\u4e86\u5f3a\u5927\u7684 AI \u5206\u6790\u529f\u80fd\u3002</p> <ul> <li>\u542f\u7528\u65b9\u5f0f: \u5728\u5177\u4f53\u5206\u6790\u6848\u4f8b\u7684\u914d\u7f6e\u4e2d\uff08\u4f8b\u5982 <code>analysis_cases</code> \u7684\u67d0\u4e2a\u5143\u7d20\u5185\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\u52a0\u5165 <code>\"ai\": true</code> \u5373\u53ef\u6fc0\u6d3b\u3002</li> <li>\u73af\u5883\u51c6\u5907: \u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09API \u51ed\u636e\u3002     <pre><code># .env file\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre></li> <li>\u529f\u80fd: \u542f\u7528\u540e\uff0c<code>tricys</code> \u4f1a\u5728\u751f\u6210\u6807\u51c6\u56fe\u8868\u548c\u6570\u636e\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u989d\u5916\u8c03\u7528 LLM\uff1a<ol> <li>\u5bf9\u5206\u6790\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\uff0c\u5e76\u5c06\u7ed3\u679c\u8ffd\u52a0\u5230\u6838\u5fc3\u7684 Markdown \u62a5\u544a\u4e2d\u3002</li> <li>\u751f\u6210\u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a (<code>academic_report.md</code>)\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u6c47\u62a5\u6216\u4f5c\u4e3a\u8bba\u6587\u521d\u7a3f\u3002</li> </ol> </li> </ul>"},{"location":"guides/tricys_analysis/index.html#16","title":"1.6. \u901a\u7528\u914d\u7f6e\u793a\u4f8b","text":"<p>\u4ee5\u4e0b JSON \u7247\u6bb5\u5c55\u793a\u4e86\u4e0a\u8ff0\u901a\u7528\u914d\u7f6e\u9879\u5728 <code>sensitivity_analysis</code> \u5bf9\u8c61\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002</p> <pre><code>\"sensitivity_analysis\": {\n    \"enabled\": true,\n    \"concurrent_cases\": true,\n    \"max_case_workers\": 4,\n    \"analysis_cases\": [\n        // ... \u6b64\u5904\u4e3a\u5177\u4f53\u5206\u6790\u6848\u4f8b\u7684\u5b9a\u4e49\uff0c\u8be6\u89c1\u5404\u5206\u6790\u7c7b\u578b\u6587\u6863 ...\n    ],\n    \"metrics_definition\": {\n        \"Startup_Inventory\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"calculate_startup_inventory\"\n        },\n        \"Doubling_Time\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"calculate_doubling_time\"\n        },\n        \"Required_TBR\": {\n            \"method\": \"bisection_search\",\n            \"parameter_to_optimize\": \"blanket.TBR\",\n            \"search_range\": [1, 1.5]\n        }\n    },\n    \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n    \"unit_map\": {\n        \"Doubling_Time\": {\n            \"unit\": \"days\",\n            \"conversion_factor\": 24\n        },\n        \"Startup_Inventory\": {\n            \"unit\": \"kg\",\n            \"conversion_factor\": 1000\n        }\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/index.html#2","title":"2. \u901a\u7528\u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u65e0\u8bba\u6267\u884c\u4f55\u79cd\u7c7b\u578b\u7684\u5206\u6790\uff0c<code>tricys</code> \u90fd\u4f1a\u5728\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u4ee5\u65f6\u95f4\u6233\u547d\u540d\u7684\u6587\u4ef6\u5939\uff0c\u7528\u4e8e\u5b58\u653e\u6240\u6709\u7ed3\u679c\u3002\u5bf9\u4e8e\u5728\u914d\u7f6e\u6587\u4ef6 <code>analysis_cases</code> \u4e2d\u5b9a\u4e49\u7684\u6bcf\u4e00\u4e2a\u5206\u6790\u6848\u4f8b\uff0c\u90fd\u4f1a\u5728\u65f6\u95f4\u6233\u6587\u4ef6\u5939\u5185\u521b\u5efa\u4e00\u4e2a\u4ee5\u6848\u4f8b <code>name</code> \u547d\u540d\u7684\u5b50\u6587\u4ef6\u5939\u3002</p> <p>\u4e00\u4e2a\u5178\u578b\u7684\u8f93\u51fa\u76ee\u5f55\u7ed3\u6784\u5982\u4e0b\u6240\u793a\uff1a</p> <pre><code>&lt;run_timestamp&gt;/\n\u251c\u2500\u2500 Case_A_Name/\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u251c\u2500\u2500 analysis_report_Case_A_Name.md              # \u6838\u5fc3\u5206\u6790\u62a5\u544a\n\u2502   \u2502   \u251c\u2500\u2500 academic_report_Case_A_Name_gpt-4.md      # (\u53ef\u9009) AI \u5b66\u672f\u62a5\u544a\n\u2502   \u2502   \u251c\u2500\u2500 analysis_plot_1.svg                         # \u5206\u6790\u56fe\u88681\n\u2502   \u2502   \u2514\u2500\u2500 analysis_plot_2.svg                         # \u5206\u6790\u56fe\u88682\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u2514\u2500\u2500 ... (\u4e2d\u95f4\u6570\u636e\u6587\u4ef6)\n\u2502\n\u251c\u2500\u2500 Case_B_Name/\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 results/\n\u2502       \u2514\u2500\u2500 ...\n\u2502\n\u2514\u2500\u2500 execution_report.md (\u5168\u5c40\u6267\u884c\u62a5\u544a)\n</code></pre> <p>\u6bcf\u4e2a\u6848\u4f8b\u5b50\u6587\u4ef6\u5939\u7684\u6838\u5fc3\u4ea7\u51fa\u90fd\u4f4d\u4e8e\u5176\u5185\u90e8\u7684 <code>report</code> \u6587\u4ef6\u5939\u4e2d\uff0c\u901a\u5e38\u5305\u542b\u4ee5\u4e0b\u5185\u5bb9\uff1a</p>"},{"location":"guides/tricys_analysis/index.html#21","title":"2.1. \u6838\u5fc3\u5206\u6790\u62a5\u544a","text":"<ul> <li>\u6587\u4ef6: <code>analysis_report_{case_name}.md</code></li> <li>\u683c\u5f0f: Markdown</li> <li>\u5185\u5bb9: \u8fd9\u662f\u5206\u6790\u7ed3\u679c\u7684\u6c47\u603b\uff0c\u4ee5\u7ed3\u6784\u5316\u7684\u65b9\u5f0f\u6574\u5408\u4e86\u914d\u7f6e\u3001\u56fe\u8868\u548c\u6570\u636e\u3002\u5176\u901a\u7528\u5185\u5bb9\u5305\u62ec\uff1a<ul> <li>\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u8be6\u60c5: \u8be6\u7ec6\u5217\u51fa\u7528\u4e8e\u672c\u6b21\u5206\u6790\u7684\u6240\u6709\u914d\u7f6e\u53c2\u6570\uff0c\u786e\u4fdd\u5206\u6790\u8fc7\u7a0b\u7684\u900f\u660e\u548c\u53ef\u590d\u73b0\u3002</li> <li>\u6027\u80fd\u6307\u6807\u603b\u8868: \u4e00\u4e2a\u6e05\u6670\u7684 Markdown \u8868\u683c\uff0c\u5217\u51fa\u4e86\u72ec\u7acb\u53d8\u91cf\u7684\u6bcf\u4e00\u6b21\u53d6\u503c\uff0c\u4ee5\u53ca\u5bf9\u5e94\u8ba1\u7b97\u51fa\u7684\u6240\u6709\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u7cbe\u786e\u6570\u503c\u3002\u8fd9\u662f\u6240\u6709\u5206\u6790\u56fe\u8868\u7684\u539f\u59cb\u6570\u636e\u6765\u6e90\u3002</li> <li>\u5206\u6790\u56fe\u8868: \u5d4c\u5165\u7684 SVG \u683c\u5f0f\u77e2\u91cf\u56fe\u3002\u56fe\u8868\u7684\u5177\u4f53\u7c7b\u578b\u548c\u5185\u5bb9\u53d6\u51b3\u4e8e\u5206\u6790\u6a21\u5f0f\uff08\u4f8b\u5982\uff0c\u5355\u53c2\u6570\u5206\u6790\u7684\u8d8b\u52bf\u7ebf\u56fe\u3001SOBOL\u5206\u6790\u7684\u654f\u611f\u6027\u6307\u6570\u6761\u5f62\u56fe\u7b49\uff09\uff0c\u5177\u4f53\u8bf7\u53c2\u9605\u5404\u5206\u6790\u7c7b\u578b\u7684\u6587\u6863\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/index.html#22-ai","title":"2.2. (\u53ef\u9009) AI \u589e\u5f3a\u62a5\u544a","text":"<p>\u5982\u679c\u914d\u7f6e\u4e86 <code>\"ai\": true</code>\uff0c<code>report</code> \u6587\u4ef6\u5939\u4e2d\u5c06\u989d\u5916\u51fa\u73b0\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\uff0c\u53ef\u76f4\u63a5\u7528\u4e8e\u6c47\u62a5\u6216\u4f5c\u4e3a\u8bba\u6587\u521d\u7a3f\u3002</li> </ul>"},{"location":"guides/tricys_analysis/index.html#3","title":"3. \u5206\u6790\u7c7b\u578b\u5bfc\u822a","text":"<p>\u6839\u636e\u60a8\u7684\u7814\u7a76\u76ee\u7684\uff0c\u53ef\u4ee5\u9009\u62e9\u4ee5\u4e0b\u4e0d\u540c\u7684\u5206\u6790\u6a21\u5f0f\u3002\u8bf7\u70b9\u51fb\u94fe\u63a5\u67e5\u770b\u6bcf\u79cd\u6a21\u5f0f\u7684\u8be6\u7ec6\u914d\u7f6e\u65b9\u6cd5\u548c\u5e94\u7528\u573a\u666f\u3002</p> <ul> <li>\u57fa\u51c6\u5de5\u51b5\u5206\u6790: \u5bf9\u5355\u4e00\u3001\u786e\u5b9a\u7684\u53c2\u6570\u914d\u7f6e\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002</li> <li>\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790: \u7814\u7a76\u5355\u4e2a\u72ec\u7acb\u53c2\u6570\u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002</li> <li>\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790: \u5206\u6790\u591a\u4e2a\u53c2\u6570\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u8026\u5408\u6548\u5e94\uff0c\u6216\u8fdb\u884c\u201c\u76ee\u6807\u5bfb\u6c42\u201d\u5f0f\u5206\u6790\u3002</li> <li>SOBOL\u5168\u5c40\u654f\u611f\u6027\u5206\u6790: \u91cf\u5316\u591a\u4e2a\u8f93\u5165\u53c2\u6570\u53ca\u5176\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002</li> <li>Latin\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u6790: \u8bc4\u4f30\u8f93\u5165\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u4f20\u64ad\u5230\u6a21\u578b\u8f93\u51fa\u4e2d\uff0c\u5e76\u5206\u6790\u8f93\u51fa\u7684\u6982\u7387\u5206\u5e03\u3002</li> </ul>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html","title":"\u57fa\u51c6\u5de5\u51b5\u5206\u6790","text":"<p>\u57fa\u51c6\u5de5\u51b5\u5206\u6790\uff08Baseline Condition Analysis\uff09\u662f <code>tricys</code> \u5206\u6790\u5de5\u5177\u96c6\u4e2d\u7684\u4e00\u9879\u6838\u5fc3\u529f\u80fd\u3002\u5b83\u7528\u4e8e\u5bf9\u5355\u4e00\u3001\u786e\u5b9a\u7684\u53c2\u6570\u914d\u7f6e\uff08\u5373\u201c\u57fa\u51c6\u5de5\u51b5\u201d\uff09\u4e0b\u7684\u7cfb\u7edf\u884c\u4e3a\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u4e00\u4efd\u6807\u51c6\u5316\u7684 Markdown \u5206\u6790\u62a5\u544a\u3002</p> <p>\u8be5\u529f\u80fd\u672c\u8d28\u4e0a\u662f <code>tricys</code> \u7684\u540e\u5904\u7406\u6a21\u5757\uff0c\u5173\u4e8e\u540e\u5904\u7406\u6a21\u5757\u7684\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u540e\u5904\u7406\u6a21\u5757\u3002\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u8be5\u5206\u6790\u7684\u914d\u7f6e\u6587\u4ef6\u662f\u4e00\u6b21\u5355\u72ec\u7684\u4eff\u771f\uff0c\u7d27\u8ddf\u7740\u4e00\u4e2a\u7279\u5b9a\u7684\u540e\u5904\u7406\u6b65\u9aa4\u3002\u56e0\u6b64\uff0c\u914d\u7f6e\u6587\u4ef6\u4e2d\u4e0d\u5305\u542b <code>sensitivity_analysis</code> \u626b\u63cf\u90e8\u5206\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]|div.I[1]|cps.I[1]|tes.I[1]|blanket.I[1]|i_iss.I[1]|wds.I[1]|o_iss.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    },\n    \"post_processing\": [\n        {\n           \"module\": \"tricys.postprocess.baseline_analysis\",\n           \"function\": \"baseline_analysis\",\n           \"params\": {\n                \"detailed_var\": \"sds.I[1]\",\n                \"glossary_path\": \"../../example_glossary/example_glossary.csv\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<p>\u6838\u5fc3\u5728\u4e8e <code>post_processing</code> \u90e8\u5206\u7684\u914d\u7f6e\uff1a</p> <ul> <li><code>module</code>: \u56fa\u5b9a\u4e3a <code>tricys.postprocess.baseline_analysis</code>\u3002</li> <li><code>function</code>: \u56fa\u5b9a\u4e3a <code>baseline_analysis</code>\u3002</li> <li><code>params</code>:<ul> <li><code>detailed_var</code> (\u5b57\u7b26\u4e32, \u9009\u586b):<ul> <li>\u63cf\u8ff0: \u6307\u5b9a\u4e00\u4e2a\u6a21\u578b\u4e2d\u7684\u53d8\u91cf\uff0c\u62a5\u544a\u5c06\u4e3a\u8be5\u53d8\u91cf\u751f\u6210\u4e00\u5f20\u5305\u542b\u201c\u7ec6\u8282\u89c6\u56fe\u201d\u7684\u65f6\u95f4\u6f14\u5316\u66f2\u7ebf\u56fe\uff0c\u653e\u5927\u5176\u201c\u81ea\u6301\u70b9\u201d\u9644\u8fd1\u533a\u57df\u3002</li> </ul> </li> <li><code>glossary_path</code> (\u5b57\u7b26\u4e32, \u9009\u586b):<ul> <li>\u63cf\u8ff0: \u6307\u5411\u4e00\u4e2a\u201c\u672f\u8bed\u8868\u201d CSV \u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul> </li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u62a5\u544a\u7684\u7ed3\u6784\u4e0e\u901a\u7528\u8bf4\u660e\u4e2d\u63cf\u8ff0\u7684\u7c7b\u4f3c\uff0c\u4f46\u5176\u6838\u5fc3\u5185\u5bb9\u662f\u9488\u5bf9\u5355\u6b21\u8fd0\u884c\u7684\u5feb\u7167\u5206\u6790\uff0c\u5305\u542b\uff1a</p> <ol> <li>\u5173\u952e\u6027\u80fd\u6307\u6807 (Key Performance Indicators): \u57fa\u4e8e <code>detailed_var</code> \u8ba1\u7b97\u51fa\u7684 <code>Startup Inventory</code>, <code>Self-Sufficiency Time</code> \u548c <code>Doubling Time</code>\u3002</li> <li>\u6a21\u62df\u7ed3\u679c\u65f6\u5e8f\u56fe (Time-series Plot): \u5305\u542b\u5168\u5c40\u89c6\u56fe\u548c\u57fa\u4e8e <code>detailed_var</code> \u7684\u7ec6\u8282\u89c6\u56fe\u3002</li> <li>\u6a21\u62df\u7ed3\u675f\u65f6\u5404\u53d8\u91cf\u6700\u7ec8\u503c (Final Values Bar Chart): \u5404\u5b50\u7cfb\u7edf\u5728\u4eff\u771f\u7ed3\u675f\u65f6\u7684\u6c1a\u5e93\u5b58\u5206\u5e03\u6761\u5f62\u56fe\u3002</li> <li>\u6570\u636e\u8868\u683c: \u5305\u62ec\u6700\u7ec8\u503c\u6570\u636e\u8868\u548c\u5173\u952e\u9636\u6bb5\uff08\u521d\u59cb\u3001\u8f6c\u6298\u70b9\u3001\u7ed3\u675f\uff09\u7684\u6570\u636e\u5207\u7247\u3002</li> </ol>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#4-ai","title":"4. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#41","title":"4.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5bf9\u4e8e\u57fa\u51c6\u5de5\u51b5\u5206\u6790\uff0cAI \u529f\u80fd\u662f\u901a\u8fc7\u5728 <code>post_processing</code> \u4efb\u52a1\u7684 <code>params</code> \u5bf9\u8c61\u4e2d\u6dfb\u52a0 <code>\"ai\": true</code> \u6765\u6fc0\u6d3b\u7684\u3002</p> <pre><code>\"post_processing\": [\n    {\n       \"module\": \"tricys.postprocess.baseline_analysis\",\n       \"function\": \"baseline_analysis\",\n       \"params\": {\n            \"detailed_var\": \"sds.I[1]\",\n            \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n            \"ai\": true\n        }\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#42","title":"4.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/baseline_condition_analysis.html#43","title":"4.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html","title":"Latin\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u6790","text":"<p>\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (Uncertainty Quantification, UQ) \u662f\u8bc4\u4f30\u6a21\u578b\u6216\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5173\u952e\u6b65\u9aa4\u3002\u5b83\u7684\u76ee\u7684\u4e0d\u662f\u627e\u51fa\u54ea\u4e2a\u53c2\u6570\u6700\u654f\u611f\uff0c\u800c\u662f\u56de\u7b54\u4e00\u4e2a\u66f4\u91cd\u8981\u7684\u95ee\u9898\uff1a\u201c\u5f53\u6211\u7684\u8f93\u5165\u53c2\u6570\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u4e0d\u786e\u5b9a\u65f6\uff0c\u6211\u7684\u8f93\u51fa\u7ed3\u679c\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u53ef\u80fd\u8303\u56f4\u662f\u591a\u5927\uff1f\u5176\u6982\u7387\u5206\u5e03\u662f\u600e\u6837\u7684\uff1f\u201d</p> <p><code>tricys</code> \u5229\u7528\u9ad8\u6548\u7684 Latin \u8d85\u7acb\u65b9\u91c7\u6837 (Latin Hypercube Sampling, LHS) \u6280\u672f\u6765\u8fdb\u884c UQ \u5206\u6790\u3002LHS \u662f\u4e00\u79cd\u5206\u5c42\u91c7\u6837\u65b9\u6cd5\uff0c\u5b83\u80fd\u7528\u76f8\u5bf9\u8f83\u5c11\u7684\u6837\u672c\u70b9\u5747\u5300\u5730\u63a2\u7d22\u6574\u4e2a\u591a\u7ef4\u53c2\u6570\u7a7a\u95f4\uff0c\u4ece\u800c\u9ad8\u6548\u5730\u8bc4\u4f30\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u4f20\u64ad\u5230\u6a21\u578b\u8f93\u51fa\u3002</p> <p>\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>LHS \u5206\u6790\u7684\u914d\u7f6e\u4e0e SOBOL \u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u975e\u5e38\u76f8\u4f3c\uff0c\u4e3b\u8981\u533a\u522b\u5728\u4e8e <code>analyzer.method</code> \u88ab\u8bbe\u7f6e\u4e3a <code>\"latin\"</code>\u3002</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_LATIN_Analysis\",\n                \"independent_variable\": [\"pulseSource.width\", \"plasma.nf\", \"plasma.fb\", \"tep_fep.to_SDS_Fraction[1]\", \"blanket.TBR\"],\n                \"independent_variable_sampling\": {\n                      \"pulseSource.width\": { \"bounds\": [50, 90], \"distribution\": \"unif\" },\n                      \"plasma.nf\": { \"bounds\": [0.1, 0.9], \"distribution\": \"unif\" },\n                      \"plasma.fb\": { \"bounds\": [0.03, 0.07], \"distribution\": \"unif\" },\n                      \"tep_fep.to_SDS_Fraction[1]\": { \"bounds\": [0.1, 0.8], \"distribution\": \"unif\" },\n                      \"blanket.TBR\": { \"bounds\": [1.05, 1.25], \"distribution\": \"unif\" }\n                },\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"analyzer\": {\n                    \"method\": \"latin\",\n                    \"sample_N\": 256\n                }\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li><code>independent_variable</code> (\u5217\u8868): \u4e00\u4e2a\u5305\u542b\u6240\u6709\u88ab\u89c6\u4e3a\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u7684\u8f93\u5165\u53c2\u6570\u7684\u5217\u8868\u3002</li> <li><code>independent_variable_sampling</code> (\u5bf9\u8c61): \u4e00\u4e2a\u5b57\u5178\uff0c\u4e3a\u6bcf\u4e2a\u4e0d\u786e\u5b9a\u53c2\u6570\u5b9a\u4e49\u5176\u91c7\u6837\u8303\u56f4\u548c\u6982\u7387\u5206\u5e03\u3002</li> <li><code>analyzer</code> (\u5bf9\u8c61): \u5b9a\u4e49\u8981\u4f7f\u7528\u7684\u5206\u6790\u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u3002</li> <li><code>method</code>: \u56fa\u5b9a\u4e3a <code>\"latin\"</code>\u3002</li> <li><code>sample_N</code>: Latin \u8d85\u7acb\u65b9\u91c7\u6837\u751f\u6210\u7684\u6837\u672c\u6570\u91cf\uff0c\u76f4\u63a5\u5bf9\u5e94\u4e8e\u5c06\u8981\u8fd0\u884c\u7684\u4eff\u771f\u603b\u6b21\u6570\u3002</li> </ul>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#3","title":"3. \u5de5\u4f5c\u6d41\u8be6\u89e3","text":"<p>\u5f53 <code>tricys</code> \u63a5\u6536\u5230\u4e00\u4e2a\u5305\u542b <code>analyzer</code> \u5b57\u6bb5\u7684\u5206\u6790\u4efb\u52a1\u65f6\uff08\u5982\u672c\u4f8b\u4e2d\u7684LHS\u5206\u6790\uff09\uff0c\u5b83\u4f1a\u542f\u52a8\u4e00\u4e2a\u57fa\u4e8e <code>SALib</code> \u5e93\u7684\u7279\u6b8a\u5de5\u4f5c\u6d41\u3002</p> <ol> <li>\u8bc6\u522b\u5206\u6790\u7c7b\u578b: \u5728 <code>tricys.simulation.simulation_analysis.py</code> \u7684\u4e3b\u6d41\u7a0b\u4e2d\uff0c\u7a0b\u5e8f\u9996\u5148\u68c0\u6d4b\u5230\u8fd9\u662f\u4e00\u4e2a SALib \u5206\u6790\u4efb\u52a1\u3002</li> <li>\u5b9a\u4e49\u95ee\u9898\u548c\u91c7\u6837: \u7a0b\u5e8f\u5c06\u4efb\u52a1\u59d4\u6258\u7ed9 <code>tricys.analysis.salib.py</code> \u6a21\u5757\uff0c\u8be5\u6a21\u5757\u6839\u636e\u914d\u7f6e\u5b9a\u4e49\u4e00\u4e2a <code>SALib</code> \u201c\u95ee\u9898\u7a7a\u95f4\u201d\uff0c\u5e76\u8c03\u7528 LHS \u91c7\u6837\u51fd\u6570\u751f\u6210 <code>N</code> \u4e2a\u53c2\u6570\u6837\u672c\u70b9\u3002</li> <li>\u6267\u884c\u6279\u91cf\u4eff\u771f: \u751f\u6210\u7684 <code>N</code> \u4e2a\u53c2\u6570\u6837\u672c\u88ab\u5199\u5165\u4e00\u4e2a\u4e34\u65f6\u7684 CSV \u6587\u4ef6\u4e2d\uff0c<code>tricys</code> \u968f\u540e\u4e3a\u6bcf\u4e2a\u6837\u672c\u70b9\u6267\u884c\u4e00\u6b21\u4eff\u771f\u3002</li> <li>\u6536\u96c6\u548c\u5206\u6790\u7ed3\u679c: \u6240\u6709\u4eff\u771f\u8fd0\u884c\u5b8c\u6bd5\u540e\uff0c\u7a0b\u5e8f\u4f1a\u8ba1\u7b97\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\u7684 <code>N</code> \u4e2a\u8f93\u51fa\u7ed3\u679c\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff08\u8ba1\u7b97\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u767e\u5206\u4f4d\u6570\u7b49\uff09\u3002</li> <li>\u751f\u6210\u62a5\u544a\u548c\u56fe\u8868: \u6700\u540e\uff0c\u7a0b\u5e8f\u6839\u636e\u7edf\u8ba1\u5206\u6790\u7ed3\u679c\u751f\u6210\u6700\u7ec8\u7684 Markdown \u62a5\u544a\uff0c\u5176\u4e2d\u5305\u542b\u8be6\u7ec6\u7684\u7edf\u8ba1\u6570\u636e\u8868\u683c\u548c\u8f93\u51fa\u5206\u5e03\u56fe\uff08\u76f4\u65b9\u56fe\u548c\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u56fe\uff09\u3002</li> </ol>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#4","title":"4. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u62a5\u544a\u7684\u6838\u5fc3\u5185\u5bb9\u662f\u9488\u5bf9\u6bcf\u4e00\u4e2a\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u72ec\u7acb\u7edf\u8ba1\u5206\u6790\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e <code>Startup_Inventory</code> \u6307\u6807\uff0c\u62a5\u544a\u4f1a\u5305\u542b\uff1a</p> <ol> <li>\u7edf\u8ba1\u6458\u8981 (Statistical Summary): \u63d0\u4f9b\u4e00\u7ec4\u6838\u5fc3\u7684\u7edf\u8ba1\u6570\u636e\uff0c\u5305\u62ec\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5c0f\u503c\u548c\u6700\u5927\u503c\u3002</li> <li>\u5206\u5e03\u5173\u952e\u70b9 (Key Distribution Points / CDF): \u63d0\u4f9b\u4e00\u7cfb\u5217\u767e\u5206\u4f4d\u6570\uff08\u59825%, 25%, 50% (\u4e2d\u4f4d\u6570), 75%, 95%\uff09\uff0c\u7528\u4e8e\u7cbe\u786e\u63cf\u8ff0\u8f93\u51fa\u6307\u6807\u7684\u7d2f\u79ef\u5206\u5e03\u60c5\u51b5\u3002</li> <li>\u8f93\u51fa\u5206\u5e03 (\u76f4\u65b9\u56fe\u6570\u636e): \u4e00\u4e2a\u8868\u683c\uff0c\u5c55\u793a\u4e86\u8f93\u51fa\u7ed3\u679c\u5728\u4e0d\u540c\u6570\u503c\u533a\u95f4\u7684\u9891\u6570\u5206\u5e03\u3002</li> <li>\u8f93\u51fa\u5206\u5e03\u56fe (Output Distribution Plot): \u5d4c\u5165\u7684 <code>.png</code> \u56fe\u8868\uff0c\u5305\u542b\u4e24\u4e2a\u5b50\u56fe\uff1a<ul> <li>\u76f4\u65b9\u56fe: \u76f4\u89c2\u5c55\u793a\u8f93\u51fa\u6307\u6807\u7684\u6982\u7387\u5bc6\u5ea6\u5206\u5e03\u5f62\u72b6\u3002</li> <li>\u7d2f\u79ef\u5206\u5e03\u51fd\u6570 (CDF): \u5c55\u793a\u4e86\u8f93\u51fa\u6307\u6807\u503c\u5c0f\u4e8e\u6216\u7b49\u4e8e\u67d0\u4e2a\u7279\u5b9a\u503c\u7684\u6982\u7387\u3002</li> </ul> </li> </ol>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#uq","title":"\u5982\u4f55\u89e3\u8bfbUQ\u7ed3\u679c","text":"<p>\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5206\u6790\u7684\u91cd\u70b9\u662f\u7406\u89e3\u8f93\u51fa\u7684\u5206\u5e03\uff0c\u800c\u4e0d\u662f\u53c2\u6570\u7684\u654f\u611f\u5ea6\u6392\u5e8f\u3002</p> <ul> <li>\u770b\u4e2d\u5fc3\u8d8b\u52bf: \u5747\u503c (Mean) \u548c \u4e2d\u4f4d\u6570 (Median) \u544a\u8bc9\u60a8\u6027\u80fd\u6307\u6807\u6700\u53ef\u80fd\u843d\u5728\u54ea\u4e2a\u503c\u9644\u8fd1\u3002</li> <li>\u770b\u79bb\u6563\u7a0b\u5ea6: \u6807\u51c6\u5dee (Standard Deviation) \u548c 5%-95%\u767e\u5206\u4f4d\u6570\u7684\u8303\u56f4 \u63ed\u793a\u4e86\u8f93\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u6709\u591a\u5927\u3002\u8303\u56f4\u8d8a\u5bbd\uff0c\u8bf4\u660e\u8f93\u5165\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u7cfb\u7edf\u6027\u80fd\u9020\u6210\u7684\u5f71\u54cd\u8d8a\u5927\uff0c\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u53ef\u80fd\u8d8a\u5dee\u3002</li> <li>\u770b\u5206\u5e03\u5f62\u72b6: \u76f4\u65b9\u56fe\u7684\u5f62\u72b6\u5f88\u91cd\u8981\u3002\u4e00\u4e2a\u5bf9\u79f0\u7684\u3001\u7c7b\u4f3c\u6b63\u6001\u5206\u5e03\u7684\u949f\u5f62\u66f2\u7ebf\u662f\u6bd4\u8f83\u7406\u60f3\u7684\u3002\u5982\u679c\u5206\u5e03\u51fa\u73b0\u957f\u5c3e\u6216\u504f\u659c\uff0c\u53ef\u80fd\u610f\u5473\u7740\u7cfb\u7edf\u5728\u67d0\u4e9b\u53c2\u6570\u7ec4\u5408\u4e0b\u5bb9\u6613\u51fa\u73b0\u6781\u7aef\u7684\u597d\u6216\u574f\u7684\u7ed3\u679c\uff0c\u8fd9\u5bf9\u4e8e\u98ce\u9669\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002</li> </ul>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#5","title":"5. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/5_latin_uncertainty_analysis/latin_uncertainty_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"SALIB_LATIN_Analysis\",                 \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\",\"plasma.fb\",\"tep_fep.to_SDS_Fraction[1]\",\"blanket.TBR\"],                 \"independent_variable_sampling\":{                       \"pulseSource.width\": {                           \"bounds\": [50,90],                           \"distribution\": \"unif\"                       },                       \"plasma.nf\": {                           \"bounds\": [0.1,0.9],                           \"distribution\": \"unif\"                       },                       \"plasma.fb\": {                           \"bounds\": [0.03,0.07],                           \"distribution\": \"unif\"                       },                       \"tep_fep.to_SDS_Fraction[1]\": {                           \"bounds\": [0.1,0.8],                           \"distribution\": \"unif\"                       },                       \"blanket.TBR\": {                           \"bounds\": [1.05, 1.25],                           \"distribution\": \"unif\"                       }                 },                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Self_Sufficiency_Time\",                     \"Doubling_Time\"                 ],                 \"analyzer\": {                     \"method\": \"latin\",                     \"sample_N\": 256                 }             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#6-ai","title":"6. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#61","title":"6.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#62","title":"6.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/latin_uncertainty_analysis.html#63","title":"6.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html","title":"\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5728\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u7684\u57fa\u7840\u4e0a\uff0c<code>tricys</code> \u63d0\u4f9b\u4e86\u529f\u80fd\u66f4\u5f3a\u5927\u7684\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002\u8be5\u529f\u80fd\u5141\u8bb8\u60a8\u5728\u7814\u7a76\u4e00\u4e2a\u4e3b\u72ec\u7acb\u53c2\u6570\uff08X\u8f74\uff09\u5bf9\u6027\u80fd\u6307\u6807\uff08Y\u8f74\uff09\u7684\u5f71\u54cd\u65f6\uff0c\u540c\u65f6\u626b\u63cf\u4e00\u4e2a\u6216\u591a\u4e2a\u80cc\u666f\u53c2\u6570\u3002</p> <p>\u8fd9\u4f7f\u5f97\u60a8\u53ef\u4ee5\u5728\u4e00\u5f20\u56fe\u4e0a\u751f\u6210\u4e00\u7ec4\u201c\u654f\u611f\u6027\u66f2\u7ebf\u65cf\u201d\uff0c\u5176\u4e2d\u6bcf\u4e00\u6761\u66f2\u7ebf\u4ee3\u8868\u4e00\u4e2a\u80cc\u666f\u53c2\u6570\u7684\u7279\u5b9a\u53d6\u503c\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u60a8\u53ef\u4ee5\u6df1\u5165\u5730\u7406\u89e3\u53c2\u6570\u4e4b\u95f4\u7684\u4ea4\u4e92\u548c\u8026\u5408\u6548\u5e94\u3002\u6b64\u5916\uff0c\u8be5\u529f\u80fd\u8fd8\u652f\u6301\u4e00\u79cd\u5f3a\u5927\u7684\u201c\u76ee\u6807\u5bfb\u6c42\u201d\u5f0f\u5206\u6790\u3002</p> <p>\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#1","title":"1. \u6838\u5fc3\u6982\u5ff5\uff1a\u53c2\u6570\u4ea4\u4e92\u5206\u6790","text":"<p>\u8fd9\u662f\u591a\u53c2\u6570\u5206\u6790\u6700\u5e38\u89c1\u7684\u7528\u6cd5\uff0c\u5176\u6838\u5fc3\u662f\u5728 <code>analysis_cases</code> \u7684\u67d0\u4e2a\u6848\u4f8b\u5185\u90e8\uff0c\u5d4c\u5165\u4e00\u4e2a <code>simulation_parameters</code> \u5b57\u6bb5\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#11","title":"1.1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<pre><code>{\n    // ...\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"DIR_PLASMA_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\", // \u4e3b\u72ec\u7acb\u53c2\u6570 (X\u8f74)\n                \"independent_variable_sampling\": [0.1, 0.3, 0.6, 0.8],\n                \"dependent_variables\": [ \"Startup_Inventory\", \"Required_TBR\" ], // \u56e0\u53d8\u91cf (Y\u8f74)\n                \"simulation_parameters\": {\n                    \"plasma.fb\": [0.02, 0.04, 0.08, 0.09, 0.1], // \u80cc\u666f\u626b\u63cf\u53c2\u6570 (\u751f\u6210\u591a\u6761\u66f2\u7ebf)\n                    \"plasma.nf\": 0.5 // \u56fa\u5b9a\u7684\u80cc\u666f\u53c2\u6570\n                }\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#12","title":"1.2. \u5de5\u4f5c\u539f\u7406","text":"<ul> <li>\u4e3b\u72ec\u7acb\u53c2\u6570 (<code>independent_variable</code>): <code>tep_fep.to_SDS_Fraction[1]</code>\uff0c\u4f5c\u4e3a\u56fe\u8868\u7684 X\u8f74\u3002</li> <li>\u80cc\u666f\u626b\u63cf\u53c2\u6570 (<code>simulation_parameters</code>):<ul> <li><code>plasma.fb</code> \u7684\u503c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u5b83\u5c06\u6210\u4e3a\u56fe\u8868\u4e2d\u7684\u56fe\u4f8b (Legend)\uff0c\u6bcf\u4e00\u6761\u66f2\u7ebf\u5bf9\u5e94 <code>plasma.fb</code> \u7684\u4e00\u4e2a\u53d6\u503c\u3002</li> <li><code>plasma.nf</code> \u7684\u503c\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u5b83\u5c06\u5728\u6240\u6709\u4eff\u771f\u4e2d\u4fdd\u6301\u4e0d\u53d8\u3002</li> </ul> </li> <li>\u6267\u884c\u903b\u8f91: \u7a0b\u5e8f\u4f1a\u6267\u884c\u4e00\u4e2a\u201c\u5d4c\u5957\u5faa\u73af\u201d\u3002\u5bf9\u4e8e <code>independent_variable</code> \u7684\u6bcf\u4e00\u4e2a\u53d6\u503c\uff0c\u7a0b\u5e8f\u4f1a\u4e3a <code>plasma.fb</code> \u7684\u6bcf\u4e00\u4e2a\u503c\u90fd\u8fd0\u884c\u4e00\u6b21\u4eff\u771f\u3002\u603b\u8fd0\u884c\u6b21\u6570\u4e3a <code>len(independent_variable_sampling) * len(plasma.fb)</code>\u3002</li> </ul>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#2","title":"2. \u9ad8\u7ea7\u7528\u6cd5\uff1a\u76ee\u6807\u5bfb\u6c42\u5206\u6790","text":"<p>\u6b64\u529f\u80fd\u652f\u6301\u4e00\u79cd\u201c\u9006\u5411\u201d\u5206\u6790\u6a21\u5f0f\uff0c\u5373\u76ee\u6807\u5bfb\u6c42 (Goal-Seeking)\u3002\u60a8\u53ef\u4ee5\u6307\u5b9a\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u4f5c\u4e3a\u76ee\u6807\uff0c\u53cd\u5411\u6c42\u89e3\u4e3a\u4e86\u8fbe\u5230\u8fd9\u4e2a\u76ee\u6807\uff0c\u67d0\u4e2a\u8f93\u5165\u53c2\u6570\u9700\u8981\u88ab\u8bbe\u7f6e\u6210\u591a\u5c11\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#21","title":"2.1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u5173\u952e\u5728\u4e8e <code>simulation_parameters</code> \u4e2d\u5305\u542b\u4e86\u4e00\u4e2a\u4e0e <code>metrics_definition</code> \u4e2d\u4f18\u5316\u6307\u6807\u540c\u540d\u7684\u7279\u6b8a\u5bf9\u8c61\uff08\u672c\u4f8b\u4e2d\u4e3a <code>Required_TBR</code>\uff09\u3002</p> <pre><code>{\n    \"name\": \"DoubleTime_PLASMA_Analysis\",\n    \"independent_variable\": \"plasma.fb\", // \u4e3b\u72ec\u7acb\u53c2\u6570 (X\u8f74)\n    \"dependent_variables\": [ \"Startup_Inventory\", \"Required_TBR\" ], // \u56e0\u53d8\u91cf (Y\u8f74)\n    \"simulation_parameters\": {\n        \"plasma.nf\": 0.5,\n        \"Required_TBR\": { // \u7279\u6b8a\u7684\u76ee\u6807\u5bfb\u6c42\u914d\u7f6e\n            \"metric_name\": \"Doubling_Time\", // \u76ee\u6807\u6307\u6807\n            \"metric_max_value\": [4380, 8760, 13140, 17530] // \u76ee\u6807\u503c\u7684\u5217\u8868 (\u5355\u4f4d: \u5c0f\u65f6)\n        }\n    },\n    // ...\n    \"metrics_definition\": {\n        // ...\n        \"Required_TBR\": {\n            \"method\": \"bisection_search\",\n            \"parameter_to_optimize\": \"blanket.TBR\", // \u9700\u8981\u6c42\u89e3\u7684\u53c2\u6570\n            // ... (bisection_search \u7684\u5176\u4ed6\u914d\u7f6e)\n        }\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#22","title":"2.2. \u5de5\u4f5c\u539f\u7406","text":"<ul> <li>\u95ee\u9898\u63cf\u8ff0: \u6b64\u914d\u7f6e\u65e8\u5728\u56de\u7b54\uff1a\u201c\u5f53 <code>plasma.fb</code> \u53d8\u5316\u65f6\uff0c\u4e3a\u4e86\u5206\u522b\u5b9e\u73b0\u4e0d\u540c\u7684 <code>Doubling_Time</code> \u76ee\u6807\uff084380h, 8760h, ...\uff09\uff0c\u6211\u4eec\u9700\u8981\u7684 <code>blanket.TBR</code> \u662f\u591a\u5c11\uff1f\u201d</li> <li>\u6267\u884c\u903b\u8f91: \u5bf9\u4e8eX\u8f74\u4e0a\u7684\u6bcf\u4e00\u4e2a <code>plasma.fb</code> \u503c\uff0c\u7a0b\u5e8f\u4f1a\u9488\u5bf9 <code>metric_max_value</code> \u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u76ee\u6807\u503c\u542f\u52a8\u4e00\u6b21 <code>bisection_search</code> \u4f18\u5316\u5faa\u73af\uff0c\u4ee5\u6c42\u89e3\u51fa\u5bf9\u5e94\u7684 <code>blanket.TBR</code> \u503c\u3002</li> <li>\u7ed3\u679c\u89e3\u8bfb: \u6700\u7ec8\u7684\u56fe\u8868\u5c06\u5c55\u793a\uff0c\u5728\u4e0d\u540c\u7684\u500d\u589e\u65f6\u95f4\u76ee\u6807\u7ea6\u675f\u4e0b\uff0c\u6240\u9700\u7684TBR\u662f\u5982\u4f55\u968f\u7740<code>plasma.fb</code>\u53d8\u5316\u7684\u3002</li> </ul>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u4e0e\u5355\u53c2\u6570\u5206\u6790\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\uff1a</p> <ul> <li>\u5bf9\u4e8e\u53c2\u6570\u4ea4\u4e92\u5206\u6790\uff0c\u56fe\u8868\u5c06\u5305\u542b\u4e00\u7ec4\u66f2\u7ebf\uff0c\u56fe\u4f8b\u5bf9\u5e94\u80cc\u666f\u53c2\u6570\uff08\u5982 <code>plasma.fb</code>\uff09\u7684\u4e0d\u540c\u53d6\u503c\u3002</li> <li>\u5bf9\u4e8e\u76ee\u6807\u5bfb\u6c42\u5206\u6790\uff0c\u56fe\u8868\u540c\u6837\u5305\u542b\u591a\u6761\u66f2\u7ebf\uff0c\u4f46\u56fe\u4f8b\u5bf9\u5e94\u7684\u662f\u4e0d\u540c\u7684\u6027\u80fd\u76ee\u6807\u7ea6\u675f\uff08\u5982 <code>Doubling_Time = 4380h</code>\uff09\u3002</li> </ul> <p>\u8fd9\u4f7f\u5f97\u591a\u7ef4\u5ea6\u7684\u6570\u636e\u5173\u7cfb\u80fd\u591f\u88ab\u6e05\u6670\u5730\u5448\u73b0\u5728\u4e00\u5f20\u4e8c\u7ef4\u56fe\u8868\u4e2d\u3002\u62a5\u544a\u7684\u5176\u4ed6\u90e8\u5206\u4e0e\u901a\u7528\u7ed3\u6784\u4e00\u81f4\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#4","title":"4. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/3_multi_parameter_sensitivity_analysis/multi_parameter_sensitivity_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"DIR_PLASMA_Analysis\",                 \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",                 \"independent_variable_sampling\": [0.1,0.3,0.6,0.8],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1],                     \"plasma.nf\":0.5                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             },             {                 \"name\": \"Pulse_PLASMA_Analysis\",                 \"independent_variable\": \"pulseSource.width\",                 \"independent_variable_sampling\": [50,60,70,80,90,99],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1],                     \"plasma.nf\":0.5                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             },             {                 \"name\": \"DoubleTime_PLASMA_Analysis\",                 \"independent_variable\": \"plasma.fb\",                 \"independent_variable_sampling\": [0.02,0.05,0.08,0.1],                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Required_TBR\"                 ],                 \"simulation_parameters\": {                     \"plasma.nf\":0.5,                     \"Required_TBR\": {                         \"metric_name\":\"Doubling_Time\",                         \"metric_max_value\": [4380,8760,13140,17530]                     }                 },                 \"plot_type\":\"line\",                 \"combine_plots\":true,                 \"sweep_time\":[\"sds.I[1]\"]             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#5-ai","title":"5. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#51","title":"5.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#52","title":"5.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/multi_parameter_sensitivity_analysis.html#53","title":"5.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html","title":"\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u662f <code>tricys</code> \u7684\u6838\u5fc3\u529f\u80fd\u4e4b\u4e00\uff0c\u65e8\u5728\u7814\u7a76\u5355\u4e2a\u72ec\u7acb\u53c2\u6570\u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u4e00\u7cfb\u5217\u7528\u6237\u5b9a\u4e49\u7684\u5173\u952e\u6027\u80fd\u6307\u6807 (KPIs)\u3002</p> <p>\u8be5\u529f\u80fd\u4f1a\u81ea\u52a8\u8fd0\u884c\u4e00\u7cfb\u5217\u4eff\u771f\uff08\u6bcf\u6b21\u4eff\u771f\u5bf9\u5e94\u72ec\u7acb\u53c2\u6570\u7684\u4e00\u4e2a\u53d6\u503c\uff09\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u4eff\u771f\u7ed3\u679c\u7684\u6027\u80fd\u6307\u6807\uff0c\u5e76\u751f\u6210\u56fe\u8868\u6765\u76f4\u89c2\u5730\u5c55\u793a\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u7684\u6838\u5fc3\u914d\u7f6e\u4f4d\u4e8e <code>analysis_cases</code> \u5217\u8868\u4e2d\u3002\u6bcf\u4e2a\u5bf9\u8c61\u4ee3\u8868\u4e00\u4e2a\u72ec\u7acb\u7684\u5206\u6790\u6848\u4f8b\u3002</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e: metrics_definition, glossary_path, unit_map)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li><code>independent_variable</code> (\u5b57\u7b26\u4e32): \u8981\u8fdb\u884c\u626b\u63cf\u7684\u72ec\u7acb\u53c2\u6570\u7684\u5b8c\u6574\u6a21\u578b\u8def\u5f84\u3002\u8fd9\u5c06\u662f\u5206\u6790\u56fe\u8868\u7684X\u8f74\u3002</li> <li><code>independent_variable_sampling</code> (\u5217\u8868): \u4e3a\u72ec\u7acb\u53c2\u6570\u63d0\u4f9b\u7684\u4e00\u7ec4\u79bb\u6563\u7684\u626b\u63cf\u503c\u3002\u7a0b\u5e8f\u4f1a\u4e3a\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u503c\u8fd0\u884c\u4e00\u6b21\u4eff\u771f\u3002</li> <li><code>dependent_variables</code> (\u5217\u8868): \u8981\u5206\u6790\u7684\u56e0\u53d8\u91cf\u5217\u8868\uff08\u5373\u5728 <code>metrics_definition</code> \u4e2d\u5b9a\u4e49\u7684\u6307\u6807\u540d\u79f0\uff09\u3002\u8fd9\u5c06\u662f\u5206\u6790\u56fe\u8868\u7684Y\u8f74\u3002</li> <li><code>plot_type</code> (\u5b57\u7b26\u4e32): \u751f\u6210\u7684\u654f\u611f\u6027\u56fe\u8868\u7684\u7c7b\u578b\uff0c\u901a\u5e38\u4e3a <code>\"line\"</code> (\u7ebf\u56fe)\u3002</li> <li><code>combine_plots</code> (\u5e03\u5c14\u503c): \u662f\u5426\u5c06\u591a\u4e2a\u56e0\u53d8\u91cf\u7684\u5206\u6790\u7ed3\u679c\u7ed8\u5236\u5728\u540c\u4e00\u5f20\u56fe\u8868\u4e2d\u3002<code>true</code> \u4f1a\u751f\u6210\u4e00\u5f20\u5305\u542b\u591a\u4e2a\u5b50\u56fe\u7684\u7ec4\u5408\u56fe\uff0c<code>false</code> \u5219\u4e3a\u6bcf\u4e2a\u56e0\u53d8\u91cf\u751f\u6210\u4e00\u5f20\u72ec\u7acb\u7684\u56fe\u3002</li> <li><code>sweep_time</code> (\u5217\u8868): \u4e00\u4e2a\u5305\u542b\u539f\u59cb\u53d8\u91cf\u540d\u7684\u5217\u8868\u3002\u5bf9\u4e8e\u6b64\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u53d8\u91cf\uff0c\u7a0b\u5e8f\u4f1a\u751f\u6210\u4e00\u5f20\u201c\u65cf\u8c31\u56fe\u201d\uff0c\u5373\u5c06\u6bcf\u6b21\u53c2\u6570\u626b\u63cf\u5f97\u5230\u7684\u65f6\u95f4\u6f14\u5316\u66f2\u7ebf\u7ed8\u5236\u5728\u540c\u4e00\u5f20\u56fe\u4e0a\uff0c\u4fbf\u4e8e\u6bd4\u8f83\u52a8\u6001\u884c\u4e3a\u7684\u5dee\u5f02\u3002</li> </ul>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u5206\u6790\u62a5\u544a\u7684\u7ed3\u6784\u4e0e\u901a\u7528\u8bf4\u660e\u4e2d\u63cf\u8ff0\u7684\u7c7b\u4f3c\uff0c\u4f46\u5176\u6838\u5fc3\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a</p> <ul> <li>\u56fe\u8868\u7684X\u8f74\u662f\u60a8\u5b9a\u4e49\u7684 <code>independent_variable</code>\u3002</li> <li>Y\u8f74\u662f <code>dependent_variables</code> \u4e2d\u5b9a\u4e49\u7684\u6027\u80fd\u6307\u6807\u3002</li> <li>\u5982\u679c <code>combine_plots</code> \u4e3a <code>true</code>\uff0c\u62a5\u544a\u5c06\u5305\u542b\u4e00\u5f20\u7ec4\u5408\u56fe\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5b50\u56fe\u5c55\u793a\u4e00\u4e2a\u6027\u80fd\u6307\u6807\u968f\u72ec\u7acb\u53c2\u6570\u53d8\u5316\u7684\u8d8b\u52bf\u3002</li> <li>\u5982\u679c <code>sweep_time</code> \u88ab\u5b9a\u4e49\uff0c\u62a5\u544a\u8fd8\u4f1a\u5305\u542b\u4e00\u5f20\u201c\u65cf\u8c31\u56fe\u201d\uff0c\u5c55\u793a\u539f\u59cb\u53d8\u91cf\uff08\u5982 <code>sds.I[1]</code>\uff09\u5728\u4e0d\u540c\u72ec\u7acb\u53c2\u6570\u53d6\u503c\u4e0b\u7684\u65f6\u95f4\u6f14\u5316\u66f2\u7ebf\u3002</li> </ul>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#4","title":"4. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/2_single_parameter_sensitivity_analysis/single_parameter_sensitivity_analysis.json <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 12000.0,\n        \"step_size\": 0.5\n    },\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"Width_Analysis\",\n                \"independent_variable\": \"pulseSource.width\",\n                \"independent_variable_sampling\": [50,60,70,80,90,99],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"Fueling_Efficiency_Analysis\",\n                \"independent_variable\": \"plasma.nf\",\n                \"independent_variable_sampling\": [0.01,0.05,0.1,0.2,0.4,0.5,0.6,0.7,0.8,0.9],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"Burn_Fraction_Analysis\",\n                \"independent_variable\": \"plasma.fb\",\n                \"independent_variable_sampling\": [0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"DIR_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",\n                \"independent_variable_sampling\": [0.1,0.15,0.2,0.3,0.4,0.6,0.8],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05,1.1,1.15,1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            },\n            {\n                \"name\": \"I_ISS_Analysis\",\n                \"independent_variable\": \"i_iss.T\",\n                \"independent_variable_sampling\": [4,6,8,10],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"plot_type\":\"line\",\n                \"combine_plots\":true,\n                \"sweep_time\":[\"sds.I[1]\"]\n            }\n        ],\n        \"metrics_definition\": {\n            \"Startup_Inventory\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_startup_inventory\"\n            },\n            \"Self_Sufficiency_Time\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"time_of_turning_point\"\n            },\n            \"Doubling_Time\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_doubling_time\"\n            },\n            \"Required_TBR\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"bisection_search\",\n                \"parameter_to_optimize\": \"blanket.TBR\",\n                \"search_range\": [1,1.5],\n                \"tolerance\": 0.005,\n                \"max_iterations\": 10\n            }\n        },\n        \"glossary_path\": \"../../example_glossary/example_glossary.csv\",\n        \"unit_map\": {\n            \"Doubling_Time\": {\n                \"unit\": \"days\",\n                \"conversion_factor\": 24\n            },\n            \"Startup_Inventory\": {\n                \"unit\": \"kg\",\n                \"conversion_factor\": 1000\n            },\n            \"Self_Sufficiency_Time\": {\n                \"unit\": \"days\",\n                \"conversion_factor\": 24\n            },\n            \"power\":{\n                \"unit\": \"MW\"\n            },\n            \"period\":{\n                \"unit\": \"hours\"\n            },\n            \"width\":{\n                \"unit\": \"%\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#5-ai","title":"5. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#51","title":"5.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#52","title":"5.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/single_parameter_sensitivity_analysis.html#53","title":"5.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html","title":"SOBOL\u5168\u5c40\u654f\u611f\u6027\u5206\u6790","text":"<p>\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (Global Sensitivity Analysis, GSA) \u662f\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u91cf\u5316\u6a21\u578b\u8f93\u5165\u53c2\u6570\uff08\u4ee5\u53ca\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff09\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002\u4e0e\u4e00\u6b21\u53ea\u6539\u53d8\u4e00\u4e2a\u53c2\u6570\u7684\u5c40\u90e8\u654f\u611f\u6027\u5206\u6790\u4e0d\u540c\uff0cGSA \u4f1a\u540c\u65f6\u5728\u6574\u4e2a\u53c2\u6570\u7a7a\u95f4\u5185\u8fdb\u884c\u63a2\u7d22\u3002</p> <p><code>tricys</code> \u96c6\u6210\u4e86\u4e1a\u754c\u6807\u51c6\u7684 <code>SALib</code> \u5e93\uff0c\u63d0\u4f9b\u4e86\u5bf9 Sobol \u65b9\u6cd5\u7684\u76f4\u63a5\u652f\u6301\u3002Sobol \u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u7684 GSA \u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u9ad8\u6548\u5730\u8ba1\u7b97\u51fa\u6bcf\u4e2a\u53c2\u6570\u5bf9\u6a21\u578b\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u8d21\u732e\u5ea6\uff0c\u5305\u62ec\u53c2\u6570\u7684\u72ec\u7acb\u5f71\u54cd\u548c\u53c2\u6570\u95f4\u7684\u4ea4\u4e92\u5f71\u54cd\u3002</p> <p>\u5173\u4e8e\u6027\u80fd\u6307\u6807\u7684\u5b9a\u4e49\u3001\u672f\u8bed\u8868\u548c\u5355\u4f4d\u6620\u5c04\u7b49\u901a\u7528\u914d\u7f6e\uff0c\u8bf7\u53c2\u8003\u901a\u7528\u4ecb\u7ecd\u3002</p>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>SOBOL \u5206\u6790\u7684\u914d\u7f6e\u4e0e\u4e4b\u524d\u7684\u654f\u611f\u6027\u5206\u6790\u6709\u663e\u8457\u4e0d\u540c\uff0c\u4e3b\u8981\u4f53\u73b0\u5728 <code>independent_variable</code> \u53d8\u4e3a\u5217\u8868\uff0c<code>independent_variable_sampling</code> \u53d8\u4e3a\u5bf9\u8c61\uff0c\u5e76\u65b0\u589e\u4e86 <code>analyzer</code> \u5b57\u6bb5\u3002</p> <pre><code>{\n    // ... (paths, simulation)\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_SOBOL_Analysis\",\n                \"independent_variable\": [\"pulseSource.width\", \"plasma.nf\", \"plasma.fb\", \"tep_fep.to_SDS_Fraction[1]\", \"blanket.TBR\"],\n                \"independent_variable_sampling\": {\n                      \"pulseSource.width\": { \"bounds\": [50, 90], \"distribution\": \"unif\" },\n                      \"plasma.nf\": { \"bounds\": [0.1, 0.9], \"distribution\": \"unif\" },\n                      \"plasma.fb\": { \"bounds\": [0.03, 0.07], \"distribution\": \"unif\" },\n                      \"tep_fep.to_SDS_Fraction[1]\": { \"bounds\": [0.1, 0.8], \"distribution\": \"unif\" },\n                      \"blanket.TBR\": { \"bounds\": [1.05, 1.25], \"distribution\": \"unif\" }\n                },\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                \"analyzer\": {\n                    \"method\": \"sobol\",\n                    \"sample_N\": 256\n                }\n            }\n        ],\n        // ... (\u901a\u7528\u914d\u7f6e)\n    }\n}\n</code></pre>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#2","title":"2. \u5173\u952e\u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li><code>independent_variable</code> (\u5217\u8868): \u4e00\u4e2a\u5305\u542b\u6240\u6709\u8981\u8fdb\u884c\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u7684\u5217\u8868\u3002</li> <li><code>independent_variable_sampling</code> (\u5bf9\u8c61): \u4e00\u4e2a\u5b57\u5178\uff0c\u4e3a <code>independent_variable</code> \u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u53c2\u6570\u5b9a\u4e49\u5176\u91c7\u6837\u8303\u56f4\u548c\u6982\u7387\u5206\u5e03\u3002</li> <li>\u952e: \u53c2\u6570\u7684\u5b8c\u6574\u8def\u5f84\u3002</li> <li>\u503c: \u5305\u542b <code>bounds</code> (\u5217\u8868 <code>[min, max]</code>) \u548c <code>distribution</code> (\u5b57\u7b26\u4e32, \u5982 <code>\"unif\"</code>) \u7684\u5bf9\u8c61\u3002</li> <li><code>analyzer</code> (\u5bf9\u8c61): \u5b9a\u4e49\u8981\u4f7f\u7528\u7684 GSA \u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u3002</li> <li><code>method</code>: \u5bf9\u4e8e Sobol \u5206\u6790\uff0c\u56fa\u5b9a\u4e3a <code>\"sobol\"</code>\u3002</li> <li><code>sample_N</code>: Sobol \u91c7\u6837\u6240\u9700\u7684\u57fa\u6570 <code>N</code>\u3002<ul> <li>\u26a0\ufe0f \u91cd\u8981: \u5b9e\u9645\u8fd0\u884c\u7684\u4eff\u771f\u603b\u6b21\u6570\u5c06\u662f <code>N * (2D + 2)</code>\uff0c\u5176\u4e2d <code>D</code> \u662f <code>independent_variable</code> \u7684\u6570\u91cf\u3002\u4f8b\u5982\uff0c\u672c\u4f8b\u4e2d <code>D=5</code>, <code>N=256</code>\uff0c\u5219\u603b\u4eff\u771f\u6b21\u6570\u4e3a <code>256 * (2*5 + 2) = 3072</code> \u6b21\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#3","title":"3. \u5206\u6790\u62a5\u544a\u8f93\u51fa","text":"<p>\u62a5\u544a\u7684\u6838\u5fc3\u5185\u5bb9\u662f\u9488\u5bf9\u6bcf\u4e00\u4e2a\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u7684\u72ec\u7acb\u5206\u6790\u7ed3\u679c\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e <code>Startup_Inventory</code> \u6307\u6807\uff0c\u62a5\u544a\u4f1a\u5305\u542b\uff1a</p> <ol> <li>Sobol\u654f\u611f\u6027\u6307\u6570\u8868: \u4e00\u4e2a Markdown \u8868\u683c\uff0c\u7cbe\u786e\u5217\u51fa\u6bcf\u4e2a\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\uff08S1\uff09\u3001\u603b\u9636\uff08ST\uff09\u654f\u611f\u6027\u6307\u6570\u53ca\u5176\u7f6e\u4fe1\u533a\u95f4\u3002</li> <li>\u654f\u611f\u6027\u6307\u6570\u56fe: \u5d4c\u5165\u7684\u6761\u5f62\u56fe\uff0c\u76f4\u89c2\u5730\u5bf9\u6bd4\u5404\u4e2a\u53c2\u6570\u7684 S1 \u548c ST \u6307\u6570\uff0c\u4fbf\u4e8e\u5feb\u901f\u8bc6\u522b\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002</li> </ol>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#sobol_1","title":"\u5982\u4f55\u89e3\u8bfbSobol\u6307\u6570","text":"<ul> <li>S1 (\u4e00\u9636\u6307\u6570): \u53c2\u6570\u7684\u72ec\u7acb\u8d21\u732e\u3002S1 \u503c\u8d8a\u9ad8\uff0c\u8868\u793a\u8be5\u53c2\u6570\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u76f4\u63a5\u5f71\u54cd\u8d8a\u5927\u3002</li> <li>ST (\u603b\u9636\u6307\u6570): \u53c2\u6570\u7684\u603b\u4f53\u8d21\u732e\uff0c\u5305\u62ec\u5176\u72ec\u7acb\u5f71\u54cd\u4ee5\u53ca\u5b83\u4e0e\u6240\u6709\u5176\u4ed6\u53c2\u6570\u7684\u4ea4\u4e92\u4f5c\u7528\u3002</li> <li>\u4ea4\u4e92\u4f5c\u7528 (Interaction): <code>ST - S1</code> \u7684\u5dee\u503c\u53ef\u4ee5\u8fd1\u4f3c\u8861\u91cf\u8be5\u53c2\u6570\u4e0e\u5176\u4ed6\u53c2\u6570\u7684\u4ea4\u4e92\u6548\u5e94\u5f3a\u5ea6\u3002\u5982\u679c\u4e00\u4e2a\u53c2\u6570\u7684 <code>ST</code> \u8fdc\u5927\u4e8e\u5176 <code>S1</code>\uff0c\u8bf4\u660e\u8be5\u53c2\u6570\u7684\u5f88\u591a\u5f71\u54cd\u662f\u901a\u8fc7\u4e0e\u5176\u4ed6\u53c2\u6570\u7684\u8026\u5408\u3001\u534f\u540c\u4f5c\u7528\u5b9e\u73b0\u7684\u3002</li> <li></li> </ul>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#4","title":"4. \u5b8c\u6574\u793a\u4f8b\u914d\u7f6e","text":"example/analysis/4_sobol_global_sensitivity_analysis/sobol_global_sensitivity_analysis.json  {     \"paths\": {         \"package_path\": \"../../example_model_single/example_model.mo\"     },     \"simulation\": {         \"model_name\": \"example_model.Cycle\",         \"variableFilter\": \"time|sds.I[1]\",         \"stop_time\": 12000.0,         \"step_size\": 0.5     },     \"sensitivity_analysis\": {         \"enabled\": true,         \"analysis_cases\": [             {                 \"name\": \"SALIB_SOBOL_Analysis\",                 \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\",\"plasma.fb\",\"tep_fep.to_SDS_Fraction[1]\",\"blanket.TBR\"],                 \"independent_variable_sampling\":{                       \"pulseSource.width\": {                           \"bounds\": [50,90],                           \"distribution\": \"unif\"                       },                       \"plasma.nf\": {                           \"bounds\": [0.1,0.9],                           \"distribution\": \"unif\"                       },                       \"plasma.fb\": {                           \"bounds\": [0.03,0.07],                           \"distribution\": \"unif\"                       },                       \"tep_fep.to_SDS_Fraction[1]\": {                           \"bounds\": [0.1,0.8],                           \"distribution\": \"unif\"                       },                       \"blanket.TBR\": {                           \"bounds\": [1.05, 1.25],                           \"distribution\": \"unif\"                       }                 },                 \"dependent_variables\": [                     \"Startup_Inventory\",                     \"Self_Sufficiency_Time\",                     \"Doubling_Time\"                 ],                 \"analyzer\": {                     \"method\": \"sobol\",                     \"sample_N\": 256                 }             }         ],         \"metrics_definition\": {             \"Startup_Inventory\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_startup_inventory\"             },             \"Self_Sufficiency_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"time_of_turning_point\"             },             \"Doubling_Time\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"calculate_doubling_time\"             },             \"Required_TBR\": {                 \"source_column\": \"sds.I[1]\",                 \"method\": \"bisection_search\",                 \"parameter_to_optimize\": \"blanket.TBR\",                 \"search_range\": [1,1.5],                 \"tolerance\": 0.005,                 \"max_iterations\": 10             }         },         \"glossary_path\": \"../../example_glossary/example_glossary.csv\",         \"unit_map\": {             \"Doubling_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"Startup_Inventory\": {                 \"unit\": \"kg\",                 \"conversion_factor\": 1000             },             \"Self_Sufficiency_Time\": {                 \"unit\": \"days\",                 \"conversion_factor\": 24             },             \"width\":{                 \"unit\": \"%\"             }         }     } }"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#5-ai","title":"5. AI \u589e\u5f3a\u5206\u6790","text":"<p><code>tricys</code> \u7684\u6240\u6709\u5206\u6790\u6a21\u5757\u90fd\u6df1\u5ea6\u96c6\u6210\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u7684\u56fe\u8868\u548c\u6570\u636e\u81ea\u52a8\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002</p>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#51","title":"5.1. \u542f\u7528\u65b9\u5f0f","text":"<p>\u5728\u60a8\u7684\u5206\u6790\u6848\u4f8b\u914d\u7f6e\u4e2d\uff08\u5373 <code>analysis_cases</code> \u5217\u8868\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5bf9\u8c61\uff0c\u6216 <code>post_processing</code> \u7684 <code>params</code> \u4e2d\uff09\uff0c\u6dfb\u52a0 <code>\"ai\": true</code> \u5373\u53ef\u4e3a\u8be5\u6848\u4f8b\u6fc0\u6d3b AI \u5206\u6790\u529f\u80fd\u3002</p> <pre><code>\"analysis_cases\": [\n    {\n        \"name\": \"TBR_Analysis_with_AI_Report\",\n        \"independent_variable\": \"blanket.TBR\",\n        \"independent_variable_sampling\": [1.05, 1.1, 1.15, 1.2],\n        \"dependent_variables\": [ \"Doubling_Time\" ],\n        \"ai\": true\n    }\n]\n</code></pre>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#52","title":"5.2. \u73af\u5883\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u6b64\u529f\u80fd\u524d\uff0c\u60a8\u5fc5\u987b\u5728\u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>.env</code> \u7684\u6587\u4ef6\uff0c\u5e76\u586b\u5165\u60a8\u7684\u5927\u8bed\u8a00\u6a21\u578b API \u51ed\u636e\u3002\u8fd9\u786e\u4fdd\u4e86\u60a8\u7684\u5bc6\u94a5\u5b89\u5168\uff0c\u4e0d\u4f1a\u88ab\u63d0\u4ea4\u5230\u7248\u672c\u63a7\u5236\u4e2d\u3002</p> <pre><code># .env file in project root\nAPI_KEY=\"sk-your_api_key_here\"\nBASE_URL=\"https://your_api_base_url/v1\"\nAI_MODEL=\"your_model_name_here\"\n</code></pre>"},{"location":"guides/tricys_analysis/sobol_global_sensitivity_analysis.html#53","title":"5.3. \u8f93\u51fa\u62a5\u544a","text":"<p>\u542f\u7528\u540e\uff0c\u9664\u4e86\u6807\u51c6\u7684\u5206\u6790\u62a5\u544a (<code>analysis_report_...md</code>)\uff0c<code>tricys</code> \u8fd8\u4f1a\u5728\u8be5\u6848\u4f8b\u7684 <code>report</code> \u6587\u4ef6\u5939\u5185\u751f\u6210\u4e24\u4efd\u989d\u5916\u7684\u62a5\u544a\uff1a</p> <ul> <li><code>analysis_report_{case_name}_{model_name}.md</code>: \u5728\u6838\u5fc3\u62a5\u544a\u7684\u57fa\u7840\u4e0a\uff0c\u672b\u5c3e\u8ffd\u52a0\u4e86\u7531 AI \u751f\u6210\u7684\u5bf9\u6570\u636e\u548c\u56fe\u8868\u7684\u6df1\u5ea6\u6587\u5b57\u89e3\u8bfb\u3002</li> <li><code>academic_report_{case_name}_{model_name}.md</code>: \u4e00\u4efd\u5b8c\u5168\u7531 AI \u64b0\u5199\u7684\u3001\u7ed3\u6784\u4e25\u8c28\u7684\u5b66\u672f\u98ce\u683c\u62a5\u544a\u3002\u8fd9\u4efd\u62a5\u544a\u901a\u5e38\u5305\u542b\u6458\u8981\u3001\u5f15\u8a00\u3001\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u8ba8\u8bba\u3001\u7ed3\u8bba\u7b49\u90e8\u5206\uff0c\u53ef\u4ee5\u76f4\u63a5\u4f5c\u4e3a\u6c47\u62a5\u6750\u6599\u6216\u8bba\u6587\u521d\u7a3f\u4f7f\u7528\u3002</li> </ul>"},{"location":"guides/tricys_basic/basic_configuration.html","title":"\u57fa\u7840\u914d\u7f6e","text":"<p>TRICYS \u7684\u6240\u6709\u4eff\u771f\u4efb\u52a1\u90fd\u7531\u4e00\u4e2a JSON \u914d\u7f6e\u6587\u4ef6\u9a71\u52a8\u3002\u8fd9\u4e2a\u6587\u4ef6\u8be6\u7ec6\u5b9a\u4e49\u4e86\u6a21\u578b\u8def\u5f84\u3001\u4eff\u771f\u53c2\u6570\u3001\u626b\u63cf\u53d8\u91cf\u4ee5\u53ca\u540e\u5904\u7406\u7b49\u6240\u6709\u73af\u8282\u3002</p> <p>\u672c\u8282\u5c06\u4ecb\u7ecd\u4e00\u4e2a\u6700\u57fa\u7840\u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u7528\u4e8e\u8fd0\u884c\u5355\u6b21\u4eff\u771f\u3002\u638c\u63e1\u57fa\u7840\u914d\u7f6e\u662f\u4f7f\u7528 TRICYS \u7684\u7b2c\u4e00\u6b65\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u914d\u7f6e\u6587\u4ef6\u5982\u4e0b\u6240\u793a\uff0c\u5b83\u5b9a\u4e49\u4e86\u8981\u8fd0\u884c\u54ea\u4e2a\u6a21\u578b\u4ee5\u53ca\u5982\u4f55\u8fd0\u884c\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    }\n}\n</code></pre> <p>\u8fd9\u4e2a\u914d\u7f6e\u6587\u4ef6\u5c06\u8fd0\u884c\u4e00\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684\u4eff\u771f\uff0c\u65f6\u957f\u4e3a 2000 \u5c0f\u65f6\uff0c\u6bcf 0.5 \u5c0f\u65f6\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\uff0c\u53ea\u4fdd\u5b58\u65f6\u95f4\u548c SDS \u7cfb\u7edf\u6c1a\u5e93\u5b58\u4e24\u4e2a\u53d8\u91cf\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#2","title":"2. \u5fc5\u987b\u914d\u7f6e\u9879","text":""},{"location":"guides/tricys_basic/basic_configuration.html#21-paths","title":"2.1. <code>paths</code> (\u8def\u5f84\u914d\u7f6e)","text":"<p>\u8fd9\u4e2a\u90e8\u5206\u7528\u4e8e\u5b9a\u4e49\u6240\u6709\u4e0e\u6587\u4ef6\u8def\u5f84\u76f8\u5173\u7684\u8bbe\u7f6e\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#package_path","title":"<code>package_path</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u6307\u5411 Modelica \u6a21\u578b\u7684\u6839 <code>package.mo</code> \u6587\u4ef6\u3002TRICYS \u5c06\u4ece\u8fd9\u91cc\u52a0\u8f7d\u548c\u89e3\u6790\u60a8\u7684\u6a21\u578b\u3002</li> <li>\u8def\u5f84\u7c7b\u578b: \u53ef\u4ee5\u662f\u7edd\u5bf9\u8def\u5f84\uff0c\u4e5f\u53ef\u4ee5\u662f\u76f8\u5bf9\u4e8e\u8be5 JSON \u914d\u7f6e\u6587\u4ef6\u6240\u5728\u4f4d\u7f6e\u7684\u76f8\u5bf9\u8def\u5f84\u3002</li> <li>\u793a\u4f8b:   <pre><code>\"package_path\": \"C:/Models/example_model/package.mo\"  // \u7edd\u5bf9\u8def\u5f84 (Windows)\n\"package_path\": \"/home/user/models/package.mo\"         // \u7edd\u5bf9\u8def\u5f84 (Linux)\n\"package_path\": \"../models/package.mo\"                 // \u76f8\u5bf9\u8def\u5f84\n</code></pre></li> </ul> <p>\u8def\u5f84\u5206\u9694\u7b26</p> <p>\u5728 JSON \u6587\u4ef6\u4e2d\uff0cWindows \u8def\u5f84\u53ef\u4ee5\u4f7f\u7528\u6b63\u659c\u6760 <code>/</code> \u6216\u53cc\u53cd\u659c\u6760 <code>\\\\</code>\uff1a <pre><code>\"package_path\": \"C:/Models/package.mo\"      // \u63a8\u8350\n\"package_path\": \"C:\\\\Models\\\\package.mo\"    // \u4e5f\u53ef\u4ee5\n</code></pre></p>"},{"location":"guides/tricys_basic/basic_configuration.html#22-simulation","title":"2.2. <code>simulation</code> (\u4eff\u771f\u914d\u7f6e)","text":"<p>\u8fd9\u4e2a\u90e8\u5206\u5305\u542b\u4e86\u8fd0\u884c\u4eff\u771f\u6240\u9700\u7684\u6838\u5fc3\u53c2\u6570\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#model_name","title":"<code>model_name</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u8981\u4eff\u771f\u7684\u5b8c\u6574 Modelica \u6a21\u578b\u540d\u79f0\u3002\u5b83\u9075\u5faa <code>\u5305\u540d.\u6a21\u578b\u540d</code> \u7684\u683c\u5f0f\u3002</li> <li>\u683c\u5f0f: <code>&lt;PackageName&gt;.&lt;ModelName&gt;</code></li> <li>\u793a\u4f8b:   <pre><code>\"model_name\": \"example_model.Cycle\"\n</code></pre>   \u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c<code>example_model</code> \u662f\u5305\u540d\uff08\u5bf9\u5e94 <code>package.mo</code>\uff09\uff0c<code>Cycle</code> \u662f\u5176\u4e2d\u5b9a\u4e49\u7684\u5177\u4f53\u6a21\u578b\u3002</li> </ul> <p>\u6a21\u578b\u540d\u79f0\u5fc5\u987b\u5b8c\u5168\u5339\u914d</p> <p>\u6a21\u578b\u540d\u79f0\u533a\u5206\u5927\u5c0f\u5199\uff0c\u5fc5\u987b\u4e0e Modelica \u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u540d\u79f0\u5b8c\u5168\u4e00\u81f4\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#variablefilter","title":"<code>variableFilter</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u4e00\u4e2a\u7528\u4e8e\u7b5b\u9009\u8f93\u51fa\u7ed3\u679c\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u3002\u53ea\u6709\u540d\u79f0\u5339\u914d\u8be5\u8868\u8fbe\u5f0f\u7684\u53d8\u91cf\u624d\u4f1a\u88ab\u4fdd\u5b58\u5230\u6700\u7ec8\u7684 <code>.csv</code> \u7ed3\u679c\u6587\u4ef6\u4e2d\u3002</li> <li>\u683c\u5f0f: \u4f7f\u7528\u7ad6\u7ebf <code>|</code> \u5206\u9694\u591a\u4e2a\u53d8\u91cf\u540d\u6216\u6a21\u5f0f\u3002</li> <li>\u793a\u4f8b:   <pre><code>// \u53ea\u4fdd\u5b58\u65f6\u95f4\u548c\u4e00\u4e2a\u53d8\u91cf\n\"variableFilter\": \"time|sds.I[1]\"\n\n// \u4fdd\u5b58\u65f6\u95f4\u548c\u4e00\u4e2a\u6570\u7ec4\u53d8\u91cf\n\"variableFilter\": \"time|sds.I[1-5]\"\n\n// \u4fdd\u5b58\u591a\u4e2a\u7279\u5b9a\u53d8\u91cf\n\"variableFilter\": \"time|sds.I[1]|blanket.I[1-5]|div.I[1-5]\"\n</code></pre></li> </ul> <p>\u5efa\u8bae</p> <p>\u4e3a\u4e86\u51cf\u5c0f\u8f93\u51fa\u6587\u4ef6\u5927\u5c0f\u548c\u63d0\u9ad8\u6027\u80fd\uff0c\u5efa\u8bae\u53ea\u4fdd\u5b58\u60a8\u771f\u6b63\u9700\u8981\u5206\u6790\u7684\u53d8\u91cf\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#stop_time","title":"<code>stop_time</code> (\u6d6e\u70b9\u6570, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u4eff\u771f\u7684\u603b\u65f6\u957f\uff08\u5355\u4f4d\uff1a\u79d2\uff09\u3002\u4eff\u771f\u5c06\u4ece <code>0</code> \u65f6\u523b\u8fd0\u884c\u5230 <code>stop_time</code>\u3002</li> <li>\u5355\u4f4d: \u5c0f\u65f6</li> </ul>"},{"location":"guides/tricys_basic/basic_configuration.html#step_size","title":"<code>step_size</code> (\u6d6e\u70b9\u6570, \u5fc5\u586b)","text":"<ul> <li>\u63cf\u8ff0: \u4eff\u771f\u7684\u65f6\u95f4\u6b65\u957f\uff08\u5355\u4f4d\uff1a\u79d2\uff09\u3002\u8fd9\u4e5f\u662f\u7ed3\u679c\u8f93\u51fa\u7684\u65f6\u95f4\u95f4\u9694\u3002</li> <li>\u6743\u8861: </li> <li>\u8f83\u5c0f\u7684\u6b65\u957f\uff1a\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u4f46\u4eff\u771f\u65f6\u95f4\u66f4\u957f\uff0c\u8f93\u51fa\u6587\u4ef6\u66f4\u5927</li> <li>\u8f83\u5927\u7684\u6b65\u957f\uff1a\u901f\u5ea6\u66f4\u5feb\uff0c\u4f46\u53ef\u80fd\u4e22\u5931\u5feb\u901f\u53d8\u5316\u7684\u7ec6\u8282</li> </ul>"},{"location":"guides/tricys_basic/basic_configuration.html#3","title":"3. \u9ed8\u8ba4\u914d\u7f6e\u9879","text":"<p>\u9664\u4e86\u4e0a\u8ff0\u5fc5\u586b\u9879\uff0cTRICYS \u8fd8\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u53ef\u9009\u914d\u7f6e\uff0c\u5b83\u4eec\u62e5\u6709\u5408\u7406\u7684\u9ed8\u8ba4\u503c\u3002\u4e0d\u8bbe\u7f6e\u8fd9\u4e9b\u9009\u9879\u65f6\uff0c\u7cfb\u7edf\u5c06\u81ea\u52a8\u4f7f\u7528\u4ee5\u4e0b\u9ed8\u8ba4\u884c\u4e3a\uff1a</p>"},{"location":"guides/tricys_basic/basic_configuration.html#31-paths","title":"3.1. <code>paths</code> (\u8def\u5f84\u914d\u7f6e)","text":"\u53c2\u6570 (Parameter) \u63cf\u8ff0 (Description) \u9ed8\u8ba4\u503c (Default Value) <code>results_dir</code> \u7528\u4e8e\u5b58\u653e\u4eff\u771f\u7ed3\u679c\u7684\u76ee\u5f55\u540d\u3002 <code>\"results\"</code> <code>temp_dir</code> \u7528\u4e8e\u5b58\u653e\u4e34\u65f6\u6587\u4ef6\u7684\u76ee\u5f55\u540d\u3002 <code>\"temp\"</code> <code>log_dir</code> \u7528\u4e8e\u5b58\u653e\u65e5\u5fd7\u6587\u4ef6\u7684\u76ee\u5f55\u540d\u3002 <code>\"log\"</code> <code>db_path</code> \u7528\u4e8e\u5b58\u50a8\u548c\u8bfb\u53d6\u6a21\u578b\u53c2\u6570\u7684 SQLite \u6570\u636e\u5e93\u6587\u4ef6\u8def\u5f84\u3002 \u5728\u6bcf\u6b21\u8fd0\u884c\u65f6\u52a8\u6001\u521b\u5efa\u4e8e\u4e34\u65f6\u76ee\u5f55\u4e2d\u3002 <p>\u8f93\u51fa\u76ee\u5f55\u7ed3\u6784</p> <p>TRICYS \u4f1a\u5728\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u4e0b\u521b\u5efa\u4e00\u4e2a\u4ee5\u65f6\u95f4\u6233\u547d\u540d\u7684\u4e3b\u8fd0\u884c\u76ee\u5f55\uff08\u4f8b\u5982 <code>20250116_103000/</code>\uff09\u3002\u4e0a\u8ff0\u6240\u6709\u8f93\u51fa\u76ee\u5f55\uff08<code>results</code>, <code>temp</code>, <code>log</code>\uff09\u90fd\u5c06\u9ed8\u8ba4\u521b\u5efa\u5728\u8fd9\u4e2a\u65f6\u95f4\u6233\u76ee\u5f55\u5185\u90e8\uff0c\u4ee5\u786e\u4fdd\u6bcf\u6b21\u8fd0\u884c\u7684\u8f93\u51fa\u7ed3\u679c\u90fd\u76f8\u4e92\u9694\u79bb\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#32-simulation","title":"3.2. <code>simulation</code> (\u4eff\u771f\u914d\u7f6e)","text":"\u53c2\u6570 (Parameter) \u63cf\u8ff0 (Description) \u9ed8\u8ba4\u503c (Default Value) <code>concurrent</code> \u662f\u5426\u5f00\u542f\u5e76\u53d1\uff08\u5e76\u884c\uff09\u4eff\u771f\uff0c\u7528\u4e8e\u52a0\u901f\u53c2\u6570\u626b\u63cf\u4efb\u52a1\u3002 <code>false</code> <code>max_workers</code> \u5982\u679c\u5f00\u542f\u5e76\u53d1\uff0c\u6b64\u9009\u9879\u7528\u4e8e\u6307\u5b9a\u6700\u5927\u5e76\u884c\u5de5\u4f5c\u8fdb\u7a0b\u6570\u3002 \u7cfb\u7edf CPU \u6838\u5fc3\u6570\u7684\u4e00\u534a <code>keep_temp_files</code> \u662f\u5426\u5728\u4eff\u771f\u7ed3\u675f\u540e\u4fdd\u7559\u4e34\u65f6\u6587\u4ef6\uff08\u5982\u6a21\u578b\u7f16\u8bd1\u6587\u4ef6\uff09\u3002\u5bf9\u4e8e\u8c03\u8bd5\u975e\u5e38\u6709\u7528\u3002 <code>true</code>"},{"location":"guides/tricys_basic/basic_configuration.html#33-logging","title":"3.3. <code>logging</code> (\u65e5\u5fd7\u914d\u7f6e)","text":"\u53c2\u6570 (Parameter) \u63cf\u8ff0 (Description) \u9ed8\u8ba4\u503c (Default Value) <code>log_level</code> \u65e5\u5fd7\u8bb0\u5f55\u7684\u6700\u4f4e\u7ea7\u522b\u3002\u53ef\u9009\u503c\u5305\u62ec \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"\u3002 <code>\"INFO\"</code> <code>log_to_console</code> \u662f\u5426\u5c06\u65e5\u5fd7\u5b9e\u65f6\u8f93\u51fa\u5230\u63a7\u5236\u53f0\u3002 <code>true</code> <code>log_count</code> \u5728\u65e5\u5fd7\u76ee\u5f55\u4e0b\u4fdd\u7559\u7684\u65e7\u65e5\u5fd7\u6587\u4ef6\u7684\u6700\u5927\u6570\u91cf\u3002 <code>5</code>"},{"location":"guides/tricys_basic/basic_configuration.html#4","title":"4. \u914d\u7f6e\u6a21\u677f","text":"<p>\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u7528\u573a\u666f\u7684\u914d\u7f6e\u6a21\u677f\uff0c\u53ef\u4ee5\u76f4\u63a5\u590d\u5236\u4f7f\u7528\uff1a</p>"},{"location":"guides/tricys_basic/basic_configuration.html#41","title":"4.1 \u5feb\u901f\u6d4b\u8bd5\u6a21\u677f","text":"<p>\u6b64\u6a21\u677f\u9002\u7528\u4e8e\u5feb\u901f\u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u80fd\u6b63\u5e38\u8fd0\u884c\uff0c\u5b83\u4f1a\u4fdd\u5b58\u6240\u6709\u53d8\u91cf\uff0c\u5e76\u4ee5\u8f83\u77ed\u7684\u65f6\u957f\u8fd0\u884c\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"path/to/your/package.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"YourModel.Name\",\n        \"variableFilter\": \"time|.*\",\n        \"stop_time\": 100.0,\n        \"step_size\": 1.0\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#42","title":"4.2 \u751f\u4ea7\u73af\u5883\u6a21\u677f","text":"<p>\u6b64\u6a21\u677f\u9002\u7528\u4e8e\u6b63\u5f0f\u7684\u3001\u957f\u65f6\u95f4\u7684\u4eff\u771f\u3002\u5b83\u53ea\u4fdd\u5b58\u5173\u952e\u53d8\u91cf\uff0c\u5c06\u7ed3\u679c\u8f93\u51fa\u5230\u6307\u5b9a\u7684\u751f\u4ea7\u76ee\u5f55\uff0c\u5e76\u914d\u7f6e\u4e86\u66f4\u4e25\u683c\u7684\u65e5\u5fd7\u8bb0\u5f55\u548c\u8c03\u8bd5\u9009\u9879\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"path/to/your/package.mo\",\n        \"results_dir\": \"production_results\"\n    },\n    \"simulation\": {\n        \"model_name\": \"YourModel.Name\",\n        \"variableFilter\": \"time|key_var1|key_var2\",\n        \"stop_time\": 86400.0,\n        \"step_size\": 10.0,\n        \"keep_temp_files\": false\n    },\n    \"logging\": {\n        \"log_level\": \"INFO\",\n        \"log_to_console\": false,\n        \"log_count\": 10\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#5","title":"5. \u5982\u4f55\u8fd0\u884c","text":"<p>\u914d\u7f6e\u597d\u6587\u4ef6\u540e\uff0c\u6709\u4e24\u79cd\u65b9\u5f0f\u8fd0\u884c\u4eff\u771f\uff1a</p>"},{"location":"guides/tricys_basic/basic_configuration.html#51","title":"5.1. \u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\u6587\u4ef6","text":"<p>\u5c06\u914d\u7f6e\u6587\u4ef6\u4fdd\u5b58\u4e3a <code>config.json</code> \u5e76\u653e\u5728\u9879\u76ee\u6839\u76ee\u5f55\uff1a</p> <pre><code>tricys\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#52","title":"5.2. \u6307\u5b9a\u914d\u7f6e\u6587\u4ef6","text":"<pre><code>tricys -c my_config.json\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#6","title":"6. \u67e5\u770b\u7ed3\u679c","text":"<p>\u4eff\u771f\u5b8c\u6210\u540e\uff0c\u7ed3\u679c\u4fdd\u5b58\u5728\u65f6\u95f4\u6233\u5b50\u76ee\u5f55{timestamp}\u4e2d\uff1a</p> <pre><code>Working Directory/\n\u2514\u2500\u2500 {timestamp}/\n    \u251c\u2500\u2500 log/        \n        \u2514\u2500\u2500 simulation_{timestamp}.log  # \u8fd0\u884c\u65e5\u5fd7\n    \u251c\u2500\u2500 result/                 \n        \u2514\u2500\u2500 simulation_result.csv       # \u4eff\u771f\u7ed3\u679c\u6570\u636e\n    \u2514\u2500\u2500 temp/\n        \u2514\u2500\u2500 job_1/                      # \u4e34\u65f6\u4efb\u52a1\u6570\u636e\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#61-python","title":"6.1. \u4f7f\u7528 Python \u5206\u6790\u7ed3\u679c","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# \u8bfb\u53d6\u7ed3\u679c\ndf = pd.read_csv('results/20250116_103000/simulation_result.csv')\n\n# \u67e5\u770b\u6570\u636e\nprint(df.head())\nprint(f\"\u4eff\u771f\u65f6\u957f: {df['time'].max()} \u79d2\")\nprint(f\"\u6700\u7ec8\u6c1a\u5e93\u5b58: {df['sds.I[1]'].iloc[-1]:.2f} g\")\n\n# \u7ed8\u5236\u6c1a\u5e93\u5b58\u53d8\u5316\u66f2\u7ebf\nplt.figure(figsize=(10, 6))\nplt.plot(df['time'], df['sds.I[1]'], label='SDS \u6c1a\u5e93\u5b58')\nplt.xlabel('\u65f6\u95f4 (\u79d2)')\nplt.ylabel('\u6c1a\u5e93\u5b58 (g)')\nplt.title('\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf\u6c1a\u5e93\u5b58\u968f\u65f6\u95f4\u53d8\u5316')\nplt.legend()\nplt.grid(True)\nplt.savefig('inventory_plot.png', dpi=300)\nplt.show()\n</code></pre>"},{"location":"guides/tricys_basic/basic_configuration.html#62-excel","title":"6.2. \u4f7f\u7528 Excel \u67e5\u770b","text":"<p>\u76f4\u63a5\u7528 Microsoft Excel \u6216 LibreOffice Calc \u6253\u5f00 <code>simulation_result.csv</code> \u6587\u4ef6\u3002</p>"},{"location":"guides/tricys_basic/basic_configuration.html#7","title":"7. \u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u4e86\u57fa\u7840\u914d\u7f6e\u540e\uff0c\u60a8\u53ef\u4ee5\u7ee7\u7eed\u5b66\u4e60\uff1a</p> <ul> <li>\u53c2\u6570\u626b\u63cf\uff1a\u7cfb\u7edf\u5730\u7814\u7a76\u53c2\u6570\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd</li> <li>\u5e76\u53d1\u8fd0\u884c\uff1a\u52a0\u901f\u5927\u89c4\u6a21\u4eff\u771f</li> <li>\u540e\u5904\u7406\u6a21\u5757\uff1a\u81ea\u52a8\u5206\u6790\u548c\u62a5\u544a\u751f\u6210</li> <li>\u534f\u540c\u4eff\u771f\uff1a\u4e0e\u5916\u90e8\u8f6f\u4ef6\u96c6\u6210</li> </ul>"},{"location":"guides/tricys_basic/co_simulation_module.html","title":"\u534f\u540c\u4eff\u771f\u6a21\u5757","text":"<p>\u534f\u540c\u4eff\u771f\uff08Co-Simulation\uff09\u662f <code>tricys</code> \u4e2d\u4e00\u9879\u9ad8\u7ea7\u4e14\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u5b83\u5141\u8bb8 Modelica \u6a21\u578b\u4e0e\u5916\u90e8\u7a0b\u5e8f\uff08\u5982 Aspen Plus, MATLAB, \u6216\u81ea\u5b9a\u4e49\u7684 Python \u811a\u672c\uff09\u8fdb\u884c\u4ea4\u4e92\uff0c\u5b9e\u73b00\u7ef4\u7cfb\u7edf\u6a21\u578b\u4e0e3\u7ef4\u5b50\u6a21\u5757\u591a\u7269\u7406\u573a\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u96c6\u6210\u3002</p> <p>\u8fd9\u5bf9\u4e8e\u4ee5\u4e0b\u573a\u666f\u5c24\u5176\u6709\u7528\uff1a</p> <ul> <li>\u67d0\u4e2a\u5b50\u7cfb\u7edf\u7684\u6a21\u578b\u5728\u53e6\u4e00\u4e2a\u4e13\u4e1a\u8f6f\u4ef6\u4e2d\u5df2\u7ecf\u5b58\u5728\u4e14\u975e\u5e38\u6210\u719f\u3002</li> <li>\u5b50\u7cfb\u7edf\u7684\u884c\u4e3a\u975e\u5e38\u590d\u6742\uff0c\u96be\u4ee5\u7528 Modelica \u8bed\u8a00\u76f4\u63a5\u63cf\u8ff0\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u5916\u90e8\u8ba1\u7b97\u5f97\u5230\u3002</li> </ul>"},{"location":"guides/tricys_basic/co_simulation_module.html#1","title":"1. \u5de5\u4f5c\u6d41\u7a0b","text":"<p>\u534f\u540c\u4eff\u771f\u7684\u6838\u5fc3\u601d\u60f3\u662f\u201c\u8fd0\u884c-\u5904\u7406-\u518d\u8fd0\u884c\u201d (Run-Process-Rerun)\u3002</p> <pre><code>graph LR\n    A[1.\u521d\u6b65\u4eff\u771f] --&gt; B[(\u7ed3\u679c)];\n    B --&gt; C[2.\u5916\u90e8\u5904\u7406\u5668 Handler ];\n    C --&gt; D[(\u65b0\u6570\u636e)];\n    D --&gt; E[3.\u6ce8\u5165\u65b0\u6570\u636e];\n    E --&gt; F[4.\u6700\u7ec8\u5b8c\u6574\u4eff\u771f];\n\n    style A fill:#A6C8FF\n    style C fill:#FFDDA6\n    style F fill:#A6FFC8</code></pre> <ol> <li>\u521d\u6b65\u4eff\u771f (Primary Run): <code>tricys</code> \u9996\u5148\u8fd0\u884c\u4e00\u4e2a\u4e0d\u5305\u542b\u88ab\u66ff\u4ee3\u5b50\u7cfb\u7edf\u7684\u521d\u6b65\u4eff\u771f\u3002</li> <li>\u8c03\u7528\u5904\u7406\u5668 (Call Handlers): \u521d\u6b65\u4eff\u771f\u7684\u7ed3\u679c\u88ab\u4f20\u9012\u7ed9\u4e00\u4e2a\u6216\u591a\u4e2a\u7528\u6237\u5b9a\u4e49\u7684\u201c\u5904\u7406\u5668\u201d(Handler)\u3002</li> <li>\u5916\u90e8\u8ba1\u7b97: \u5904\u7406\u5668\u51fd\u6570\u63a5\u6536\u7ed3\u679c\uff0c\u5e76\u8c03\u7528\u5916\u90e8\u7a0b\u5e8f\uff08\u5982 Aspen\uff09\u6216\u6267\u884c\u5185\u90e8\u7b97\u6cd5\uff0c\u8ba1\u7b97\u51fa\u65b0\u7684\u6570\u636e\u3002</li> <li>\u6570\u636e\u6ce8\u5165 (Injection): \u5904\u7406\u5668\u8fd4\u56de\u4e00\u4e2a\u6570\u636e\u5b57\u5178\u3002<code>tricys</code> \u4f1a\u52a8\u6001\u5730\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u9876\u5c42\u6a21\u578b\uff0c\u7528 <code>CombiTimeTable</code> (\u6570\u636e\u8868) \u6a21\u5757\u66ff\u6362\u6389\u539f\u6765\u7684\u5b50\u7cfb\u7edf\uff0c\u5e76\u5c06\u5904\u7406\u5668\u8fd4\u56de\u7684\u6570\u636e\u4f5c\u4e3a\u8fd9\u4e2a\u6570\u636e\u8868\u7684\u5185\u5bb9\u3002</li> <li>\u6700\u7ec8\u4eff\u771f (Final Run): <code>tricys</code> \u8fd0\u884c\u8fd9\u4e2a\u88ab\u52a8\u6001\u4fee\u6539\u8fc7\u7684\u3001\u5305\u542b\u6ce8\u5165\u6570\u636e\u7684\u65b0\u6a21\u578b\uff0c\u4ece\u800c\u5b8c\u6210\u4e00\u6b21\u5b8c\u6574\u7684\u534f\u540c\u4eff\u771f\u3002</li> </ol>"},{"location":"guides/tricys_basic/co_simulation_module.html#2","title":"2. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u901a\u8fc7\u5728 <code>config.json</code> \u4e2d\u5b9a\u4e49 <code>co_simulation</code> \u5b57\u6bb5\u6765\u542f\u7528\u6b64\u529f\u80fd\u3002</p> <pre><code>{\n    \"paths\": { ... },\n    \"simulation\": { ... },\n    \"simulation_parameters\": { ... },\n    \"co_simulation\": {\n        \"mode\": \"replacement\",\n        \"handlers\":[\n            {\n                \"submodel_name\": \"example_model.I_ISS\",\n                \"instance_name\": \"i_iss\",\n                \"handler_module\": \"tricys.handlers.i_iss_handler\",\n                \"handler_function\": \"run_dummy_simulation\",\n                \"params\": {\n                    \"description\": \"This is a dummy handler for i_iss.\",\n                    \"dummy_value\": 123.45\n                }\n            },\n            {\n                \"submodel_name\": \"example_model.DIV\",\n                \"instance_name\": \"div\",\n                \"handler_module\": \"tricys.handlers.div_handler\",\n                \"handler_function\": \"run_div_simulation\",\n                \"params\": {\n                    \"description\": \"This is a dummy handler for i_iss.\",\n                    \"dummy_value\": 123.45\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/co_simulation_module.html#3","title":"3. \u914d\u7f6e\u9879\u8be6\u89e3","text":""},{"location":"guides/tricys_basic/co_simulation_module.html#31-co_simulation","title":"3.1. <code>co_simulation</code> (\u9876\u5c42\u5bf9\u8c61)","text":"\u53c2\u6570 (Parameter) \u7c7b\u578b\u4e0e\u8981\u6c42 \u63cf\u8ff0 <code>mode</code> \u5b57\u7b26\u4e32, \u9009\u586b \u5b9a\u4e49\u534f\u540c\u4eff\u771f\u7684\u96c6\u6210\u6a21\u5f0f\u3002\u9ed8\u8ba4\u4e3a <code>\"interceptor\"</code>\u3002 <code>handlers</code> \u5217\u8868, \u5fc5\u586b \u4e00\u4e2a\u6216\u591a\u4e2a\u201c\u5904\u7406\u5668\u914d\u7f6e\u5bf9\u8c61\u201d\u7684\u5217\u8868\uff0c\u6bcf\u4e2a\u5bf9\u8c61\u5b9a\u4e49\u5982\u4f55\u5904\u7406\u4e00\u4e2a\u7279\u5b9a\u7684\u5b50\u6a21\u578b\u3002"},{"location":"guides/tricys_basic/co_simulation_module.html#32-mode","title":"3.2. <code>mode</code> (\u96c6\u6210\u6a21\u5f0f)","text":"<p><code>mode</code> \u5b57\u6bb5\u51b3\u5b9a\u4e86 <code>tricys</code> \u5982\u4f55\u5c06\u5916\u90e8\u8ba1\u7b97\u7ed3\u679c\u96c6\u6210\u56de Modelica \u6a21\u578b\u4e2d\u3002</p> <ul> <li> <p><code>\"interceptor\"</code> (\u9ed8\u8ba4\u6a21\u5f0f):</p> <ul> <li>\u975e\u4fb5\u5165\u5f0f\u3002\u5b83\u4f1a\u4e3a\u76ee\u6807\u5b50\u6a21\u578b\u751f\u6210\u4e00\u4e2a\u201c\u62e6\u622a\u5668\u201d\u5305\u88f9\u6a21\u578b\uff0c\u5e76\u5728\u4e00\u4e2a\u65b0\u7684\u9876\u5c42\u7cfb\u7edf\u6a21\u578b\u4e2d\u91cd\u5b9a\u5411\u8fde\u63a5\u3002</li> <li>\u4f18\u70b9: \u539f\u59cb\u6a21\u578b\u6587\u4ef6\uff08\u5305\u62ec\u5b50\u6a21\u578b\u548c\u9876\u5c42\u6a21\u578b\uff09\u90fd\u4fdd\u6301\u4e0d\u53d8\uff0c\u5b89\u5168\u6027\u9ad8\u3002</li> <li>\u9002\u7528\u573a\u666f: \u63a8\u8350\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f7f\u7528\uff0c\u5c24\u5176\u662f\u5f53\u60a8\u4e0d\u5e0c\u671b\u4fee\u6539\u539f\u59cb\u6a21\u578b\u5e93\u65f6\u3002</li> </ul> </li> <li> <p><code>\"replacement\"</code>:</p> <ul> <li>\u4fb5\u5165\u5f0f\u3002\u5b83\u4f1a\u76f4\u63a5\u4fee\u6539\u76ee\u6807\u5b50\u6a21\u578b\u7684 <code>.mo</code> \u6587\u4ef6\uff08\u4f1a\u521b\u5efa <code>.bak</code> \u5907\u4efd\uff09\uff0c\u5c06\u5176\u5185\u90e8\u903b\u8f91\u5b8c\u5168\u66ff\u6362\u4e3a\u4eceCSV\u6587\u4ef6\u8bfb\u53d6\u6570\u636e\u7684\u903b\u8f91\u3002</li> <li>\u4f18\u70b9: \u5b9e\u73b0\u66f4\u76f4\u63a5\uff0c\u4e0d\u9700\u8981\u751f\u6210\u65b0\u7684\u9876\u5c42\u6a21\u578b\u3002</li> <li>\u9002\u7528\u573a\u666f: \u5f53\u60a8\u5e0c\u671b\u5bf9\u5b50\u6a21\u578b\u8fdb\u884c\u6c38\u4e45\u6027\u6216\u534a\u6c38\u4e45\u6027\u7684\u884c\u4e3a\u66ff\u6362\uff0c\u6216\u8005\u5728\u67d0\u4e9b\u590d\u6742\u7684\u6a21\u578b\u7ed3\u6784\u4e2d\uff0c\u201c\u62e6\u622a\u5668\u201d\u6a21\u5f0f\u96be\u4ee5\u5b9e\u73b0\u8fde\u63a5\u91cd\u8def\u7531\u65f6\u3002</li> </ul> </li> </ul>"},{"location":"guides/tricys_basic/co_simulation_module.html#33-handlers","title":"3.3. <code>handlers</code> (\u914d\u7f6e\u5bf9\u8c61\u5217\u8868)","text":"<p><code>handlers</code> \u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u66ff\u6362\u4efb\u52a1\u3002</p> \u53c2\u6570 (Parameter) \u7c7b\u578b\u4e0e\u8981\u6c42 \u63cf\u8ff0 <code>submodel_name</code> \u5b57\u7b26\u4e32, \u5fc5\u586b \u8981\u88ab\u5916\u90e8\u5904\u7406\u5668\u66ff\u4ee3\u7684\u5b50\u6a21\u578b\u7684\u5b8c\u6574 Modelica \u7c7b\u8def\u5f84\u3002\u4f8b\u5982 <code>example_model.DIV</code>\u3002 <code>instance_name</code> \u5b57\u7b26\u4e32, \u5fc5\u586b \u8be5\u5b50\u6a21\u578b\u5728\u9876\u5c42\u4eff\u771f\u6a21\u578b (<code>simulation.model_name</code>) \u4e2d\u7684\u5b9e\u4f8b\u540d\u3002\u4f8b\u5982\uff0c\u5982\u679c\u9876\u5c42\u6a21\u578b\u4e2d\u6709 <code>DIV div;</code>\uff0c\u90a3\u4e48\u8fd9\u91cc\u7684 <code>instance_name</code> \u5c31\u662f <code>div</code>\u3002 <code>handler_script_path</code> \u5b57\u7b26\u4e32, \u63a8\u8350 \u6307\u5411\u5305\u542b\u5904\u7406\u5668\u903b\u8f91\u7684 Python \u811a\u672c\u6587\u4ef6\u7684\u76f8\u5bf9\u6216\u7edd\u5bf9\u8def\u5f84\u3002\u8fd9\u662f\u6307\u5b9a\u5904\u7406\u5668\u7684\u9996\u9009\u65b9\u6cd5\u3002 <code>handler_module</code> \u5b57\u7b26\u4e32, \u517c\u5bb9 \u5305\u542b\u5904\u7406\u5668\u903b\u8f91\u7684 Python \u6a21\u5757\u7684\u8def\u5f84\uff08\u4f8b\u5982 <code>tricys.handlers.div_handler</code>\uff09\u3002\u7528\u4e8e\u5411\u540e\u517c\u5bb9\u3002\u5982\u679c\u540c\u65f6\u63d0\u4f9b\u4e86 <code>handler_script_path</code>\uff0c\u5219\u4f18\u5148\u4f7f\u7528\u811a\u672c\u8def\u5f84\u3002 <code>handler_function</code> \u5b57\u7b26\u4e32, \u5fc5\u586b \u5728\u5904\u7406\u5668\u811a\u672c\u6216\u6a21\u5757\u4e2d\u8981\u8c03\u7528\u7684\u51fd\u6570\u540d\u3002 <code>params</code> \u5b57\u5178, \u9009\u586b \u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u4e2d\u5305\u542b\u7684\u952e\u503c\u5bf9\u5c06\u4f5c\u4e3a\u5173\u952e\u5b57\u53c2\u6570\u4f20\u9012\u7ed9\u5904\u7406\u5668\u51fd\u6570\u3002"},{"location":"guides/tricys_basic/co_simulation_module.html#4","title":"4. \u7ed3\u679c\u8f93\u51fa","text":"<p>\u534f\u540c\u4eff\u771f\u7684\u6700\u7ec8\u8f93\u51fa\u4e0e\u6807\u51c6\u4eff\u771f\u7c7b\u4f3c\uff0c\u4f1a\u6839\u636e\u4efb\u52a1\u6570\u91cf\u5728\u7ed3\u679c\u76ee\u5f55 (<code>results_dir</code>) \u4e2d\u751f\u6210\u4e00\u4e2a\u5408\u5e76\u7684 CSV \u6587\u4ef6\uff1a</p> <ul> <li>\u5355\u6b21\u8fd0\u884c: <code>simulation_result.csv</code></li> <li>\u53c2\u6570\u626b\u63cf: <code>sweep_results.csv</code></li> </ul> <p>\u5728\u8fd9\u4e2a\u6587\u4ef6\u4e2d\uff0c\u88ab\u5916\u90e8\u5904\u7406\u5668\u66ff\u4ee3\u7684\u5b50\u6a21\u5757\u7684\u76f8\u5173\u53d8\u91cf\u5217\uff0c\u5176\u6570\u636e\u5c06\u6765\u6e90\u4e8e\u60a8\u7684\u5904\u7406\u5668\u51fd\u6570\u7684\u8ba1\u7b97\u7ed3\u679c\uff0c\u800c\u4e0d\u662f\u539f\u59cb Modelica \u6a21\u578b\u7684\u8ba1\u7b97\u7ed3\u679c\u3002</p>"},{"location":"guides/tricys_basic/co_simulation_module.html#5","title":"5. \u81ea\u5b9a\u4e49\u5904\u7406\u5668","text":"<p>\u8981\u771f\u6b63\u53d1\u6325\u534f\u540c\u4eff\u771f\u7684\u5a01\u529b\uff0c\u60a8\u9700\u8981\u521b\u5efa\u81ea\u5df1\u7684\u5904\u7406\u5668\u51fd\u6570\u3002</p>"},{"location":"guides/tricys_basic/co_simulation_module.html#51","title":"5.1. \u5904\u7406\u5668\u51fd\u6570\u89c4\u8303","text":"<p>\u60a8\u7684\u5904\u7406\u5668\u5fc5\u987b\u9075\u5faa\u4ee5\u4e0b\u89c4\u8303\uff1a</p> <ol> <li> <p>\u51fd\u6570\u7b7e\u540d:     <pre><code>def my_handler(temp_input_csv: str, temp_output_csv: str, **params) -&gt; dict:\n    # ... \u51fd\u6570\u4f53 ...\n</code></pre></p> <ul> <li><code>temp_input_csv</code>: <code>tricys</code> \u4f20\u5165\u7684 \u8f93\u5165\u6587\u4ef6\u8def\u5f84\u3002\u8be5 CSV \u6587\u4ef6\u5305\u542b\u4e86\u7b2c\u4e00\u9636\u6bb5\u4eff\u771f\u8bb0\u5f55\u7684\u3001\u5b50\u6a21\u5757\u6240\u9700\u7684\u6240\u6709\u8f93\u5165\u7aef\u53e3\u6570\u636e\u3002</li> <li><code>temp_output_csv</code>: \u60a8\u9700\u8981\u5c06\u8ba1\u7b97\u7ed3\u679c\u5199\u5165\u7684 \u8f93\u51fa\u6587\u4ef6\u8def\u5f84\u3002</li> <li><code>**params</code>: \u4e00\u4e2a\u5b57\u5178\uff0c\u5305\u542b\u4e86\u60a8\u5728 <code>config.json</code> \u4e2d\u4e3a\u8be5\u5904\u7406\u5668\u914d\u7f6e\u7684\u6240\u6709 <code>params</code>\u3002</li> </ul> </li> <li> <p>\u6838\u5fc3\u903b\u8f91:</p> <ul> <li>\u4f7f\u7528 <code>pandas</code> \u6216\u5176\u4ed6\u5e93\u8bfb\u53d6 <code>temp_input_csv</code> \u7684\u6570\u636e\u3002</li> <li>\u6267\u884c\u60a8\u7684\u6838\u5fc3\u8ba1\u7b97\u903b\u8f91\u3002</li> <li>\u5c06\u7ed3\u679c\uff08\u5fc5\u987b\u5305\u542b 'time' \u5217\uff09\u4fdd\u5b58\u5230 <code>temp_output_csv</code> \u8def\u5f84\u3002</li> </ul> </li> <li> <p>\u8fd4\u56de\u503c (\u91cd\u8981):</p> <ul> <li>\u51fd\u6570 \u5fc5\u987b \u8fd4\u56de\u4e00\u4e2a\u5b57\u5178\uff0c\u8be5\u5b57\u5178\u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u60a8\u8f93\u51fa\u7684 CSV \u6587\u4ef6\u4e2d\u7684\u6570\u636e\u5217\u6620\u5c04\u5230 Modelica \u5b50\u6a21\u5757\u7684\u8f93\u51fa\u7aef\u53e3\u3002</li> <li>\u952e (key): Modelica \u5b50\u6a21\u5757\u7684\u8f93\u51fa\u7aef\u53e3\u540d (\u5b57\u7b26\u4e32)\u3002</li> <li>\u503c (value): \u4e00\u4e2a\u8868\u793a Modelica \u6570\u7ec4\u7684\u5b57\u7b26\u4e32\uff0c\u683c\u5f0f\u4e3a <code>\"{t, y1, y2, ...}\"</code>\u3002\u5176\u4e2d <code>t</code> \u662f <code>time</code> \u5217\u7684\u7d22\u5f15\uff08\u901a\u5e38\u662f1\uff09\uff0c<code>y1</code>, <code>y2</code>... \u662f\u5bf9\u5e94\u7aef\u53e3\u5404\u7ef4\u5ea6\u6570\u636e\u5217\u7684\u7d22\u5f15\u3002</li> </ul> </li> </ol>"},{"location":"guides/tricys_basic/co_simulation_module.html#52","title":"5.2. \u5904\u7406\u5668\u793a\u4f8b","text":"<p>\u5047\u8bbe\u6211\u4eec\u8981\u66ff\u6362\u7684 Modelica \u5b50\u6a21\u5757 <code>MySubModel</code> \u6709\u4e00\u4e2a5\u7ef4\u8f93\u51fa\u7aef\u53e3 <code>to_O_ISS</code>\u3002</p> <p><code>my_div_handler.py</code>: <pre><code>import pandas as pd\n\ndef run_div_simulation(temp_input_csv: str, temp_output_csv: str, **params) -&gt; dict:\n    \"\"\"\n    \u4e00\u4e2a\u7b80\u5355\u7684\u5904\u7406\u5668\u793a\u4f8b\u3002\n    \u5b83\u8bfb\u53d6\u8f93\u5165\uff0c\u5c06\u6240\u6709\u8f93\u5165\u503c\u4e58\u4ee5\u4e00\u4e2a\u6765\u81ea\u914d\u7f6e\u7684\u56e0\u5b50\uff0c\u7136\u540e\u5199\u56de\u3002\n    \"\"\"\n    # \u6253\u5370\u4ece config.json \u4f20\u5165\u7684\u53c2\u6570\n    factor = params.get(\"factor\", 1.0)\n    print(f\"Running DIV handler with factor: {factor}\")\n\n    # 1. \u8bfb\u53d6\u8f93\u5165\u6570\u636e\n    input_df = pd.read_csv(temp_input_csv)\n\n    # 2. \u6267\u884c\u8ba1\u7b97 (\u793a\u4f8b\uff1a\u5c06\u6240\u6709\u8f93\u5165\u4e58\u4ee5\u56e0\u5b50)\n    # \u5047\u8bbe\u8f93\u5165\u7aef\u53e3\u540d\u4e3a 'div.from_plasma[1]' \u5230 '[5]'\n    output_df = pd.DataFrame()\n    output_df['time'] = input_df['time']\n    for i in range(1, 6):\n        input_col_name = f'div.from_plasma[{i}]'\n        output_col_name = f'to_O_ISS_{i}' # \u5728CSV\u4e2d\u81ea\u5b9a\u4e49\u5217\u540d\n        if input_col_name in input_df.columns:\n            output_df[output_col_name] = input_df[input_col_name] * factor\n        else:\n            output_df[output_col_name] = 0 # \u5982\u679c\u8f93\u5165\u4e0d\u5b58\u5728\uff0c\u5219\u8f93\u51fa0\n\n    # 3. \u5c06\u7ed3\u679c\u5199\u5165\u6307\u5b9a\u7684\u8f93\u51faCSV\u6587\u4ef6\n    output_df.to_csv(temp_output_csv, index=False)\n\n    # 4. \u8fd4\u56de\u7aef\u53e3\u5230CSV\u5217\u7684\u6620\u5c04\n    # CSV\u67096\u5217: time, to_O_ISS_1, ..., to_O_ISS_5\n    # Modelica\u7aef\u53e3 to_O_ISS \u662f5\u7ef4\u7684\n    # \u6620\u5c04\u5173\u7cfb:\n    # time -&gt; column 1\n    # to_O_ISS[1] -&gt; column 2 (to_O_ISS_1)\n    # to_O_ISS[2] -&gt; column 3 (to_O_ISS_2)\n    # ...\n    # to_O_ISS[5] -&gt; column 6 (to_O_ISS_5)\n    return {\n        \"to_O_ISS\": \"{1,2,3,4,5,6}\"\n    }\n</code></pre></p>"},{"location":"guides/tricys_basic/co_simulation_module.html#53","title":"5.3. \u66f4\u65b0\u914d\u7f6e\u6587\u4ef6","text":"<p>\u73b0\u5728\uff0c\u60a8\u53ef\u4ee5\u66f4\u65b0 <code>config.json</code> \u6765\u4f7f\u7528\u8fd9\u4e2a\u65b0\u7684\u672c\u5730\u5904\u7406\u5668\u811a\u672c\u3002\u6211\u4eec\u63a8\u8350\u4f7f\u7528 <code>handler_script_path</code>\uff0c\u56e0\u4e3a\u5b83\u6bd4 <code>handler_module</code> \u66f4\u76f4\u63a5\u3002</p> <p>\u540c\u65f6\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u660e\u786e\u6307\u5b9a\u534f\u540c\u4eff\u771f\u7684 <code>mode</code>\u3002</p> <pre><code>{\n    ...\n    \"co_simulation\": {\n        \"mode\": \"interceptor\", // \"interceptor\" (\u9ed8\u8ba4) \u6216 \"replacement\"\n        \"handlers\": [\n            {\n                \"submodel_name\": \"example_model.DIV\",\n                \"instance_name\": \"div\",\n                \"handler_script_path\": \"path/to/my_div_handler.py\", // \u4f7f\u7528\u811a\u672c\u8def\u5f84\n                \"handler_function\": \"run_div_simulation\",\n                \"params\": {\n                    \"factor\": 1.5 // \u4f20\u9012\u7ed9\u51fd\u6570\u7684\u81ea\u5b9a\u4e49\u53c2\u6570\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/co_simulation_module.html#6","title":"6. \u9ad8\u7ea7\uff1a\u539f\u7406\u89e3\u8bf4","text":"<ul> <li>\u534f\u540c\u4eff\u771f\uff1a\u534f\u540c\u4eff\u771f\u4e2d\u4e24\u79cd\u5c06\u5916\u90e8\u6570\u636e\u6ce8\u5165 Modelica \u6a21\u578b\u7684\u65b9\u6cd5\u3002</li> </ul>"},{"location":"guides/tricys_basic/concurrent_operation.html","title":"\u5e76\u53d1\u8fd0\u884c","text":"<p>\u5bf9\u4e8e\u5305\u542b\u5927\u91cf\u4eff\u771f\u4efb\u52a1\u7684\u53c2\u6570\u626b\u63cf\uff0c\u9010\u4e2a\u987a\u5e8f\u6267\u884c\u53ef\u80fd\u4f1a\u975e\u5e38\u8017\u65f6\u3002<code>tricys</code> \u652f\u6301\u5e76\u53d1\u8fd0\u884c\uff08\u5e76\u884c\u8ba1\u7b97\uff09\uff0c\u53ef\u4ee5\u5145\u5206\u5229\u7528\u60a8\u8ba1\u7b97\u673a\u7684\u591a\u4e2a CPU \u6838\u5fc3\uff0c\u663e\u8457\u7f29\u77ed\u603b\u4eff\u771f\u65f6\u95f4\u3002</p>"},{"location":"guides/tricys_basic/concurrent_operation.html#1","title":"1. \u5982\u4f55\u542f\u7528\u5e76\u53d1","text":"<p>\u542f\u7528\u5e76\u53d1\u975e\u5e38\u7b80\u5355\uff0c\u53ea\u9700\u5728\u914d\u7f6e\u6587\u4ef6\u7684 <code>simulation</code> \u90e8\u5206\u5c06 <code>concurrent</code> \u6807\u5fd7\u8bbe\u7f6e\u4e3a <code>true</code>\u3002</p> <pre><code>{\n    \"paths\": {\n        ...\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        ...\n        \"concurrent\": true,\n        \"max_workers\": 4\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/concurrent_operation.html#2","title":"2. \u914d\u7f6e\u9879\u8be6\u89e3","text":""},{"location":"guides/tricys_basic/concurrent_operation.html#21-simulationconcurrent","title":"2.1. <code>simulation.concurrent</code>","text":"<ul> <li>\u63cf\u8ff0: \u662f\u5426\u542f\u7528\u5e76\u53d1\u8fd0\u884c\u3002</li> <li>\u7c7b\u578b: \u5e03\u5c14\u503c (<code>true</code> \u6216 <code>false</code>)\u3002</li> <li>\u9ed8\u8ba4\u503c: <code>false</code>\u3002</li> <li>\u5de5\u4f5c\u539f\u7406: \u5f53\u8bbe\u7f6e\u4e3a <code>true</code> \u65f6\uff0c<code>tricys</code> \u4f1a\u542f\u52a8\u4e00\u4e2a\u8fdb\u7a0b\u6c60\uff0c\u5c06\u4eff\u771f\u4efb\u52a1\uff08\u4f8b\u5982\u53c2\u6570\u626b\u63cf\u4e2d\u7684\u6bcf\u4e00\u6b21\u8fd0\u884c\uff09\u5206\u914d\u7ed9\u4e0d\u540c\u7684\u8fdb\u7a0b\u5e76\u884c\u6267\u884c\u3002</li> </ul>"},{"location":"guides/tricys_basic/concurrent_operation.html#22-simulationmax_workers","title":"2.2. <code>simulation.max_workers</code>","text":"<ul> <li>\u63cf\u8ff0: \u63a7\u5236\u7528\u4e8e\u5e76\u53d1\u6267\u884c\u7684\u6700\u5927\u8fdb\u7a0b\u6570\uff08\u6216\u79f0\u201c\u5de5\u4f5c\u8fdb\u7a0b\u201d\u6570\u91cf\uff09\u3002</li> <li>\u7c7b\u578b: \u6574\u6570 (\u9009\u586b)\u3002</li> <li>\u9ed8\u8ba4\u503c: \u5982\u679c\u4e0d\u6307\u5b9a\u8be5\u53c2\u6570\uff0c<code>tricys</code> \u5c06\u9ed8\u8ba4\u4f7f\u7528\u60a8\u8ba1\u7b97\u673a\u4e0a\u7684 \u6240\u6709\u53ef\u7528 CPU \u6838\u5fc3\u6570\u3002</li> <li>\u5efa\u8bae:<ul> <li>\u5bf9\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\uff0c\u5efa\u8bae\u5c06\u6b64\u503c\u8bbe\u7f6e\u4e3a\u4e0d\u8d85\u8fc7\u60a8\u8ba1\u7b97\u673a\u7684\u7269\u7406\u6838\u5fc3\u6570\uff0c\u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u3002</li> <li>\u5982\u679c\u5728\u4eff\u771f\u8fc7\u7a0b\u4e2d\u9047\u5230\u5185\u5b58\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u9002\u5f53\u8c03\u4f4e <code>max_workers</code> \u7684\u503c\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u8fdb\u7a0b\u90fd\u4f1a\u72ec\u7acb\u52a0\u8f7d\u6a21\u578b\u5e76\u6d88\u8017\u4e00\u5b9a\u7684\u5185\u5b58\u3002</li> </ul> </li> </ul> <p>\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c<code>\"concurrent\": true</code> \u548c <code>\"max_workers\": 4</code> \u610f\u5473\u7740 <code>tricys</code> \u4f1a\u521b\u5efa\u4e00\u4e2a\u5305\u542b 4 \u4e2a\u5de5\u4f5c\u8fdb\u7a0b\u7684\u8fdb\u7a0b\u6c60\uff0c\u6765\u5e76\u884c\u5904\u7406\u7531\u53c2\u6570\u626b\u63cf\u751f\u6210\u7684 10 \u4e2a\u4eff\u771f\u4efb\u52a1\u3002</p> <p>\u9002\u7528\u573a\u666f</p> <p>\u5e76\u53d1\u8fd0\u884c\u4e0d\u4ec5\u9002\u7528\u4e8e\u6807\u51c6\u7684\u53c2\u6570\u626b\u63cf\uff0c\u4e5f\u540c\u6837\u9002\u7528\u4e8e\u534f\u540c\u4eff\u771f\u548c\u81ea\u52a8\u5206\u6790\u6d41\u7a0b\uff0c\u80fd\u591f\u5168\u9762\u63d0\u5347 <code>tricys</code> \u7684\u6267\u884c\u6548\u7387\u3002</p>"},{"location":"guides/tricys_basic/parameter_sweep.html","title":"\u53c2\u6570\u626b\u63cf","text":"<p>\u53c2\u6570\u626b\u63cf\u662f <code>tricys</code> \u7684\u6838\u5fc3\u529f\u80fd\u4e4b\u4e00\uff0c\u5b83\u5141\u8bb8\u60a8\u7cfb\u7edf\u5730\u7814\u7a76\u4e00\u4e2a\u6216\u591a\u4e2a\u6a21\u578b\u53c2\u6570\u7684\u53d8\u5316\u5bf9\u4eff\u771f\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u60a8\u53ea\u9700\u4e3a\u6bcf\u4e2a\u611f\u5174\u8da3\u7684\u53c2\u6570\u63d0\u4f9b\u4e00\u7ec4\u503c\uff0c<code>tricys</code> \u4f1a\u81ea\u52a8\u521b\u5efa\u5e76\u8fd0\u884c\u6240\u6709\u53ef\u80fd\u7684\u53c2\u6570\u7ec4\u5408\u3002</p>"},{"location":"guides/tricys_basic/parameter_sweep.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u5728\u57fa\u7840\u914d\u7f6e\u4e4b\u4e0a\uff0c\u6211\u4eec\u53ea\u9700\u6dfb\u52a0\u4e00\u4e2a <code>simulation_parameters</code> \u5b57\u6bb5\uff0c\u5373\u53ef\u5b9a\u4e49\u53c2\u6570\u626b\u63cf\u3002</p> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    },\n    \"simulation_parameters\": {\n        \"tep_fep.to_SDS_Fraction[1]\": [0.1, 0.15, 0.2, 0.3, 0.4, 0.6, 0.8],\n        \"blanket.TBR\": \"linspace:1.05:1.15:3\"\n    }\n}\n</code></pre>"},{"location":"guides/tricys_basic/parameter_sweep.html#2","title":"2. \u914d\u7f6e\u9879\u8be6\u89e3","text":"<ul> <li>\u63cf\u8ff0: <code>simulation_parameters</code>\u914d\u7f6e\u9879 \u662f\u4e00\u4e2a\u5b57\u5178\uff08\u952e\u503c\u5bf9\u96c6\u5408\uff09\uff0c\u7528\u4e8e\u5b9a\u4e49\u8981\u626b\u63cf\u7684\u53c2\u6570\u53ca\u5176\u5bf9\u5e94\u7684\u503c\u3002</li> <li>\u952e (Key): \u5fc5\u987b\u662f Modelica \u6a21\u578b\u4e2d\u53d8\u91cf\u7684\u5b8c\u6574\u8def\u5f84\u3002\u4f8b\u5982 <code>blanket.TBR</code> \u6216 <code>tep_fep.to_SDS_Fraction[1]</code>\u3002</li> <li> <p>\u503c (Value): \u53ef\u4ee5\u662f\u4ee5\u4e0b\u51e0\u79cd\u683c\u5f0f\uff1a</p> <ol> <li> <p>\u79bb\u6563\u503c\u5217\u8868 (List):</p> <ul> <li>\u683c\u5f0f: <code>[v1, v2, v3, ...]</code></li> <li>\u793a\u4f8b: <code>[0.1, 0.15, 0.2]</code></li> <li>\u8bf4\u660e: \u7a0b\u5e8f\u5c06\u4f9d\u6b21\u4f7f\u7528\u5217\u8868\u4e2d\u7684\u6bcf\u4e00\u4e2a\u503c\u8fdb\u884c\u4eff\u771f\u3002</li> </ul> </li> <li> <p>\u9ad8\u7ea7\u626b\u63cf\u683c\u5f0f (String):</p> <ul> <li>\u63cf\u8ff0: <code>tricys</code> \u652f\u6301\u591a\u79cd\u7d27\u51d1\u7684\u5b57\u7b26\u4e32\u683c\u5f0f\u6765\u751f\u6210\u6570\u503c\u5e8f\u5217\uff0c\u975e\u5e38\u9002\u5408\u5b9a\u4e49\u7ebf\u6027\u3001\u5bf9\u6570\u7b49\u5e8f\u5217\u3002</li> <li>\u793a\u4f8b: <code>\"linspace:1.05:1.15:3\"</code> \u8868\u793a\u5728 1.05 \u548c 1.15 \u4e4b\u95f4\u751f\u6210 3 \u4e2a\u7b49\u95f4\u8ddd\u7684\u6570\u503c\u3002</li> <li>\u652f\u6301\u7684\u683c\u5f0f:</li> </ul> </li> </ol> </li> </ul> \u683c\u5f0f \u8bed\u6cd5 \u63cf\u8ff0 \u7ebf\u6027\u5e8f\u5217 (Range) <code>\"start:stop:step\"</code> \u4ece <code>start</code> \u5230 <code>stop</code> \u751f\u6210\u4e00\u4e2a\u6b65\u957f\u4e3a <code>step</code> \u7684\u7b49\u5dee\u5e8f\u5217\u3002\u4f8b\u5982: <code>\"1:5:2\"</code> \u4f1a\u751f\u6210 <code>[1, 3, 5]</code>\u3002 \u7ebf\u6027\u95f4\u9694 (Linspace) <code>\"linspace:start:stop:num\"</code> \u5728 <code>start</code> \u548c <code>stop</code> \u4e4b\u95f4\u751f\u6210 <code>num</code> \u4e2a\u7b49\u95f4\u8ddd\u7684\u6570\u503c\u3002\u4f8b\u5982: <code>\"linspace:0:10:3\"</code> \u4f1a\u751f\u6210 <code>[0, 5, 10]</code>\u3002 \u5bf9\u6570\u95f4\u9694 (Logspace) <code>\"log:start:stop:num\"</code> \u5728 <code>start</code> \u548c <code>stop</code> \u4e4b\u95f4\u751f\u6210 <code>num</code> \u4e2a\u5bf9\u6570\u7b49\u8ddd\u7684\u6570\u503c\uff0c\u9002\u5408\u8de8\u6570\u91cf\u7ea7\u7684\u626b\u63cf\u3002\u4f8b\u5982: <code>\"log:1:100:3\"</code> \u4f1a\u751f\u6210 <code>[1, 10, 100]</code>\u3002 \u968f\u673a\u6570 (Random) <code>\"rand:min:max:count\"</code> \u5728 <code>min</code> \u548c <code>max</code> \u4e4b\u95f4\u751f\u6210 <code>count</code> \u4e2a\u5747\u5300\u5206\u5e03\u7684\u968f\u673a\u6570\u3002\u4f8b\u5982: <code>\"rand:0:1:2\"</code> \u53ef\u80fd\u4f1a\u751f\u6210 <code>[0.23, 0.87]</code>\u3002 \u4ece\u6587\u4ef6\u8bfb\u53d6 (From File) <code>\"file:path/to/data.csv:column_name\"</code> \u4ece\u6307\u5b9a\u7684 CSV \u6587\u4ef6\u4e2d\u7684 <code>column_name</code> \u5217\u8bfb\u53d6\u6570\u503c\u4f5c\u4e3a\u626b\u63cf\u5217\u8868\u3002 \u6570\u7ec4\u5c55\u5f00 (Array Expansion) <code>\"{val1, val2, ...}\"</code> \u7528\u4e8e\u4e00\u6b21\u6027\u8bbe\u7f6e Modelica \u6570\u7ec4\u4e2d\u591a\u4e2a\u5143\u7d20\u7684\u7279\u6b8a\u683c\u5f0f\u3002\u4f8b\u5982\uff0c\u4e3a\u53c2\u6570 <code>my_array</code> \u8bbe\u7f6e\u503c <code>\"{10, 25, 50}\"</code>\uff0c\u5c06\u4f1a\u88ab\u81ea\u52a8\u5c55\u5f00\u4e3a <code>my_array[1]=10</code>, <code>my_array[2]=25</code>, <code>my_array[3]=50</code>\u3002\u82b1\u62ec\u53f7\u5185\u7684\u503c\u672c\u8eab\u4e5f\u53ef\u4ee5\u662f\u5176\u4ed6\u9ad8\u7ea7\u683c\u5f0f\u7684\u5b57\u7b26\u4e32\u3002 <p>\u591a\u53c2\u6570\u626b\u63cf</p> <ul> <li>\u60a8\u53ef\u4ee5\u540c\u65f6\u5b9a\u4e49\u591a\u4e2a\u53c2\u6570\u8fdb\u884c\u626b\u63cf\uff0c<code>tricys</code> \u4f1a\u8ba1\u7b97\u6240\u6709\u53c2\u6570\u503c\u7684\u7b1b\u5361\u5c14\u79ef\uff0c\u751f\u6210\u4e00\u4e2a\u5305\u542b\u6240\u6709\u53ef\u80fd\u7ec4\u5408\u7684\u4eff\u771f\u4efb\u52a1\u5217\u8868\u3002</li> <li>\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c<code>tep_fep.to_SDS_Fraction[1]</code> \u6709 7 \u4e2a\u503c\uff0c<code>blanket.TBR</code> \u6709 3 \u4e2a\u503c\uff0c\u56e0\u6b64\u7a0b\u5e8f\u603b\u5171\u4f1a\u8fd0\u884c <code>7 * 3 = 21</code> \u6b21\u4eff\u771f\u3002</li> </ul>"},{"location":"guides/tricys_basic/parameter_sweep.html#3","title":"3. \u7ed3\u679c\u8f93\u51fa","text":"<p>\u5bf9\u4e8e\u53c2\u6570\u626b\u63cf\u4efb\u52a1\uff0c\u9664\u4e86\u6bcf\u6b21\u5355\u72ec\u8fd0\u884c\u7684 <code>simulation_result.csv</code> \u6587\u4ef6\u5916\uff0c<code>tricys</code> \u8fd8\u4f1a\u751f\u6210\u4e00\u4e2a\u6c47\u603b\u6587\u4ef6 <code>sweep_results.csv</code>\uff0c\u5982\u4e0b\uff1a</p> <pre><code>Working Directory/\n\u2514\u2500\u2500 {timestamp}/\n    \u251c\u2500\u2500 log/        \n        \u2514\u2500\u2500 simulation_{timestamp}.log      # \u8fd0\u884c\u65e5\u5fd7\n    \u251c\u2500\u2500 result/                 \n        \u2514\u2500\u2500 sweep_results.csv               # \u4eff\u771f\u7ed3\u679c\u6c47\u603b\u6570\u636e\n    \u2514\u2500\u2500 temp/\n        \u251c\u2500\u2500 job_1/                      \n            \u2514\u2500\u2500 job_1_simulation_result.csv # \u4eff\u771f\u4efb\u52a1\u4e00\u6a21\u62df\u7ed3\u679c\n        \u251c\u2500\u2500 job_2/                      \n            \u2514\u2500\u2500 job_2_simulation_result.csv # \u4eff\u771f\u4efb\u52a1\u4e8c\u6a21\u62df\u7ed3\u679c\n        \u2514\u2500\u2500 ......\n</code></pre> <ul> <li><code>sweep_results.csv</code>:</li> <li>\u7b2c\u4e00\u5217: <code>time</code>\uff0c\u8868\u793a\u65f6\u95f4\u8f74\u3002</li> <li>\u5176\u4f59\u5217: \u6bcf\u4e00\u5217\u4ee3\u8868\u4e00\u6b21\u7279\u5b9a\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u4eff\u771f\u7ed3\u679c\u3002\u5217\u6807\u9898\u6e05\u6670\u5730\u6807\u660e\u4e86\u8be5\u6b21\u8fd0\u884c\u6240\u4f7f\u7528\u7684\u53c2\u6570\u53ca\u5176\u503c\uff0c\u4f8b\u5982 <code>sds.I[1]&amp;tep_fep.to_SDS_Fraction[1]=0.1&amp;blanket.TBR=1.05</code>\uff0c\u65b9\u4fbf\u60a8\u76f4\u63a5\u5728 CSV \u6587\u4ef6\u4e2d\u6bd4\u8f83\u4e0d\u540c\u5de5\u51b5\u4e0b\u7684\u7ed3\u679c\u3002</li> </ul>"},{"location":"guides/tricys_basic/parameter_sweep.html#4","title":"4. \u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u4e86\u53c2\u6570\u626b\u63cf\u540e\uff0c\u60a8\u53ef\u4ee5\u63a2\u7d22\u66f4\u9ad8\u7ea7\u7684\u529f\u80fd\u6765\u63d0\u5347\u6548\u7387\u548c\u5206\u6790\u6df1\u5ea6\uff1a</p> <ul> <li>\u5e76\u53d1\u8fd0\u884c\uff1a\u5b66\u4e60\u5982\u4f55\u5229\u7528\u591a\u6838\u5904\u7406\u5668\u5e76\u884c\u6267\u884c\u5927\u91cf\u626b\u63cf\u4efb\u52a1\uff0c\u5927\u5e45\u7f29\u77ed\u4eff\u771f\u65f6\u95f4\u3002</li> <li>\u540e\u5904\u7406\u6a21\u5757\uff1a\u4e86\u89e3\u5982\u4f55\u81ea\u52a8\u5206\u6790\u626b\u63cf\u7ed3\u679c\uff0c\u4f8b\u5982\u8ba1\u7b97\u6bcf\u4e2a\u5de5\u51b5\u4e0b\u7684\u6700\u5927\u503c\u3001\u5e73\u5747\u503c\u6216\u62a5\u8b66\u6b21\u6570\u3002</li> <li>\u654f\u611f\u6027\u5206\u6790\uff1a\u8fdb\u884c\u66f4\u7cfb\u7edf\u5316\u7684\u53c2\u6570\u5f71\u54cd\u7814\u7a76\uff0c\u4f8b\u5982 Sobol \u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html","title":"\u540e\u5904\u7406\u6a21\u5757","text":"<p><code>tricys</code> \u4e0d\u4ec5\u80fd\u8fd0\u884c\u4eff\u771f\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u540e\u5904\u7406\uff08Post-Processing\uff09\u6846\u67b6\uff0c\u5141\u8bb8\u60a8\u5728\u4eff\u771f\u4efb\u52a1\u5b8c\u6210\u540e\u81ea\u52a8\u5bf9\u7ed3\u679c\u8fdb\u884c\u5206\u6790\u3001\u751f\u6210\u62a5\u544a\u6216\u6267\u884c\u5176\u4ed6\u81ea\u5b9a\u4e49\u64cd\u4f5c\u3002</p> <p>\u540e\u5904\u7406\u529f\u80fd\u901a\u8fc7\u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u6dfb\u52a0 <code>post_processing</code> \u5b57\u6bb5\u6765\u5b9e\u73b0\u3002</p>"},{"location":"guides/tricys_basic/post_processing_module.html#1","title":"1. \u914d\u7f6e\u6587\u4ef6\u793a\u4f8b","text":"<p>\u4ee5\u4e0b\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u5728\u53c2\u6570\u626b\u63cf\u5b8c\u6210\u540e\uff0c\u81ea\u52a8\u6267\u884c\u4e24\u4e2a\u5206\u6790\u4efb\u52a1\uff1a\u4e00\u4e2a\u4f7f\u7528\u5185\u7f6e\u7684 <code>module</code>\uff0c\u53e6\u4e00\u4e2a\u4f7f\u7528\u7528\u6237\u81ea\u5b9a\u4e49\u7684 <code>script_path</code>\u3002</p> <pre><code>{\n    \"paths\": {\n        ...\n    },\n    \"simulation\": {\n        ...\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    },\n    \"post_processing\": [\n        {\n            \"module\": \"tricys.postprocess.static_alarm\",\n            \"function\": \"check_thresholds\",\n            \"params\": {\n                \"rules\": [{\"columns\": [\"sds.I[1]\"], \"min\": 0.0}]\n            }\n        },\n        {\n            \"script_path\": \"scripts/my_custom_analyzer.py\",\n            \"function\": \"analyze_peak_value\",\n            \"params\": {\n                \"target_column_pattern\": \"sds.I[1]*\",\n                \"report_filename\": \"peak_values.json\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/tricys_basic/post_processing_module.html#2","title":"2. \u914d\u7f6e\u9879\u8be6\u89e3","text":""},{"location":"guides/tricys_basic/post_processing_module.html#21-post_processing","title":"2.1. <code>post_processing</code>","text":"<ul> <li>\u63cf\u8ff0: \u8fd9\u662f\u4e00\u4e2a\u5217\u8868\uff08Array\uff09\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2a\u72ec\u7acb\u7684\u540e\u5904\u7406\u6b65\u9aa4\u3002\u8fd9\u4e9b\u6b65\u9aa4\u4f1a\u6309\u7167\u5b83\u4eec\u5728\u5217\u8868\u4e2d\u7684\u987a\u5e8f\u4f9d\u6b21\u6267\u884c\u3002</li> <li>\u6267\u884c\u65f6\u673a: \u6240\u6709\u4eff\u771f\u4efb\u52a1\uff08\u4f8b\u5982\u53c2\u6570\u626b\u63cf\u4e2d\u7684\u6bcf\u4e00\u6b21\u8fd0\u884c\uff09\u5168\u90e8\u5b8c\u6210\u540e\uff0c<code>tricys</code> \u4f1a\u5c06\u6c47\u603b\u7684\u7ed3\u679c\uff08<code>sweep_results.csv</code>\uff09\u52a0\u8f7d\u5230\u4e00\u4e2a Pandas DataFrame \u4e2d\uff0c\u5e76\u5c06\u5176\u4f20\u9012\u7ed9\u60a8\u6307\u5b9a\u7684\u540e\u5904\u7406\u51fd\u6570\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#22","title":"2.2. \u540e\u5904\u7406\u51fd\u6570","text":"<p>\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u5bf9\u8c61\u90fd\u5b9a\u4e49\u4e86\u4e00\u4e2a\u8981\u6267\u884c\u7684 Python \u51fd\u6570\u3002\u60a8\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u4e24\u79cd\u65b9\u5f0f\u4e4b\u4e00\u6765\u6307\u5b9a\u8981\u8c03\u7528\u7684\u4ee3\u7801\uff1a</p>"},{"location":"guides/tricys_basic/post_processing_module.html#module","title":"\u65b9\u5f0f\u4e00\uff1a<code>module</code> (\u6a21\u5757\u52a0\u8f7d)","text":"<ul> <li><code>module</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</li> <li>\u63cf\u8ff0: \u8981\u8c03\u7528\u7684 Python \u51fd\u6570\u6240\u5728\u7684\u6a21\u5757\u7684\u5b8c\u6574\u8def\u5f84\u3002\u8fd9\u8981\u6c42\u60a8\u7684\u4ee3\u7801\u662f\u4e00\u4e2a\u53ef\u4ee5\u901a\u8fc7 <code>import</code> \u8bed\u53e5\u52a0\u8f7d\u7684 Python \u5305\u6216\u6a21\u5757\uff08\u4f8b\u5982\uff0c\u5df2\u5b89\u88c5\u6216\u4f4d\u4e8e\u5e26\u6709 <code>__init__.py</code> \u7684\u76ee\u5f55\u4e2d\uff09\u3002</li> <li>\u793a\u4f8b: <code>tricys.postprocess.static_alarm</code></li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#script_path","title":"\u65b9\u5f0f\u4e8c\uff1a<code>script_path</code> (\u811a\u672c\u8def\u5f84\u52a0\u8f7d)","text":"<ul> <li><code>script_path</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</li> <li>\u63cf\u8ff0: \u6307\u5411\u5305\u542b\u8981\u8c03\u7528\u51fd\u6570\u7684\u5355\u4e2a Python \u811a\u672c\u6587\u4ef6\u7684\u8def\u5f84\u3002\u8fd9\u66f4\u52a0\u7075\u6d3b\uff0c\u4e0d\u9700\u8981\u60a8\u7684\u811a\u672c\u6210\u4e3a\u4e00\u4e2a\u6b63\u5f0f\u7684\u5305\u3002</li> <li>\u793a\u4f8b: <code>scripts/my_custom_analyzer.py</code></li> </ul> <p>\u65e0\u8bba\u4f7f\u7528\u54ea\u79cd\u65b9\u5f0f\uff0c\u60a8\u90fd\u9700\u8981\u63d0\u4f9b\u4ee5\u4e0b\u5b57\u6bb5\uff1a</p> <ul> <li><code>function</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b):</li> <li>\u63cf\u8ff0: \u8981\u5728\u6307\u5b9a\u6a21\u5757\u6216\u811a\u672c\u4e2d\u8c03\u7528\u7684\u51fd\u6570\u540d\u3002</li> <li> <p>\u793a\u4f8b: <code>check_thresholds</code></p> </li> <li> <p><code>params</code> (\u5b57\u5178, \u9009\u586b):</p> </li> <li>\u63cf\u8ff0: \u4e00\u4e2a\u5305\u542b\u8981\u4f20\u9012\u7ed9\u76ee\u6807\u51fd\u6570\u7684\u5173\u952e\u5b57\u53c2\u6570\uff08keyword arguments\uff09\u7684\u5b57\u5178\u3002</li> <li>\u793a\u4f8b: \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c<code>params</code> \u4e3a <code>check_thresholds</code> \u51fd\u6570\u63d0\u4f9b\u4e86 <code>rules</code> \u53c2\u6570\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#3","title":"3. \u5185\u7f6e\u540e\u5904\u7406\u6a21\u5757","text":"<p><code>tricys</code> \u81ea\u5e26\u4e86\u4e00\u4e9b\u5e38\u7528\u7684\u540e\u5904\u7406\u6a21\u5757\uff0c\u4f4d\u4e8e <code>tricys/postprocess</code> \u76ee\u5f55\u4e0b\uff1a</p> <ul> <li><code>rise_analysis</code>: \u7528\u4e8e\u5206\u6790\u4fe1\u53f7\u7684\u4e0a\u5347\u65f6\u95f4\u3001\u4e0b\u964d\u65f6\u95f4\u3001\u5cf0\u503c\u7b49\u52a8\u6001\u7279\u6027\u3002</li> <li><code>static_alarm</code>: \u7528\u4e8e\u68c0\u67e5\u7ed3\u679c\u662f\u5426\u8d85\u51fa\u4e86\u9884\u8bbe\u7684\u9759\u6001\u9608\u503c\uff08\u4e0a\u9650\u6216\u4e0b\u9650\uff09\u3002</li> <li><code>baseline_analysis</code>: \u7528\u4e8e\u6267\u884c\u57fa\u51c6\u5de5\u51b5\u5206\u6790\u3002</li> </ul>"},{"location":"guides/tricys_basic/post_processing_module.html#4","title":"4. \u81ea\u5b9a\u4e49\u540e\u5904\u7406\u6a21\u5757","text":"<p>\u540e\u5904\u7406\u6846\u67b6\u6700\u5927\u7684\u4f18\u52bf\u5728\u4e8e\u5176\u6269\u5c55\u6027\u3002\u60a8\u53ef\u4ee5\u8f7b\u677e\u7f16\u5199\u81ea\u5df1\u7684 Python \u811a\u672c\u6765\u6267\u884c\u4efb\u4f55\u60f3\u8981\u7684\u5206\u6790\u3002</p>"},{"location":"guides/tricys_basic/post_processing_module.html#41","title":"4.1. \u51fd\u6570\u7b7e\u540d","text":"<p>\u4e3a\u4e86\u80fd\u88ab <code>tricys</code> \u6846\u67b6\u6b63\u786e\u8c03\u7528\uff0c\u60a8\u7684\u81ea\u5b9a\u4e49\u540e\u5904\u7406\u51fd\u6570\u5fc5\u987b\u9075\u5faa\u7279\u5b9a\u7684\u7b7e\u540d\u3002\u6846\u67b6\u4f1a\u81ea\u52a8\u901a\u8fc7\u5173\u952e\u5b57\u53c2\u6570\u4f20\u5165\u4e24\u4e2a\u6838\u5fc3\u6570\u636e\uff1a</p> <ol> <li><code>results_df</code> (pd.DataFrame): \u5305\u542b\u6240\u6709\u4eff\u771f\u8fd0\u884c\u6c47\u603b\u7ed3\u679c\u7684 Pandas DataFrame\u3002</li> <li><code>output_dir</code> (str): \u4e00\u4e2a\u4e13\u5c5e\u7684\u8f93\u51fa\u76ee\u5f55\u8def\u5f84\uff0c\u4f9b\u60a8\u4fdd\u5b58\u62a5\u544a\u3001\u56fe\u8868\u7b49\u5206\u6790\u4ea7\u7269\u3002</li> </ol> <p>\u56e0\u6b64\uff0c\u60a8\u7684\u51fd\u6570\u7b7e\u540d\u5fc5\u987b\u80fd\u591f\u63a5\u6536\u8fd9\u4e24\u4e2a\u53c2\u6570\uff0c\u4ee5\u53ca\u60a8\u5728 <code>params</code> \u4e2d\u5b9a\u4e49\u7684\u4efb\u4f55\u5176\u4ed6\u81ea\u5b9a\u4e49\u53c2\u6570\u3002</p> <p>\u4e00\u4e2a\u6807\u51c6\u7684\u51fd\u6570\u7b7e\u540d\u5982\u4e0b\uff1a</p> <pre><code>import pandas as pd\n\ndef my_custom_function(results_df: pd.DataFrame, output_dir: str, **kwargs):\n    \"\"\"\n    \u4e00\u4e2a\u901a\u7528\u7684\u540e\u5904\u7406\u51fd\u6570\u7b7e\u540d\u3002\n\n    - results_df: \u7531 tricys \u4f20\u5165\u7684\u4eff\u771f\u7ed3\u679c\u3002\n    - output_dir: \u7531 tricys \u63d0\u4f9b\u7684\u7528\u4e8e\u4fdd\u5b58\u62a5\u544a\u7684\u76ee\u5f55\u3002\n    - **kwargs: \u7528\u4e8e\u63a5\u6536\u6765\u81ea JSON \u914d\u7f6e\u4e2d \"params\" \u7684\u6240\u6709\u81ea\u5b9a\u4e49\u53c2\u6570\u3002\n    \"\"\"\n    # \u4ece kwargs \u4e2d\u83b7\u53d6\u81ea\u5b9a\u4e49\u53c2\u6570\n    my_param = kwargs.get(\"my_param\", \"default_value\")\n\n    # \u5728\u8fd9\u91cc\u7f16\u5199\u60a8\u7684\u5206\u6790\u4ee3\u7801...\n    print(f\"\u5206\u6790\u62a5\u544a\u5c06\u4fdd\u5b58\u5728: {output_dir}\")\n    print(f\"\u6536\u5230\u7684\u81ea\u5b9a\u4e49\u53c2\u6570 my_param \u7684\u503c\u4e3a: {my_param}\")\n    print(\"\u7ed3\u679c\u6570\u636e\u9884\u89c8:\")\n    print(results_df.head())\n</code></pre>"},{"location":"guides/tricys_basic/post_processing_module.html#42","title":"4.2. \u5b8c\u6574\u793a\u4f8b","text":"<p>\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u5b8c\u6574\u7684\u81ea\u5b9a\u4e49\u540e\u5904\u7406\u811a\u672c\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u901a\u8fc7 <code>script_path</code> \u5728\u914d\u7f6e\u4e2d\u8c03\u7528\u5b83\u3002</p> <p>\u6b65\u9aa4 1: \u521b\u5efa\u5206\u6790\u811a\u672c</p> <p>\u5047\u8bbe\u6211\u4eec\u5728\u9879\u76ee\u4e0b\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a <code>scripts/my_custom_analyzer.py</code> \u7684\u6587\u4ef6\uff1a</p> <pre><code># scripts/my_custom_analyzer.py\nimport pandas as pd\nimport os\nimport json\n\ndef analyze_peak_value(results_df: pd.DataFrame, output_dir: str, target_column_pattern: str, report_filename: str = \"peak_report.json\"):\n    \"\"\"\n    \u5728\u6240\u6709\u5339\u914d\u7684\u5217\u4e2d\u67e5\u627e\u5cf0\u503c\uff0c\u5e76\u751f\u6210\u4e00\u4efd\u62a5\u544a\u3002\n    \"\"\"\n    # \u7b5b\u9009\u51fa\u7b26\u5408\u6a21\u5f0f\u7684\u5217\n    target_columns = [col for col in results_df.columns if target_column_pattern in col]\n\n    if not target_columns:\n        print(f\"\u8b66\u544a: \u672a\u627e\u5230\u5339\u914d '{target_column_pattern}' \u7684\u5217\u3002\")\n        return\n\n    # \u8ba1\u7b97\u6bcf\u4e00\u5217\u7684\u5cf0\u503c\n    peak_values = results_df[target_columns].max().to_dict()\n\n    # \u5b9a\u4e49\u62a5\u544a\u8f93\u51fa\u8def\u5f84\n    report_path = os.path.join(output_dir, report_filename)\n\n    # \u4fdd\u5b58\u62a5\u544a\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(peak_values, f, indent=4)\n\n    print(f\"\u5cf0\u503c\u5206\u6790\u62a5\u544a\u5df2\u4fdd\u5b58\u81f3: {report_path}\")\n</code></pre> <p>\u6b65\u9aa4 2: \u66f4\u65b0\u914d\u7f6e\u6587\u4ef6</p> <p>\u73b0\u5728\uff0c\u5728\u60a8\u7684 <code>config.json</code> \u4e2d\u914d\u7f6e <code>post_processing</code> \u90e8\u5206\u6765\u8c03\u7528\u8fd9\u4e2a\u811a\u672c\uff1a</p> <pre><code>{\n    ...\n    \"post_processing\": [\n        {\n            \"script_path\": \"scripts/my_custom_analyzer.py\",\n            \"function\": \"analyze_peak_value\",\n            \"params\": {\n                \"target_column_pattern\": \"sds.I[1]\",\n                \"report_filename\": \"sds_peak_values.json\"\n            }\n        }\n    ]\n}\n</code></pre> <p>\u5f53 <code>tricys</code> \u5b8c\u6210\u6240\u6709\u4eff\u771f\u540e\uff0c\u5b83\u4f1a\u81ea\u52a8\u6267\u884c <code>analyze_peak_value</code> \u51fd\u6570\uff0c\u5e76\u5c06\u4eff\u771f\u7ed3\u679c\u4e2d\u6240\u6709\u5305\u542b <code>sds.I[1]</code> \u7684\u5217\u7684\u5cf0\u503c\u8ba1\u7b97\u51fa\u6765\uff0c\u6700\u540e\u5c06\u7ed3\u679c\u4fdd\u5b58\u5230 <code>post_processing/sds_peak_values.json</code> \u6587\u4ef6\u4e2d\u3002</p> <p>\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u60a8\u53ef\u4ee5\u5c06\u4efb\u610f\u590d\u6742\u7684\u6570\u636e\u5206\u6790\u6d41\u7a0b\u65e0\u7f1d\u96c6\u6210\u5230 <code>tricys</code> \u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\u3002</p>"},{"location":"guides/tricys_basic/post_processing_module.html#5","title":"5. \u4e0b\u4e00\u6b65","text":"<p>\u638c\u63e1\u4e86\u5982\u4f55\u521b\u5efa\u548c\u4f7f\u7528\u540e\u5904\u7406\u6a21\u5757\u540e\uff0c\u60a8\u53ef\u4ee5\u5c06\u5b83\u5e94\u7528\u5230\u66f4\u590d\u6742\u7684\u573a\u666f\u4e2d\uff1a</p> <ul> <li>\u654f\u611f\u6027\u5206\u6790\uff1a\u4e3a\u590d\u6742\u7684\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u7f16\u5199\u4e13\u7528\u7684\u540e\u5904\u7406\u811a\u672c\uff0c\u4ee5\u63d0\u53d6\u5173\u952e\u6307\u6807\u548c\u751f\u6210\u53ef\u89c6\u5316\u56fe\u8868\u3002</li> <li>\u534f\u540c\u4eff\u771f\uff1a\u5bf9\u5305\u542b\u5916\u90e8\u6a21\u5757\u7684\u534f\u540c\u4eff\u771f\u7ed3\u679c\u8fdb\u884c\u6574\u5408\u4e0e\u5206\u6790\u3002</li> </ul>"},{"location":"questions/advanced_features.html","title":"\ud83d\udd2c \u9ad8\u7ea7\u529f\u80fd","text":"\u95ee\uff1a\u4ec0\u4e48\u662f\u534f\u540c\u4eff\u771f\uff1f\u5982\u4f55\u4f7f\u7528\uff1f <p>\u534f\u540c\u4eff\u771f\u5141\u8bb8 TRICYS \u4e0e\u5916\u90e8\u8f6f\u4ef6\uff08\u5982 Aspen Plus\uff09\u4ea4\u4e92\uff1a</p> <p>\u5de5\u4f5c\u6d41\u7a0b\uff1a 1. \u8fd0\u884c\u521d\u6b65\u4eff\u771f 2. \u8c03\u7528\u5916\u90e8\u5904\u7406\u5668\uff08Handler\uff09 3. \u5916\u90e8\u8f6f\u4ef6\u8ba1\u7b97\u65b0\u6570\u636e 4. \u5c06\u6570\u636e\u6ce8\u5165\u56de Modelica \u6a21\u578b 5. \u8fd0\u884c\u6700\u7ec8\u5b8c\u6574\u4eff\u771f</p> <p>\u914d\u7f6e\u793a\u4f8b\uff1a <pre><code>{\n    \"co_simulation\": [\n        {\n            \"mode\": \"interceptor\",\n            \"submodel_name\": \"example_model.I_ISS\",\n            \"instance_name\": \"i_iss\",\n            \"handler_module\": \"tricys.handlers.i_iss_handler\",\n            \"handler_function\": \"run_aspen_simulation\",\n            \"params\": {\n                \"bkp_path\": \"path/to/aspen/file.bkp\"\n            }\n        }\n    ]\n}\n</code></pre></p> <ul> <li><code>mode</code>\uff1a<code>interceptor</code>\uff08\u9ed8\u8ba4\uff09\u6216<code>replacement</code>\u3002</li> <li><code>handler_module</code>\uff1a\u5904\u7406\u5668\u6240\u5728\u7684\u6a21\u5757\u3002</li> <li><code>handler_script_path</code>\uff1a\u6216\u8005\uff0c\u76f4\u63a5\u63d0\u4f9b\u5904\u7406\u5668\u811a\u672c\u7684\u8def\u5f84\u3002</li> </ul> <p>\u8be6\u89c1\uff1a\u534f\u540c\u4eff\u771f\u6a21\u5757</p> \u95ee\uff1a\u5982\u4f55\u521b\u5efa\u81ea\u5b9a\u4e49\u540e\u5904\u7406\u6a21\u5757\uff1f <p>\u540e\u5904\u7406\u6a21\u5757\u662f Python \u51fd\u6570\uff0c\u63a5\u6536\u4eff\u771f\u7ed3\u679c\u5e76\u6267\u884c\u5206\u6790\uff1a</p> <p>1. \u521b\u5efa\u5904\u7406\u51fd\u6570\uff1a <pre><code># my_postprocess.py\ndef analyze_results(df, output_filename=\"my_report.txt\"):\n    \"\"\"\n    \u81ea\u5b9a\u4e49\u540e\u5904\u7406\u51fd\u6570\n\n    Args:\n        df: Pandas DataFrame\uff0c\u5305\u542b\u4eff\u771f\u7ed3\u679c\n        output_filename: \u8f93\u51fa\u6587\u4ef6\u540d\n    \"\"\"\n    # \u6267\u884c\u5206\u6790\n    max_inventory = df['sds.I[1]'].max()\n\n    # \u4fdd\u5b58\u7ed3\u679c\n    with open(output_filename, 'w') as f:\n        f.write(f\"\u6700\u5927\u6c1a\u5e93\u5b58: {max_inventory} g\\n\")\n</code></pre> \u6ce8\u610f\uff1a\u8bf7\u5c06\u81ea\u5b9a\u4e49\u6a21\u5757\uff08\u5982<code>my_postprocess.py</code>\uff09\u653e\u7f6e\u5728 <code>tricys</code> \u9879\u76ee\u7684\u6839\u76ee\u5f55\u4e0b\uff0c\u6216\u786e\u4fdd\u5b83\u5728 Python \u7684\u53ef\u53ef\u5bfc\u5165\u8def\u5f84\u4e2d\u3002</p> <p>2. \u5728\u914d\u7f6e\u6587\u4ef6\u4e2d\u5f15\u7528\uff1a <pre><code>{\n    \"post_processing\": [\n        {\n            \"module\": \"my_postprocess\",\n            \"function\": \"analyze_results\",\n            \"params\": {\n                \"output_filename\": \"custom_report.txt\"\n            }\n        }\n    ]\n}\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff1f <p>TRICYS \u63d0\u4f9b\u591a\u79cd\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\uff1a</p> <p>1. \u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a <pre><code>tricys analysis -c single_param_analysis.json\n</code></pre></p> <p>\u7814\u7a76\u5355\u4e2a\u53c2\u6570\u5bf9 KPIs \u7684\u5f71\u54cd\u3002</p> <p>2. \u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\uff1a <pre><code>tricys analysis -c multi_param_analysis.json\n</code></pre></p> <p>\u7814\u7a76\u53c2\u6570\u95f4\u7684\u8026\u5408\u6548\u5e94\u3002</p> <p>3. SOBOL \u5168\u5c40\u654f\u611f\u6027\u5206\u6790\uff1a <pre><code>tricys analysis -c sobol_analysis.json\n</code></pre></p> <p>\u91cf\u5316\u53c2\u6570\u53ca\u5176\u4ea4\u4e92\u4f5c\u7528\u7684\u8d21\u732e\u3002</p> <p>4. Latin \u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff1a <pre><code>tricys analysis -c latin_analysis.json\n</code></pre></p> <p>\u8bc4\u4f30\u8f93\u5165\u4e0d\u786e\u5b9a\u6027\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002</p> <p>\u8be6\u89c1\uff1a\u654f\u611f\u6027\u5206\u6790\u6559\u7a0b</p> \u95ee\uff1a\u5982\u4f55\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6027\u80fd\u6307\u6807\uff1f <p>\u6027\u80fd\u6307\u6807\uff08Metrics\uff09\u5728 <code>sensitivity_analysis.metrics_definition</code> \u4e2d\u5b9a\u4e49\uff1a</p> <p>\u4f7f\u7528\u5185\u7f6e\u6307\u6807\uff1a <pre><code>{\n    \"metrics_definition\": {\n        \"Max_Inventory\": {\n            \"source_column\": \"sds.I[1]\",\n            \"method\": \"max_value\"\n        }\n    }\n}\n</code></pre></p> <p>\u5185\u7f6e\u6307\u6807\u65b9\u6cd5\uff1a * <code>get_final_value</code> * <code>max_value</code>, <code>min_value</code>, <code>mean_value</code> * <code>time_of_max</code>, <code>time_of_min</code> * <code>time_of_turning_point</code> * <code>calculate_startup_inventory</code> * <code>calculate_doubling_time</code> * <code>calculate_required_tbr</code>\uff08\u4e8c\u5206\u6cd5\u641c\u7d22\uff09</p> <p>\u5173\u4e8e\u5185\u7f6e\u6307\u6807\u7684\u8be6\u7ec6\u7269\u7406\u610f\u4e49\uff0c\u8bf7\u53c2\u8003 \u6838\u5fc3\u6027\u80fd\u6307\u6807\u8be6\u89e3\u3002</p> <p>\u521b\u5efa\u81ea\u5b9a\u4e49\u6307\u6807\uff1a <pre><code># my_metrics.py\ndef calculate_peak_to_peak(series):\n    \"\"\"\u8ba1\u7b97\u5cf0\u5cf0\u503c\"\"\"\n    return series.max() - series.min()\n</code></pre></p> <p>\u5728 <code>tricys/analysis/metric.py</code> \u4e2d\u6ce8\u518c\u60a8\u7684\u51fd\u6570\uff0c\u6216\u76f4\u63a5\u5728\u914d\u7f6e\u4e2d\u5f15\u7528\u3002</p>"},{"location":"questions/best_practices.html","title":"\ud83d\udca1 \u6700\u4f73\u5b9e\u8df5","text":"\u95ee\uff1a\u5982\u4f55\u7ec4\u7ec7\u5927\u578b\u4eff\u771f\u9879\u76ee\uff1f <p>\u63a8\u8350\u7684\u76ee\u5f55\u7ed3\u6784\uff1a</p> <pre><code>my_fusion_project/\n\u251c\u2500\u2500 models/                 # Modelica \u6a21\u578b\n\u2502   \u251c\u2500\u2500 package.mo\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 configs/                # \u914d\u7f6e\u6587\u4ef6\n\u2502   \u251c\u2500\u2500 baseline.json\n\u2502   \u251c\u2500\u2500 sensitivity.json\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 scripts/                # \u8f85\u52a9\u811a\u672c\n\u2502   \u251c\u2500\u2500 prepare_data.py\n\u2502   \u2514\u2500\u2500 post_analysis.py\n\u251c\u2500\u2500 data/                   # \u8f93\u5165\u6570\u636e\n\u2502   \u2514\u2500\u2500 external_data.csv\n\u251c\u2500\u2500 results/                # \u4eff\u771f\u7ed3\u679c\uff08\u81ea\u52a8\u751f\u6210\uff09\n\u2514\u2500\u2500 reports/                # \u6700\u7ec8\u62a5\u544a\n</code></pre> \u95ee\uff1a\u5982\u4f55\u7248\u672c\u7ba1\u7406\u914d\u7f6e\u6587\u4ef6\uff1f <p>\u4f7f\u7528 Git \u8fdb\u884c\u7248\u672c\u63a7\u5236\uff1a</p> <pre><code># \u521d\u59cb\u5316 Git \u4ed3\u5e93\ngit init\n\n# \u521b\u5efa .gitignore\necho \"results/\" &gt;&gt; .gitignore\necho \"*.log\" &gt;&gt; .gitignore\necho \"*.pyc\" &gt;&gt; .gitignore\necho \"__pycache__/\" &gt;&gt; .gitignore\n\n# \u63d0\u4ea4\u914d\u7f6e\u6587\u4ef6\ngit add configs/*.json\ngit commit -m \"feat: add baseline configuration\"\n</code></pre> \u95ee\uff1a\u5982\u4f55\u5728\u591a\u53f0\u673a\u5668\u4e0a\u5206\u5e03\u5f0f\u8fd0\u884c\uff1f <p>\u76ee\u524d TRICYS \u4e0d\u76f4\u63a5\u652f\u6301\u5206\u5e03\u5f0f\u8ba1\u7b97\uff0c\u4f46\u60a8\u53ef\u4ee5\uff1a</p> <ol> <li>\u624b\u52a8\u5206\u5272\u4efb\u52a1\uff1a</li> <li>\u5c06\u53c2\u6570\u626b\u63cf\u5206\u6210\u591a\u4e2a\u5b50\u96c6</li> <li>\u5728\u4e0d\u540c\u673a\u5668\u4e0a\u8fd0\u884c\u4e0d\u540c\u7684\u5b50\u96c6</li> <li> <p>\u624b\u52a8\u5408\u5e76\u7ed3\u679c</p> </li> <li> <p>\u4f7f\u7528\u96c6\u7fa4\u8c03\u5ea6\u5668\uff08\u5982 SLURM\uff09\uff1a</p> </li> <li>\u5c06\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u4f5c\u4e3a\u72ec\u7acb\u7684\u4f5c\u4e1a\u63d0\u4ea4</li> <li>\u4f7f\u7528\u540e\u5904\u7406\u811a\u672c\u6c47\u603b\u7ed3\u679c</li> </ol> \u95ee\uff1a\u5982\u4f55\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff1f <p>Modelica \u6a21\u578b\u5c42\u9762\uff1a 1. \u7b80\u5316\u6a21\u578b\u7ed3\u6784\uff0c\u907f\u514d\u8fc7\u5ea6\u590d\u6742\u7684\u65b9\u7a0b 2. \u4f7f\u7528\u9002\u5f53\u7684\u6570\u503c\u6c42\u89e3\u5668\u8bbe\u7f6e 3. \u907f\u514d\u4ee3\u6570\u73af\u548c\u4e8b\u4ef6\u8fc7\u591a</p> <p>TRICYS \u5c42\u9762\uff1a 1. \u542f\u7528\u5e76\u53d1\u8fd0\u884c 2. \u51cf\u5c11\u8f93\u51fa\u53d8\u91cf 3. \u4f7f\u7528\u534f\u540c\u4eff\u771f\u66ff\u4ee3\u590d\u6742\u5b50\u7cfb\u7edf</p>"},{"location":"questions/configuration.html","title":"\u2699\ufe0f \u914d\u7f6e\u8fd0\u884c","text":"\u95ee\uff1a\u5982\u4f55\u8fd0\u884c\u4eff\u771f\uff1f <p>TRICYS \u63d0\u4f9b\u591a\u79cd\u8fd0\u884c\u65b9\u5f0f\uff1a</p> <p>1. \u547d\u4ee4\u884c\uff08CLI\uff09\uff1a <pre><code># \u4f7f\u7528\u9ed8\u8ba4\u914d\u7f6e\u6587\u4ef6 config.json\ntricys\n\n# \u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\ntricys -c my_config.json\n\n# \u8fd0\u884c\u5206\u6790\u4efb\u52a1\ntricys analysis -c analysis_config.json\n</code></pre></p> <p>2. \u56fe\u5f62\u754c\u9762\uff08GUI\uff09\uff1a <pre><code>tricys gui\n</code></pre></p> <p>3. \u4ea4\u4e92\u5f0f\u793a\u4f8b\uff1a <pre><code># \u8fd0\u884c\u6240\u6709\u793a\u4f8b\u7684\u4ea4\u4e92\u5f0f\u83dc\u5355\ntricys example\n\n# \u8fd0\u884c\u57fa\u7840\u4eff\u771f\u793a\u4f8b\ntricys basic example\n\n# \u8fd0\u884c\u5206\u6790\u793a\u4f8b\ntricys analysis example\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u7406\u89e3\u8f93\u51fa\u6587\u4ef6\uff1f <p>\u4eff\u771f\u5b8c\u6210\u540e\uff0c\u7ed3\u679c\u4fdd\u5b58\u5728 <code>results/</code> \u76ee\u5f55\u4e0b\u7684\u65f6\u95f4\u6233\u5b50\u76ee\u5f55\u4e2d\uff1a</p> \u6587\u4ef6\u540d \u8bf4\u660e <code>simulation_result.csv</code> \u5355\u53c2\u6570\u7ec4\u5408\u7684\u8be6\u7ec6\u7ed3\u679c\uff0c\u5305\u542b\u6240\u6709\u53d8\u91cf\u968f\u65f6\u95f4\u7684\u53d8\u5316\u3002 <code>sweep_results.csv</code> \u591a\u53c2\u6570\u7ec4\u5408\uff08\u53c2\u6570\u626b\u63cf\uff09\u7684\u6c47\u603b\u7ed3\u679c\u3002 <code>sensitivity_analysis_summary.csv</code> \u3010\u4ec5\u5206\u6790\u4efb\u52a1\u3011 \u654f\u611f\u6027\u5206\u6790\u7684\u6c47\u603b\u6307\u6807\uff0c\u6bcf\u884c\u662f\u4e00\u6b21\u8fd0\u884c\u7684KPI\u3002 <code>requierd_tbr_summary.csv</code> \u3010\u4ec5\u5206\u6790\u4efb\u52a1\u3011 \u5f53\u6267\u884c\u201cTBR\u9700\u6c42\u201d\u7b49\u76ee\u6807\u641c\u7d22\u4efb\u52a1\u65f6\u751f\u6210\u7684\u4f18\u5316\u7ed3\u679c\u3002 <code>simulation_*.log</code> \u8be6\u7ec6\u7684\u8fd0\u884c\u65e5\u5fd7\uff0c\u5305\u542b\u8c03\u8bd5\u4fe1\u606f\u3002 <code>config.json</code> \u672c\u6b21\u8fd0\u884c\u4f7f\u7528\u7684\u5b8c\u6574\u914d\u7f6e\u5907\u4efd\u3002 <code>*_report.md</code> \u3010\u4ec5\u5206\u6790\u4efb\u52a1\u3011 \u81ea\u52a8\u751f\u6210\u7684AI\u5206\u6790\u62a5\u544a\u3002 <code>*.png</code> / <code>*.csv</code> \u5404\u79cd\u56fe\u8868\u548c\u6570\u636e\u5bfc\u51fa\u3002 <p>\u7ed3\u679c\u6587\u4ef6CSV\u7ed3\u6784</p> <p>\u65e0\u8bba\u8fd0\u884c\u4e00\u4e2a\u8fd8\u662f\u591a\u4e2a\u53c2\u6570\u7ec4\u5408\uff0c\u6700\u7ec8\u7684CSV\u6587\u4ef6\u90fd\u9075\u5faa\u76f8\u4f3c\u7684\u5217\u547d\u540d\u89c4\u5219\u3002</p> <ul> <li> <p>\u57fa\u7840\u60c5\u51b5 (\u65e0\u626b\u63cf\u53c2\u6570):     \u5982\u679c <code>simulation_parameters</code> \u4e3a\u7a7a\uff0c\u5217\u540d\u5c31\u662f <code>variableFilter</code> \u4e2d\u5b9a\u4e49\u7684\u53d8\u91cf\u540d\u3002     <pre><code>time,sds.I[1],blanket.I[1],...\n0.0,10.5,2.3,...\n</code></pre></p> </li> <li> <p>\u53c2\u6570\u626b\u63cf\u60c5\u51b5:     \u5f53 <code>simulation_parameters</code> \u4e0d\u4e3a\u7a7a\u65f6\uff0c\u5217\u540d\u4f1a\u9644\u52a0\u53c2\u6570\u4fe1\u606f\u3002     <pre><code>time,sds.I[1]&amp;blanket.TBR=1.05,sds.I[1]&amp;blanket.TBR=1.1,...\n</code></pre></p> <ul> <li>\u5217\u540d\u683c\u5f0f: <code>&lt;\u53d8\u91cf\u540d&gt;&amp;&lt;\u53c2\u65701&gt;=&lt;\u503c1&gt;&amp;&lt;\u53c2\u65702&gt;=&lt;\u503c2&gt;...</code></li> <li><code>time</code> \u5217\u4fdd\u6301\u4e0d\u53d8\u3002</li> <li>\u6bcf\u4e2a\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u6bcf\u4e2a\u53d8\u91cf\u90fd\u6210\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u5217\u3002\u5217\u540d\u7531 \u53d8\u91cf\u540d \u548c \u53c2\u6570-\u503c \u5bf9\u62fc\u63a5\u800c\u6210\uff0c\u5e76\u7528 <code>&amp;</code> \u7b26\u53f7\u5206\u9694\u3002</li> </ul> </li> </ul> \u95ee\uff1a\u5982\u4f55\u5b9a\u4e49\u590d\u6742\u7684\u53c2\u6570\u626b\u63cf\uff1f <p>TRICYS \u652f\u6301\u591a\u79cd\u53c2\u6570\u626b\u63cf\u683c\u5f0f\uff1a</p> \u529f\u80fd \u683c\u5f0f \u793a\u4f8b \u8bf4\u660e \u79bb\u6563\u5217\u8868 <code>[v1, v2, ...]</code> <code>[6, 12, 18]</code> \u4e00\u7ec4\u79bb\u6563\u503c \u7b49\u5dee\u5e8f\u5217 <code>\"start:stop:step\"</code> <code>\"1.05:1.15:0.05\"</code> \u8d77\u59cb\u503c\u3001\u7ec8\u6b62\u503c\u3001\u6b65\u957f \u7ebf\u6027\u95f4\u9694 <code>\"linspace:start:stop:num\"</code> <code>\"linspace:10:20:5\"</code> \u751f\u6210 <code>num</code> \u4e2a\u7b49\u95f4\u8ddd\u70b9 \u5bf9\u6570\u95f4\u9694 <code>\"log:start:stop:num\"</code> <code>\"log:1:1000:4\"</code> \u751f\u6210 <code>num</code> \u4e2a\u5bf9\u6570\u5c3a\u5ea6\u7684\u70b9 \u4ece\u6587\u4ef6\u8bfb\u53d6 <code>\"file:path:column\"</code> <code>\"file:data.csv:voltage\"</code> \u4ece CSV \u6587\u4ef6\u7684\u6307\u5b9a\u5217\u8bfb\u53d6 <p>\u793a\u4f8b\u914d\u7f6e\uff1a <pre><code>{\n    \"simulation_parameters\": {\n        \"blanket.TBR\": [1.05, 1.1, 1.15, 1.2],\n        \"plasma.fb\": \"linspace:0.01:0.1:10\",\n        \"tep_fep.to_SDS_Fraction[1]\": \"log:0.1:1.0:5\"\n    }\n}\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u8fc7\u6ee4\u8f93\u51fa\u53d8\u91cf\uff1f <p>\u4f7f\u7528 <code>variableFilter</code> \u53c2\u6570\u6765\u9009\u62e9\u9700\u8981\u4fdd\u5b58\u7684\u53d8\u91cf\u3002\u8be5\u53c2\u6570\u652f\u6301\u6b63\u5219\u8868\u8fbe\u5f0f\uff0c\u4f46\u8bf7\u6ce8\u610f\u5176\u8bed\u6cd5\u4ee5\u5339\u914dModelica\u53d8\u91cf\u547d\u540d\u89c4\u5219\u3002</p> <p>\u914d\u7f6e\u793a\u4f8b\uff1a</p> <pre><code>{\n    \"simulation\": {\n        \"variableFilter\": \"time|sds.I[1]|blanket.I[1-5]|div.I[1-5]\"\n    }\n}\n</code></pre> <p>\u5e38\u7528\u6a21\u5f0f\uff1a *   <code>time</code>\uff1a\u65f6\u95f4\u53d8\u91cf\uff08\u5fc5\u987b\u5305\u542b\uff09 *   <code>sds.I[1]</code>\uff1a\u7cbe\u786e\u5339\u914d\u5355\u4e2a\u53d8\u91cf *   <code>sds.I[1-5]</code>\uff1a\u5339\u914d\u6570\u7ec4\u53d8\u91cf <code>sds.I[1]</code> \u5230 <code>sds.I[5]</code> *   <code>blanket.I[1-5]|div.I[1-5]</code>\uff1a\u5339\u914d\u591a\u4e2a\u7279\u5b9a\u6570\u7ec4\u53d8\u91cf</p> \u95ee\uff1a\u4eff\u771f\u65f6\u95f4\u5f88\u957f\uff0c\u5982\u4f55\u52a0\u901f\uff1f <p>\u53ef\u4ee5\u91c7\u53d6\u4ee5\u4e0b\u4f18\u5316\u63aa\u65bd\uff1a</p> <p>1. \u542f\u7528\u5e76\u53d1\u8fd0\u884c\uff1a <pre><code>{\n    \"simulation\": {\n        \"concurrent\": true,\n        \"max_workers\": 4\n    }\n}\n</code></pre></p> <p>2. \u51cf\u5c11\u8f93\u51fa\u53d8\u91cf\uff1a <pre><code>{\n    \"simulation\": {\n        \"variableFilter\": \"time|sds.I[1]\"  # \u53ea\u4fdd\u5b58\u5173\u952e\u53d8\u91cf\n    }\n}\n</code></pre></p> <p>3. \u589e\u5927\u65f6\u95f4\u6b65\u957f\uff08\u6743\u8861\u7cbe\u5ea6\uff09\uff1a <pre><code>{\n    \"simulation\": {\n        \"step_size\": 1.0  # \u4ece 0.5 \u589e\u52a0\u5230 1.0\n    }\n}\n</code></pre></p> <p>4. \u51cf\u5c11\u626b\u63cf\u70b9\u6570\uff1a <pre><code>{\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1.05:1.15:5\"  # \u4ece 20 \u51cf\u5c11\u5230 5\n    }\n}\n</code></pre></p>"},{"location":"questions/installation.html","title":"\ud83d\ude80 \u5b89\u88c5\u73af\u5883","text":"\u95ee\uff1a\u652f\u6301\u54ea\u4e9b\u64cd\u4f5c\u7cfb\u7edf\uff1f <p>TRICYS \u652f\u6301\u4ee5\u4e0b\u64cd\u4f5c\u7cfb\u7edf\uff1a</p> <ul> <li>Windows 10/11\uff08\u63a8\u8350\u4f7f\u7528 WSL2 + Docker\uff09</li> <li>Ubuntu 20.04+</li> <li>CentOS/Rocky Linux 8+</li> <li>macOS\uff08\u901a\u8fc7 Docker\uff09</li> </ul> \u95ee\uff1a\u5fc5\u987b\u4f7f\u7528 Docker \u5417\uff1f <p>\u4e0d\u662f\u5fc5\u987b\u7684\u3002Docker \u63d0\u4f9b\u4e86\u6700\u7b80\u4fbf\u7684\u5b89\u88c5\u65b9\u5f0f\uff0c\u4f46\u60a8\u4e5f\u53ef\u4ee5\uff1a</p> <ul> <li>\u5728 Windows \u4e0a\u672c\u5730\u5b89\u88c5\uff08\u9700\u8981\u5b89\u88c5 OpenModelica \u548c Python\uff09</li> <li>\u5728 Linux \u4e0a\u672c\u5730\u5b89\u88c5</li> <li>\u4f7f\u7528 WSL2\uff08Windows Subsystem for Linux\uff09</li> </ul> <p>Docker \u7684\u4f18\u52bf\u662f\u73af\u5883\u9694\u79bb\u548c\u5f00\u7bb1\u5373\u7528\uff0c\u9002\u5408\u521d\u5b66\u8005\u3002</p> \u95ee\uff1a\u9700\u8981\u4ec0\u4e48\u7248\u672c\u7684 Python\uff1f <p>TRICYS \u8981\u6c42 Python 3.8 \u6216\u66f4\u9ad8\u7248\u672c\u3002\u63a8\u8350\u4f7f\u7528 Python 3.10 \u6216 3.11 \u4ee5\u83b7\u5f97\u6700\u4f73\u6027\u80fd\u548c\u517c\u5bb9\u6027\u3002</p> \u95ee\uff1aOpenModelica \u662f\u5fc5\u9700\u7684\u5417\uff1f <p>\u662f\u7684\u3002TRICYS \u4f7f\u7528 OpenModelica \u4f5c\u4e3a\u5efa\u6a21\u548c\u4eff\u771f\u540e\u7aef\u3002\u8bf7\u786e\u4fdd\uff1a</p> <ol> <li>\u5df2\u5b89\u88c5 OpenModelica</li> <li><code>omc</code> \u547d\u4ee4\u53ef\u5728\u547d\u4ee4\u884c\u4e2d\u8bbf\u95ee\uff08\u5df2\u6dfb\u52a0\u5230 PATH\uff09</li> </ol> <p>\u9a8c\u8bc1\u65b9\u6cd5\uff1a <pre><code>omc --version\n</code></pre></p> \u95ee\uff1a\u5982\u4f55\u89e3\u51b3\\\"\u627e\u4e0d\u5230 omc \u547d\u4ee4\\\"\u7684\u9519\u8bef\uff1f <p>Windows\uff1a 1. \u786e\u8ba4 OpenModelica \u5b89\u88c5\u8def\u5f84\uff08\u901a\u5e38\u662f <code>C:\\OpenModelica\\bin</code>\uff09 2. \u6dfb\u52a0\u5230\u7cfb\u7edf\u73af\u5883\u53d8\u91cf PATH 3. \u91cd\u542f\u7ec8\u7aef\u6216 VSCode</p> <p>Linux\uff1a <pre><code># \u68c0\u67e5 omc \u4f4d\u7f6e\nwhich omc\n\n# \u5982\u679c\u672a\u627e\u5230\uff0c\u6dfb\u52a0\u5230 PATH\nexport PATH=\"/opt/openmodelica/bin:$PATH\"\n\n# \u6216\u8005\u6c38\u4e45\u6dfb\u52a0\u5230 ~/.bashrc\necho 'export PATH=\"/opt/openmodelica/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre></p> \u95ee\uff1aDocker \u955c\u50cf\u4e0b\u8f7d\u5f88\u6162\u600e\u4e48\u529e\uff1f <p>\u53ef\u4ee5\u4f7f\u7528\u56fd\u5185\u7684 Docker \u955c\u50cf\u52a0\u901f\u5668\uff1a</p> <pre><code># \u7f16\u8f91 Docker \u914d\u7f6e\uff08Linux\uff09\nsudo nano /etc/docker/daemon.json\n\n# \u6dfb\u52a0\u955c\u50cf\u52a0\u901f\u5730\u5740\n{\n  \"registry-mirrors\": [\n    \"https://docker.mirrors.ustc.edu.cn\",\n    \"https://hub-mirror.c.163.com\"\n  ]\n}\n\n# \u91cd\u542f Docker\nsudo systemctl restart docker\n</code></pre> \u95ee\uff1a\u9879\u76ee\u4e2d\u7684 <code>Makefile</code> \u548c <code>Makefile.bat</code> \u662f\u505a\u4ec0\u4e48\u7528\u7684\uff1f <p><code>Makefile</code> (\u9002\u7528\u4e8e Linux/macOS) \u548c <code>Makefile.bat</code> (\u9002\u7528\u4e8e Windows) \u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u5feb\u6377\u547d\u4ee4\u6765\u7b80\u5316\u5e38\u89c1\u7684\u5f00\u53d1\u4efb\u52a1\uff0c\u4f8b\u5982\u5b89\u88c5\u3001\u6e05\u7406\u548c\u6d4b\u8bd5\u3002</p> <p>\u5e38\u7528\u547d\u4ee4:</p> <ul> <li> <p>\u5b89\u88c5\u4f9d\u8d56:     <pre><code># (Linux/macOS)\nmake dev-install\n\n# (Windows)\nMakefile.bat dev-install\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u5b89\u88c5\u9879\u76ee\u7684\u6240\u6709\u5f00\u53d1\u4f9d\u8d56\u3002</p> </li> <li> <p>\u4ee3\u7801\u683c\u5f0f\u5316\u4e0e\u68c0\u67e5:     <pre><code># (Linux/macOS)\nmake check\n\n# (Windows)\nMakefile.bat check\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u81ea\u52a8\u683c\u5f0f\u5316\u4ee3\u7801\u5e76\u8fd0\u884c\u9759\u6001\u68c0\u67e5\u3002</p> </li> <li> <p>\u8fd0\u884c\u6d4b\u8bd5:     <pre><code># (Linux/macOS)\nmake test\n\n# (Windows)\nMakefile.bat test\n</code></pre></p> </li> <li> <p>\u6e05\u7406\u9879\u76ee:     <pre><code># (Linux/macOS)\nmake clean\n\n# (Windows)\nMakefile.bat clean\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u5220\u9664\u6240\u6709\u6784\u5efa\u7f13\u5b58\u548c\u4e34\u65f6\u6587\u4ef6\u3002</p> </li> </ul> <p>\u4f7f\u7528\u8fd9\u4e9b\u547d\u4ee4\u53ef\u4ee5\u5e2e\u52a9\u60a8\u4fdd\u6301\u5f00\u53d1\u73af\u5883\u7684\u4e00\u81f4\u6027\u3002\u66f4\u591a\u547d\u4ee4\u8bf7\u67e5\u770b\u6587\u4ef6\u5185\u5bb9\u6216\u4f7f\u7528 <code>make help</code> / <code>Makefile.bat help</code>\u3002</p> \u95ee\uff1a\u5982\u4f55\u624d\u80fd\u5728\u672c\u5730\u67e5\u770b\u548c\u6784\u5efa\u6587\u6863\uff1f <p>\u9879\u76ee\u4f7f\u7528 MkDocs \u548c Material for MkDocs \u4e3b\u9898\u6765\u751f\u6210\u6587\u6863\u3002\u6211\u4eec\u5df2\u7ecf\u901a\u8fc7 <code>Makefile</code> \u548c <code>Makefile.bat</code> \u63d0\u4f9b\u4e86\u5feb\u6377\u547d\u4ee4\u3002</p> <p>\u6b65\u9aa4\u5982\u4e0b:</p> <ol> <li> <p>\u5b89\u88c5\u6587\u6863\u4f9d\u8d56:     <pre><code># (Linux/macOS)\nmake docs-install\n\n# (Windows)\nMakefile.bat docs-install\n</code></pre></p> </li> <li> <p>\u542f\u52a8\u672c\u5730\u9884\u89c8\u670d\u52a1\u5668:     <pre><code># (Linux/macOS)\nmake docs-serve\n\n# (Windows)\nMakefile.bat docs-serve\n</code></pre>     \u6b64\u547d\u4ee4\u4f1a\u542f\u52a8\u4e00\u4e2a\u672c\u5730\u670d\u52a1\u5668\uff08\u901a\u5e38\u5728 <code>http://127.0.0.1:18000</code>\uff09\uff0c\u5e76\u4e14\u5f53\u60a8\u4fee\u6539\u6587\u6863\u6e90\u6587\u4ef6\u65f6\uff0c\u7f51\u9875\u4f1a\u81ea\u52a8\u5237\u65b0\u3002</p> </li> <li> <p>\u6784\u5efa\u9759\u6001\u7f51\u7ad9 (\u53ef\u9009):     <pre><code># (Linux/macOS)\nmake docs-build\n\n# (Windows)\nMakefile.bat docs-build\n</code></pre>     \u5982\u679c\u60a8\u60f3\u751f\u6210\u5b8c\u6574\u7684\u9759\u6001 HTML \u6587\u4ef6\uff08\u4f8b\u5982\u7528\u4e8e\u90e8\u7f72\uff09\uff0c\u53ef\u4ee5\u8fd0\u884c\u6b64\u547d\u4ee4\u3002\u751f\u6210\u7684\u6587\u4ef6\u4f4d\u4e8e <code>site/</code> \u76ee\u5f55\u4e0b\u3002</p> </li> </ol>"},{"location":"questions/troubleshooting.html","title":"\ud83d\udc1b \u6545\u969c\u6392\u9664","text":"\u95ee\uff1a\u4eff\u771f\u5931\u8d25\uff0c\u5982\u4f55\u8c03\u8bd5\uff1f <p>1. \u67e5\u770b\u65e5\u5fd7\u6587\u4ef6\uff1a <pre><code># \u67e5\u770b\u6700\u65b0\u8fd0\u884c\u7684\u65e5\u5fd7\ntail -f results/&lt;timestamp&gt;/simulation_*.log\n</code></pre></p> <p>2. \u5e38\u89c1\u9519\u8bef\u53ca\u89e3\u51b3\u65b9\u6cd5\uff1a</p> \u9519\u8bef\u4fe1\u606f \u53ef\u80fd\u539f\u56e0 \u89e3\u51b3\u65b9\u6cd5 <code>Model not found</code> \u6a21\u578b\u8def\u5f84\u9519\u8bef \u68c0\u67e5 <code>package_path</code> \u662f\u5426\u6b63\u786e <code>Failed to compile</code> Modelica \u8bed\u6cd5\u9519\u8bef \u5728 OMEdit \u4e2d\u6253\u5f00\u6a21\u578b\u68c0\u67e5\u9519\u8bef <code>Variable not found</code> <code>variableFilter</code> \u4e2d\u7684\u53d8\u91cf\u4e0d\u5b58\u5728 \u68c0\u67e5\u53d8\u91cf\u540d\u62fc\u5199\uff0c\u4f7f\u7528\u6b63\u786e\u7684\u8def\u5f84 <code>Out of memory</code> \u5e76\u53d1\u8fdb\u7a0b\u8fc7\u591a\u6216\u6a21\u578b\u592a\u5927 \u51cf\u5c11 <code>max_workers</code> \u6216\u589e\u52a0\u7cfb\u7edf\u5185\u5b58 <code>Permission denied</code> \u6587\u4ef6\u6743\u9650\u95ee\u9898 \u68c0\u67e5\u5de5\u4f5c\u76ee\u5f55\u7684\u8bfb\u5199\u6743\u9650 <p>3. \u542f\u7528\u8be6\u7ec6\u65e5\u5fd7\uff1a <pre><code>{\n    \"logging\": {\n        \"level\": \"DEBUG\"\n    }\n}\n</code></pre></p> \u95ee\uff1aGUI \u65e0\u6cd5\u542f\u52a8\u6216\u663e\u793a\u4e0d\u6b63\u5e38\uff1f <p>Windows/Linux \u672c\u5730\uff1a * \u786e\u4fdd\u5b89\u88c5\u4e86 Tkinter\uff1a<code>pip install tk</code> * \u68c0\u67e5\u663e\u793a\u73af\u5883\u53d8\u91cf\uff1a<code>echo $DISPLAY</code></p> <p>Docker \u5bb9\u5668\uff1a * Windows 11\uff1a\u786e\u4fdd WSL2 \u7684 WSLg \u529f\u80fd\u5df2\u542f\u7528 * Linux\uff1a\u8fd0\u884c <code>xhost +local:</code> \u5141\u8bb8\u5bb9\u5668\u8bbf\u95ee X11 * \u4f7f\u7528\u5305\u542b GUI \u652f\u6301\u7684\u955c\u50cf\uff1a<code>tricys_openmodelica_gui</code></p> \u95ee\uff1a\u53c2\u6570\u626b\u63cf\u7ed3\u679c\u4e0d\u5b8c\u6574\uff1f <p>\u53ef\u80fd\u7684\u539f\u56e0\uff1a</p> <ol> <li>\u67d0\u4e9b\u4eff\u771f\u5931\u8d25\uff1a</li> <li>\u67e5\u770b\u65e5\u5fd7\u6587\u4ef6\u4e2d\u7684\u9519\u8bef\u4fe1\u606f</li> <li> <p>\u68c0\u67e5\u53c2\u6570\u503c\u662f\u5426\u5408\u7406\uff08\u5982\u907f\u514d\u9664\u96f6\u3001\u8d1f\u503c\u7b49\uff09</p> </li> <li> <p>\u8f93\u51fa\u53d8\u91cf\u8fc7\u6ee4\u5668\u592a\u4e25\u683c\uff1a</p> </li> <li> <p>\u68c0\u67e5 <code>variableFilter</code> \u662f\u5426\u5339\u914d\u4e86\u6240\u9700\u53d8\u91cf</p> </li> <li> <p>\u5e76\u53d1\u95ee\u9898\uff1a</p> </li> <li>\u5c1d\u8bd5\u7981\u7528\u5e76\u53d1\uff1a<code>\"concurrent\": false</code></li> <li>\u67e5\u770b\u662f\u5426\u6709\u8fdb\u7a0b\u5d29\u6e83</li> </ol> \u95ee\uff1a\u5982\u4f55\u62a5\u544a Bug\uff1f <p>\u8bf7\u5728 GitHub Issues \u4e2d\u521b\u5efa\u65b0 Issue\uff0c\u5e76\u63d0\u4f9b\uff1a</p> <ol> <li>\u73af\u5883\u4fe1\u606f\uff1a</li> <li>\u64cd\u4f5c\u7cfb\u7edf\u548c\u7248\u672c</li> <li>Python \u7248\u672c</li> <li>OpenModelica \u7248\u672c</li> <li> <p>TRICYS \u7248\u672c</p> </li> <li> <p>\u91cd\u73b0\u6b65\u9aa4\uff1a</p> </li> <li>\u5b8c\u6574\u7684\u914d\u7f6e\u6587\u4ef6</li> <li>\u8fd0\u884c\u7684\u547d\u4ee4</li> <li> <p>\u4f7f\u7528\u7684\u6a21\u578b\uff08\u5982\u679c\u53ef\u80fd\uff09</p> </li> <li> <p>\u9519\u8bef\u4fe1\u606f\uff1a</p> </li> <li>\u5b8c\u6574\u7684\u9519\u8bef\u5806\u6808</li> <li> <p>\u76f8\u5173\u7684\u65e5\u5fd7\u7247\u6bb5</p> </li> <li> <p>\u9884\u671f\u884c\u4e3a\uff1a</p> </li> <li>\u60a8\u671f\u671b\u53d1\u751f\u4ec0\u4e48</li> <li>\u5b9e\u9645\u53d1\u751f\u4e86\u4ec0\u4e48</li> </ol>"}]}