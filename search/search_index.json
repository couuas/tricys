{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\u4e3b\u9875","text":"<p>Hello</p>"},{"location":"explanation/","title":"\u539f\u7406\u89e3\u8bf4\uff08Explanation)","text":""},{"location":"explanation/#_1","title":"\u6838\u5fc3\u5de5\u4f5c\u6d41","text":"<p><code>tricys</code> \u4e3b\u8981\u652f\u6301\u4e24\u79cd\u5de5\u4f5c\u6d41\u7a0b\uff1a</p> <ol> <li> <p>\u6807\u51c6\u53c2\u6570\u626b\u63cf (Standard Parameter Sweep):</p> <ul> <li>\u76ee\u7684: \u7814\u7a76\u4e00\u4e2a\u6216\u591a\u4e2a\u6a21\u578b\u53c2\u6570\u53d8\u5316\u5bf9\u7cfb\u7edf\u884c\u4e3a\u7684\u5f71\u54cd\u3002</li> <li>\u65b9\u5f0f: <code>tricys</code> \u81ea\u52a8\u751f\u6210\u6240\u6709\u53c2\u6570\u7ec4\u5408\uff0c\u5e76\u884c\u6216\u987a\u5e8f\u5730\u6267\u884c\u6bcf\u4e00\u6b21\u4eff\u771f\uff0c\u5e76\u6700\u540e\u6c47\u603b\u7ed3\u679c\u3002</li> </ul> </li> <li> <p>\u6df7\u5408\u534f\u540c\u4eff\u771f (Hybrid Co-Simulation):</p> <ul> <li>\u76ee\u7684: \u96c6\u6210\u5916\u90e8\u7a0b\u5e8f\uff08\u5982 Aspen Plus\u3001MATLAB\u3001Python\u811a\u672c\uff09\uff0c\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u7cfb\u7edf\u7ea7\u4eff\u771f\u3002</li> <li>\u65b9\u5f0f: \u901a\u8fc7\u201c\u8fd0\u884c-\u5904\u7406-\u518d\u8fd0\u884c\u201d\u7684\u6d41\u7a0b\u3002<code>tricys</code> \u9996\u5148\u8fd0\u884c\u4e00\u6b21\u521d\u6b65\u4eff\u771f\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u4ea4\u7ed9\u7528\u6237\u5b9a\u4e49\u7684\u201c\u5904\u7406\u5668\u201d(Handler)\u8fdb\u884c\u5916\u90e8\u8ba1\u7b97\uff0c\u6700\u540e\u5c06\u5904\u7406\u5668\u7684\u7ed3\u679c\u201c\u6ce8\u5165\u201d\u56de Modelica \u6a21\u578b\uff0c\u8fd0\u884c\u4e00\u6b21\u6700\u7ec8\u7684\u5b8c\u6574\u4eff\u771f\u3002</li> </ul> </li> </ol>"},{"location":"explanation/#cli","title":"\u547d\u4ee4\u884c (CLI) \u5de5\u4f5c\u6d41\u7a0b\u56fe","text":"<pre><code>graph TB\n    Start[\u7a0b\u5e8f\u542f\u52a8] --&gt; LoadConfig[\u52a0\u8f7dJSON\u914d\u7f6e]\n    LoadConfig --&gt; GenJobs[\u751f\u6210\u4eff\u771f\u4efb\u52a1\u5217\u8868]\n    GenJobs --&gt; CheckCoSim{\u534f\u540c\u4eff\u771f?}\n\n    CheckCoSim --&gt;|\u662f| CoSimPath[\u534f\u540c\u4eff\u771f\u6d41\u7a0b]\n    CheckCoSim --&gt;|\u5426| StdSimPath[\u6807\u51c6\u4eff\u771f\u6d41\u7a0b]\n\n    StdSimPath --&gt; CheckConcurrent1{\u5e76\u53d1?}\n    CheckConcurrent1 --&gt;|\u662f| ConcurrentRun[\u5e76\u884c\u6267\u884c\u6240\u6709\u4efb\u52a1]\n    CheckConcurrent1 --&gt;|\u5426| SequentialRun[\u987a\u5e8f\u6267\u884c\u6240\u6709\u4efb\u52a1]\n\n    CoSimPath --&gt; CheckConcurrent2{\u5e76\u53d1?}\n    CheckConcurrent2 --&gt;|\u662f| ConcurrentCoSim[\u5e76\u884c\u6267\u884c\u534f\u540c\u4eff\u771f]\n    CheckConcurrent2 --&gt;|\u5426| SequentialCoSim[\u987a\u5e8f\u6267\u884c\u534f\u540c\u4eff\u771f]\n\n    ConcurrentRun --&gt; RunSingleJob[_run_single_job]\n    SequentialRun --&gt; RunSingleJob\n\n    ConcurrentCoSim --&gt; RunCoSim[_run_co_simulation]\n    SequentialCoSim --&gt; RunCoSim\n\n    RunSingleJob --&gt; Simulate[OMC\u6267\u884c\u4eff\u771f]\n\n    RunCoSim --&gt; SimulatePrimary[1. \u8fd0\u884c\u521d\u6b65\u4eff\u771f]\n    SimulatePrimary --&gt; CallHandlers[2. \u8c03\u7528\u5916\u90e8Handler]\n    CallHandlers --&gt; IntegrateInterceptor[3. \u52a8\u6001\u751f\u6210\u96c6\u6210\u6a21\u578b]\n    IntegrateInterceptor --&gt; FinalSimulation[4. \u8fd0\u884c\u6700\u7ec8\u4eff\u771f]\n\n    Simulate --&gt; CollectResults[\u6536\u96c6\u7ed3\u679c]\n    FinalSimulation --&gt; CollectResults\n\n    CollectResults --&gt; PostProcess{\u6709\u540e\u5904\u7406?}\n    PostProcess --&gt;|\u662f| RunPostProcess[\u6267\u884c\u540e\u5904\u7406\u811a\u672c]\n    PostProcess --&gt;|\u5426| End[\u7ed3\u675f]\n    RunPostProcess --&gt; End\n\n    style Start fill:#90EE90\n    style End fill:#FFB6C1\n    style RunCoSim fill:#DDA0DD\n    style RunSingleJob fill:#DDA0DD</code></pre>"},{"location":"guides/","title":"\u64cd\u4f5c\u6307\u5357\uff08Q&amp;A\uff09","text":""},{"location":"guides/#_1","title":"\u5982\u4f55\u8fd0\u884c\u4eff\u771f\uff1f","text":"<p><code>tricys</code> \u63d0\u4f9b\u547d\u4ee4\u884c (CLI) \u548c\u56fe\u5f62\u754c\u9762 (GUI) \u4e24\u79cd\u65b9\u5f0f\u3002</p> <ul> <li>CLI (\u547d\u4ee4\u884c):</li> <li>\u57fa\u7840\u548c\u534f\u540c\u4eff\u771f: <code>tricys -c &lt;your_config.json&gt;</code></li> <li>\u9ad8\u7ea7\u654f\u611f\u6027\u5206\u6790: <code>tricys-ana -c &lt;your_analysis_config.json&gt;</code></li> </ul> <p>CLI\u6a21\u5f0f\u901a\u8fc7JSON\u914d\u7f6e\u6587\u4ef6\u9a71\u52a8\uff0c\u9002\u5408\u81ea\u52a8\u5316\u548c\u6279\u91cf\u4efb\u52a1\u3002</p> <ul> <li>GUI (\u56fe\u5f62\u754c\u9762):</li> <li>\u542f\u52a8\u547d\u4ee4: <code>tricys-gui</code></li> <li>\u6838\u5fc3\u6b65\u9aa4:<ol> <li>\u8bbe\u7f6e\u5de5\u4f5c\u533a: \u542f\u52a8\u540e\uff0c\u9996\u5148\u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\u3002</li> <li>\u52a0\u8f7d\u6a21\u578b: \u586b\u5199\u6a21\u578b\u8def\u5f84 (<code>package.mo</code>) \u548c\u6570\u636e\u5e93\u8def\u5f84 (<code>.db</code>)\uff0c\u7136\u540e\u70b9\u51fb <code>Load Model to DB</code>\u3002\u53c2\u6570\u8868\u683c\u5c06\u88ab\u586b\u5145\u3002</li> <li>\u5b9a\u4e49\u626b\u63cf: \u5728\u53c2\u6570\u8868\u683c\u7684 <code>Sweep Value</code> \u5217\u4e2d\u586b\u5165\u626b\u63cf\u503c\uff08\u5982 <code>[1,2,3]</code> \u6216 <code>\"linspace:1:10:5\"</code>\uff09\u3002</li> <li>\u8fd0\u884c: \u70b9\u51fb <code>Run Simulation</code>\u3002</li> <li>\u76d1\u63a7: \u70b9\u51fb <code>Open the log window</code> \u67e5\u770b\u5b9e\u65f6\u65e5\u5fd7\u3002</li> </ol> </li> </ul>"},{"location":"guides/#_2","title":"\u5982\u4f55\u7406\u89e3\u8f93\u51fa\u6587\u4ef6\uff1f","text":"<p>\u6bcf\u6b21\u8fd0\u884c\u90fd\u4f1a\u5728\u7ed3\u679c\u76ee\u5f55 (<code>results_dir</code>) \u5185\u521b\u5efa\u4e00\u4e2a\u4ee5\u65f6\u95f4\u6233\u547d\u540d\u7684\u5b50\u76ee\u5f55\uff0c\u5982 <code>results/20230901_103000/</code>\u3002</p> <ul> <li><code>simulation_result.csv</code>: \u5355\u6b21\u8fd0\u884c\u7684\u7ed3\u679c\uff0c\u5305\u542b\u53d8\u91cf\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6570\u636e\u3002</li> <li><code>sweep_results.csv</code>: \u53c2\u6570\u626b\u63cf\u7684\u6c47\u603b\u7ed3\u679c\u3002\u7b2c\u4e00\u5217\u662f\u65f6\u95f4\uff0c\u5176\u4f59\u5217\u662f\u6bcf\u6b21\u4eff\u771f\u8fd0\u884c\u7684\u7ed3\u679c\uff0c\u5217\u540d\u7531\u53c2\u6570\u540d\u548c\u503c\u6784\u6210\uff08\u5982 <code>blanket.TBR=1.1_i_iss.T=6</code>\uff09\u3002</li> <li><code>*_sensitivity_analysis.png</code>/<code>.csv</code>: \u654f\u611f\u6027\u5206\u6790\u751f\u6210\u7684\u56fe\u8868\u548c\u6570\u636e\u3002</li> <li><code>*_sobol_analysis.png</code>/<code>.csv</code>: Sobol\u5206\u6790\u7684\u7ed3\u679c\u3002</li> </ul>"},{"location":"guides/#_3","title":"\u5982\u4f55\u5b9a\u4e49\u590d\u6742\u7684\u53c2\u6570\u626b\u63cf\uff1f","text":"<p>\u5728JSON\u914d\u7f6e\u6587\u4ef6\u6216GUI\u7684<code>Sweep Value</code>\u8f93\u5165\u6846\u4e2d\uff0c\u652f\u6301\u591a\u79cd\u9ad8\u7ea7\u683c\u5f0f\uff1a</p> \u529f\u80fd \u683c\u5f0f \u793a\u4f8b \u8bf4\u660e \u5217\u8868 <code>[v1, v2, ...]</code> <code>[6, 12, 18]</code> \u4e00\u7ec4\u79bb\u6563\u503c\u3002 \u8303\u56f4 <code>\"start:stop:step\"</code> <code>\"1.05:1.15:0.05\"</code> \u7b49\u5dee\u5e8f\u5217\u3002 \u7ebf\u6027\u95f4\u9694 <code>\"linspace:start:stop:num\"</code> <code>\"linspace:10:20:5\"</code> <code>num</code> \u4e2a\u7b49\u95f4\u8ddd\u70b9\u3002 \u5bf9\u6570\u95f4\u9694 <code>\"log:start:stop:num\"</code> <code>\"log:1:1000:4\"</code> <code>num</code> \u4e2a\u5bf9\u6570\u5c3a\u5ea6\u7684\u70b9\u3002 \u4ece\u6587\u4ef6\u8bfb\u53d6 <code>\"file:path:column\"</code> <code>\"file:data.csv:voltage\"</code> \u4eceCSV\u6587\u4ef6\u7684\u6307\u5b9a\u5217\u8bfb\u53d6\u3002"},{"location":"reference/","title":"API\u53c2\u8003\uff08Reference\uff09","text":"<p><code>tricys</code> \u7684\u6838\u5fc3\u903b\u8f91\u5c01\u88c5\u5728 <code>tricys/</code> \u76ee\u5f55\u4e0b\u7684\u5404\u4e2a\u6a21\u5757\u4e2d\uff0c\u4e3a\u9ad8\u7ea7\u7528\u6237\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6269\u5c55\u80fd\u529b\u3002</p>"},{"location":"reference/#simulation","title":"\u4e3b\u7a0b\u5e8f\u4eff\u771f\u5165\u53e3 (Simulation)","text":""},{"location":"reference/#tricyssimulationsimulation","title":"<code>tricys.simulation.simulation</code>","text":""},{"location":"reference/#tricys.simulation.simulation.main","title":"<code>main(config_path)</code>","text":"<p>Main entry point for a standard simulation run.</p> <p>This function prepares the configuration, sets up logging, and calls the main <code>run_simulation</code> orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>The path to the JSON configuration file.</p> required Source code in <code>tricys/simulation/simulation.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point for a standard simulation run.\n\n    This function prepares the configuration, sets up logging, and calls\n    the main `run_simulation` orchestrator.\n\n    Args:\n        config_path (str): The path to the JSON configuration file.\n    \"\"\"\n    config, original_config = basic_prepare_config(config_path)\n    setup_logging(config, original_config)\n    logger.info(\n        \"Loading configuration\",\n        extra={\n            \"config_path\": os.path.abspath(config_path),\n        },\n    )\n    try:\n        run_simulation(config)\n        logger.info(\"Main execution completed successfully\")\n    except Exception as e:\n        logger.error(\n            \"Main execution failed\", exc_info=True, extra={\"exception\": str(e)}\n        )\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#tricys.simulation.simulation.run_simulation","title":"<code>run_simulation(config)</code>","text":"<p>Orchestrates the main simulation workflow.</p> <p>This function serves as the primary orchestrator for running simulations. It generates jobs from parameters, executes them (concurrently or sequentially, as standard or co-simulations), merges the results into a single DataFrame, and triggers any configured post-processing steps.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary for the run.</p> required Source code in <code>tricys/simulation/simulation.py</code> <pre><code>def run_simulation(config: Dict[str, Any]) -&gt; None:\n    \"\"\"Orchestrates the main simulation workflow.\n\n    This function serves as the primary orchestrator for running simulations.\n    It generates jobs from parameters, executes them (concurrently or sequentially,\n    as standard or co-simulations), merges the results into a single DataFrame,\n    and triggers any configured post-processing steps.\n\n    Args:\n        config (Dict[str, Any]): The main configuration dictionary for the run.\n    \"\"\"\n    jobs = generate_simulation_jobs(config.get(\"simulation_parameters\", {}))\n\n    try:\n        results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n    except KeyError as e:\n        logger.error(f\"Missing required path key in configuration file: {e}\")\n        sys.exit(1)\n\n    simulation_results = {}\n    use_concurrent = config[\"simulation\"].get(\"concurrent\", False)\n\n    try:\n        max_workers = config[\"simulation\"].get(\"max_workers\", os.cpu_count())\n        if config.get(\"co_simulation\") is None:\n            if use_concurrent:\n                logger.info(\n                    \"Starting simulation\",\n                    extra={\n                        \"mode\": \"CONCURRENT\",\n                        \"max_workers\": max_workers,\n                    },\n                )\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_single_job, config, job_params, i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            result_path = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n            else:\n                logger.info(\"Starting simulation\", extra={\"mode\": \"SEQUENTIAL\"})\n                result_paths = _run_sequential_sweep(config, jobs)\n                for i, result_path in enumerate(result_paths):\n                    if result_path:\n                        simulation_results[tuple(sorted(jobs[i].items()))] = result_path\n        else:\n            if use_concurrent:\n                logger.info(\n                    \"Starting co-simulation\",\n                    extra={\n                        \"mode\": \"CONCURRENT\",\n                        \"max_workers\": max_workers,\n                    },\n                )\n\n                with concurrent.futures.ProcessPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_co_simulation, config, job_params, job_id=i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            result_path = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                                logger.info(\n                                    \"Successfully finished co-simulation job\",\n                                    extra={\n                                        \"job_params\": job_params,\n                                    },\n                                )\n                            else:\n                                logger.warning(\n                                    \"Co-simulation job did not return a result path\",\n                                    extra={\n                                        \"job_params\": job_params,\n                                    },\n                                )\n                        except Exception as exc:\n                            logger.error(\n                                \"Co-simulation job generated an exception\",\n                                exc_info=True,\n                                extra={\n                                    \"job_params\": job_params,\n                                    \"exception\": str(exc),\n                                },\n                            )\n            else:\n                logger.info(\"Starting co-simulation\", extra={\"mode\": \"SEQUENTIAL\"})\n                for i, job_params in enumerate(jobs):\n                    job_id = i + 1\n                    logger.info(\n                        \"Starting Sequential Co-simulation Job\",\n                        extra={\n                            \"job_index\": f\"{job_id}/{len(jobs)}\",\n                        },\n                    )\n                    try:\n                        result_path = _run_co_simulation(\n                            config, job_params, job_id=job_id\n                        )\n                        if result_path:\n                            simulation_results[tuple(sorted(job_params.items()))] = (\n                                result_path\n                            )\n                            logger.info(\n                                \"Successfully finished co-simulation job\",\n                                extra={\n                                    \"job_params\": job_params,\n                                },\n                            )\n                        else:\n                            logger.warning(\n                                \"Co-simulation job did not return a result path\",\n                                extra={\n                                    \"job_params\": job_params,\n                                },\n                            )\n                    except Exception as exc:\n                        logger.error(\n                            \"Co-simulation job generated an exception\",\n                            exc_info=True,\n                            extra={\n                                \"job_params\": job_params,\n                                \"exception\": str(exc),\n                            },\n                        )\n                    logger.info(\n                        \"Finished Sequential Co-simulation Job\",\n                        extra={\n                            \"job_index\": f\"{job_id}/{len(jobs)}\",\n                        },\n                    )\n    except Exception as e:\n        raise RuntimeError(\"Failed to run simulation\", e)\n\n    # --- Result Handling ---\n    # The simulation_results dictionary now contains paths to results inside temporary job workspaces.\n    # The results_dir from the config is now the self-contained workspace's results folder.\n    run_results_dir = results_dir\n    os.makedirs(run_results_dir, exist_ok=True)\n\n    # Unified result processing for both single and multiple jobs\n    logger.info(\n        \"Processing jobs and combining results\",\n        extra={\n            \"num_jobs\": len(jobs),\n        },\n    )\n    combined_df = None\n\n    all_dfs = []\n    time_df_added = False\n\n    for job_params in jobs:\n        job_key = tuple(sorted(job_params.items()))\n        result_path = simulation_results.get(job_key)\n\n        if not result_path or not os.path.exists(result_path):\n            logger.warning(\n                \"Job produced no result file\",\n                extra={\n                    \"job_params\": job_params,\n                },\n            )\n            continue\n\n        # Read the current job's result file\n        df = pd.read_csv(result_path)\n\n        # From the very first valid DataFrame, grab the 'time' column\n        if not time_df_added and \"time\" in df.columns:\n            all_dfs.append(df[[\"time\"]])\n            time_df_added = True\n\n        # Prepare the parameter string for column renaming\n        param_string = \"&amp;\".join([f\"{k}={v}\" for k, v in job_params.items()])\n\n        # Isolate the data columns (everything except 'time')\n        data_columns = df.drop(columns=[\"time\"], errors=\"ignore\")\n\n        # Create a dictionary to map old column names to new ones\n        # e.g., {'voltage': 'voltage&amp;param1=A&amp;param2=B'}\n        rename_mapping = {\n            col: f\"{col}&amp;{param_string}\" if param_string else col\n            for col in data_columns.columns\n        }\n\n        # Rename the columns and add the resulting DataFrame to our list\n        all_dfs.append(data_columns.rename(columns=rename_mapping))\n\n    # Concatenate all the DataFrames in the list along the columns axis (axis=1)\n    if all_dfs:\n        combined_df = pd.concat(all_dfs, axis=1)\n    else:\n        combined_df = pd.DataFrame()  # Or None, as you had before\n\n    if combined_df is not None and not combined_df.empty:\n        if len(jobs) == 1:\n            # For single job, save as simulation_result.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"simulation_result.csv\"\n            )\n        else:\n            # For multiple jobs, save as sweep_results.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"sweep_results.csv\"\n            )\n\n        combined_df.to_csv(combined_csv_path, index=False)\n        logger.info(\n            \"Combined results saved\",\n            extra={\n                \"file_path\": combined_csv_path,\n            },\n        )\n    else:\n        logger.warning(\"No valid results found to combine\")\n\n    # --- Post-Processing ---\n    if combined_df is not None:\n        # Calculate the top-level post-processing directory\n        top_level_run_workspace = os.path.abspath(config[\"run_timestamp\"])\n        top_level_post_processing_dir = os.path.join(\n            top_level_run_workspace, \"post_processing\"\n        )\n        _run_post_processing(config, combined_df, top_level_post_processing_dir)\n    else:\n        logger.warning(\"No simulation results generated, skipping post-processing\")\n\n    # --- Final Cleanup ---\n    # The primary cleanup of job workspaces is handled by the `finally` block in `_run_co_simulation`.\n    # This is an additional safeguard.\n    if not config[\"simulation\"].get(\"keep_temp_files\", True):\n        temp_dir_path = os.path.abspath(config[\"paths\"].get(\"temp_dir\", \"temp\"))\n        logger.info(\n            \"Cleaning up temporary directory\",\n            extra={\n                \"directory\": temp_dir_path,\n            },\n        )\n        if os.path.exists(temp_dir_path):\n            try:\n                shutil.rmtree(temp_dir_path)\n                os.makedirs(temp_dir_path)  # Recreate for next run\n            except OSError as e:\n                logger.error(\n                    \"Error cleaning up temporary directory\",\n                    extra={\n                        \"directory\": temp_dir_path,\n                        \"error\": str(e),\n                    },\n                )\n</code></pre>"},{"location":"reference/#tricyssimulationsimulation_analysis","title":"<code>tricys.simulation.simulation_analysis</code>","text":""},{"location":"reference/#tricys.simulation.simulation_analysis.main","title":"<code>main(config_path)</code>","text":"<p>Main entry point for a simulation analysis run.</p> <p>This function prepares the configuration for an analysis run, sets up logging, and calls the main <code>run_simulation</code> orchestrator for analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>The path to the JSON configuration file.</p> required Source code in <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point for a simulation analysis run.\n\n    This function prepares the configuration for an analysis run, sets up\n    logging, and calls the main `run_simulation` orchestrator for analysis.\n\n    Args:\n        config_path (str): The path to the JSON configuration file.\n    \"\"\"\n    config, original_config = analysis_prepare_config(config_path)\n    setup_logging(config, original_config)\n    logger.info(\n        \"Loading configuration\",\n        extra={\n            \"config_path\": os.path.abspath(config_path),\n        },\n    )\n    try:\n        run_simulation(config)\n        logger.info(\"Main execution completed successfully\")\n    except Exception as e:\n        logger.error(\n            \"Main execution failed\", exc_info=True, extra={\"exception\": str(e)}\n        )\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#tricys.simulation.simulation_analysis.retry_analysis","title":"<code>retry_analysis(timestamp)</code>","text":"<p>Retries a failed AI analysis for a given run timestamp.</p> <p>This function restores the configuration from the log file of a previous run and re-triggers the AI-dependent parts of the analysis, including report generation and consolidation.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>str</code> <p>The timestamp of the run to retry (e.g., \"20230101_120000\").</p> required Source code in <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def retry_analysis(timestamp: str) -&gt; None:\n    \"\"\"Retries a failed AI analysis for a given run timestamp.\n\n    This function restores the configuration from the log file of a previous\n    run and re-triggers the AI-dependent parts of the analysis, including\n    report generation and consolidation.\n\n    Args:\n        timestamp (str): The timestamp of the run to retry (e.g., \"20230101_120000\").\n    \"\"\"\n    config, original_config = restore_configs_from_log(timestamp)\n    if not config or not original_config:\n        # Error is printed inside the helper function\n        sys.exit(1)\n\n    config[\"run_timestamp\"] = timestamp\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        stream=sys.stdout,\n    )\n    logger = logging.getLogger(__name__)\n    logger.info(\n        f\"Successfully restored configuration for timestamp {timestamp} for retry.\"\n    )\n\n    logger.info(\"Starting in AI analysis retry mode...\")\n    if not analysis_validate_config(config):\n        sys.exit(1)\n\n    case_configs = analysis_setup_analysis_cases_workspaces(config)\n    if not case_configs:\n        logger.error(\"Could not set up case workspaces for retry. Aborting.\")\n        sys.exit(1)\n\n    retry_ai_analysis(case_configs, config)\n    consolidate_reports(case_configs, config)\n\n    logger.info(\"AI analysis retry and consolidation complete.\")\n</code></pre>"},{"location":"reference/#tricys.simulation.simulation_analysis.run_simulation","title":"<code>run_simulation(config)</code>","text":"<p>Orchestrates the simulation analysis workflow.</p> <p>This is the main orchestrator for a simulation analysis run. It handles different execution paths based on the configuration: - If 'analysis_cases' are defined, it sets up and executes each case,   potentially in parallel. - If a SALib analysis is defined, it delegates to the SALib workflow. - Otherwise, it runs a standard parameter sweep, merges results,   generates plots, and triggers sensitivity analysis and post-processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary for the run.</p> required Source code in <code>tricys/simulation/simulation_analysis.py</code> <pre><code>def run_simulation(config: Dict[str, Any]) -&gt; None:\n    \"\"\"Orchestrates the simulation analysis workflow.\n\n    This is the main orchestrator for a simulation analysis run. It handles\n    different execution paths based on the configuration:\n    - If 'analysis_cases' are defined, it sets up and executes each case,\n      potentially in parallel.\n    - If a SALib analysis is defined, it delegates to the SALib workflow.\n    - Otherwise, it runs a standard parameter sweep, merges results,\n      generates plots, and triggers sensitivity analysis and post-processing.\n\n    Args:\n        config (Dict[str, Any]): The main configuration dictionary for the run.\n    \"\"\"\n\n    # 1. Split analysis_cases and determine salib_analysis_case\n    has_analysis_cases = (\n        \"sensitivity_analysis\" in config\n        and \"analysis_cases\" in config[\"sensitivity_analysis\"]\n        and (\n            # Support list format\n            (\n                isinstance(config[\"sensitivity_analysis\"][\"analysis_cases\"], list)\n                and len(config[\"sensitivity_analysis\"][\"analysis_cases\"]) &gt; 0\n            )\n            or\n            # Support single object format\n            isinstance(config[\"sensitivity_analysis\"][\"analysis_cases\"], dict)\n        )\n    )\n\n    # Check if it's a SALib analysis case (and not a multi-case analysis)\n    sa_config = config.get(\"sensitivity_analysis\", {})\n    analysis_case = sa_config.get(\"analysis_case\")\n\n    has_salib_analysis_case = (\n        not has_analysis_cases\n        and isinstance(analysis_case, dict)\n        and isinstance(analysis_case.get(\"independent_variable\"), list)\n        and isinstance(analysis_case.get(\"independent_variable_sampling\"), dict)\n        and \"analyzer\" in analysis_case\n    )\n\n    if has_analysis_cases and not has_salib_analysis_case:\n        logger.info(\n            \"Detected analysis_cases field, starting to create independent working directories for each analysis case...\"\n        )\n\n        # Create independent working directories and configuration files for each analysis_case\n        case_configs = analysis_setup_analysis_cases_workspaces(config)\n\n        if not case_configs:\n            logger.error(\n                \"Unable to create analysis_cases working directories, stopping execution\"\n            )\n            return\n\n        logger.info(f\"Starting execution of {len(case_configs)} analysis cases...\")\n\n        sa_config = config.get(\"sensitivity_analysis\", {})\n        run_cases_concurrently = sa_config.get(\"concurrent_cases\", False)\n        successful_cases = 0\n\n        if run_cases_concurrently:\n            logger.info(\n                f\"Starting execution of {len(case_configs)} analysis cases in PARALLEL.\"\n            )\n            max_workers = sa_config.get(\"max_case_workers\", os.cpu_count())\n            logger.info(\n                f\"Using up to {max_workers} parallel processes for analysis cases.\"\n            )\n\n            with concurrent.futures.ProcessPoolExecutor(\n                max_workers=max_workers\n            ) as executor:\n                future_to_case = {\n                    executor.submit(_execute_analysis_case, case_info): case_info\n                    for case_info in case_configs\n                }\n                for future in concurrent.futures.as_completed(future_to_case):\n                    case_info = future_to_case[future]\n                    case_name = case_info[\"case_data\"].get(\"name\", case_info[\"index\"])\n                    try:\n                        if future.result():\n                            successful_cases += 1\n                            logger.info(\n                                f\"Parallel case '{case_name}' completed successfully.\"\n                            )\n                        else:\n                            logger.warning(\n                                f\"Parallel case '{case_name}' completed with errors.\"\n                            )\n                    except Exception as exc:\n                        logger.error(\n                            f\"Parallel case '{case_name}' failed in executor with: {exc}\",\n                            exc_info=True,\n                        )\n        else:\n            logger.info(\n                f\"Starting execution of {len(case_configs)} analysis cases SEQUENTIALLY.\"\n            )\n            for case_info in case_configs:\n                try:\n                    case_index = case_info[\"index\"]\n                    case_workspace = case_info[\"workspace\"]\n                    case_config = case_info[\"config\"]\n                    case_data = case_info[\"case_data\"]\n\n                    logger.info(\n                        f\"\\n=== Starting execution of analysis case {case_index + 1}/{len(case_configs)} ===\"\n                    )\n                    logger.info(\n                        f\"Case name: {case_data.get('name', f'Case{case_index+1}')}\"\n                    )\n                    logger.info(\n                        f\"Independent variable: {case_data['independent_variable']}\"\n                    )\n                    logger.info(f\"Working directory: {case_workspace}\")\n\n                    original_cwd = os.getcwd()\n                    os.chdir(case_workspace)\n\n                    try:\n                        setup_logging(case_config)\n                        run_simulation(case_config)\n                        successful_cases += 1\n                        logger.info(\n                            f\"\u2713 Analysis case {case_index + 1} executed successfully\"\n                        )\n                    except Exception as case_e:\n                        logger.error(\n                            f\"\u2717 Analysis case {case_index + 1} execution failed: {case_e}\",\n                            exc_info=True,\n                        )\n                    finally:\n                        os.chdir(original_cwd)\n                        setup_logging(config)\n\n                except Exception as e:\n                    logger.error(\n                        f\"\u2717 Error processing analysis case {case_index + 1}: {e}\",\n                        exc_info=True,\n                    )\n\n        logger.info(\"\\n=== Analysis Cases Execution Completed ===\")\n        logger.info(\n            f\"Successfully executed: {successful_cases}/{len(case_configs)} cases\"\n        )\n\n        generate_analysis_cases_summary(case_configs, config)\n\n        return  # End analysis_cases processing\n    elif has_salib_analysis_case:\n        logger.info(\"Detected SALib analysis case, diverting to SALib workflow...\")\n        run_salib_analysis(config)\n        return  # SALib workflow is self-contained, so we exit here.\n\n    # 2. Core operational logic\n    jobs = generate_simulation_jobs(config.get(\"simulation_parameters\", {}))\n\n    # --- START: Add baseline jobs based on default parameter values ---\n    analysis_case = config.get(\"sensitivity_analysis\", {}).get(\"analysis_case\", {})\n    default_values = analysis_case.get(\"default_simulation_values\")\n\n    if default_values:\n        logger.info(\n            \"Found default_simulation_values, generating additional baseline jobs.\"\n        )\n\n        # Prepare simulation parameters for the baseline run, starting with default values\n        baseline_params = default_values.copy()\n\n        # Add the main independent variable sweep to the baseline parameters\n        independent_var = analysis_case.get(\"independent_variable\")\n        independent_sampling = analysis_case.get(\"independent_variable_sampling\")\n\n        if independent_var and independent_sampling:\n            baseline_params[independent_var] = independent_sampling\n\n            # Generate the additional jobs using the baseline config\n            default_jobs = generate_simulation_jobs(baseline_params)\n\n            # Combine with existing jobs and deduplicate\n            combined_jobs = jobs + default_jobs\n\n            # Deduplicate the list of job dictionaries\n            seen = set()\n            unique_jobs = []\n            for job in combined_jobs:\n                job_tuple = tuple(sorted(job.items()))\n                if job_tuple not in seen:\n                    seen.add(job_tuple)\n                    unique_jobs.append(job)\n\n            logger.info(\n                f\"Original jobs: {len(jobs)}, Combined jobs: {len(combined_jobs)}, Unique jobs after deduplication: {len(unique_jobs)}\"\n            )\n            jobs = unique_jobs\n    # --- END: Add baseline jobs ---\n\n    try:\n        results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n    except KeyError as e:\n        logger.error(f\"Missing required path key in configuration file: {e}\")\n        sys.exit(1)\n\n    simulation_results = {}\n    use_concurrent = config[\"simulation\"].get(\"concurrent\", False)\n\n    try:\n        if config.get(\"co_simulation\") is None:\n            if use_concurrent:\n                logger.info(\"Starting simulation in CONCURRENT mode.\")\n                max_workers = config[\"simulation\"].get(\"max_workers\", os.cpu_count())\n                logger.info(f\"Using up to {max_workers} parallel workers.\")\n                final_results = []\n                with concurrent.futures.ThreadPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_single_job, config, job_params, i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            (\n                                optimal_params,\n                                optimal_values,\n                                result_path,\n                            ) = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n\n                if _get_optimization_tasks(config):\n                    results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n                    os.makedirs(results_dir, exist_ok=True)\n                    if final_results:\n                        final_df = pd.DataFrame(final_results)\n                        output_path = os.path.join(\n                            results_dir, \"requierd_tbr_summary.csv\"\n                        )\n                        final_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n                        logger.info(\n                            f\"Sweep optimization summary saved to: {output_path}\"\n                        )\n            else:\n                logger.info(\"Starting simulation in SEQUENTIAL mode.\")\n                result_paths = _run_sequential_sweep(config, jobs)\n                for i, result_path in enumerate(result_paths):\n                    if result_path:\n                        simulation_results[tuple(sorted(jobs[i].items()))] = result_path\n        else:\n            if use_concurrent:\n                logger.info(\"Starting co-simulation in CONCURRENT mode.\")\n                max_workers = config[\"simulation\"].get(\"max_workers\", 4)\n                logger.info(f\"Using up to {max_workers} parallel processes.\")\n\n                final_results = []\n\n                with concurrent.futures.ProcessPoolExecutor(\n                    max_workers=max_workers\n                ) as executor:\n                    future_to_job = {\n                        executor.submit(\n                            _run_co_simulation, config, job_params, job_id=i + 1\n                        ): job_params\n                        for i, job_params in enumerate(jobs)\n                    }\n\n                    for future in concurrent.futures.as_completed(future_to_job):\n                        job_params = future_to_job[future]\n                        try:\n                            (\n                                optimal_params,\n                                optimal_values,\n                                result_path,\n                            ) = future.result()\n                            if result_path:\n                                simulation_results[\n                                    tuple(sorted(job_params.items()))\n                                ] = result_path\n                                logger.info(\n                                    f\"Successfully finished job for params: {job_params}\"\n                                )\n                            else:\n                                logger.warning(\n                                    f\"Job for params {job_params} did not return a result path.\"\n                                )\n                        except Exception as exc:\n                            logger.error(\n                                f\"Job for params {job_params} generated an exception: {exc}\",\n                                exc_info=True,\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n            else:\n                logger.info(\"Starting co-simulation in SEQUENTIAL mode.\")\n                final_results = []\n                for i, job_params in enumerate(jobs):\n                    job_id = i + 1\n                    logger.info(f\"--- Starting Sequential Job {job_id}/{len(jobs)} ---\")\n                    try:\n                        (\n                            optimal_params,\n                            optimal_values,\n                            result_path,\n                        ) = _run_co_simulation(config, job_params, job_id=job_id)\n                        if result_path:\n                            simulation_results[tuple(sorted(job_params.items()))] = (\n                                result_path\n                            )\n                            logger.info(\n                                f\"Successfully finished job for params: {job_params}\"\n                            )\n                        else:\n                            logger.warning(\n                                f\"Job for params {job_params} did not return a result path.\"\n                            )\n                        final_result_entry = job_params.copy()\n                        final_result_entry.update(optimal_params)\n                        final_result_entry.update(optimal_values)\n                        final_results.append(final_result_entry)\n                    except Exception as exc:\n                        logger.error(\n                            f\"Job for params {job_params} generated an exception: {exc}\",\n                            exc_info=True,\n                        )\n                    logger.info(f\"--- Finished Sequential Job {job_id}/{len(jobs)} ---\")\n\n            if _get_optimization_tasks(config):\n                results_dir = os.path.abspath(config[\"paths\"][\"results_dir\"])\n                os.makedirs(results_dir, exist_ok=True)\n                if final_results:\n                    final_df = pd.DataFrame(final_results)\n                    output_path = os.path.join(results_dir, \"requierd_tbr_summary.csv\")\n                    final_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n                    logger.info(f\"Sweep optimization summary saved to: {output_path}\")\n    except Exception as e:\n        raise RuntimeError(f\"Failed to run simualtion: {e}\")\n\n    # 3. Data merging and processing\n    run_results_dir = results_dir\n    os.makedirs(run_results_dir, exist_ok=True)\n\n    # Unified result processing for both single and multiple jobs\n    logger.info(f\"Processing {len(jobs)} job(s). Combining results.\")\n    combined_df = None\n\n    all_dfs = []\n    time_df_added = False\n\n    for job_params in jobs:\n        job_key = tuple(sorted(job_params.items()))\n        result_path = simulation_results.get(job_key)\n\n        if not result_path or not os.path.exists(result_path):\n            logger.warning(f\"Job {job_params} produced no result file. Skipping.\")\n            continue\n\n        # Read the current job's result file\n        df = pd.read_csv(result_path)\n\n        # From the very first valid DataFrame, grab the 'time' column\n        if not time_df_added and \"time\" in df.columns:\n            all_dfs.append(df[[\"time\"]])\n            time_df_added = True\n\n        # Prepare the parameter string for column renaming\n        param_string = \"&amp;\".join([f\"{k}={v}\" for k, v in job_params.items()])\n\n        # Isolate the data columns (everything except 'time')\n        data_columns = df.drop(columns=[\"time\"], errors=\"ignore\")\n\n        # Create a dictionary to map old column names to new ones\n        # e.g., {'voltage': 'voltage&amp;param1=A&amp;param2=B'}\n        rename_mapping = {\n            col: f\"{col}&amp;{param_string}\" if param_string else col\n            for col in data_columns.columns\n        }\n\n        # Rename the columns and add the resulting DataFrame to our list\n        all_dfs.append(data_columns.rename(columns=rename_mapping))\n\n    # Concatenate all the DataFrames in the list along the columns axis (axis=1)\n    if all_dfs:\n        combined_df = pd.concat(all_dfs, axis=1)\n    else:\n        combined_df = pd.DataFrame()  # Or None, as you had before\n\n    if combined_df is not None and not combined_df.empty:\n        if len(jobs) == 1:\n            # For single job, save as simulation_result.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"simulation_result.csv\"\n            )\n        else:\n            # For multiple jobs, save as sweep_results.csv\n            combined_csv_path = get_unique_filename(\n                run_results_dir, \"sweep_results.csv\"\n            )\n\n        # Clean up rows where the 'time' column is blank, which often occurs as redundant rows at the end of the file.\n        combined_df.dropna(subset=[\"time\"], inplace=True)\n        combined_df.to_csv(combined_csv_path, index=False)\n        logger.info(f\"Combined results saved to: {combined_csv_path}\")\n    else:\n        logger.warning(\"No valid results found to combine.\")\n\n    # Check if sweep_time plotting is enabled\n    analysis_case = config[\"sensitivity_analysis\"].get(\"analysis_case\", {})\n    sweep_time_list = analysis_case.get(\"sweep_time\", None)\n    if sweep_time_list and len(sweep_time_list) &gt;= 1:\n        # Get parameters for plot_sweep_time_series\n        independent_var = analysis_case.get(\"independent_variable\")\n        dependent_vars = analysis_case.get(\"dependent_variables\", [])\n        independent_var_alias = analysis_case.get(\"independent_variable_alias\")\n\n        if (\n            independent_var\n            and dependent_vars\n            and combined_csv_path\n            and os.path.exists(combined_csv_path)\n        ):\n\n            try:\n                # Get default values if they exist to filter the plot\n                default_values = analysis_case.get(\"default_simulation_values\")\n\n                plot_path = plot_sweep_time_series(\n                    csv_path=combined_csv_path,\n                    save_dir=run_results_dir,\n                    y_var_name=sweep_time_list,\n                    independent_var_name=independent_var,\n                    independent_var_alias=independent_var_alias,\n                    default_params=default_values,  # Pass default values to the plot function\n                    glossary_path=config[\"sensitivity_analysis\"].get(\n                        \"glossary_path\", None\n                    ),\n                )\n                if plot_path:\n                    logger.info(f\"Sweep time series plot generated: {plot_path}\")\n                else:\n                    logger.warning(\"Failed to generate sweep time series plot\")\n            except Exception as e:\n                logger.error(f\"Error generating sweep time series plot: {e}\")\n\n    # 4. Sensitivity analysis\n    _run_sensitivity_analysis(config, run_results_dir, jobs)\n\n    # 5. Post-processing\n    if combined_df is not None:\n        # Calculate the top-level post-processing directory\n        top_level_run_workspace = os.path.abspath(\"post_processing\")\n        _run_post_processing(config, combined_df, top_level_run_workspace)\n    else:\n        logger.warning(\n            \"No simulation results were generated, skipping post-processing.\"\n        )\n\n    # 6. Intermediate data cleaning\n    if not config[\"simulation\"].get(\"keep_temp_files\", True):\n        logger.info(\"Cleaning up temporary directory...\")\n        temp_dir_path = os.path.abspath(config[\"paths\"].get(\"temp_dir\", \"temp\"))\n        if os.path.exists(temp_dir_path):\n            try:\n                shutil.rmtree(temp_dir_path)\n                os.makedirs(temp_dir_path)  # Recreate for next run\n            except OSError as e:\n                logger.error(f\"Error cleaning up temp directory: {e}\")\n</code></pre>"},{"location":"reference/#core","title":"\u6838\u5fc3\u6a21\u5757 (Core)","text":""},{"location":"reference/#tricyscorejobs","title":"<code>tricys.core.jobs</code>","text":""},{"location":"reference/#tricys.core.jobs.generate_simulation_jobs","title":"<code>generate_simulation_jobs(simulation_params)</code>","text":"<p>Generates a list of simulation jobs from parameters, handling sweeps and array expansion.</p> Source code in <code>tricys/core/jobs.py</code> <pre><code>def generate_simulation_jobs(\n    simulation_params: Dict[str, Any],\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Generates a list of simulation jobs from parameters, handling sweeps and array expansion.\"\"\"\n\n    logger.info(\n        \"Generating simulation jobs\",\n        extra={\n            \"simulation_parameters\": simulation_params,\n        },\n    )\n    if \"file\" in simulation_params:\n        file_value = simulation_params[\"file\"]\n        if isinstance(file_value, str):\n            csv_jobs = _load_jobs_from_csv(file_value)\n\n            other_params = {k: v for k, v in simulation_params.items() if k != \"file\"}\n            for job in csv_jobs:\n                job.update(other_params)\n\n            return csv_jobs\n\n    # First, expand any array-like parameters before processing.\n    processed_params = _expand_array_parameters(simulation_params)\n\n    sweep_params = {}\n    single_value_params = {}\n\n    for name, value in processed_params.items():\n        parsed_values = parse_parameter_value(value)\n        if len(parsed_values) &gt; 1:\n            sweep_params[name] = parsed_values\n        else:\n            single_value_params[name] = parsed_values[0] if parsed_values else None\n\n    if not sweep_params:\n        return [single_value_params] if single_value_params else [{}]\n\n    sweep_names = list(sweep_params.keys())\n    sweep_values = list(sweep_params.values())\n    jobs = []\n    for combo in itertools.product(*sweep_values):\n        job = single_value_params.copy()\n        job.update(dict(zip(sweep_names, combo)))\n        jobs.append(job)\n    return jobs\n</code></pre>"},{"location":"reference/#tricys.core.jobs.parse_parameter_value","title":"<code>parse_parameter_value(value)</code>","text":"<p>Parses a parameter value which can be a single value, a list, or a string with special formats: - \"start:stop:step\" -&gt; e.g., \"1:10:2\" for a linear range. - \"linspace:start:stop:num\" -&gt; e.g., \"linspace:0:10:5\" for 5 points from 0 to 10. - \"log:start:stop:num\" -&gt; e.g., \"log:1:1000:4\" for 4 points on a log scale. - \"rand:min:max:count\" -&gt; e.g., \"rand:0:1:10\" for 10 random numbers. - \"file:path:column\" -&gt; e.g., \"file:data.csv:voltage\" to read a CSV column. - \"file:path\" -&gt; e.g., \"file:sampling.csv\" to read all parameters from CSV (first row as parameter names).</p> Source code in <code>tricys/core/jobs.py</code> <pre><code>def parse_parameter_value(value: Any) -&gt; List[Any]:\n    \"\"\"\n    Parses a parameter value which can be a single value, a list, or a string\n    with special formats:\n    - \"start:stop:step\" -&gt; e.g., \"1:10:2\" for a linear range.\n    - \"linspace:start:stop:num\" -&gt; e.g., \"linspace:0:10:5\" for 5 points from 0 to 10.\n    - \"log:start:stop:num\" -&gt; e.g., \"log:1:1000:4\" for 4 points on a log scale.\n    - \"rand:min:max:count\" -&gt; e.g., \"rand:0:1:10\" for 10 random numbers.\n    - \"file:path:column\" -&gt; e.g., \"file:data.csv:voltage\" to read a CSV column.\n    - \"file:path\" -&gt; e.g., \"file:sampling.csv\" to read all parameters from CSV (first row as parameter names).\n    \"\"\"\n    if not isinstance(value, str):\n        return value if isinstance(value, list) else [value]\n\n    if \":\" not in value:\n        return [value]  # Just a plain string\n\n    try:\n        prefix, args_str = value.split(\":\", 1)\n        prefix = prefix.lower()\n\n        if prefix == \"linspace\":\n            start, stop, num = map(float, args_str.split(\":\"))\n            return np.linspace(start, stop, int(num)).round(8).tolist()\n\n        if prefix == \"log\":\n            start, stop, num = map(float, args_str.split(\":\"))\n            if start &lt;= 0 or stop &lt;= 0:\n                raise ValueError(\"Log scale start and stop values must be positive.\")\n            return (\n                np.logspace(np.log10(start), np.log10(stop), int(num)).round(8).tolist()\n            )\n\n        if prefix == \"rand\":\n            low, high, count = map(float, args_str.split(\":\"))\n            return np.random.uniform(low, high, int(count)).round(8).tolist()\n\n        if prefix == \"file\":\n            # Handle file paths that may contain colons (e.g., Windows C:\\...)\n            try:\n                # Check if there's a column name specified\n                if \":\" in args_str:\n                    file_path, column_name = args_str.rsplit(\":\", 1)\n                    if not os.path.isabs(file_path.strip()):\n                        abs_file_path = os.path.abspath(\n                            os.path.join(os.getcwd(), file_path.strip())\n                        )\n                    else:\n                        abs_file_path = file_path.strip()\n                    df = pd.read_csv(abs_file_path)\n                    return df[column_name.strip()].tolist()\n                else:\n                    # Return the file path for later processing\n                    return [args_str.strip()]\n            except (ValueError, FileNotFoundError, KeyError):\n                # Re-raise to be caught by the outer try-except block\n                raise\n\n        # Fallback to original start:stop:step logic if no prefix matches\n        start, stop, step = map(float, value.split(\":\"))\n        return np.arange(start, stop + step / 2, step).round(8).tolist()\n\n    except (ValueError, FileNotFoundError, KeyError, IndexError) as e:\n        logger.error(\n            \"Invalid format or error processing parameter value\",\n            extra={\n                \"value\": value,\n                \"error\": str(e),\n            },\n        )\n        return [value]  # On any error, treat as a single literal value\n</code></pre>"},{"location":"reference/#tricyscoremodelica","title":"<code>tricys.core.modelica</code>","text":"<p>Utilities for interacting with OpenModelica via OMPython.</p> <p>This module provides a set of functions to manage an OpenModelica session, load models, retrieve parameter details, and format parameter values for simulation.</p>"},{"location":"reference/#tricys.core.modelica.format_parameter_value","title":"<code>format_parameter_value(name, value)</code>","text":"<p>Formats a parameter value into a string recognized by OpenModelica.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the parameter.</p> required <code>value</code> <code>Any</code> <p>The value of the parameter.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A formatted string for use in simulation overrides (e.g., \"p=1.0\").</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def format_parameter_value(name: str, value: Any) -&gt; str:\n    \"\"\"Formats a parameter value into a string recognized by OpenModelica.\n\n    Args:\n        name (str): The name of the parameter.\n        value (Any): The value of the parameter.\n\n    Returns:\n        str: A formatted string for use in simulation overrides (e.g., \"p=1.0\").\n    \"\"\"\n    if isinstance(value, list):\n        # Format lists as {v1,v2,...}\n        return f\"{name}={{{','.join(map(str, value))}}}\"\n    elif isinstance(value, str):\n        # Format strings as \"value\"\n        return f'{name}=\"{value}\"'\n    # For numbers and booleans, direct string conversion is fine\n    return f\"{name}={value}\"\n</code></pre>"},{"location":"reference/#tricys.core.modelica.get_all_parameters_details","title":"<code>get_all_parameters_details(omc, model_name)</code>","text":"<p>Recursively retrieves detailed information for all parameters in a given model.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>model_name</code> <code>str</code> <p>The full name of the model.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: A list of dictionaries, where each dictionary contains the detailed information of a single parameter.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_all_parameters_details(\n    omc: OMCSessionZMQ, model_name: str\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Recursively retrieves detailed information for all parameters in a given model.\n\n    Args:\n        omc (OMCSessionZMQ): The active OpenModelica session object.\n        model_name (str): The full name of the model.\n\n    Returns:\n        List[Dict[str, Any]]: A list of dictionaries, where each dictionary\n            contains the detailed information of a single parameter.\n    \"\"\"\n    logger.info(\n        \"Getting detailed parameters via recursion\", extra={\"model_name\": model_name}\n    )\n    all_params_details = []\n    try:\n        if not omc.sendExpression(f\"isModel({model_name})\"):\n            logger.error(\"Model not found in package\", extra={\"model_name\": model_name})\n            return []\n        _recursive_get_parameters(omc, model_name, \"\", all_params_details)\n        logger.info(\n            \"Successfully found parameter details\",\n            extra={\"count\": len(all_params_details)},\n        )\n        return all_params_details\n    except Exception as e:\n        logger.error(\n            \"Failed to get detailed parameters via recursion\",\n            exc_info=True,\n            extra={\"error\": str(e)},\n        )\n        return []\n</code></pre>"},{"location":"reference/#tricys.core.modelica.get_model_default_parameters","title":"<code>get_model_default_parameters(omc, model_name)</code>","text":"<p>Retrieves the default values for all parameters in a given model, parsing them into appropriate Python types.</p> <p>This function leverages get_all_parameters_details to fetch detailed parameter information and then extracts and parses the name and default value into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>model_name</code> <code>str</code> <p>The full name of the model.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: A dictionary mapping parameter names to their default values (e.g., float, list, bool, str). Returns an empty dictionary if the model is not found or has no parameters.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_model_default_parameters(omc: OMCSessionZMQ, model_name: str) -&gt; Dict[str, Any]:\n    \"\"\"Retrieves the default values for all parameters in a given model,\n    parsing them into appropriate Python types.\n\n    This function leverages get_all_parameters_details to fetch detailed\n    parameter information and then extracts and parses the name and default value\n    into a dictionary.\n\n    Args:\n        omc (OMCSessionZMQ): The active OpenModelica session object.\n        model_name (str): The full name of the model.\n\n    Returns:\n        Dict[str, Any]: A dictionary mapping parameter names to their\n            default values (e.g., float, list, bool, str). Returns an empty\n            dictionary if the model is not found or has no parameters.\n    \"\"\"\n    logger.info(\n        \"Getting and parsing default parameter values\", extra={\"model_name\": model_name}\n    )\n\n    # Use the existing detailed function to get all parameter info\n    all_params_details = get_all_parameters_details(omc, model_name)\n\n    if not all_params_details:\n        logger.warning(\n            \"No parameters found for model\", extra={\"model_name\": model_name}\n        )\n        return {}\n\n    # Convert the list of dicts into a single dict of name: parsed_defaultValue\n    default_params = {\n        param[\"name\"]: _parse_om_value(param[\"defaultValue\"])\n        for param in all_params_details\n    }\n\n    logger.info(\n        \"Found and parsed default parameters\",\n        extra={\n            \"count\": len(default_params),\n            \"model_name\": model_name,\n        },\n    )\n    return default_params\n</code></pre>"},{"location":"reference/#tricys.core.modelica.get_model_parameter_names","title":"<code>get_model_parameter_names(omc, model_name)</code>","text":"<p>Parses and returns all subcomponent parameter names for a given model.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>model_name</code> <code>str</code> <p>The full name of the model (e.g., 'example.Cycle').</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of all available parameter names (e.g., ['blanket.TBR']).</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_model_parameter_names(omc: OMCSessionZMQ, model_name: str) -&gt; List[str]:\n    \"\"\"Parses and returns all subcomponent parameter names for a given model.\n\n    Args:\n        omc (OMCSessionZMQ): The active OpenModelica session object.\n        model_name (str): The full name of the model (e.g., 'example.Cycle').\n\n    Returns:\n        List[str]: A list of all available parameter names (e.g., ['blanket.TBR']).\n    \"\"\"\n    logger.info(\"Getting parameter names for model\", extra={\"model_name\": model_name})\n    all_params = []\n    try:\n        if not omc.sendExpression(f\"isModel({model_name})\"):\n            logger.warning(\n                \"Model not found in package\", extra={\"model_name\": model_name}\n            )\n            return []\n\n        components = omc.sendExpression(f\"getComponents({model_name})\")\n        if not components:\n            logger.warning(\n                \"No components found for model\", extra={\"model_name\": model_name}\n            )\n            return []\n\n        for comp in components:\n            comp_type, comp_name = comp[0], comp[1]\n            if comp_type.startswith(model_name.split(\".\")[0]):\n                params = omc.sendExpression(f\"getParameterNames({comp_type})\")\n                for param in params:\n                    full_param = f\"{comp_name}.{param}\"\n                    if full_param not in all_params:\n                        all_params.append(full_param)\n\n        logger.info(\"Found parameter names\", extra={\"count\": len(all_params)})\n        return all_params\n\n    except Exception as e:\n        logger.error(\n            \"Failed to get parameter names\", exc_info=True, extra={\"error\": str(e)}\n        )\n        return []\n</code></pre>"},{"location":"reference/#tricys.core.modelica.get_om_session","title":"<code>get_om_session()</code>","text":"<p>Initializes and returns a new OMCSessionZMQ session.</p> <p>Returns:</p> Name Type Description <code>OMCSessionZMQ</code> <code>OMCSessionZMQ</code> <p>An active OpenModelica session object.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def get_om_session() -&gt; OMCSessionZMQ:\n    \"\"\"Initializes and returns a new OMCSessionZMQ session.\n\n    Returns:\n        OMCSessionZMQ: An active OpenModelica session object.\n    \"\"\"\n    logger.debug(\"Initializing new OMCSessionZMQ session\")\n    return OMCSessionZMQ()\n</code></pre>"},{"location":"reference/#tricys.core.modelica.load_modelica_package","title":"<code>load_modelica_package(omc, package_path)</code>","text":"<p>Loads a Modelica package into the OpenModelica session.</p> <p>Parameters:</p> Name Type Description Default <code>omc</code> <code>OMCSessionZMQ</code> <p>The active OpenModelica session object.</p> required <code>package_path</code> <code>str</code> <p>The file path to the Modelica package (<code>package.mo</code>).</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the package was loaded successfully, False otherwise.</p> Source code in <code>tricys/core/modelica.py</code> <pre><code>def load_modelica_package(omc: OMCSessionZMQ, package_path: str) -&gt; bool:\n    \"\"\"Loads a Modelica package into the OpenModelica session.\n\n    Args:\n        omc (OMCSessionZMQ): The active OpenModelica session object.\n        package_path (str): The file path to the Modelica package (`package.mo`).\n\n    Returns:\n        bool: True if the package was loaded successfully, False otherwise.\n    \"\"\"\n    logger.info(\"Loading package\", extra={\"package_path\": package_path})\n    load_result = omc.sendExpression(f'loadFile(\"{package_path}\")')\n    if not load_result:\n        logger.error(\"Failed to load package\", extra={\"package_path\": package_path})\n        return False\n    return True\n</code></pre>"},{"location":"reference/#tricyscoreinterceptor","title":"<code>tricys.core.interceptor</code>","text":""},{"location":"reference/#tricys.core.interceptor.integrate_interceptor_model","title":"<code>integrate_interceptor_model(package_path, model_name, interception_configs)</code>","text":"<p>Integrates one or more interceptor models into a system model.</p> <p>This function performs a multi-step process: 1. Generates individual interceptor models based on the configuration. 2. Modifies the main system model to instantiate these interceptors. 3. Re-routes the connections of the original components through the interceptors. 4. Saves the modified system model to a new file.</p> <p>Parameters:</p> Name Type Description Default <code>package_path</code> <code>str</code> <p>The file path to the Modelica package. For multi-file packages,           this should be the path to <code>package.mo</code>. For single-file packages,           this should be the path to the <code>.mo</code> file containing the package.</p> required <code>model_name</code> <code>str</code> <p>The full name of the system model to be modified.</p> required <code>interception_configs</code> <code>list</code> <p>A list of dictionaries, each defining an interception task.</p> required Source code in <code>tricys/core/interceptor.py</code> <pre><code>def integrate_interceptor_model(\n    package_path: str, model_name: str, interception_configs: list\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Integrates one or more interceptor models into a system model.\n\n    This function performs a multi-step process:\n    1. Generates individual interceptor models based on the configuration.\n    2. Modifies the main system model to instantiate these interceptors.\n    3. Re-routes the connections of the original components through the interceptors.\n    4. Saves the modified system model to a new file.\n\n    Args:\n        package_path: The file path to the Modelica package. For multi-file packages,\n                      this should be the path to `package.mo`. For single-file packages,\n                      this should be the path to the `.mo` file containing the package.\n        model_name: The full name of the system model to be modified.\n        interception_configs: A list of dictionaries, each defining an interception task.\n    \"\"\"\n    # For multi-file packages, package_path is the path to the `package.mo` file.\n    # The directory of this file is the package directory.\n    # For single-file packages, package_path is the path to the file itself.\n    if os.path.isdir(package_path):\n        # Handle cases where a directory is passed, find package.mo\n        package_file = os.path.join(package_path, \"package.mo\")\n        if os.path.exists(package_file):\n            return _integrate_interceptor_multi_file(\n                package_file, model_name, interception_configs\n            )\n        else:\n            raise FileNotFoundError(\n                \"No package.mo found in the directory\",\n                extra={\n                    \"directory\": package_path,\n                },\n            )\n    elif os.path.isfile(package_path) and package_path.endswith(\"package.mo\"):\n        return _integrate_interceptor_multi_file(\n            package_path, model_name, interception_configs\n        )\n    elif os.path.isfile(package_path):\n        return _integrate_interceptor_single_file(\n            package_path, model_name, interception_configs\n        )\n    else:\n        raise FileNotFoundError(\n            \"Invalid package path provided\",\n            extra={\n                \"package_path\": package_path,\n            },\n        )\n</code></pre>"},{"location":"reference/#analysis","title":"\u5206\u6790\u6a21\u5757 (Analysis)","text":""},{"location":"reference/#tricysanalysismetric","title":"<code>tricys.analysis.metric</code>","text":""},{"location":"reference/#tricys.analysis.metric.calculate_doubling_time","title":"<code>calculate_doubling_time(series, time_series)</code>","text":"<p>Calculates the time it takes for the inventory to double its initial value.</p> <p>This function finds the first time point, after the inventory's minimum (turning point), where the inventory level reaches or exceeds twice its initial value.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The inventory time series data.</p> required <code>time_series</code> <code>Series</code> <p>The corresponding time data.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The doubling time, or NaN if the inventory never doubles.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def calculate_doubling_time(series: pd.Series, time_series: pd.Series) -&gt; float:\n    \"\"\"Calculates the time it takes for the inventory to double its initial value.\n\n    This function finds the first time point, after the inventory's minimum\n    (turning point), where the inventory level reaches or exceeds twice its\n    initial value.\n\n    Args:\n        series (pd.Series): The inventory time series data.\n        time_series (pd.Series): The corresponding time data.\n\n    Returns:\n        float: The doubling time, or NaN if the inventory never doubles.\n    \"\"\"\n    if time_series is None:\n        raise ValueError(\"time_series must be provided for calculate_doubling_time\")\n    initial_inventory = series.iloc[0]\n    doubled_inventory = 2 * initial_inventory\n\n    # Find the first index where the inventory is &gt;= doubled_inventory\n    # We should only consider the part of the series after the turning point\n    min_index = series.idxmin()\n    after_turning_point_series = series.loc[min_index:]\n\n    doubling_indices = after_turning_point_series[\n        after_turning_point_series &gt;= doubled_inventory\n    ].index\n\n    if not doubling_indices.empty:\n        doubling_index = doubling_indices[0]\n        return time_series.loc[doubling_index]\n    else:\n        # If it never doubles, return NaN\n        return np.nan\n</code></pre>"},{"location":"reference/#tricys.analysis.metric.calculate_startup_inventory","title":"<code>calculate_startup_inventory(series, time_series=None)</code>","text":"<p>Calculates the startup inventory.</p> <p>The startup inventory is calculated as the difference between the initial inventory and the minimum inventory (the turning point).</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The inventory time series data.</p> required <code>time_series</code> <code>Optional[Series]</code> <p>The corresponding time data (unused).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The calculated startup inventory.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def calculate_startup_inventory(\n    series: pd.Series, time_series: Optional[pd.Series] = None\n) -&gt; float:\n    \"\"\"Calculates the startup inventory.\n\n    The startup inventory is calculated as the difference between the initial\n    inventory and the minimum inventory (the turning point).\n\n    Args:\n        series (pd.Series): The inventory time series data.\n        time_series (Optional[pd.Series]): The corresponding time data (unused).\n\n    Returns:\n        float: The calculated startup inventory.\n    \"\"\"\n    initial_inventory = series.iloc[0]\n    minimum_inventory = series.min()\n    return initial_inventory - minimum_inventory\n</code></pre>"},{"location":"reference/#tricys.analysis.metric.extract_metrics","title":"<code>extract_metrics(results_df, metrics_definition, analysis_case)</code>","text":"<p>Extracts summary metrics from detailed simulation results.</p> <p>This function processes a DataFrame from a parameter sweep, calculates various metrics for each run based on a definitions dictionary, and pivots the results into a summary DataFrame where each row corresponds to a unique parameter combination.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame from the combined sweep results.</p> required <code>metrics_definition</code> <code>Dict[str, Any]</code> <p>Dictionary defining how to calculate each metric (e.g., source column, method).</p> required <code>analysis_case</code> <code>Dict[str, Any]</code> <p>The analysis case configuration, used to identify dependent variables.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A pivoted DataFrame with parameters as the index and           metric names as columns.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def extract_metrics(\n    results_df: pd.DataFrame,\n    metrics_definition: Dict[str, Any],\n    analysis_case: Dict[str, Any],\n) -&gt; pd.DataFrame:\n    \"\"\"Extracts summary metrics from detailed simulation results.\n\n    This function processes a DataFrame from a parameter sweep, calculates\n    various metrics for each run based on a definitions dictionary, and\n    pivots the results into a summary DataFrame where each row corresponds\n    to a unique parameter combination.\n\n    Args:\n        results_df (pd.DataFrame): DataFrame from the combined sweep results.\n        metrics_definition (Dict[str, Any]): Dictionary defining how to calculate\n            each metric (e.g., source column, method).\n        analysis_case (Dict[str, Any]): The analysis case configuration, used\n            to identify dependent variables.\n\n    Returns:\n        pd.DataFrame: A pivoted DataFrame with parameters as the index and\n                      metric names as columns.\n    \"\"\"\n\n    analysis_results = []\n\n    source_to_metric = {}\n    dependent_vars = analysis_case.get(\"dependent_variables\", [])\n\n    for metric_name in dependent_vars:\n        definition = metrics_definition.get(metric_name)\n\n        # If the metric is not in the definition or is calculated via optimization, skip it.\n        if not definition or definition.get(\"method\") == \"bisection_search\":\n            continue\n\n        source = definition[\"source_column\"]\n        if source not in source_to_metric:\n            source_to_metric[source] = []\n        source_to_metric[source].append(\n            {\n                \"metric_name\": metric_name,\n                \"method\": definition[\"method\"],\n            }\n        )\n\n    for col_name in results_df.columns:\n        if col_name.lower() == \"time\":\n            continue\n\n        source_var = None\n        for var in source_to_metric.keys():\n            if col_name.startswith(var):\n                source_var = var\n                break\n\n        if not source_var:\n            continue\n\n        param_str = col_name[len(source_var) :].lstrip(\"&amp;\")\n\n        try:\n            params = dict(item.split(\"=\") for item in param_str.split(\"&amp;\"))\n        except ValueError:\n            print(\n                f\"Warning: Could not parse parameters from column '{col_name}'. Skipping.\"\n            )\n            continue\n\n        for k, v in params.items():\n            try:\n                params[k] = float(v)\n            except ValueError:\n                params[k] = v\n\n        for metric_info in source_to_metric[source_var]:\n            method_name = metric_info[\"method\"]\n            metric_name = metric_info[\"metric_name\"]\n\n            if method_name == \"final_value\":\n                calculation_func = get_final_value\n            elif method_name == \"calculate_startup_inventory\":\n                calculation_func = calculate_startup_inventory\n            elif method_name == \"time_of_turning_point\":\n                calculation_func = time_of_turning_point\n            elif method_name == \"calculate_doubling_time\":\n                calculation_func = calculate_doubling_time\n            else:\n                print(\n                    f\"Warning: Calculation method '{method_name}' not implemented. Skipping.\"\n                )\n                continue\n\n            metric_value = calculation_func(results_df[col_name], results_df[\"time\"])\n\n            result_row = params.copy()\n            result_row[\"metric_name\"] = metric_name\n            result_row[\"metric_value\"] = metric_value\n            analysis_results.append(result_row)\n\n    if not analysis_results:\n        return pd.DataFrame()\n\n    summary_df = pd.DataFrame(analysis_results)\n\n    # Dynamically identify all parameter columns from the dataframe\n    param_cols = [\n        col for col in summary_df.columns if col not in [\"metric_name\", \"metric_value\"]\n    ]\n\n    if not param_cols:\n        return pd.DataFrame()\n\n    try:\n        pivot_df = summary_df.pivot_table(\n            index=param_cols, columns=\"metric_name\", values=\"metric_value\"\n        ).reset_index()\n        return pivot_df\n    except Exception as e:\n        print(f\"Error during pivoting: {e}\")\n        return pd.DataFrame()\n</code></pre>"},{"location":"reference/#tricys.analysis.metric.get_final_value","title":"<code>get_final_value(series, time_series=None)</code>","text":"<p>Gets the final value of a time series.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The time series data.</p> required <code>time_series</code> <code>Optional[Series]</code> <p>The corresponding time data (unused).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The last value in the series.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def get_final_value(\n    series: pd.Series, time_series: Optional[pd.Series] = None\n) -&gt; float:\n    \"\"\"Gets the final value of a time series.\n\n    Args:\n        series (pd.Series): The time series data.\n        time_series (Optional[pd.Series]): The corresponding time data (unused).\n\n    Returns:\n        float: The last value in the series.\n    \"\"\"\n    return series.iloc[-1]\n</code></pre>"},{"location":"reference/#tricys.analysis.metric.time_of_turning_point","title":"<code>time_of_turning_point(series, time_series)</code>","text":"<p>Finds the time of the turning point (minimum value) in a series.</p> <p>This function identifies the time corresponding to the minimum value in the series, which often represents the self-sufficiency time in tritium inventory simulations. To handle noisy data, it first smooths the series to find the general trend's minimum. If the smoothed minimum is not at the boundaries, it returns the time of the absolute minimum from the original data.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The time series data to analyze.</p> required <code>time_series</code> <code>Series</code> <p>The corresponding time data.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The time of the turning point, or NaN if the trend is monotonic.</p> Source code in <code>tricys/analysis/metric.py</code> <pre><code>def time_of_turning_point(series: pd.Series, time_series: pd.Series) -&gt; float:\n    \"\"\"Finds the time of the turning point (minimum value) in a series.\n\n    This function identifies the time corresponding to the minimum value in the\n    series, which often represents the self-sufficiency time in tritium inventory\n    simulations. To handle noisy data, it first smooths the series to find the\n    general trend's minimum. If the smoothed minimum is not at the boundaries,\n    it returns the time of the absolute minimum from the original data.\n\n    Args:\n        series (pd.Series): The time series data to analyze.\n        time_series (pd.Series): The corresponding time data.\n\n    Returns:\n        float: The time of the turning point, or NaN if the trend is monotonic.\n    \"\"\"\n\n    print(\n        f\"Calculating time_of_turning_point for series with length {len(series)} and {len(time_series)} \"\n    )\n    if time_series is None:\n        raise ValueError(\"time_series must be provided for time_of_turning_point\")\n\n    # Define a window size for the rolling average, e.g., 5% of the data length\n    # with a minimum size of 1. This helps in smoothing out local fluctuations.\n    window_size = max(1, int(len(series) * 0.001))\n    smoothed_series = series.rolling(\n        window=window_size, center=True, min_periods=1\n    ).mean()\n\n    # Find the index label of the minimum value in the smoothed series.\n    smooth_min_index = smoothed_series.idxmin()\n    min_index = series.idxmin()\n\n    # Check if the minimum of the smoothed data is within the first or last 5%\n    # of the series. If so, the trend is considered monotonic.\n    smooth_min_pos = series.index.get_loc(smooth_min_index)\n    five_percent_threshold = int(len(series) * 0.3)\n\n    if smooth_min_pos &gt;= len(series) - five_percent_threshold:\n        return np.nan\n    else:\n        # A clear turning point is identified in the overall trend.\n        # Now, find the precise turning point in the original, noisy data.\n        min_index = series.idxmin()\n        return time_series.loc[min_index]\n</code></pre>"},{"location":"reference/#tricysanalysisplot","title":"<code>tricys.analysis.plot</code>","text":"<p>Utility functions for plotting simulation results.</p> <p>This module provides functions to generate plots from the simulation output CSV files, such as visualizing startup tritium inventory or time-series data.</p>"},{"location":"reference/#tricys.analysis.plot.generate_analysis_plots","title":"<code>generate_analysis_plots(summary_df, analysis_case, save_dir, unit_map=None, glossary_path=None)</code>","text":"<p>Generates and saves plots based on the sensitivity analysis summary. This function first generates dedicated plots for all 'Required_***' metrics, then handles plotting for all other standard metrics.</p> <p>Parameters:</p> Name Type Description Default <code>summary_df</code> <code>DataFrame</code> <p>DataFrame containing the summarized analysis results.</p> required <code>analysis_case</code> <code>dict</code> <p>Configuration for the analysis cases.</p> required <code>save_dir</code> <code>str</code> <p>Directory to save the plot images.</p> required <code>unit_map</code> <code>dict</code> <p>Optional dictionary for unit conversion and labeling.</p> <code>None</code> <code>glossary_path</code> <code>str</code> <p>Optional path to the glossary CSV file for professional labels.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>A list of paths to the saved plot images.</p> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def generate_analysis_plots(\n    summary_df: pd.DataFrame,\n    analysis_case: dict,\n    save_dir: str,\n    unit_map: dict = None,\n    glossary_path: str = None,\n) -&gt; list:\n    \"\"\"\n    Generates and saves plots based on the sensitivity analysis summary.\n    This function first generates dedicated plots for all 'Required_***' metrics,\n    then handles plotting for all other standard metrics.\n\n    Args:\n        summary_df: DataFrame containing the summarized analysis results.\n        analysis_case: Configuration for the analysis cases.\n        save_dir: Directory to save the plot images.\n        unit_map: Optional dictionary for unit conversion and labeling.\n        glossary_path: Optional path to the glossary CSV file for professional labels.\n\n    Returns:\n        A list of paths to the saved plot images.\n    \"\"\"\n    if glossary_path:\n        load_glossary(glossary_path)\n\n    if summary_df.empty:\n        return []\n\n    analysis_cases = [analysis_case]  # Keep as a list for consistency\n    sns.set_theme(style=\"whitegrid\")\n    line_colors = sns.color_palette(\"viridis\", 10)\n\n    plot_paths = []\n\n    # If unit_map is not provided, initialize as empty dict\n    if unit_map is None:\n        unit_map = {}\n\n    # --- 1. Handle ALL 'Required_***' plots first and separately ---\n    all_required_vars_from_config = {\n        var\n        for case in analysis_cases\n        for var in case.get(\"dependent_variables\", [])\n        if var.startswith(\"Required_\")\n    }\n\n    for req_var in all_required_vars_from_config:\n        # Find all actual columns in the dataframe for this base name\n        matching_cols = sorted(\n            [\n                c\n                for c in summary_df.columns\n                if c == req_var or c.startswith(req_var + \"(\")\n            ]\n        )\n\n        if not matching_cols:\n            continue\n\n        case_for_plot = analysis_cases[0]\n\n        if len(matching_cols) &gt; 1:\n            # Multi-value case -&gt; generate a multi-subplot figure\n            multi_plot_paths = _generate_multi_required_plot(\n                summary_df,\n                case_for_plot,\n                matching_cols,\n                req_var,\n                save_dir,\n                unit_map=unit_map,\n            )\n            plot_paths.extend(multi_plot_paths)\n        elif len(matching_cols) == 1:\n            # Single-value case -&gt; generate a single, individual plot\n            plot_config = {\n                \"case_name\": case_for_plot[\"name\"],\n                \"x_var\": case_for_plot[\"independent_variable\"],\n                \"y_var\": matching_cols[0],\n                \"plot_type\": \"line\",\n                \"hue_vars\": sorted(\n                    list(case_for_plot.get(\"default_simulation_values\", {}).keys())\n                ),\n            }\n            single_plot_path = _generate_individual_plots(\n                summary_df, [plot_config], save_dir, line_colors, unit_map=unit_map\n            )\n            plot_paths.extend(single_plot_path)\n\n    # --- 2. Handle all other (non-Required) plots ---\n\n    # Collect plot configurations for remaining standard variables\n    valid_plots_for_combine = []\n    for case in analysis_cases:\n        case_name = case[\"name\"]\n        x_var = case[\"independent_variable\"]\n\n        # Filter out the Required_*** vars that we just plotted\n        y_vars = [\n            v\n            for v in case.get(\"dependent_variables\", [])\n            if not v.startswith(\"Required_\")\n        ]\n\n        if x_var not in summary_df.columns:\n            print(\n                f\"Warning: Independent variable '{x_var}' not found in summary data for case '{case_name}'. Skipping.\"\n            )\n            continue\n\n        case_sim_params = case.get(\"default_simulation_values\", {})\n        hue_vars = sorted(list(case_sim_params.keys()))\n\n        for y_var in y_vars:\n            if y_var not in summary_df.columns:\n                print(\n                    f\"Warning: Dependent variable '{y_var}' not found in summary data for case '{case_name}'. Skipping.\"\n                )\n                continue\n\n            # We assume standard metrics have a 1-to-1 name match in the dataframe\n            valid_plots_for_combine.append(\n                {\n                    \"case_name\": case_name,\n                    \"x_var\": x_var,\n                    \"y_var\": y_var,\n                    \"plot_type\": \"line\",\n                    \"hue_vars\": hue_vars,\n                }\n            )\n\n    if valid_plots_for_combine:\n        combine_plots = any(case.get(\"combine_plots\", False) for case in analysis_cases)\n        generated_paths = []\n        if combine_plots:\n            generated_paths = _generate_combined_plots(\n                summary_df,\n                valid_plots_for_combine,\n                save_dir,\n                line_colors,\n                unit_map=unit_map,\n            )\n        else:\n            # If not combining, plot them individually anyway\n            generated_paths = _generate_individual_plots(\n                summary_df,\n                valid_plots_for_combine,\n                save_dir,\n                line_colors,\n                unit_map=unit_map,\n            )\n        plot_paths.extend(generated_paths)\n\n    return plot_paths\n</code></pre>"},{"location":"reference/#tricys.analysis.plot.load_glossary","title":"<code>load_glossary(glossary_path)</code>","text":"<p>Loads glossary data from a CSV file.</p> <p>The CSV file should contain columns for the model parameter, the English term, and the Chinese translation. This data is used to format plot labels.</p> <p>Parameters:</p> Name Type Description Default <code>glossary_path</code> <code>str</code> <p>The path to the glossary CSV file.</p> required Source code in <code>tricys/analysis/plot.py</code> <pre><code>def load_glossary(glossary_path: str) -&gt; None:\n    \"\"\"Loads glossary data from a CSV file.\n\n    The CSV file should contain columns for the model parameter, the English\n    term, and the Chinese translation. This data is used to format plot labels.\n\n    Args:\n        glossary_path (str): The path to the glossary CSV file.\n    \"\"\"\n    global _english_glossary_map, _chinese_glossary_map\n\n    if not glossary_path or not os.path.exists(glossary_path):\n        print(\n            f\"Warning: Glossary file not found at {glossary_path}. No labels will be loaded.\"\n        )\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n        return\n\n    try:\n        df = pd.read_csv(glossary_path)\n        if (\n            \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\" in df.columns\n            and \"\u82f1\u6587\u672f\u8bed (English Term)\" in df.columns\n            and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\" in df.columns\n        ):\n            df.dropna(subset=[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"], inplace=True)\n            _english_glossary_map = pd.Series(\n                df[\"\u82f1\u6587\u672f\u8bed (English Term)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            _chinese_glossary_map = pd.Series(\n                df[\"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            print(f\"Successfully loaded glossary from {glossary_path}.\")\n        else:\n            print(\"Warning: Glossary CSV does not contain expected columns.\")\n            _english_glossary_map = {}\n            _chinese_glossary_map = {}\n    except Exception as e:\n        print(f\"Warning: Failed to load or parse glossary file. Error: {e}\")\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n</code></pre>"},{"location":"reference/#tricys.analysis.plot.plot_sweep_time_series","title":"<code>plot_sweep_time_series(csv_path, save_dir, y_var_name, independent_var_name, independent_var_alias=None, default_params=None, glossary_path=None)</code>","text":"<p>Generates a single figure with two subplots: an overall time-series view and a zoomed-in view around the minimum point of the curves. The time axis is in days. The overall view hides data points for a curve if they exceed twice its initial value.</p> <p>Parameters:</p> Name Type Description Default <code>csv_path</code> <code>str</code> <p>Path to the scan result CSV file.</p> required <code>save_dir</code> <code>str</code> <p>Directory to save the image.</p> required <code>y_var_name</code> <code>Union[str, List[str]]</code> <p>Name(s) of the Y-axis variable(s).</p> required <code>independent_var_name</code> <code>str</code> <p>Full name of the scan parameter.</p> required <code>independent_var_alias</code> <code>str</code> <p>Alias for the scan parameter for cleaner plot titles.</p> <code>None</code> <code>default_params</code> <code>Dict[str, Any]</code> <p>A dictionary of default parameters. If provided, only curves matching these parameters will be plotted.</p> <code>None</code> <code>glossary_path</code> <code>str</code> <p>Path to the glossary file for professional labels.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>A list of paths to the saved plot images, or an empty list on failure.</p> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def plot_sweep_time_series(\n    csv_path: str,\n    save_dir: str,\n    y_var_name: Union[str, List[str]],\n    independent_var_name: str,\n    independent_var_alias: str = None,\n    default_params: Dict[str, Any] = None,\n    glossary_path: str = None,\n) -&gt; List[str]:\n    \"\"\"\n    Generates a single figure with two subplots: an overall time-series view and a\n    zoomed-in view around the minimum point of the curves. The time axis is in days.\n    The overall view hides data points for a curve if they exceed twice its initial value.\n\n    Args:\n        csv_path (str): Path to the scan result CSV file.\n        save_dir (str): Directory to save the image.\n        y_var_name (Union[str, List[str]]): Name(s) of the Y-axis variable(s).\n        independent_var_name (str): Full name of the scan parameter.\n        independent_var_alias (str): Alias for the scan parameter for cleaner plot titles.\n        default_params (Dict[str, Any], optional): A dictionary of default parameters.\n            If provided, only curves matching these parameters will be plotted.\n        glossary_path (str, optional): Path to the glossary file for professional labels.\n\n    Returns:\n        A list of paths to the saved plot images, or an empty list on failure.\n    \"\"\"\n    if glossary_path:\n        load_glossary(glossary_path)\n\n    try:\n        df = pd.read_csv(csv_path)\n    except FileNotFoundError:\n        print(f\"Error: Could not find results file at {csv_path}\")\n        return []\n\n    if \"time\" not in df.columns:\n        print(f\"Error: 'time' column not found in {csv_path}\")\n        return []\n\n    # Convert time from hours to days\n    time_days = df[\"time\"] / 24\n\n    # Use alias if provided, otherwise format the original name\n    raw_plot_alias = (\n        independent_var_alias if independent_var_alias else independent_var_name\n    )\n\n    if isinstance(y_var_name, str):\n        y_var_names = [y_var_name]\n    else:\n        y_var_names = y_var_name\n\n    y_var_columns = []\n    for y_var in y_var_names:\n        y_var_columns.extend(\n            [col for col in df.columns if col != \"time\" and y_var in col]\n        )\n    y_var_columns = list(dict.fromkeys(y_var_columns))\n\n    # If default_params are provided, filter columns to only plot baseline curves\n    if default_params:\n        filtered_columns = []\n        for col in y_var_columns:\n            try:\n                param_str = col.split(\"&amp;\", 1)[1]\n                col_params = dict(p.split(\"=\", 1) for p in param_str.split(\"&amp;\"))\n\n                # Check if all default_params match the parameters in the column name\n                is_match = all(\n                    col_params.get(key) == str(val)\n                    for key, val in default_params.items()\n                )\n\n                if is_match:\n                    filtered_columns.append(col)\n            except IndexError:\n                # This column does not have parameters in its name, so it can't be a match\n                continue\n        y_var_columns = filtered_columns\n\n    if not y_var_columns:\n        print(\n            f\"Warning: No columns found containing any of {y_var_names} in {csv_path} that match the criteria.\"\n        )\n        return []\n\n    # Convert y-axis data from grams to kilograms\n    for col in y_var_columns:\n        df[col] = df[col] / 1000.0\n\n    # Generate clean labels (values only) for the legend\n    plot_labels = []\n    for col in y_var_columns:\n        label = col\n        try:\n            param_parts = col.split(\"&amp;\")[1:]\n            for part in param_parts:\n                if part.startswith(independent_var_name + \"=\"):\n                    label = part.split(\"=\", 1)[1]  # Extract just the value\n                    break\n        except IndexError:\n            pass  # No parameters in name, use full column name\n        plot_labels.append(label)\n\n    print(\n        f\"Found {len(y_var_columns)} columns to plot containing {y_var_names}: {y_var_columns}\"\n    )\n\n    sns.set_theme(style=\"whitegrid\")\n    plot_paths = []\n    original_lang_is_chinese = _use_chinese_labels\n\n    for lang in [\"en\", \"cn\"]:\n        set_plot_language(lang)\n\n        colors = sns.color_palette(\"plasma\", len(y_var_columns))\n\n        # Create a figure with two subplots (overall and zoom)\n        fig, (ax1, ax2) = plt.subplots(\n            2, 1, figsize=(12, 16), sharex=False, gridspec_kw={\"height_ratios\": [2, 1]}\n        )\n        y_var_names_formatted = [_format_label(y) for y in y_var_names]\n\n        min_y_global = float(\"inf\")\n        min_x_global = float(\"inf\")\n\n        # Define the y-axis label with units\n        y_label = f\"{', '.join(y_var_names_formatted)} ({_get_text('kg')})\"\n\n        # --- Subplot 1: Overall View ---\n        for i, column in enumerate(y_var_columns):\n            y_data = df[column]\n\n            # For the global view, mask data that is more than 2x the initial value\n            if not y_data.empty:\n                initial_value = y_data.iloc[0]\n                threshold = 2 * initial_value\n                y_masked = y_data.where(y_data &lt;= threshold)\n            else:\n                y_masked = y_data\n\n            ax1.plot(\n                time_days,\n                y_masked,\n                label=plot_labels[i],\n                color=colors[i],\n                linewidth=1.2,\n                alpha=0.85,\n            )\n\n            # Calculations for zoom window should use the original, unmasked data\n            if not y_data.empty:\n                min_idx = y_data.idxmin()\n                current_min_y = y_data.loc[min_idx]\n                if current_min_y &lt; min_y_global:\n                    min_y_global = current_min_y\n                    min_x_global = time_days.loc[min_idx]\n\n        ax1.set_ylabel(y_label, fontsize=12)\n        ax1.set_title(_get_text(\"overall_view\"), fontsize=12)\n        ax1.legend(loc=\"best\", title=_format_label(independent_var_name))\n        ax1.grid(True)\n\n        # --- Subplot 2: Zoomed-in View (uses original data) ---\n        if min_y_global != float(\"inf\") and np.isfinite(min_y_global):\n            for i, column in enumerate(y_var_columns):\n                # Plot original, unmasked data in the zoom plot\n                ax2.plot(\n                    time_days,\n                    df[column],\n                    label=plot_labels[i],\n                    color=colors[i],\n                    linewidth=1.8,\n                    alpha=0.9,\n                )\n\n            # Define the zoom window from t=0 to a bit after the minimum\n            x1 = 0\n            x2 = min_x_global + 2  # Show 2 days past the minimum\n\n            # Filter the DataFrame to the new x-range to find the y-range\n            zoom_mask = (time_days &gt;= x1) &amp; (time_days &lt;= x2)\n            df_zoom_range = df[zoom_mask]\n\n            # Find y-min and y-max within this specific range\n            y_min_in_range = df_zoom_range[y_var_columns].min().min()\n            y_max_in_range = df_zoom_range[y_var_columns].max().max()\n\n            # Add padding to the y-axis\n            y_padding = (y_max_in_range - y_min_in_range) * 0.05\n            y1 = y_min_in_range - y_padding\n            y2 = y_max_in_range + y_padding\n\n            ax2.set_xlim(x1, x2)\n            ax2.set_ylim(y1, y2)\n\n            ax2.set_xlabel(_get_text(\"time_days\"), fontsize=12)\n            ax2.set_ylabel(y_label, fontsize=12)\n            ax2.set_title(_get_text(\"detailed_view\"), fontsize=12)\n            ax2.grid(True, linestyle=\"--\")\n\n            # Add a rectangle to the main plot to indicate the new zoom area\n            rect = patches.Rectangle(\n                (x1, y1),\n                (x2 - x1),\n                (y2 - y1),\n                linewidth=1,\n                edgecolor=\"r\",\n                facecolor=\"none\",\n                linestyle=\"--\",\n                alpha=0.7,\n            )\n            ax1.add_patch(rect)\n        else:\n            # If no zoom, hide the second subplot\n            ax2.set_visible(False)\n\n        ax1.set_xlabel(_get_text(\"time_days\"), fontsize=12)\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust for suptitle\n\n        # --- Save Figure ---\n        safe_y_vars = \"_\".join(\n            [\n                var.replace(\".\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\")\n                for var in y_var_names\n            ]\n        )\n        safe_param = raw_plot_alias.replace(\".\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\")\n        suffix = \"_zh\" if lang == \"cn\" else \"\"\n        svg_path = os.path.join(\n            save_dir, f\"sweep_{safe_y_vars}_vs_{safe_param}{suffix}.svg\"\n        )\n\n        try:\n            # Force text to be rendered as paths in SVG.\n            plt.rcParams[\"svg.fonttype\"] = \"path\"\n            plt.savefig(svg_path, format=\"svg\", bbox_inches=\"tight\")\n            print(f\"Successfully generated combined sweep plot: {svg_path}\")\n            plot_paths.append(svg_path)\n        except Exception as e:\n            print(f\"Error saving plot: {e}\")\n        finally:\n            plt.close(fig)\n\n    set_plot_language(\"cn\" if original_lang_is_chinese else \"en\")\n    return plot_paths\n</code></pre>"},{"location":"reference/#tricys.analysis.plot.set_plot_language","title":"<code>set_plot_language(lang='en')</code>","text":"<p>Sets the preferred language for plot labels and text.</p> <p>Parameters:</p> Name Type Description Default <code>lang</code> <code>str</code> <p>The language to set. 'en' for English (default), 'cn' for Chinese.</p> <code>'en'</code> Source code in <code>tricys/analysis/plot.py</code> <pre><code>def set_plot_language(lang: str = \"en\") -&gt; None:\n    \"\"\"Sets the preferred language for plot labels and text.\n\n    Args:\n        lang (str): The language to set. 'en' for English (default),\n            'cn' for Chinese.\n    \"\"\"\n    global _use_chinese_labels\n    _use_chinese_labels = lang.lower() == \"cn\"\n\n    if _use_chinese_labels:\n        # To display Chinese characters correctly, specify a list of fallback fonts.\n        plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # \u66ff\u6362\u6210\u4f60\u7535\u8111\u4e0a\u6709\u7684\u5b57\u4f53\n        plt.rcParams[\"axes.unicode_minus\"] = False  # To display minus sign correctly.\n        plt.rcParams[\"font.family\"] = \"sans-serif\"  # \u786e\u4fdd\u5b57\u4f53\u5bb6\u65cf\u8bbe\u7f6e\u751f\u6548\n    else:\n        # Restore default settings\n        plt.rcParams[\"font.sans-serif\"] = plt.rcParamsDefault[\"font.sans-serif\"]\n        plt.rcParams[\"axes.unicode_minus\"] = plt.rcParamsDefault[\"axes.unicode_minus\"]\n</code></pre>"},{"location":"reference/#tricysanalysisreport","title":"<code>tricys.analysis.report</code>","text":""},{"location":"reference/#tricys.analysis.report.call_openai_analysis_api","title":"<code>call_openai_analysis_api(case_name, df, api_key, base_url, ai_model, independent_variable, report_content, original_config, case_data, reference_col_for_turning_point=None)</code>","text":"<p>Constructs a text-only prompt, calls the OpenAI API for analysis, and returns the result string.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def call_openai_analysis_api(\n    case_name: str,\n    df: pd.DataFrame,\n    api_key: str,\n    base_url: str,\n    ai_model: str,\n    independent_variable: str,\n    report_content: str,\n    original_config: dict,\n    case_data: dict,\n    reference_col_for_turning_point: str = None,  # NEW PARAMETER\n) -&gt; Optional[str]:\n    \"\"\"\n    Constructs a text-only prompt, calls the OpenAI API for analysis, and returns the result string.\n    \"\"\"\n    try:\n        logger.info(f\"Proceeding with LLM analysis for case {case_name}.\")\n\n        # 1. Construct the prompt for the API\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u805a\u53d8\u53cd\u5e94\u5806\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u7684\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7**\u5b8c\u5168\u57fa\u4e8e**\u4e0b\u65b9\u63d0\u4f9b\u7684**\u4e24\u7c7b\u6570\u636e\u8868\u683c**\uff0c\u5bf9\u805a\u53d8\u5806\u71c3\u6599\u5faa\u73af\u6a21\u578b\u7684**\u654f\u611f\u6027\u5206\u6790**\u7ed3\u679c\u8fdb\u884c\u6df1\u5ea6\u89e3\u8bfb\u3002\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n**\u5206\u6790\u6570\u636e\uff1a**(\u6ce8\u610f\uff1a\u5206\u6790\u4e2d\u4e0d\u53ef\u4f7f\u7528\u4efb\u4f55\u56fe\u8868\u4fe1\u606f\uff0c\u6240\u6709\u7ed3\u8bba\u5fc5\u987b\u6e90\u4e8e\u6570\u636e\u8868\u683c\u3002)\n\n{report_content}\n\"\"\"\n\n        # --- Dynamic Prompt Construction ---\n\n        # 1. Detect analysis scenario\n        has_sim_params = bool(case_data.get(\"simulation_parameters\"))\n\n        # 2. Build prompt sections dynamically\n        prompt_sections = []\n\n        # Section 1: Global Sensitivity Analysis\n        global_sensitivity_points = [\n            \"1.  **\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (\u53c2\u8003\u201c\u6027\u80fd\u6307\u6807\u603b\u8868\u201d) :**\",\n            \"    *   \u5206\u6790\u6027\u80fd\u6307\u6807\u603b\u8868\uff08 `Startup_Inventory`, `Doubling_Time` \u4ee5\u53ca\u4ee5 `Required_` \u5f00\u5934\u7684\u6c42\u89e3\u6307\u6807\u7b49\uff09\u5448\u73b0\u51fa\u600e\u6837\u7684**\u603b\u4f53\u8d8b\u52bf**\uff1f\u8bf7\u8fdb\u884c\u91cf\u5316\u63cf\u8ff0\u3002\",\n            f\"    *   \u5982\u679c\u5b58\u5728\u591a\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5206\u6790\u54ea\u4e2a\u6027\u80fd\u6307\u6807\u5bf9\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u7684\u53d8\u5316\u6700\u4e3a\u654f\u611f\uff1f\u54ea\u4e2a\u6700\u4e0d\u654f\u611f\uff1f\\n\",\n        ]\n\n        # Interaction effect analysis, with refined description\n        if has_sim_params:\n            param_names_list = []\n            for p in case_data[\"simulation_parameters\"].keys():\n                if p == \"Required_TBR\":\n                    label = \"`Required_TBR\u7ea6\u675f\u503c (hour)`\"\n                else:\n                    label = f\"`{p}`\"\n                param_names_list.append(label)\n            param_names = \", \".join(param_names_list)\n\n            interaction_text = (\n                f\"2.  **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a** \u672c\u6b21\u5206\u6790\u5305\u542b\u4e86\u591a\u53d8\u91cf\u7684\u4ea4\u4e92\u6548\u5e94\u3002\u8bf7\u5206\u6790\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \"\n                f\"\u4e0e\u80cc\u666f\u626b\u63cf\u53c2\u6570 ({param_names}) \u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u5404\u9879\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\u3002\"\n                \"\u8bf7\u6ce8\u610f\uff0c\u72ec\u7acb\u53d8\u91cf\u6216\u80cc\u666f\u626b\u63cf\u53c2\u6570\u4e2d\uff0c\u53ef\u80fd\u5305\u542b\u5e38\u89c4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u53ef\u80fd\u5305\u542b\u4e3a\u6ee1\u8db3\u7279\u5b9a\u6027\u80fd\u76ee\u6807\uff08\u9650\u5236\u500d\u589e\u65f6\u95f4Double_Time\u8fbe\u5230\u500d\u589e\uff09\u800c\u6c42\u89e3\u51fa\u7684\u7279\u6b8a\u53d8\u91cf\uff08\u7ea6\u675f\u9650\u5236\u53d8\u91cfDouble_Time\uff09\u3002\"\n                \"\u8bf7\u8ba8\u8bba\u5728\u4e0d\u540c\u7684\u53d8\u91cf\u7ec4\u5408\u4e0b\uff0c\u6027\u80fd\u6307\u6807\u7684\u654f\u611f\u6027\u6709\u4f55\u4e0d\u540c\uff1f\u662f\u5426\u5b58\u5728\u663e\u8457\u7684\u4ea4\u4e92\u6548\u5e94\uff1f\"\n            )\n            global_sensitivity_points.append(interaction_text)\n\n        prompt_sections.append(\"\\n\".join(global_sensitivity_points))\n\n        # Section 2: Dynamic Process Analysis\n        if reference_col_for_turning_point:\n            dynamic_process_points = [\n                \"3.  **\u52a8\u6001\u8fc7\u7a0b\u5206\u6790 (\u53c2\u8003\u201c\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u8fc7\u7a0b\u6570\u636e\u201d) :**\",\n                \"    *   \u89c2\u5bdf\u8fc7\u7a0b\u6570\u636e\u5207\u7247\uff1a\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u9636\u6bb5\u201d\u548c\u201c\u7ed3\u675f\u9636\u6bb5\u201d\u7684\u884c\u4e3a\u6709\u4f55\u4e0d\u540c\uff1f\",\n                f\"    *   \u4ee5 `{reference_col_for_turning_point}` \u4e3a\u53c2\u8003\uff0c\u5176\u201c\u8f6c\u6298\u70b9\u9636\u6bb5\u201d\u7684\u6570\u636e\u63ed\u793a\u4e86\u4ec0\u4e48\u7269\u7406\u8fc7\u7a0b\uff1f\uff08\u4f8b\u5982\uff0c\u5b83\u662f\u5426\u662f\u6c1a\u5e93\u5b58\u7531\u6d88\u8017\u8f6c\u4e3a\u51c0\u589e\u957f\u7684\u5173\u952e\u65f6\u523b\uff1f\uff09\",\n            ]\n            prompt_sections.append(\"\\n\".join(dynamic_process_points))\n\n        # Section 3: Overall Conclusion (renumbered from 4)\n        conclusion_points = [\"3.  **\u7efc\u5408\u7ed3\u8bba\uff1a**\"]\n        conclusion_intro = \"\u7ed3\u5408\u6240\u6709\u5206\u6790\uff08\u5305\u62ec\u4e3b\u8d8b\u52bf\"\n        if has_sim_params:\n            conclusion_intro += \"\u3001\u80cc\u666f\u53c2\u6570\u4ea4\u4e92\u6548\u5e94\"\n        conclusion_intro += \"\uff09\uff0c\"\n\n        conclusion_points.append(\n            conclusion_intro\n            + f\"\u603b\u7ed3\u5728\u4e0d\u540c\u7684\u8fd0\u884c\u573a\u666f\u4e0b\uff0c\u8c03\u6574 `{independent_variable}` \u5bf9\u6574\u4e2a\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u7684\u7efc\u5408\u5f71\u54cd\u548c\u6f5c\u5728\u7684\u5229\u5f0a\u6743\u8861\u3002\"\n        )\n        conclusion_points.append(\n            \"    *   \u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u53ef\u4ee5\u5f97\u51fa\u54ea\u4e9b\u5173\u4e8e\u7cfb\u7edf\u8bbe\u8ba1\u6216\u8fd0\u884c\u4f18\u5316\u7684\u521d\u6b65\u5efa\u8bae\uff1f\"\n        )\n        prompt_sections.append(\"\\n\".join(conclusion_points))\n\n        # Assemble the final prompt\n        points_prompt = \"\\n\\n\".join(prompt_sections)\n        points_prompt = (\n            \"\\n**\u5206\u6790\u8981\u70b9 (\u5fc5\u987b\u4e25\u683c\u4f9d\u636e\u6570\u636e\u8868\u683c\u4f5c\u7b54)\uff1a**\\n\\n\" + points_prompt\n        )\n\n        # 2. Call API with retry logic\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for case {case_name} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, analysis_prompt, points_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                analysis_result = response.choices[0].message.content\n\n                logger.info(f\"LLM analysis successful for case {case_name}.\")\n                return (\n                    role_prompt\n                    + points_prompt\n                    + \"\\n```\\n\\n\"\n                    + \"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\"\n                    + analysis_result\n                )  # Return the result string\n\n            except Exception as e:\n                logger.error(f\"Error calling OpenAI API on attempt {attempt + 1}: {e}\")\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to call OpenAI API after {max_retries} attempts.\"\n                    )\n                    return None  # Return None on failure\n\n    except Exception as e:\n        logger.error(\n            f\"Error in call_openai_analysis_api for case {case_name}: {e}\",\n            exc_info=True,\n        )\n        return None\n</code></pre>"},{"location":"reference/#tricys.analysis.report.consolidate_reports","title":"<code>consolidate_reports(case_configs, original_config)</code>","text":"<p>Consolidates generated reports and their images into a 'report' directory for each case.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def consolidate_reports(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"\n    Consolidates generated reports and their images into a 'report' directory for each case.\n    \"\"\"\n    logger.info(\"Consolidating analysis reports...\")\n    try:\n        for case_info in case_configs:\n            case_workspace = case_info[\"workspace\"]\n            source_dir = os.path.join(case_workspace, \"results\")\n            dest_dir = os.path.join(case_workspace, \"report\")\n\n            if not os.path.isdir(source_dir):\n                logger.warning(\n                    f\"Source directory not found, skipping consolidation for case: {case_workspace}\"\n                )\n                continue\n\n            # Find files to copy\n            files_to_copy = []\n            for filename in os.listdir(source_dir):\n                if (\n                    filename.startswith(\"analysis_report\")\n                    or filename.startswith(\"academic_report\")\n                ) and filename.endswith(\".md\"):\n                    files_to_copy.append(filename)\n                elif filename.endswith((\".svg\", \".png\")):\n                    files_to_copy.append(filename)\n\n            if not files_to_copy:\n                logger.info(\n                    f\"No reports or images found in {source_dir}, skipping consolidation.\"\n                )\n                continue\n\n            # Create destination directory and copy files\n            os.makedirs(dest_dir, exist_ok=True)\n            logger.info(f\"Consolidating reports into: {dest_dir}\")\n\n            for filename in files_to_copy:\n                source_path = os.path.join(source_dir, filename)\n                shutil.move(source_path, dest_dir)\n                logger.info(f\"Moved {filename} to {dest_dir}\")\n\n    except Exception as e:\n        logger.error(f\"Error during report consolidation: {e}\", exc_info=True)\n</code></pre>"},{"location":"reference/#tricys.analysis.report.generate_analysis_cases_summary","title":"<code>generate_analysis_cases_summary(case_configs, original_config)</code>","text":"<p>Generate summary report for analysis_cases</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def generate_analysis_cases_summary(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"\n    Generate summary report for analysis_cases\"\"\"\n    try:\n        run_timestamp = original_config[\"run_timestamp\"]\n        # Generate report in current working directory\n        current_dir = os.getcwd()\n\n        # Create summary report\n        summary_data = []\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n            case_workspace = case_info[\"workspace\"]\n\n            # Check if case results exist\n            case_results_dir = os.path.join(case_workspace, \"results\")\n            has_results = (\n                os.path.exists(case_results_dir)\n                and len(os.listdir(case_results_dir)) &gt; 0\n            )\n\n            summary_entry = {\n                \"case_name\": case_data.get(\"name\", f\"Case{case_info['index']+1}\"),\n                \"independent_variable\": case_data[\"independent_variable\"],\n                \"independent_variable_sampling\": case_data[\n                    \"independent_variable_sampling\"\n                ],\n                \"workspace_path\": case_workspace,\n                \"has_results\": has_results,\n                \"config_file\": case_info[\"config_path\"],\n            }\n            summary_data.append(summary_entry)\n\n        # Generate text report\n        report_lines = [\n            \"# Analysis Cases Execution Report\",\n            \"\\n## Basic Information\",\n            f\"- Execution time: {run_timestamp}\",\n            f\"- Total cases: {len(case_configs)}\",\n            f\"- Successfully executed: {sum(1 for entry in summary_data if entry['has_results'])}\",\n            f\"- Working directory: {current_dir}\",\n            \"\\n## Case Details\",\n        ]\n\n        for i, entry in enumerate(summary_data, 1):\n            status = \"\u2713 Success\" if entry[\"has_results\"] else \"\u2717 Failed\"\n            report_lines.extend(\n                [\n                    f\"\\n### {i}. {entry['case_name']}\",\n                    f\"- Status: {status}\",\n                    f\"- Independent variable: {entry['independent_variable']}\",\n                    f\"- Sampling method: {entry['independent_variable_sampling']}\",\n                    f\"- Working directory: {entry['workspace_path']}\",\n                    f\"- Configuration file: {entry['config_file']}\",\n                ]\n            )\n\n        # Save report to current directory\n        report_path = os.path.join(\n            current_dir,\n            run_timestamp,\n            f\"execution_report_{run_timestamp}.md\",\n        )\n        os.makedirs(os.path.dirname(report_path), exist_ok=True)\n        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"\\n\".join(report_lines))\n\n        logger.info(\"Summary report generated:\")\n        logger.info(f\"  - Detailed report: {report_path}\")\n\n        # Generate prompt engineering template for each case\n        generate_prompt_templates(case_configs, original_config)\n\n        # Consolidate all generated reports\n        consolidate_reports(case_configs, original_config)\n\n    except Exception as e:\n        logger.error(f\"Error generating summary report: {e}\", exc_info=True)\n</code></pre>"},{"location":"reference/#tricys.analysis.report.generate_prompt_templates","title":"<code>generate_prompt_templates(case_configs, original_config)</code>","text":"<p>Generate detailed Markdown analysis reports for each analysis case.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def generate_prompt_templates(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"Generate detailed Markdown analysis reports for each analysis case.\"\"\"\n\n    def _find_unit_config(var_name: str, unit_map: dict) -&gt; dict | None:\n        \"\"\"\n        Finds the unit configuration for a variable name from the unit_map.\n        1. Checks for an exact match.\n        2. Checks if the last part of a dot-separated name matches.\n        3. Checks for a simple substring containment as a fallback, matching longest keys first.\n        \"\"\"\n        if not unit_map or not var_name:\n            return None\n        if var_name in unit_map:\n            return unit_map[var_name]\n        components = var_name.split(\".\")\n        if len(components) &gt; 1 and components[-1] in unit_map:\n            return unit_map[components[-1]]\n        for key in sorted(unit_map.keys(), key=len, reverse=True):\n            if key in var_name:\n                return unit_map[key]\n        return None\n\n    def _format_label(label: str) -&gt; str:\n        \"\"\"Formats a label for display, replacing underscores/dots with spaces and capitalizing each word.\"\"\"\n        if not isinstance(label, str):\n            return label\n        label = label.replace(\"_\", \" \")\n        label = re.sub(r\"(?&lt;!\\d)\\.|\\.(?!\\d)\", \" \", label)\n        return label  # .title()\n\n    try:\n        sensitivity_analysis_config = original_config.get(\"sensitivity_analysis\", {})\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n\n            if \"analyzer\" in case_data and case_data.get(\"analyzer\", {}).get(\"method\"):\n                logger.info(\n                    f\"Skipping default report generation for SALib case: {case_data.get('name', 'Unknown')}\"\n                )\n                continue\n\n            case_workspace = case_info[\"workspace\"]\n            case_name = case_data.get(\"name\", f\"Case{case_info['index']+1}\")\n\n            case_results_dir = os.path.join(case_workspace, \"results\")\n            if not os.path.exists(case_results_dir):\n                continue\n\n            summary_csv_path = os.path.join(\n                case_results_dir, \"sensitivity_analysis_summary.csv\"\n            )\n            sweep_csv_path = os.path.join(case_results_dir, \"sweep_results.csv\")\n\n            if not os.path.exists(summary_csv_path):\n                logger.warning(\n                    f\"summary_csv not found for case {case_name}, skipping report generation.\"\n                )\n                continue\n\n            summary_df = pd.read_csv(summary_csv_path)\n            independent_variable = case_data.get(\"independent_variable\", \"\u71c3\u70e7\u7387\")\n\n            # Use a dictionary to ensure we only get one version of each plot, prioritizing Chinese\n            all_plots_all_langs = [\n                f for f in os.listdir(case_results_dir) if f.endswith(\".svg\")\n            ]\n            plot_map = {}\n            for plot in sorted(\n                all_plots_all_langs, reverse=True\n            ):  # Process _zh.svg first\n                base_name = plot.replace(\"_zh.svg\", \".svg\")\n                if base_name not in plot_map:\n                    plot_map[base_name] = plot\n\n            all_plots = list(plot_map.values())\n            sweep_plots = [f for f in all_plots if f.startswith(\"sweep_\")]\n            combined_plots = [f for f in all_plots if f.startswith(\"combined_\")]\n            multi_metric_plots = [\n                f\n                for f in all_plots\n                if f.startswith(\"multi_\") and f.endswith(\"_analysis_by_param.svg\")\n            ]\n            all_individual_plots = [\n                f\n                for f in all_plots\n                if not f.startswith(\"sweep_\")\n                and not f.startswith(\"combined_\")\n                and not f.startswith(\"multi_\")\n            ]\n            required_individual_plots = [\n                f for f in all_individual_plots if f.startswith(\"line_Required_\")\n            ]\n            standard_individual_plots = [\n                f for f in all_individual_plots if not f.startswith(\"line_Required_\")\n            ]\n\n            # --- Markdown Generation (with dynamic title) ---\n            sim_params = case_data.get(\"simulation_parameters\")\n            if sim_params:\n                main_var_label = _format_label(independent_variable)\n\n                other_vars_labels_list = []\n                for p in sim_params.keys():\n                    if p == \"Required_TBR\":\n                        label = \"Required_TBR\u7ea6\u675f\u503c\"\n                    else:\n                        label = _format_label(p)\n                    other_vars_labels_list.append(label)\n                other_vars_labels = \"\u3001\".join(other_vars_labels_list)\n\n                report_title = (\n                    f\"# {main_var_label} \u4e0e {other_vars_labels} \u4ea4\u4e92\u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n                )\n            else:\n                report_title = (\n                    f\"# {_format_label(independent_variable)} \u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n                )\n\n            prompt_lines = [\n                report_title,\n                f\"\u751f\u6210\u65f6\u95f4: {pd.Timestamp.now()}\\n\\n\",\n            ]\n\n            config_details_lines = [\n                \"## \u5206\u6790\u6848\u4f8b\u914d\u7f6e\u8be6\u60c5\\n\\n\",\n                \"\u672c\u5206\u6790\u6848\u4f8b\u7684\u5177\u4f53\u914d\u7f6e\u5982\u4e0b\uff0c\u8fd9\u51b3\u5b9a\u4e86\u4eff\u771f\u7684\u626b\u63cf\u65b9\u5f0f\u548c\u5206\u6790\u7684\u91cd\u70b9\uff1a\\n\\n\",\n                \"| \u914d\u7f6e\u9879 | \u503c | \u8bf4\u660e |\",\n                \"| :--- | :--- | :--- |\",\n            ]\n\n            def format_for_md(value):\n                return f\"`{json.dumps(value, ensure_ascii=False)}`\".replace(\"|\", \"\\\\|\")\n\n            config_details_lines.extend(\n                [\n                    f\"| **`name`** | {format_for_md(case_name)} | \u672c\u6b21\u5206\u6790\u6848\u4f8b\u7684\u540d\u79f0\u3002 |\",\n                    f\"| **`independent_variable`** | {format_for_md(independent_variable)} | \u72ec\u7acb\u626b\u63cf\u53d8\u91cf\uff0c\u5373\u672c\u6b21\u5206\u6790\u4e2d\u4e3b\u8981\u6539\u53d8\u7684\u53c2\u6570\u3002 |\",\n                    f\"| **`independent_variable_sampling`** | {format_for_md(case_data.get('independent_variable_sampling'))} | \u72ec\u7acb\u53d8\u91cf\u7684\u91c7\u6837\u65b9\u6cd5\u548c\u8303\u56f4\u3002 |\",\n                ]\n            )\n            if \"default_independent_values\" in case_data:\n                config_details_lines.append(\n                    f\"| **`default_independent_values`** | {format_for_md(case_data['default_independent_values'])} | \u72ec\u7acb\u626b\u63cf\u53d8\u91cf\u5728\u6a21\u578b\u4e2d\u7684\u539f\u59cb\u9ed8\u8ba4\u503c\u3002 |\"\n                )\n            if (\n                \"simulation_parameters\" in case_data\n                and case_data[\"simulation_parameters\"]\n            ):\n                config_details_lines.append(\n                    f\"| **`simulation_parameters`** | {format_for_md(case_data['simulation_parameters'])} | \u80cc\u666f\u626b\u63cf\u53c2\u6570\uff0c\u4e0e\u72ec\u7acb\u53d8\u91cf\u7ec4\u5408\u5f62\u6210\u591a\u7ef4\u626b\u63cf\u3002 |\"\n                )\n            if (\n                \"default_simulation_values\" in case_data\n                and case_data[\"default_simulation_values\"]\n            ):\n                config_details_lines.append(\n                    f\"| **`default_simulation_values`** | {format_for_md(case_data['default_simulation_values'])} | \u80cc\u666f\u626b\u63cf\u53c2\u6570\u5728\u6a21\u578b\u4e2d\u7684\u539f\u59cb\u9ed8\u8ba4\u503c\u3002 |\"\n                )\n            config_details_lines.append(\n                f\"| **`dependent_variables`** | {format_for_md(case_data.get('dependent_variables'))} | \u56e0\u53d8\u91cf\uff0c\u5373\u6211\u4eec\u5173\u5fc3\u7684\u3001\u968f\u81ea\u53d8\u91cf\u53d8\u5316\u7684\u6027\u80fd\u6307\u6807\u3002 |\"\n            )\n            config_details_lines.append(\"\\n\")\n            prompt_lines.extend(config_details_lines)\n\n            optimization_metrics = [\n                v\n                for v in case_data.get(\"dependent_variables\", [])\n                if v.startswith(\"Required_\")\n            ]\n            if optimization_metrics:\n                for metric_name in optimization_metrics:\n                    metric_config = (\n                        original_config.get(\"sensitivity_analysis\", {})\n                        .get(\"metrics_definition\", {})\n                        .get(metric_name)\n                    )\n                    if metric_config:\n                        details_lines = [\n                            f\"## \u201c{metric_name}\u201d\u4f18\u5316\u914d\u7f6e\\n\",\n                            f\"\u5f53\u201c{metric_name}\u201d\u4f5c\u4e3a\u56e0\u53d8\u91cf\u65f6\uff0c\u7cfb\u7edf\u4f1a\u542f\u7528\u4e00\u4e2a\u4e8c\u5206\u67e5\u627e\u7b97\u6cd5\u6765\u5bfb\u627e\u6ee1\u8db3\u7279\u5b9a\u6027\u80fd\u6307\u6807\u7684\u6700\u5c0f`{metric_config.get('parameter_to_optimize', 'N/A')}`\u503c\u3002\u4ee5\u4e0b\u662f\u672c\u6b21\u4f18\u5316\u4efb\u52a1\u7684\u5177\u4f53\u914d\u7f6e\uff1a\\n\\n\",\n                            \"| \u914d\u7f6e\u9879 | \u503c | \u8bf4\u660e |\",\n                            \"| :--- | :--- | :--- |\",\n                        ]\n                        config_map = {\n                            \"source_column\": \"\u9650\u5236\u6761\u4ef6\u7684\u6570\u636e\u6e90\u5217\u3002\",\n                            \"parameter_to_optimize\": \"\u4f18\u5316\u7684\u76ee\u6807\u53c2\u6570\u3002\",\n                            \"search_range\": \"\u53c2\u6570\u7684\u641c\u7d22\u8303\u56f4\u3002\",\n                            \"tolerance\": \"\u641c\u7d22\u7684\u6536\u655b\u7cbe\u5ea6\u3002\",\n                            \"max_iterations\": \"\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u3002\",\n                            \"metric_name\": \"\u9650\u5236\u6761\u4ef6\u7684\u6027\u80fd\u6307\u6807\u3002\",\n                            \"metric_max_value\": \"\u9650\u5236\u6761\u4ef6\u6ee1\u8db3\u7684\u4e0a\u9650\u503c\u3002\uff08hour\uff09\",\n                        }\n                        for key, description in config_map.items():\n                            if key in metric_config:\n                                value = metric_config[key]\n                                details_lines.append(\n                                    f\"| **`{key}`** | {format_for_md(value)} | {description} |\"\n                                )\n\n                            metric_config_sim = case_data.get(\n                                \"simulation_parameters\", {}\n                            ).get(\"Required_TBR\", {})\n                            if metric_config_sim and key in metric_config_sim:\n                                value = metric_config_sim[key]\n                                details_lines.append(\n                                    f\"| **`{key} (from simulation_parameters)`** | {format_for_md(value)} | {description} |\"\n                                )\n\n                        details_lines.append(\"\\n\")\n                        prompt_lines.extend(details_lines)\n\n            for plot in sweep_plots:\n                prompt_lines.extend(\n                    [\n                        \"## SDS Inventory \u7684\u65f6\u95f4\u66f2\u7ebf\u56fe:\\n\\n\",\n                        f\"![SDS Inventory \u7684\u65f6\u95f4\u66f2\u7ebf\u56fe]({plot})\\n\\n\",\n                    ]\n                )\n                if \"default_simulation_values\" in case_data and case_data.get(\n                    \"default_simulation_values\"\n                ):\n                    default_values_str = json.dumps(\n                        case_data[\"default_simulation_values\"],\n                        ensure_ascii=False,\n                        indent=4,\n                    )\n                    note = (\n                        \"**\u7b5b\u9009\u8bf4\u660e**\uff1a\u5f53\u5b58\u5728\u591a\u4e2a\u80cc\u666f\u626b\u63cf\u53c2\u6570 (`simulation_parameters`) \u65f6\uff0c\u4e3a\u7a81\u51fa\u91cd\u70b9\uff0c\u4e0a\u56fe\u9ed8\u8ba4\u4ec5\u663e\u793a\u4e0e\u539f\u59cb\u9ed8\u8ba4\u503c \"\n                        f\"(`default_simulation_values`) \u76f8\u5339\u914d\u7684\u57fa\u51c6\u60c5\u666f\u66f2\u7ebf\u3002\u672c\u6b21\u5206\u6790\u4e2d\u7528\u4e8e\u7b5b\u9009\u7684\u9ed8\u8ba4\u503c\u4e3a\uff1a\\n\\n\"\n                        f\"```json\\n{default_values_str}\\n```\\n\\n\"\n                        \"\u6b64\u65b9\u6cd5\u6709\u52a9\u4e8e\u5728\u56fa\u5b9a\u7684\u57fa\u51c6\u6761\u4ef6\u4e0b\uff0c\u6e05\u6670\u5730\u89c2\u5bdf\u72ec\u7acb\u53d8\u91cf\u53d8\u5316\u5e26\u6765\u7684\u5f71\u54cd\u3002\\n\"\n                    )\n                    prompt_lines.append(note)\n\n            if combined_plots:\n                for plot in combined_plots:\n                    title = \"\u6027\u80fd\u6307\u6807\u8d8b\u52bf\u66f2\u7ebf\u56fe\"\n                    prompt_lines.extend([f\"## {title}\\n\\n\", f\"![{title}]({plot})\\n\"])\n            elif standard_individual_plots:\n                prompt_lines.append(\"## \u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\\n\\n\")\n                for plot in standard_individual_plots:\n                    title = _format_label(\n                        os.path.splitext(plot)[0].replace(\"line_\", \"\")\n                    )\n                    prompt_lines.extend([f\"### {title}\\n\", f\"![{title}]({plot})\\n\\n\"])\n\n            if multi_metric_plots or required_individual_plots:\n                prompt_lines.append(\"## \u7ea6\u675f\u6c42\u89e3\u6027\u80fd\u6307\u6807\u5206\u6790\u56fe\\n\\n\")\n                for plot_file in multi_metric_plots:\n                    try:\n                        base_metric_name = plot_file.replace(\"multi_\", \"\").replace(\n                            \"_analysis_by_param.svg\", \"\"\n                        )\n                        friendly_name = _format_label(base_metric_name)\n                    except Exception:\n                        friendly_name = \"Optimization\"\n                    prompt_lines.extend(\n                        [\n                            f\"### \u4e0d\u540c\u7ea6\u675f\u503c\u4e0b\u7684\u201c{friendly_name}\u201d\u5206\u6790 (\u6309\u53c2\u6570\u5206\u7ec4)\\n\",\n                            f\"\u4e0b\u56fe\u5c55\u793a\u4e86\u201c{friendly_name}\u201d\u6307\u6807\u968f\u72ec\u7acb\u53d8\u91cf\u53d8\u5316\u7684\u8d8b\u52bf\u3002\u6bcf\u4e2a\u5b50\u56fe\u5bf9\u5e94\u4e00\u7ec4\u7279\u5b9a\u7684\u80cc\u666f\u626b\u63cf\u53c2\u6570\u7ec4\u5408\uff0c\u5b50\u56fe\u5185\u7684\u6bcf\u6761\u66f2\u7ebf\u4ee3\u8868\u4e00\u4e2a\u5177\u4f53\u7684\u7ea6\u675f\u503c\u3002\\n\\n\",\n                            f\"![\u4e0d\u540c\u7ea6\u675f\u503c\u4e0b\u7684{friendly_name}\u5206\u6790]({plot_file})\\n\\n\",\n                        ]\n                    )\n                for plot_file in required_individual_plots:\n                    title = _format_label(\n                        os.path.splitext(plot_file)[0].replace(\"line_\", \"\")\n                    )\n                    prompt_lines.extend(\n                        [f\"### {title}\\n\", f\"![{title}]({plot_file})\\n\\n\"]\n                    )\n\n            def _format_df_to_md(\n                sub_df: pd.DataFrame,\n                ind_var: str,\n                case_data: dict,\n                current_unit_map: dict,\n            ) -&gt; str:\n                if sub_df.empty:\n                    return \"\u65e0\u6570\u636e\u3002\"\n                all_markdown_lines = []\n                all_cols = sub_df.columns.tolist()\n                if ind_var in all_cols:\n                    all_cols.remove(ind_var)\n                standard_cols = [\n                    c\n                    for c in all_cols\n                    if not (c.startswith(\"Required_\") or \"_for_Required_\" in c)\n                ]\n                required_groups = {}\n                required_base_names = [\n                    v\n                    for v in case_data.get(\"dependent_variables\", [])\n                    if v.startswith(\"Required_\")\n                ]\n                for base_name in required_base_names:\n                    group_cols = []\n                    # pattern = re.compile(f\"_for_{re.escape(base_name)}(?:\\\\(.*\\\\))?$\")\n                    for col in all_cols:\n                        if col == base_name or col.startswith(base_name + \"(\"):\n                            group_cols.append(col)\n                    if group_cols:\n                        required_groups[base_name] = group_cols\n\n                def _format_slice_to_md(df_slice: pd.DataFrame, umap: dict) -&gt; str:\n                    if df_slice.empty:\n                        return \"\"\n                    df_formatted = df_slice.copy()\n                    new_columns = {}\n                    for col_name in df_formatted.columns:\n                        unit_config = _find_unit_config(col_name, umap)\n                        new_col_name = _format_label(col_name)\n                        if unit_config:\n                            unit = unit_config.get(\"unit\")\n                            factor = unit_config.get(\"conversion_factor\")\n                            if factor and pd.api.types.is_numeric_dtype(\n                                df_formatted[col_name]\n                            ):\n                                df_formatted[col_name] = df_formatted[col_name] / float(\n                                    factor\n                                )\n                            if unit:\n                                new_col_name = f\"{new_col_name} ({unit})\"\n                        new_columns[col_name] = new_col_name\n                    df_formatted.rename(columns=new_columns, inplace=True)\n                    format_map = {}\n                    for original_col_name in df_slice.columns:\n                        if original_col_name.startswith(\"Required_\"):\n                            format_map[new_columns[original_col_name]] = \"{:.4f}\"\n                    default_format = \"{:.2f}\"\n                    for col in df_formatted.columns:\n                        if pd.api.types.is_numeric_dtype(df_formatted[col]):\n                            formatter = format_map.get(col, default_format)\n                            df_formatted[col] = df_formatted[col].apply(\n                                lambda x: formatter.format(x) if pd.notnull(x) else x\n                            )\n                    return df_formatted.to_markdown(index=False)\n\n                if standard_cols:\n                    all_markdown_lines.append(\"##### \u6027\u80fd\u6307\u6807\\n\")\n                    std_df_slice = sub_df[[ind_var] + sorted(standard_cols)]\n                    all_markdown_lines.append(\n                        _format_slice_to_md(std_df_slice, current_unit_map)\n                    )\n                    all_markdown_lines.append(\"\\n\")\n                if required_groups:\n                    for base_name, cols in required_groups.items():\n                        existing_cols = [c for c in cols if c in sub_df.columns]\n                        if not existing_cols:\n                            continue\n\n                        all_markdown_lines.append(\n                            f\"##### \u201c{_format_label(base_name)}\u201d \u76f8\u5173\u6570\u636e\\n\"\n                        )\n                        req_df_slice = sub_df[[ind_var] + sorted(existing_cols)]\n\n                        try:\n                            # --- PIVOT LOGIC to transform data from wide to long format ---\n                            # e.g., from [A, B(v1), B(v2)] to [A, new_col, B]\n\n                            # Columns to unpivot, e.g., ['Required_TBR(7.0)', 'Required_TBR(10.0)']\n                            value_vars = [\n                                c\n                                for c in req_df_slice.columns\n                                if c.startswith(base_name)\n                                and \"(\" in c\n                                and c.endswith(\")\")\n                            ]\n\n                            # If no columns are in the format B(v), pivot is not applicable.\n                            if not value_vars:\n                                all_markdown_lines.append(\n                                    _format_slice_to_md(req_df_slice, current_unit_map)\n                                )\n                                all_markdown_lines.append(\"\\n\")\n                                continue\n\n                            # Melt the dataframe from wide to long format\n                            melted_df = req_df_slice.melt(\n                                id_vars=[ind_var],\n                                value_vars=value_vars,\n                                var_name=\"variable_col\",\n                                value_name=base_name,\n                            )\n\n                            # Determine the name for the new column from config (e.g., 'Doubling_Time')\n                            new_col_name = \"Constraint\"  # Default name\n                            metric_def = case_data.get(\"simulation_parameters\").get(\n                                \"Required_TBR\"\n                            )\n                            if metric_def and metric_def.get(\"metric_name\"):\n                                new_col_name = \"Constraint \" + metric_def[\"metric_name\"]\n\n                            # Extract constraint value from old column name, e.g., '7.0' from 'Required_TBR(7.0)'\n                            pattern_str = f\"{re.escape(base_name)}\\\\((.*)\\\\)\"\n                            melted_df[new_col_name] = melted_df[\n                                \"variable_col\"\n                            ].str.extract(pat=pattern_str)\n\n                            # Create the final dataframe with the desired columns: [A, new_col, B]\n                            final_df = melted_df[\n                                [ind_var, new_col_name, base_name]\n                            ].copy()\n                            final_df.dropna(subset=[base_name], inplace=True)\n\n                            all_markdown_lines.append(final_df.to_markdown(index=False))\n                            all_markdown_lines.append(\"\\n\")\n\n                        except Exception as e:\n                            logger.warning(\n                                f\"Could not pivot data for '{base_name}', displaying in wide format. Error: {e}\"\n                            )\n                            all_markdown_lines.append(\n                                _format_slice_to_md(req_df_slice, current_unit_map)\n                            )\n                            all_markdown_lines.append(\"\\n\")\n                return \"\\n\".join(all_markdown_lines)\n\n            reference_col_for_turning_point = None\n            if case_data.get(\"sweep_time\") and os.path.exists(sweep_csv_path):\n                try:\n                    logger.info(\"Loading sweep_results.csv for dynamic slicing.\")\n                    sweep_df = pd.read_csv(sweep_csv_path)\n                    if \"time\" in sweep_df.columns and len(sweep_df.columns) &gt; 1:\n                        reference_col_for_turning_point = sweep_df.columns[\n                            len(sweep_df.columns) // 2\n                        ]\n                    if reference_col_for_turning_point:\n                        data_to_slice_df = sweep_df.copy()\n                        data_to_slice_df.reset_index(drop=True, inplace=True)\n                        if not data_to_slice_df.empty:\n                            prompt_lines.append(\"## \u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff1a\u8fc7\u7a0b\u6570\u636e\\n\\n\")\n                            prompt_lines.append(\n                                f\"\u4e0b\u8868\u5c55\u793a\u4e86\u8fc7\u7a0b\u6570\u636e\u4e2d\uff0c\u4ee5 `{reference_col_for_turning_point}` \u4e3a\u53c2\u8003\u53d8\u91cf\uff0c\u5728\u5173\u952e\u9636\u6bb5\u7684\u6570\u636e\u5207\u7247\u3002**\u6ce8\u610f\uff1a\u4e0b\u8868\u4e2d\u7684\u9ed8\u8ba4\u5355\u4f4d\u4e3a\uff1a\u65f6\u95f4(h), \u5e93\u5b58(g), \u529f\u7387(MW)\u3002**\\n\\n\"\n                            )\n                            base_var_name = reference_col_for_turning_point.split(\"&amp;\")[\n                                0\n                            ]\n                            cols_to_rename = [\n                                c for c in data_to_slice_df.columns if c != \"time\"\n                            ]\n                            rename_map = {\n                                col: f\"C{i+1}\" for i, col in enumerate(cols_to_rename)\n                            }\n                            legend_lines = [\n                                \"**\u8868\u683c\u56fe\u4f8b\u8bf4\u660e**\uff1a\",\n                                \"| \u7b80\u79f0 | \u53c2\u6570\u7ec4\u5408 |\",\n                                \"| :--- | :--- |\",\n                            ]\n                            for original_name, abbr in rename_map.items():\n                                param_parts = original_name.split(\"&amp;\", 1)\n                                param_str = (\n                                    param_parts[1] if len(param_parts) &gt; 1 else \"\u65e0\"\n                                )\n                                param_str_formatted = (\n                                    \"`\" + \"`, `\".join(param_str.split(\"&amp;\")) + \"`\"\n                                )\n                                legend_lines.append(\n                                    f\"| **{abbr}** | {param_str_formatted} |\"\n                                )\n                            base_var_info = f\"**\u6ce8**\uff1a\u8868\u683c\u4e2d\u6240\u6709\u7b80\u79f0\u5217\uff08C1, C2, ...\uff09\u7684\u6570\u636e\u5747\u4ee3\u8868\u53d8\u91cf `{base_var_name}` \u5728\u4e0d\u540c\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u503c\u3002\\n\"\n                            legend_md = base_var_info + \"\\n\".join(legend_lines) + \"\\n\\n\"\n                            prompt_lines.append(legend_md)\n                            primary_y_var = reference_col_for_turning_point\n                            min_idx = -1\n                            if primary_y_var in data_to_slice_df.columns:\n                                y_data = data_to_slice_df[primary_y_var]\n                                if not y_data.empty:\n                                    min_idx = y_data.idxmin()\n                            num_points, interval = 20, 2\n                            window_size = (num_points - 1) * interval + 1\n                            start_data = data_to_slice_df.iloc[:window_size:interval]\n                            end_data = data_to_slice_df.iloc[-(window_size)::interval]\n                            prompt_lines.append(\n                                f\"### 1. \u521d\u59cb\u9636\u6bb5 (\u524d {num_points} \u4e2a\u6570\u636e\u70b9, \u95f4\u9694 {interval})\\n\"\n                            )\n                            prompt_lines.append(\n                                start_data.rename(columns=rename_map).to_markdown(\n                                    index=False\n                                )\n                                + \"\\n\\n\"\n                            )\n                            if min_idx != -1:\n                                window_radius_indices = (num_points // 2) * interval\n                                start_idx = max(0, min_idx - window_radius_indices)\n                                end_idx = min(\n                                    len(data_to_slice_df),\n                                    min_idx + window_radius_indices,\n                                )\n                                turning_point_data = data_to_slice_df.iloc[\n                                    start_idx:end_idx:interval\n                                ]\n                                prompt_lines.append(\n                                    f\"### 2. \u8f6c\u6298\u70b9\u9636\u6bb5 (\u56f4\u7ed5 '{primary_y_var}' \u6700\u5c0f\u503c)\\n\"\n                                )\n                                prompt_lines.append(\n                                    turning_point_data.rename(\n                                        columns=rename_map\n                                    ).to_markdown(index=False)\n                                    + \"\\n\\n\"\n                                )\n                            prompt_lines.append(\n                                f\"### 3. \u7ed3\u675f\u9636\u6bb5 (\u540e {num_points} \u4e2a\u6570\u636e\u70b9, \u95f4\u9694 {interval})\\n\"\n                            )\n                            prompt_lines.append(\n                                end_data.rename(columns=rename_map).to_markdown(\n                                    index=False\n                                )\n                                + \"\\n\\n\"\n                            )\n                except Exception as e:\n                    logger.warning(\n                        f\"Could not generate dynamic data slices for case {case_name}: {e}\"\n                    )\n\n            grouping_vars = list(case_data.get(\"default_simulation_values\", {}).keys())\n            if not grouping_vars:\n                prompt_lines.append(\"## \u6027\u80fd\u6307\u6807\u603b\u8868\\n\\n\")\n                prompt_lines.append(\n                    _format_df_to_md(\n                        summary_df, independent_variable, case_data, unit_map\n                    )\n                )\n            else:\n                prompt_lines.append(\n                    f\"## \u6027\u80fd\u6307\u6807\u603b\u8868 (\u5206\u7ec4: `{'`, `'.join(grouping_vars)}`)\\n\\n\"\n                )\n                groups = dict(list(summary_df.groupby(grouping_vars)))\n                default_values = case_data.get(\"default_simulation_values\")\n                default_group_key = None\n                if default_values:\n                    try:\n                        default_group_key = tuple(\n                            default_values[key] for key in grouping_vars\n                        )\n                    except KeyError:\n                        logger.warning(\n                            \"Mismatch between default_simulation_values and grouping_vars. Cannot find default group.\"\n                        )\n                        default_group_key = None\n                if default_group_key and default_group_key in groups:\n                    default_group_df = groups.pop(default_group_key)\n                    header = \" &amp; \".join(\n                        f\"`{var}={val}`\"\n                        for var, val in zip(grouping_vars, default_group_key)\n                    )\n                    prompt_lines.append(f\"#### \u6570\u636e\u5b50\u8868 (\u539f\u59cb\u9ed8\u8ba4\u503c: {header})\\n\")\n                    sub_df_to_format = default_group_df.drop(\n                        columns=grouping_vars, errors=\"ignore\"\n                    )\n                    prompt_lines.append(\n                        _format_df_to_md(\n                            sub_df_to_format, independent_variable, case_data, unit_map\n                        )\n                    )\n                    prompt_lines.append(\"\\n---\\n\")\n                if groups:\n                    prompt_lines.append(\"&gt; \u5176\u4ed6\u53c2\u6570\u7ec4\u5408\u4e0b\u7684\u6570\u636e\u5b50\u8868\uff1a\\n\")\n                for group_name, group_df in groups.items():\n                    header = (\n                        \" &amp; \".join(\n                            f\"`{var}={val}`\"\n                            for var, val in zip(grouping_vars, group_name)\n                        )\n                        if isinstance(group_name, tuple)\n                        else f\"`{grouping_vars[0]}={group_name}`\"\n                    )\n                    prompt_lines.append(f\"#### \u6570\u636e\u5b50\u8868 (\u5f53 {header} \u65f6)\\n\")\n                    sub_df_to_format = group_df.drop(\n                        columns=grouping_vars, errors=\"ignore\"\n                    )\n                    prompt_lines.append(\n                        _format_df_to_md(\n                            sub_df_to_format, independent_variable, case_data, unit_map\n                        )\n                    )\n                    prompt_lines.append(\"\\n\")\n\n            base_report_content = \"\\n\".join(prompt_lines)\n\n            # --- AI Analysis and Report Writing ---\n            if not case_data.get(\"ai\", False):\n                # AI is off: write a single, simple report\n                report_path = os.path.join(\n                    case_results_dir, f\"analysis_report_{case_name}.md\"\n                )\n                with open(report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Detailed analysis report generated for {case_name}: {report_path}\"\n                )\n                continue  # Go to next case\n\n            # AI is ON: go into multi-model logic\n            load_dotenv()\n            api_key = os.environ.get(\"API_KEY\")\n            base_url = os.environ.get(\"BASE_URL\")\n\n            ai_models_str = os.environ.get(\"AI_MODELS\")\n            if not ai_models_str:\n                ai_models_str = os.environ.get(\"AI_MODEL\")\n\n            if not all((api_key, base_url, ai_models_str)):\n                logger.warning(\n                    \"API_KEY, BASE_URL, or AI_MODELS/AI_MODEL not found in environment variables. Skipping LLM analysis.\"\n                )\n                # Also write the base report here so something is generated\n                report_path = os.path.join(\n                    case_results_dir, f\"analysis_report_{case_name}.md\"\n                )\n                with open(report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Wrote base report for {case_name} because AI credentials were not found: {report_path}\"\n                )\n                continue\n\n            ai_models = [model.strip() for model in ai_models_str.split(\",\")]\n\n            for ai_model in ai_models:\n                logger.info(\n                    f\"Generating AI analysis for case '{case_name}' with model '{ai_model}'.\"\n                )\n\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                model_report_filename = (\n                    f\"analysis_report_{case_name}_{sanitized_model_name}.md\"\n                )\n                model_report_path = os.path.join(\n                    case_results_dir, model_report_filename\n                )\n\n                with open(model_report_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(base_report_content)\n                logger.info(\n                    f\"Generated base report for model {ai_model}: {model_report_path}\"\n                )\n\n                llm_analysis = call_openai_analysis_api(\n                    case_name=case_name,\n                    df=summary_df,\n                    api_key=api_key,\n                    base_url=base_url,\n                    ai_model=ai_model,\n                    independent_variable=independent_variable,\n                    report_content=base_report_content,\n                    original_config=original_config,\n                    case_data=case_data,\n                    reference_col_for_turning_point=reference_col_for_turning_point,\n                )\n\n                if llm_analysis:\n                    with open(model_report_path, \"a\", encoding=\"utf-8\") as f:\n                        f.write(\n                            f\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd ({ai_model})\\n\\n```markdown\\n\"\n                        )\n                        f.write(llm_analysis)\n                        f.write(\"\\n```\\n\")\n                    logger.info(f\"Appended LLM analysis to {model_report_path}\")\n\n                    generate_sensitivity_academic_report(\n                        case_name=case_name,\n                        case_workspace=case_workspace,\n                        independent_variable=independent_variable,\n                        original_config=original_config,\n                        case_data=case_data,\n                        ai_model=ai_model,\n                        report_path=model_report_path,\n                    )\n\n    except Exception as e:\n        logger.error(f\"Error generating detailed analysis reports: {e}\", exc_info=True)\n</code></pre>"},{"location":"reference/#tricys.analysis.report.generate_sensitivity_academic_report","title":"<code>generate_sensitivity_academic_report(case_name, case_workspace, independent_variable, original_config, case_data, ai_model, report_path)</code>","text":"<p>Generates a professional academic analysis summary for a sensitivity analysis case by sending the existing report and a glossary of terms to an LLM.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def generate_sensitivity_academic_report(\n    case_name: str,\n    case_workspace: str,\n    independent_variable: str,\n    original_config: dict,\n    case_data: dict,\n    ai_model: str,\n    report_path: str,\n) -&gt; None:\n    \"\"\"\n    Generates a professional academic analysis summary for a sensitivity analysis case\n    by sending the existing report and a glossary of terms to an LLM.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Starting generation of the academic analysis summary for case {case_name} with model {ai_model}.\"\n        )\n\n        # 1. Read the existing report\n        results_dir = os.path.join(case_workspace, \"results\")\n        report_filename = os.path.basename(report_path)\n\n        if not os.path.exists(report_path):\n            logger.error(\n                f\"Cannot generate academic summary: Original report '{report_path}' not found.\"\n            )\n            return\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            original_report_content = f.read()\n\n        # 2. Read the glossary\n        glossary_path = original_config.get(\"sensitivity_analysis\", {}).get(\n            \"glossary_path\", \"./sheets.csv\"\n        )\n        if not os.path.exists(glossary_path):\n            logger.error(\n                f\"Cannot generate academic summary: Glossary file '{glossary_path}' not found.\"\n            )\n            return\n        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n            glossary_content = f.read()\n\n        # 3. Check for API credentials\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        if not all([api_key, base_url, ai_model]):\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not found. Skipping academic summary generation.\"\n            )\n            return\n\n        # 4. Construct the prompt\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e**\u654f\u611f\u6027\u5206\u6790**\u7684\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7684\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\"\"\"\n\n        # Extract relevant details from case_data for the prompt\n        sampling_range = case_data.get(\"independent_variable_sampling\", {})\n        simulation_parameters = case_data.get(\"simulation_parameters\", {})\n        dependent_variables = case_data.get(\"dependent_variables\", [])\n\n        simulation_params_str = \"\"\n        if simulation_parameters:\n            params_list = []\n            # Access metric definitions from the original config\n            metrics_definitions = original_config.get(\"sensitivity_analysis\", {}).get(\n                \"metrics_definition\", {}\n            )\n\n            for k, v in simulation_parameters.items():\n                # Check if the parameter is a 'Required_' metric and has configurations defined\n                if (\n                    k.startswith(\"Required_\")\n                    and k in metrics_definitions\n                    and \"configurations\" in metrics_definitions[k]\n                ):\n                    try:\n                        metric_configs = metrics_definitions[k][\"configurations\"]\n                        # Look up the metric_max_value for each configuration key in the scan list `v`\n                        actual_values = [\n                            metric_configs.get(conf_name, {}).get(\n                                \"metric_max_value\", conf_name\n                            )\n                            for conf_name in v\n                        ]\n                        params_list.append(f\"`{k}` (\u7ea6\u675f\u626b\u63cf\u503c): {actual_values}\")\n                    except Exception:\n                        # If lookup fails for any reason, fall back to the original representation\n                        params_list.append(f\"`{k}`: {v}\")\n                else:\n                    # For regular parameters\n                    params_list.append(f\"`{k}`: {v}\")\n\n            simulation_params_str = (\n                \"\\n        *   **\u80cc\u666f\u626b\u63cf\u53c2\u6570 (Simulation Parameters):** \"\n                + \", \".join(params_list)\n            )\n\n        dependent_vars_str = \"\"\n        if dependent_variables:\n            dependent_vars_str = (\n                \"\\n        *   **\u56e0\u53d8\u91cf (Dependent Variables):** \"\n                + \", \".join([f\"`{v}`\" for v in dependent_variables])\n            )\n\n        # Find all plots to instruct the LLM to include them, prioritizing Chinese versions\n        all_files = [f for f in os.listdir(results_dir) if f.endswith((\".svg\", \".png\"))]\n\n        plot_map = {}\n        # Handle SVGs, prioritizing _zh versions\n        svg_plots = sorted([f for f in all_files if f.endswith(\".svg\")], reverse=True)\n        for plot in svg_plots:\n            base_name = plot.replace(\"_zh.svg\", \".svg\")\n            if base_name not in plot_map:\n                plot_map[base_name] = plot\n\n        # Add PNGs (which are not bilingual)\n        png_plots = [f for f in all_files if f.endswith(\".png\")]\n        for plot in png_plots:\n            plot_map[plot] = plot  # Use plot name as key for uniqueness\n\n        all_plots = list(plot_map.values())\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n\n        # Dynamically build the \"Results and Discussion\" section for the prompt\n        results_and_discussion_points = []\n\n        # 1. Main Effect Analysis (always included)\n        main_effect_text = (\n            f\"           *   **\u4e3b\u6548\u5e94\u5206\u6790\uff1a** \u8be6\u7ec6\u5206\u6790\u72ec\u7acb\u53d8\u91cf **`{independent_variable}`** \u7684\u53d8\u5316\u5bf9\u4e3b\u8981\u6027\u80fd\u6307\u6807\uff08\u5982 `Startup_Inventory`, `Doubling_Time` \u7b49\uff09\u7684\u603b\u4f53\u5f71\u54cd\u8d8b\u52bf\u3002\"\n            \"\u8bc4\u4f30\u4e0d\u540c\u6307\u6807\u5bf9\u81ea\u53d8\u91cf\u53d8\u5316\u7684\u654f\u611f\u5ea6\uff0c\u5e76\u8ba8\u8bba\u6307\u6807\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\"\n        )\n        results_and_discussion_points.append(main_effect_text)\n\n        # 2. Interaction Effect Analysis (conditional)\n        if simulation_parameters:\n            interaction_text = (\n                f\"           *   **\u4ea4\u4e92\u6548\u5e94\u5206\u6790\uff1a** \u6df1\u5165\u63a2\u8ba8\u72ec\u7acb\u53d8\u91cf\u4e0e\u80cc\u666f\u53c2\u6570\u95f4\u7684**\u4ea4\u4e92\u6548\u5e94**\u3002\"\n                \"\u80cc\u666f\u53c2\u6570\u53ef\u80fd\u5305\u542b\u5e38\u89c4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u53ef\u80fd\u5305\u542b\u7ea6\u675f\u76f8\u5173\u7684\u53d8\u91cf\uff08\u4f8b\u5982 `Required_TBR`\uff09\u3002\"\n                f\"\u8bf7\u9610\u8ff0\u5728\u4e0d\u540c\u7684\u80cc\u666f\u53c2\u6570\u7ec4\u5408\u4e0b\uff0c`{independent_variable}` \u5bf9\u6027\u80fd\u6307\u6807\u7684\u654f\u611f\u6027\u662f\u5426\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08\u4f8b\u5982\uff0c\u662f\u88ab\u653e\u5927\u8fd8\u662f\u51cf\u5f31\uff09\u3002\"\n                \"\u8bf7\u7279\u522b\u5173\u6ce8\u5f53\u72ec\u7acb\u53d8\u91cf\u4e0e\u7ea6\u675f\u7c7b\u80cc\u666f\u53c2\u6570\u4ea4\u4e92\u65f6\uff0c\u5bf9\u7cfb\u7edf\u6027\u80fd\u548c\u8fbe\u6210\u5de5\u7a0b\u76ee\u6807\u7684\u5f71\u54cd\u3002\"\n            )\n            results_and_discussion_points.append(interaction_text)\n\n        # 3. Dynamic Behavior Analysis (conditional)\n        if \"\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\" in original_report_content:\n            dynamic_text = (\n                f\"           *   **\u52a8\u6001\u884c\u4e3a\u5206\u6790\uff1a** \u89e3\u8bfb\u7cfb\u7edf\u5728\u201c\u521d\u59cb\u201d\u3001\u201c\u8f6c\u6298\u70b9\u201d\u548c\u201c\u7ed3\u675f\u201d\u9636\u6bb5\u7684\u884c\u4e3a\u53d8\u5316\u3002\"\n                f\"\u5206\u6790 **`{independent_variable}`** \u7684\u53d8\u5316\u5982\u4f55\u5f71\u54cd\u7cfb\u7edf\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u5982\u8fbe\u5230\u5e73\u8861\u7684\u65f6\u95f4\u3001\u5e93\u5b58\u7684\u8f6c\u6298\u70b9\u7b49\u3002\"\n            )\n            results_and_discussion_points.append(dynamic_text)\n\n        results_and_discussion_str = \"\\n\".join(results_and_discussion_points)\n\n        # Dynamically create the title instruction\n        if simulation_parameters:\n            title_instruction_text = \"\u8bf7\u5728\u6807\u9898\u4e2d\u660e\u786e\u6307\u51fa\uff0c\u672c\u6b21\u5206\u6790\u662f\u5173\u4e8e\u201c\u72ec\u7acb\u53d8\u91cf\u201d\u4e0e\u201c\u80cc\u666f\u626b\u63cf\u53c2\u6570\u201d\u7684\u3010\u4ea4\u4e92\u654f\u611f\u6027\u5206\u6790\u3011\u3002\"\n        else:\n            title_instruction_text = (\n                \"\u8bf7\u5728\u6807\u9898\u4e2d\u660e\u786e\u6307\u51fa\uff0c\u672c\u6b21\u5206\u6790\u662f\u5173\u4e8e\u201c\u72ec\u7acb\u53d8\u91cf\u201d\u7684\u3010\u654f\u611f\u6027\u5206\u6790\u3011\u3002\"\n            )\n\n        instructions_prompt = f\"\"\"**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\u4f8b\u5982\uff0c\u5e94\u5c06\u201c`sds`\u7684\u5e93\u5b58\u201d\u8868\u8ff0\u4e3a\u201c\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS) \u7684\u6c1a\u5e93\u5b58\u91cf (Tritium Inventory)\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\u907f\u514d\u4f7f\u7528\u201c\u770b\u8d77\u6765\u201d\u3001\u201c\u597d\u50cf\u201d\u7b49\u6a21\u7cca\u8bcd\u6c47\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u6027\u80fd\u6307\u6807\u603b\u8868\u6216\u5173\u952e\u52a8\u6001\u6570\u636e\u5207\u7247\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u654f\u611f\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6807\u9898 (Title):** {title_instruction_text}\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u654f\u611f\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u660e\u72ec\u7acb\u53d8\u91cf\u662f **`{independent_variable}`** \u4ee5\u53ca\u80cc\u666f\u626b\u63cf\u53c2\u6570\uff0c\u603b\u7ed3\u5176\u5bf9\u54ea\u4e9b\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u542f\u52a8\u5e93\u5b58\u3001\u589e\u6b96\u65f6\u95f4\u7b49\uff09\u5f71\u54cd\u6700\u663e\u8457\uff0c\u5e76\u9648\u8ff0\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u5173\u4e8e **`{independent_variable}`** \u7684\u654f\u611f\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30 **`{independent_variable}`** \u7684\u53d8\u5316\u5bf9\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\n        *   **\u72ec\u7acb\u53d8\u91cf\u91c7\u6837 (Independent Variable Sampling):** \u672c\u6b21\u5206\u6790\u4e2d\uff0c\u72ec\u7acb\u53d8\u91cf `{independent_variable}` \u626b\u63cf\u8303\u56f4\u4e3a `{sampling_range}`\u3002\n{simulation_params_str}{dependent_vars_str}\n    *   **\u65b9\u6cd5 (Methodology):** \u7b80\u8981\u8bf4\u660e\u5206\u6790\u65b9\u6cd5\uff0c\u5305\u62ec\u63d0\u53ca **`{independent_variable}`** \u7684\u626b\u63cf\u8303\u56f4\u548c\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u6240\u6709\u56fe\u8868\u548c\u6570\u636e\u8868\u683c\uff0c\u5e76\u6839\u636e\u5206\u6790\u5185\u5bb9\uff0c\u7ec4\u7ec7\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n{results_and_discussion_str}\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u654f\u611f\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff0c\u5e76\u5bf9\u53cd\u5e94\u5806\u8bbe\u8ba1\u6216\u672a\u6765\u8fd0\u884c\u7b56\u7565\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\uff08\u5305\u62ec\u56fe\u8868\u548c\u8868\u683c\uff09\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n---\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a (`{report_filename}`)\n---\n{original_report_content}\n\n---\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868 (`sheets.csv`)\n---\n{glossary_content}\n\"\"\"\n\n        # 5. Call the API\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for academic summary for case {case_name} with model {ai_model} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, instructions_prompt, analysis_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                academic_summary = response.choices[0].message.content\n\n                # 6. Save the result\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                summary_filename = (\n                    f\"academic_report_{case_name}_{sanitized_model_name}.md\"\n                )\n                summary_path = os.path.join(results_dir, summary_filename)\n                with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(academic_summary)\n\n                logger.info(\n                    f\"Successfully generated academic analysis summary: {summary_path}\"\n                )\n                return  # Exit after success\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling OpenAI API for academic summary on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to generate academic summary for {case_name} after {max_retries} attempts.\"\n                    )\n                    return  # Exit after all retries failed\n\n    except Exception as e:\n        logger.error(\n            f\"Error in generate_sensitivity_academic_report for case {case_name}: {e}\",\n            exc_info=True,\n        )\n</code></pre>"},{"location":"reference/#tricys.analysis.report.retry_ai_analysis","title":"<code>retry_ai_analysis(case_configs, original_config)</code>","text":"<p>Retries AI analysis for cases where it might have failed due to network issues. It checks for existing reports and re-runs only the AI-dependent parts if they are missing. This function can be triggered by setting an environment variable.</p> Source code in <code>tricys/analysis/report.py</code> <pre><code>def retry_ai_analysis(\n    case_configs: List[Dict[str, Any]], original_config: Dict[str, Any]\n) -&gt; None:\n    \"\"\"\n    Retries AI analysis for cases where it might have failed due to network issues.\n    It checks for existing reports and re-runs only the AI-dependent parts if they are missing.\n    This function can be triggered by setting an environment variable.\n    \"\"\"\n    logger.info(\"Starting AI analysis retry process...\")\n    try:\n        for case_info in case_configs:\n            case_data = case_info[\"case_data\"]\n            if \"analyzer\" in case_data and case_data.get(\"analyzer\", {}).get(\"method\"):\n                _retry_salib_case(case_info, original_config)\n            else:\n                _retry_standard_case(case_info, original_config)\n    except Exception as e:\n        logger.error(f\"Error during AI analysis retry process: {e}\", exc_info=True)\n</code></pre>"},{"location":"reference/#tricysanalysissalib","title":"<code>tricys.analysis.salib</code>","text":""},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer","title":"<code>TricysSALibAnalyzer</code>","text":"<p>Integrated SALib's Tricys Sensitivity Analyzer</p> <p>Supported Analysis Methods: - Sobol: Variance-based global sensitivity analysis - Morris: Screening-based sensitivity analysis - FAST: Fourier Amplitude Sensitivity Test - LHS: Latin Hypercube Sampling uncertainty analysis</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>class TricysSALibAnalyzer:\n    \"\"\"\n    Integrated SALib's Tricys Sensitivity Analyzer\n\n    Supported Analysis Methods:\n    - Sobol: Variance-based global sensitivity analysis\n    - Morris: Screening-based sensitivity analysis\n    - FAST: Fourier Amplitude Sensitivity Test\n    - LHS: Latin Hypercube Sampling uncertainty analysis\n    \"\"\"\n\n    def __init__(self, base_config: Dict[str, Any]) -&gt; None:\n        \"\"\"\n        Initialize the analyzer\n\n        Args:\n            base_config: Tricys base configuration dictionary\n        \"\"\"\n        self.base_config = base_config.copy()\n        self.problem = None\n        self.parameter_samples = None\n        self.simulation_results = None\n        self.sensitivity_results = {}\n\n        self._setup_chinese_font()\n        self._validate_tricys_config()\n\n    def _setup_chinese_font(self) -&gt; None:\n        \"\"\"Set the Chinese font to ensure proper display of Chinese characters in the chart\"\"\"\n        try:\n            import matplotlib.font_manager as fm\n\n            chinese_fonts = [\n                \"SimHei\",  # \u9ed1\u4f53\n                \"Microsoft YaHei\",  # \u5fae\u8f6f\u96c5\u9ed1\n                \"KaiTi\",  # \u6977\u4f53\n                \"FangSong\",  # \u4eff\u5b8b\n                \"STSong\",  # \u534e\u6587\u5b8b\u4f53\n                \"STKaiti\",  # \u534e\u6587\u6977\u4f53\n                \"STHeiti\",  # \u534e\u6587\u9ed1\u4f53\n                \"DejaVu Sans\",  # \u5907\u7528\u5b57\u4f53\n                \"Arial Unicode MS\",  # \u5907\u7528\u5b57\u4f53\n            ]\n\n            available_font = None\n            system_fonts = [f.name for f in fm.fontManager.ttflist]\n\n            for font in chinese_fonts:\n                if font in system_fonts:\n                    available_font = font\n                    break\n\n            if available_font:\n                plt.rcParams[\"font.sans-serif\"] = [available_font] + plt.rcParams[\n                    \"font.sans-serif\"\n                ]\n                logger.info(\"Using Chinese font\", extra={\"font\": available_font})\n            else:\n                logger.warning(\n                    \"No suitable Chinese font found, which may affect Chinese display\"\n                )\n\n            plt.rcParams[\"axes.unicode_minus\"] = False\n\n        except Exception as e:\n            logger.warning(\n                \"Failed to set Chinese font, using default font\",\n                extra={\"error\": str(e)},\n            )\n\n    def _handle_nan_values(\n        self, Y: np.ndarray, method_name: str = \"Sensitivity analysis\"\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Handling NaN values with maximum interpolation\n\n        Args:\n            Y: Output array that may contain NaN values\n            method_name: Analysis method name for logging\n\n        Returns:\n            Processed output array\n        \"\"\"\n        nan_indices = np.isnan(Y)\n        if np.any(nan_indices):\n            n_nan = np.sum(nan_indices)\n            logger.info(\n                \"Found NaN values, using maximum value for imputation\",\n                extra={\n                    \"method_name\": method_name,\n                    \"nan_count\": n_nan,\n                },\n            )\n\n            valid_values = Y[~nan_indices]\n\n            if len(valid_values) &gt; 0:\n                max_value = np.max(valid_values)\n                Y_processed = Y.copy()\n                Y_processed[nan_indices] = max_value\n                return Y_processed\n            else:\n                logger.error(\n                    \"All values are NaN, analysis cannot be performed\",\n                    extra={\n                        \"method_name\": method_name,\n                    },\n                )\n                raise ValueError(\n                    f\"{method_name}: All simulation results are NaN, sensitivity analysis cannot be performed\"\n                )\n        return Y\n\n    def _validate_tricys_config(self) -&gt; None:\n        \"\"\"Validate the Tricys configuration for required sections and keys.\"\"\"\n        required_keys = {\n            \"paths\": [\"package_path\"],\n            \"simulation\": [\"model_name\", \"stop_time\"],\n        }\n\n        for section, keys in required_keys.items():\n            if section not in self.base_config:\n                logger.warning(\n                    \"Missing configuration section, default values will be used\",\n                    extra={\n                        \"section\": section,\n                    },\n                )\n                continue\n\n            for key in keys:\n                if key not in self.base_config[section]:\n                    logger.warning(\n                        \"Missing configuration item, using default value\",\n                        extra={\n                            \"section\": section,\n                            \"key\": key,\n                        },\n                    )\n\n        package_path = self.base_config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            logger.warning(\n                \"Model file does not exist, which may cause simulation failure\",\n                extra={\n                    \"package_path\": package_path,\n                },\n            )\n\n    def _find_unit_config(self, var_name: str, unit_map: dict) -&gt; dict | None:\n        \"\"\"\n        Finds the unit configuration for a variable name from the unit_map.\n        1. Checks for an exact match.\n        2. Checks if the last part of a dot-separated name matches.\n        3. Checks for a simple substring containment as a fallback, matching longest keys first.\n        \"\"\"\n        if not unit_map or not var_name:\n            return None\n        if var_name in unit_map:\n            return unit_map[var_name]\n        components = var_name.split(\".\")\n        if len(components) &gt; 1 and components[-1] in unit_map:\n            return unit_map[components[-1]]\n        # Fallback to substring match, longest key first\n        for key in sorted(unit_map.keys(), key=len, reverse=True):\n            if key in var_name:\n                return unit_map[key]\n        return None\n\n    def define_problem(\n        self,\n        param_bounds: Dict[str, Tuple[float, float]],\n        param_distributions: Dict[str, str] = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Define SALib problem space\n\n        Args:\n            param_bounds: Parameter bounds dictionary {'param_name': (min_val, max_val)}\n            param_distributions: Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}\n                                Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'\n\n        Returns:\n            SALib problem definition dictionary\n        \"\"\"\n        if param_distributions is None:\n            param_distributions = {name: \"unif\" for name in param_bounds.keys()}\n\n        valid_dists = [\"unif\", \"triang\", \"norm\", \"truncnorm\", \"lognorm\"]\n        for name, dist in param_distributions.items():\n            if dist not in valid_dists:\n                logger.warning(\n                    \"Invalid distribution type, using 'unif' instead\",\n                    extra={\n                        \"parameter_name\": name,\n                        \"invalid_distribution\": dist,\n                    },\n                )\n                param_distributions[name] = \"unif\"\n\n        self.problem = {\n            \"num_vars\": len(param_bounds),\n            \"names\": list(param_bounds.keys()),\n            \"bounds\": list(param_bounds.values()),\n            \"dists\": [\n                param_distributions.get(name, \"unif\") for name in param_bounds.keys()\n            ],\n        }\n\n        logger.info(\n            \"Defined a problem space\",\n            extra={\n                \"num_parameters\": self.problem[\"num_vars\"],\n            },\n        )\n        for i, name in enumerate(self.problem[\"names\"]):\n            logger.info(\n                \"Parameter definition\",\n                extra={\n                    \"parameter_name\": name,\n                    \"bounds\": self.problem[\"bounds\"][i],\n                    \"distribution\": self.problem[\"dists\"][i],\n                },\n            )\n\n        return self.problem\n\n    def generate_samples(\n        self, method: str = \"sobol\", N: int = 1024, **kwargs\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Generate parameter samples\n\n        Args:\n            method: Sampling method ('sobol', 'morris', 'fast', 'latin')\n            N: Number of samples (for Sobol this is the base sample count, actual sample count is N*(2*D+2))\n            **kwargs: Method-specific parameters\n\n        Returns:\n            Parameter sample array (n_samples, n_params)\n        \"\"\"\n        if self.problem is None:\n            raise ValueError(\n                \"You must first call define_problem() to define the problem space.\"\n            )\n\n        logger.info(\n            \"Generating samples\",\n            extra={\n                \"method\": method,\n                \"base_sample_count\": N,\n            },\n        )\n\n        if method.lower() == \"sobol\":\n            # Sobol method: generate N*(2*D+2) samples\n            self.parameter_samples = saltelli.sample(self.problem, N, **kwargs)\n            actual_samples = N * (2 * self.problem[\"num_vars\"] + 2)\n\n        elif method.lower() == \"morris\":\n            # Morris method: Generate N trajectories\n            # Note: Different versions of SALib may have different parameter names\n            morris_kwargs = {\"num_levels\": 4}\n            # Check the SALib version and use the correct parameter names\n            try:\n                morris_kwargs.update(kwargs)\n                self.parameter_samples = morris.sample(self.problem, N, **morris_kwargs)\n            except TypeError as e:\n                if \"grid_jump\" in str(e):\n                    morris_kwargs = {\n                        k: v for k, v in morris_kwargs.items() if k != \"grid_jump\"\n                    }\n                    morris_kwargs.update(\n                        {k: v for k, v in kwargs.items() if k != \"grid_jump\"}\n                    )\n                    self.parameter_samples = morris.sample(\n                        self.problem, N, **morris_kwargs\n                    )\n                else:\n                    raise e\n\n            actual_samples = len(self.parameter_samples)\n\n        elif method.lower() == \"fast\":\n            # FAST method\n            fast_kwargs = {\"M\": 4}\n            fast_kwargs.update(kwargs)\n            self.parameter_samples = fast_sampler.sample(self.problem, N, **fast_kwargs)\n            actual_samples = len(self.parameter_samples)\n\n        elif method.lower() == \"latin\":\n            # Latin Hypercube Sampling\n            self.parameter_samples = latin.sample(self.problem, N, **kwargs)\n            actual_samples = N\n\n        else:\n            raise ValueError(f\"Unsupported sampling method: {method}\")\n\n        logger.info(\n            \"Successfully generated samples\", extra={\"actual_samples\": actual_samples}\n        )\n\n        if self.parameter_samples is not None:\n            self.parameter_samples = np.round(self.parameter_samples, decimals=5)\n            logger.info(\"Parameter sample precision adjusted to 5 decimal places\")\n\n        self._last_sampling_method = method.lower()\n\n        return self.parameter_samples\n\n    def run_tricys_simulations(self, output_metrics: List[str] = None) -&gt; str:\n        \"\"\"\n        Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.\n\n        Args:\n            output_metrics: List of output metrics to be extracted (for recording but does not affect CSV generation)\n            max_workers: Number of concurrent worker processes (reserved for compatibility, currently unused)\n\n        Returns:\n            Path to the generated CSV file\n        \"\"\"\n        if self.parameter_samples is None:\n            raise ValueError(\n                \"You must first call generate_samples() to generate samples.\"\n            )\n\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        logger.info(\"Target output metrics\", extra={\"output_metrics\": output_metrics})\n\n        sampled_param_names = self.problem[\"names\"]\n\n        base_params = self.base_config.get(\"simulation_parameters\", {}).copy()\n        csv_output_path = (\n            Path(self.base_config.get(\"paths\", {}).get(\"temp_dir\"))\n            / \"salib_sampling.csv\"\n        )\n\n        os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n\n        param_data = []\n        for i, sample in enumerate(self.parameter_samples):\n            sampled_params = {\n                sampled_param_names[j]: sample[j]\n                for j in range(len(sampled_param_names))\n            }\n\n            job_params = base_params.copy()\n            job_params.update(sampled_params)\n\n            param_data.append(job_params)\n\n        df = pd.DataFrame(param_data)\n\n        for col in df.columns:\n            if df[col].dtype in [\"float64\", \"float32\"]:\n                df[col] = df[col].round(5)\n\n        df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n\n        logger.info(\n            \"Successfully generated parameter samples\",\n            extra={\"num_samples\": len(param_data)},\n        )\n        logger.info(\"Parameter file saved\", extra={\"file_path\": csv_output_path})\n        logger.info(\"Parameter file columns\", extra={\"columns\": list(df.columns)})\n        logger.info(\"Parameter precision set to 5 decimal places\")\n        logger.info(\"Sample statistics\", extra={\"statistics\": df.describe().to_dict()})\n\n        self.sampling_csv_path = csv_output_path\n\n        return csv_output_path\n\n    def generate_tricys_config(\n        self, csv_file_path: str = None, output_metrics: List[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Generate Tricys configuration file for reading CSV parameter files and executing simulations\n        This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs\n\n        Args:\n            csv_file_path: Path to the CSV parameter file. If None, the last generated file is used\n            output_metrics: List of output metrics to be calculated\n\n        Returns:\n            Path of the generated configuration file\n        \"\"\"\n        if csv_file_path is None:\n            if hasattr(self, \"sampling_csv_path\"):\n                csv_file_path = self.sampling_csv_path\n            else:\n                raise ValueError(\n                    \"CSV file path not found, please first call run_tricys_simulations() or specify csv_file_path\"\n                )\n\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        csv_abs_path = os.path.abspath(csv_file_path)\n\n        import copy\n\n        tricys_config = copy.deepcopy(self.base_config)\n        tricys_config[\"simulation_parameters\"] = {\"file\": csv_abs_path}\n\n        if \"sensitivity_analysis\" not in tricys_config:\n            tricys_config[\"sensitivity_analysis\"] = {\"enabled\": True}\n\n        tricys_config[\"sensitivity_analysis\"][\"analysis_case\"] = {\n            \"name\": \"SALib_Analysis\",\n            \"independent_variable\": \"file\",\n            \"independent_variable_sampling\": csv_abs_path,\n            \"dependent_variables\": output_metrics,\n        }\n\n        return tricys_config\n\n    def load_tricys_results(\n        self, sensitivity_summary_csv: str, output_metrics: List[str] = None\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys\n\n        Args:\n            sensitivity_summary_csv: Path to the sensitivity analysis summary CSV file output by Tricys\n            output_metrics: List of output metrics to extract\n\n        Returns:\n            Simulation result array (n_samples, n_metrics)\n        \"\"\"\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        logger.info(f\"Read data from the Tricys result file: {sensitivity_summary_csv}\")\n\n        df = pd.read_csv(sensitivity_summary_csv)\n\n        logger.info(f\"Read {len(df)} simulation results\")\n        logger.info(f\"Result file columns: {list(df.columns)}\")\n\n        param_cols = []\n        metric_cols = []\n\n        for col in df.columns:\n            if col in output_metrics:\n                metric_cols.append(col)\n            elif col in self.problem[\"names\"] if self.problem else False:\n                param_cols.append(col)\n\n        logger.info(f\"Recognized parameter columns: {param_cols}\")\n        logger.info(f\"Identified metric columns: {metric_cols}\")\n\n        ordered_metric_cols = []\n        for metric in output_metrics:\n            if metric in metric_cols:\n                ordered_metric_cols.append(metric)\n            else:\n                logger.warning(f\"Metric column not found: {metric}\")\n\n        if not ordered_metric_cols:\n            raise ValueError(f\"No valid output metrics columns found: {output_metrics}\")\n\n        results_data = df[ordered_metric_cols].values\n\n        self.simulation_results = results_data\n\n        logger.info(f\"Successfully loaded simulation results: {results_data.shape}\")\n        logger.info(\n            f\"Result Statistics:\\n{pd.DataFrame(results_data, columns=ordered_metric_cols).describe()}\"\n        )\n        logger.info(\n            f\"Result preview:\\n{pd.DataFrame(results_data, columns=metric_cols).head()}\"\n        )\n        return self.simulation_results\n\n    def get_compatible_analysis_methods(self, sampling_method: str) -&gt; List[str]:\n        \"\"\"\n        Get analysis methods compatible with the specified sampling method.\n\n        Args:\n            sampling_method: Sampling method\n\n        Returns:\n            List of compatible analysis methods\n        \"\"\"\n        compatibility_map = {\n            \"sobol\": [\"sobol\"],\n            \"morris\": [\"morris\"],\n            \"fast\": [\"fast\"],\n            \"latin\": [\"latin\"],\n            \"unknown\": [],\n        }\n\n        return compatibility_map.get(sampling_method, [])\n\n    def run_tricys_analysis(\n        self, csv_file_path: str = None, output_metrics: List[str] = None\n    ) -&gt; str:\n        \"\"\"\n        Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results\n\n        Args:\n            csv_file_path: Path to the CSV parameter file. If None, the last generated file will be used\n            output_metrics: List of output metrics to be calculated\n            config_output_path: Path for the configuration file output. If None, it will be automatically generated\n\n        Returns:\n            Path to the sensitivity_analysis_summary.csv file\n        \"\"\"\n        # Generate Tricys configuration file\n        tricys_config = self.generate_tricys_config(\n            csv_file_path=csv_file_path, output_metrics=output_metrics\n        )\n\n        logger.info(\"Starting Tricys simulation analysis...\")\n\n        try:\n            # Call the Tricys simulation engine\n            from datetime import datetime\n\n            from tricys.simulation.simulation_analysis import run_simulation\n\n            tricys_config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n            run_simulation(tricys_config)\n\n            results_dir = tricys_config[\"paths\"][\"results_dir\"]\n\n            return Path(results_dir) / \"sensitivity_analysis_summary.csv\"\n\n        except Exception as e:\n            logger.error(f\"Tricys simulation execution failed: {e}\")\n            raise\n\n    def analyze_sobol(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform Sobol Sensitivity Analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Sobol analysis parameters\n\n        Returns:\n            Sobol sensitivity analysis results\n\n        Note:\n            Sobol analysis requires samples generated using the Saltelli sampling method!\n            Results from Morris or FAST sampling cannot be used.\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        # Check sampling method compatibility\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"sobol\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f Currently using {self._last_sampling_method} sampling, but Sobol analysis requires Saltelli sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('sobol')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"Sobol\u5206\u6790\")\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n        #    X = self.parameter_samples[valid_indices]\n        # else:\n        #    X = self.parameter_samples\n\n        try:\n            Si = sobol.analyze(self.problem, Y, **kwargs)\n\n            if \"sobol\" not in self.sensitivity_results:\n                self.sensitivity_results[\"sobol\"] = {}\n\n            metric_name = f\"metric_{output_index}\"\n            self.sensitivity_results[\"sobol\"][metric_name] = {\n                \"output_index\": output_index,\n                \"Si\": Si,\n                \"S1\": Si[\"S1\"],\n                \"ST\": Si[\"ST\"],\n                \"S2\": Si.get(\"S2\", None),\n                \"S1_conf\": Si[\"S1_conf\"],\n                \"ST_conf\": Si[\"ST_conf\"],\n                \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n            }\n\n            logger.info(f\"Sobol sensitivity analysis completed (index {output_index})\")\n            return self.sensitivity_results[\"sobol\"][metric_name]\n\n        except Exception as e:\n            if \"saltelli\" in str(e).lower() or \"sample\" in str(e).lower():\n                raise ValueError(\n                    f\"Sobol analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('sobol')\"\n                ) from e\n            else:\n                raise\n\n    def analyze_morris(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform Morris sensitivity analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Morris analysis parameters\n\n        Returns:\n            Morris sensitivity analysis results\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"Morris\u5206\u6790\")\n        X = self.parameter_samples\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n        #    X = self.parameter_samples[valid_indices]\n        # else:\n        #    X = self.parameter_samples\n\n        # Perform Morris analysis\n        logger.info(\n            f\"Start Morris sensitivity analysis: X.shape={X.shape}, Y.shape={Y.shape}, X.dtype={X.dtype}\"\n        )\n\n        try:\n            Si = morris_analyze.analyze(self.problem, X, Y, **kwargs)\n        except Exception as e:\n            logger.error(f\"Morris analysis execution failed: {e}\")\n            logger.error(f\"problem: {self.problem}\")\n            logger.error(f\"X shape: {X.shape}, type: {X.dtype}\")\n            logger.error(f\"Yshape: {Y.shape}, type: {Y.dtype}\")\n            if hasattr(X, \"dtype\") and X.dtype == \"object\":\n                logger.error(\n                    \"X contains non-numeric data, please check the sampled data\"\n                )\n            raise\n\n        if \"morris\" not in self.sensitivity_results:\n            self.sensitivity_results[\"morris\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"morris\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"mu\": Si[\"mu\"],\n            \"mu_star\": Si[\"mu_star\"],\n            \"sigma\": Si[\"sigma\"],\n            \"mu_star_conf\": Si[\"mu_star_conf\"],\n        }\n\n        logger.info(f\"Morris sensitivity analysis completed (metric {output_index})\")\n        return self.sensitivity_results[\"morris\"][metric_name]\n\n    def analyze_fast(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform FAST sensitivity analysis\n\n        Args:\n            output_index: Output variable index\n            **kwargs: FAST analysis parameters\n\n        Returns:\n            FAST sensitivity analysis results\n\n        Note:\n            FAST analysis requires samples generated by the fast_sampler sampling method!\n            Results from Morris or Sobol sampling cannot be used.\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"fast\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but FAST analysis requires FAST sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('fast')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        Y = self._handle_nan_values(Y, \"FAST\u5206\u6790\")\n\n        # Remove NaN values\n        # valid_indices = ~np.isnan(Y)\n        # if not np.all(valid_indices):\n        #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n        #    Y = Y[valid_indices]\n\n        try:\n            # Perform FAST analysis\n            Si = fast.analyze(self.problem, Y, **kwargs)\n\n            if \"fast\" not in self.sensitivity_results:\n                self.sensitivity_results[\"fast\"] = {}\n\n            metric_name = f\"metric_{output_index}\"\n            self.sensitivity_results[\"fast\"][metric_name] = {\n                \"output_index\": output_index,\n                \"Si\": Si,\n                \"S1\": Si[\"S1\"],\n                \"ST\": Si[\"ST\"],\n                \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n            }\n\n            logger.info(\n                f\"FAST sensitivity analysis completed (indicator {output_index})\"\n            )\n            return self.sensitivity_results[\"fast\"][metric_name]\n\n        except Exception as e:\n            if \"fast\" in str(e).lower() or \"sample\" in str(e).lower():\n                raise ValueError(\n                    f\"FAST analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('fast')\"\n                ) from e\n            else:\n                raise\n\n    def analyze_lhs(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform LHS (Latin Hypercube Sampling) uncertainty analysis\n\n        Note: This is a basic statistical analysis method for LHS samples,\n        providing descriptive statistics and basic sensitivity indices.\n\n        Args:\n            output_index: Output variable index\n            **kwargs: Analysis parameters (reserved for future use)\n\n        Returns:\n            LHS uncertainty analysis results\n        \"\"\"\n        if self.simulation_results is None:\n            raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n        if (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method != \"latin\"\n        ):\n            logger.warning(\n                f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but LHS analysis is designed for Latin Hypercube Sampling!\"\n            )\n            logger.warning(\n                \"Suggestion: Regenerate samples using generate_samples('latin')\"\n            )\n\n        Y = self.simulation_results[:, output_index]\n\n        # Handle NaN values\n        Y = self._handle_nan_values(Y, \"LHS\u5206\u6790\")\n\n        # Basic statistical analysis\n        mean_val = np.mean(Y)\n        std_val = np.std(Y)\n        min_val = np.min(Y)\n        max_val = np.max(Y)\n        percentile_5 = np.percentile(Y, 5)\n        percentile_95 = np.percentile(Y, 95)\n\n        # Create results dictionary\n        Si = {\n            \"mean\": mean_val,\n            \"std\": std_val,\n            \"min\": min_val,\n            \"max\": max_val,\n            \"percentile_5\": percentile_5,\n            \"percentile_95\": percentile_95,\n        }\n\n        if \"latin\" not in self.sensitivity_results:\n            self.sensitivity_results[\"latin\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"latin\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"mean\": mean_val,\n            \"std\": std_val,\n            \"min\": min_val,\n            \"max\": max_val,\n            \"percentile_5\": percentile_5,\n            \"percentile_95\": percentile_95,\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(f\"LHS uncertainty analysis completed (\u6307\u6807 {output_index})\")\n        return self.sensitivity_results[\"latin\"][metric_name]\n\n    def run_salib_analysis_from_tricys_results(\n        self,\n        sensitivity_summary_csv: str,\n        param_bounds: Dict[str, Tuple[float, float]] = None,\n        output_metrics: List[str] = None,\n        methods: List[str] = [\"sobol\", \"morris\", \"fast\"],\n        save_dir: str = None,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys\n\n        Args:\n            sensitivity_summary_csv: Path to the sensitivity summary CSV file output by Tricys\n            param_bounds: Dictionary of parameter bounds, inferred from the CSV file if None\n            output_metrics: List of output metrics to analyze\n            methods: List of sensitivity analysis methods to execute\n            save_dir: Directory to save the results\n\n        Returns:\n            Dictionary containing all analysis results\n        \"\"\"\n        if output_metrics is None:\n            output_metrics = [\n                \"Startup_Inventory\",\n                \"Self_Sufficiency_Time\",\n                \"Doubling_Time\",\n            ]\n\n        if save_dir is None:\n            save_dir = os.path.join(\n                os.path.dirname(sensitivity_summary_csv), \"salib_analysis\"\n            )\n        os.makedirs(save_dir, exist_ok=True)\n\n        df = pd.read_csv(sensitivity_summary_csv)\n\n        if param_bounds is None:\n            param_bounds = {}\n            param_candidates = []\n            for col in df.columns:\n                if col not in output_metrics and \".\" in col:\n                    param_candidates.append(col)\n\n            for param in param_candidates:\n                param_data = df[param].dropna()\n                if len(param_data) &gt; 0:\n                    param_bounds[param] = (param_data.min(), param_data.max())\n\n        if not param_bounds:\n            raise ValueError(\n                \"Unable to determine parameter boundaries, please provide the param_bounds parameter\"\n            )\n\n        self.define_problem(param_bounds)\n\n        self.load_tricys_results(sensitivity_summary_csv, output_metrics)\n\n        detected_method = self._last_sampling_method\n\n        methods = self.get_compatible_analysis_methods(detected_method)\n\n        all_results = {}\n\n        for metric_idx, metric_name in enumerate(output_metrics):\n            if metric_idx &gt;= self.simulation_results.shape[1]:\n                logger.warning(f\"The metric {metric_name} is out of range, skipping\")\n                continue\n\n            logger.info(f\"\\n=== Analysis indicators: {metric_name} ===\")\n            metric_results = {}\n\n            # Check data validity\n            Y = self.simulation_results[:, metric_idx]\n            valid_ratio = np.sum(~np.isnan(Y)) / len(Y)\n            logger.info(f\"Valid data ratio: {valid_ratio:.2%}\")\n\n            if valid_ratio &lt; 0.5:\n                logger.warning(\n                    f\"The metric {metric_name} has less than 50% valid data, which may affect the analysis quality.\"\n                )\n\n            # Sobol analysis\n            if \"sobol\" in methods:\n                try:\n                    logger.info(\"Performing Sobol sensitivity analysis...\")\n                    sobol_result = self.analyze_sobol(output_index=metric_idx)\n                    metric_results[\"sobol\"] = sobol_result\n\n                    # Display Sobol results summary\n                    logger.info(\"\\nSobol sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        s1 = sobol_result[\"S1\"][i]\n                        st = sobol_result[\"ST\"][i]\n                        logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"Sobol analysis failed: {e}\")\n\n            # Morris analysis\n            if \"morris\" in methods:\n                try:\n                    logger.info(\"Performing Morris sensitivity analysis...\")\n                    morris_result = self.analyze_morris(output_index=metric_idx)\n                    metric_results[\"morris\"] = morris_result\n\n                    # Display Morris results summary\n                    logger.info(\"\\nMorris sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        mu_star = morris_result[\"mu_star\"][i]\n                        sigma = morris_result[\"sigma\"][i]\n                        logger.info(f\"  {param_name}: \u03bc*={mu_star:.4f}, \u03c3={sigma:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"Morris analysis failed: {e}\")\n\n            # FAST analysis\n            if \"fast\" in methods:\n                try:\n                    logger.info(\"Performing FAST sensitivity analysis...\")\n                    fast_result = self.analyze_fast(output_index=metric_idx)\n                    metric_results[\"fast\"] = fast_result\n\n                    # Display FAST results summary\n                    logger.info(\"\\nFAST sensitivity index:\")\n                    for i, param_name in enumerate(self.problem[\"names\"]):\n                        s1 = fast_result[\"S1\"][i]\n                        st = fast_result[\"ST\"][i]\n                        logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"FAST analysis failed: {e}\")\n\n            # LHS analysis\n            if \"latin\" in methods:\n                try:\n                    logger.info(\"Performing LHS uncertainty analysis...\")\n                    lhs_result = self.analyze_lhs(output_index=metric_idx)\n                    metric_results[\"latin\"] = lhs_result\n\n                    # Display LHS results summary\n                    logger.info(\"\\nLHS\u5206\u6790\u7ed3\u679c:\")\n                    logger.info(f\"  \u5747\u503c: {lhs_result['mean']:.4f}\")\n                    logger.info(f\"  \u6807\u51c6\u5dee: {lhs_result['std']:.4f}\")\n                    logger.info(f\"  \u6700\u5c0f\u503c: {lhs_result['min']:.4f}\")\n                    logger.info(f\"  \u6700\u5927\u503c: {lhs_result['max']:.4f}\")\n                    logger.info(f\"  5%\u5206\u4f4d\u6570: {lhs_result['percentile_5']:.4f}\")\n                    logger.info(f\"  95%\u5206\u4f4d\u6570: {lhs_result['percentile_95']:.4f}\")\n\n                except Exception as e:\n                    logger.error(f\"LHS\u5206\u6790\u5931\u8d25: {e}\")\n\n            all_results[metric_name] = metric_results\n\n        try:\n            if \"sobol\" in methods and \"sobol\" in self.sensitivity_results:\n                self.plot_sobol_results(save_dir=save_dir, metric_names=output_metrics)\n\n            if \"morris\" in methods and \"morris\" in self.sensitivity_results:\n                self.plot_morris_results(save_dir=save_dir, metric_names=output_metrics)\n\n            if \"fast\" in methods and \"fast\" in self.sensitivity_results:\n                self.plot_fast_results(save_dir=save_dir, metric_names=output_metrics)\n\n            # Plot LHS results\n            if \"latin\" in methods and \"latin\" in self.sensitivity_results:\n                self.plot_lhs_results(save_dir=save_dir, metric_names=output_metrics)\n\n        except Exception as e:\n            logger.warning(f\"Drawing failed: {e}\")\n\n        try:\n            self.save_results(\n                save_dir=save_dir, format=\"csv\", metric_names=output_metrics\n            )\n\n            report_content = self._save_sensitivity_report(all_results, save_dir)\n            report_path = os.path.join(save_dir, \"analysis_report.md\")\n\n            load_dotenv()\n\n            # --- LLM Calls for analysis ---\n            api_key = os.environ.get(\"API_KEY\")\n            base_url = os.environ.get(\"BASE_URL\")\n            ai_model = os.environ.get(\"AI_MODEL\")\n\n            sa_config = self.base_config.get(\"sensitivity_analysis\", {})\n            case_config = sa_config.get(\"analysis_case\", {})\n            ai_config = case_config.get(\"ai\")\n\n            ai_enabled = False\n            if isinstance(ai_config, bool):\n                ai_enabled = ai_config\n            elif isinstance(ai_config, dict):\n                ai_enabled = ai_config.get(\"enabled\", False)\n\n            if api_key and base_url and ai_model and ai_enabled:\n                # First LLM call for initial analysis\n                wrapper_prompt, llm_summary = call_llm_for_salib_analysis(\n                    report_content=report_content,\n                    api_key=api_key,\n                    base_url=base_url,\n                    ai_model=ai_model,\n                    method=detected_method,\n                )\n                if wrapper_prompt and llm_summary:\n                    with open(report_path, \"a\", encoding=\"utf-8\") as f:\n                        f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd\\n\\n\")\n                        f.write(\"```markdown\\n\")\n                        f.write(wrapper_prompt)\n                        f.write(\"\\n```\\n\\n\")\n                        f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\")\n                        f.write(llm_summary)\n                    logger.info(f\"Appended LLM prompt and summary to {report_path}\")\n\n                    # Second LLM call for academic report\n                    glossary_path = None\n                    if isinstance(case_config, dict):\n                        glossary_path = sa_config.get(\"glossary_path\")\n\n                    if glossary_path and os.path.exists(glossary_path):\n                        try:\n                            with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n                                glossary_content = f.read()\n\n                            (\n                                academic_wrapper_prompt,\n                                academic_report,\n                            ) = call_llm_for_academic_report(\n                                analysis_report=llm_summary,\n                                glossary_content=glossary_content,\n                                api_key=api_key,\n                                base_url=base_url,\n                                ai_model=ai_model,\n                                problem_details=self.problem,\n                                metric_names=output_metrics,\n                                method=detected_method,\n                                save_dir=save_dir,\n                            )\n\n                            if academic_wrapper_prompt and academic_report:\n                                academic_report_path = os.path.join(\n                                    save_dir, \"academic_report.md\"\n                                )\n                                with open(\n                                    academic_report_path, \"w\", encoding=\"utf-8\"\n                                ) as f:\n                                    f.write(academic_report)\n                                logger.info(\n                                    f\"Generated academic report: {academic_report_path}\"\n                                )\n                        except Exception as e:\n                            logger.error(\n                                f\"Failed to generate or save academic report: {e}\"\n                            )\n                    elif glossary_path:\n                        logger.warning(\n                            f\"Glossary file not found at {glossary_path}, skipping academic report generation.\"\n                        )\n\n            else:\n                logger.warning(\n                    \"API_KEY, BASE_URL, or AI_MODEL not set, or AI analysis is disabled. Skipping LLM summary generation.\"\n                )\n\n        except Exception as e:\n            logger.warning(f\"Failed to save result: {e}\")\n\n        logger.info(\"\\n\u2705 SALib sensitivity analysis completed!\")\n        logger.info(f\"\ud83d\udcc1 The result has been saved to: {save_dir}\")\n\n        return all_results\n\n    def _save_sensitivity_report(\n        self, all_results: Dict[str, Any], save_dir: str\n    ) -&gt; str:\n        \"\"\"The result has been saved to: {save_dir}\"\"\"\n        report_file = os.path.join(save_dir, \"analysis_report.md\")\n        # Determine analysis type based on sampling method\n        is_uncertainty_analysis = (\n            hasattr(self, \"_last_sampling_method\")\n            and self._last_sampling_method == \"latin\"\n        )\n        report_title = (\n            \"# SALib \u4e0d\u786e\u5b9a\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n            if is_uncertainty_analysis\n            else \"# SALib \u654f\u611f\u6027\u5206\u6790\u62a5\u544a\\n\\n\"\n        )\n        report_lines = []\n        report_lines.append(report_title)\n        report_lines.append(f\"\u751f\u6210\u65f6\u95f4: {pd.Timestamp.now()}\\n\\n\")\n        # Get unit_map from config\n        sensitivity_analysis_config = self.base_config.get(\"sensitivity_analysis\", {})\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n        report_lines.append(\"## \u5206\u6790\u53c2\u6570\\n\\n\")\n        if self.problem:\n            for i, param_name in enumerate(self.problem[\"names\"]):\n                bounds = self.problem[\"bounds\"][i]\n                # --- Unit Conversion Logic for Bounds ---\n                unit_config = self._find_unit_config(param_name, unit_map)\n                display_bounds = list(bounds)\n                unit_str = \"\"\n                if unit_config:\n                    unit = unit_config.get(\"unit\")\n                    factor = unit_config.get(\"conversion_factor\")\n                    if factor:\n                        display_bounds[0] /= float(factor)\n                        display_bounds[1] /= float(factor)\n                    if unit:\n                        unit_str = f\" ({unit})\"\n                # --- End Conversion Logic ---\n                report_lines.append(\n                    f\"- **{param_name}**: [{display_bounds[0]:.4f}, {display_bounds[1]:.4f}]{unit_str}\\n\"\n                )\n        report_lines.append(\"\\n\")\n        for metric_name, metric_results in all_results.items():\n            metric_section_title = (\n                f\"## {metric_name} \u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7ed3\u679c\\n\\n\"\n                if is_uncertainty_analysis\n                else f\"## {metric_name} \u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\\n\\n\"\n            )\n            report_lines.append(metric_section_title)\n            if \"sobol\" in metric_results:\n                report_lines.append(\"### Sobol\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\n                    \"| \u53c2\u6570 | S1 (\u4e00\u9636) | ST (\u603b) | S1\u7f6e\u4fe1\u533a\u95f4 | ST\u7f6e\u4fe1\u533a\u95f4 |\\n\"\n                )\n                report_lines.append(\n                    \"|------|----------|---------|------------|------------|\\n\"\n                )\n                sobol_data = metric_results[\"sobol\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = sobol_data[\"S1\"][i]\n                    st = sobol_data[\"ST\"][i]\n                    s1_conf = sobol_data[\"S1_conf\"][i]\n                    st_conf = sobol_data[\"ST_conf\"][i]\n                    report_lines.append(\n                        f\"| {param_name} | {s1:.4f} | {st:.4f} | \u00b1{s1_conf:.4f} | \u00b1{st_conf:.4f} |\\n\"\n                    )\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'sobol_sensitivity_indices_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![Sobol Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"morris\" in metric_results:\n                report_lines.append(\"### Morris\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\n                    \"| \u53c2\u6570 | \u03bc* (\u5e73\u5747\u7edd\u5bf9\u6548\u5e94) | \u03c3 (\u6807\u51c6\u5dee) | \u03bc*\u7f6e\u4fe1\u533a\u95f4 |\\n\"\n                )\n                report_lines.append(\n                    \"|------|-------------------|------------|------------|\\n\"\n                )\n                morris_data = metric_results[\"morris\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    mu_star = morris_data[\"mu_star\"][i]\n                    sigma = morris_data[\"sigma\"][i]\n                    mu_star_conf = morris_data[\"mu_star_conf\"][i]\n                    report_lines.append(\n                        f\"| {param_name} | {mu_star:.4f} | {sigma:.4f} | \u00b1{mu_star_conf:.4f} |\\n\"\n                    )\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'morris_sensitivity_analysis_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![Morris Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"fast\" in metric_results:\n                report_lines.append(\"### FAST\u654f\u611f\u6027\u6307\u6570\\n\\n\")\n                report_lines.append(\"| \u53c2\u6570 | S1 (\u4e00\u9636) | ST (\u603b) |\\n\")\n                report_lines.append(\"|------|----------|---------|\\n\")\n                fast_data = metric_results[\"fast\"]\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = fast_data[\"S1\"][i]\n                    st = fast_data[\"ST\"][i]\n                    report_lines.append(f\"| {param_name} | {s1:.4f} | {st:.4f} |\\n\")\n                report_lines.append(\"\\n\")\n                plot_filename = (\n                    f'fast_sensitivity_indices_{metric_name.replace(\" \", \"_\")}.png'\n                )\n                report_lines.append(\n                    f\"![FAST Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n            if \"latin\" in metric_results:\n                # --- Unit Conversion Logic for Metrics ---\n                unit_config = self._find_unit_config(metric_name, unit_map)\n                unit_str = \"\"\n                factor = 1.0\n                if unit_config:\n                    unit = unit_config.get(\"unit\")\n                    conv_factor = unit_config.get(\"conversion_factor\")\n                    if conv_factor:\n                        factor = float(conv_factor)\n                    if unit:\n                        unit_str = f\" ({unit})\"\n                # --- End Conversion Logic ---\n                # 1. Get raw data and clean it\n                output_index = metric_results[\"latin\"][\"output_index\"]\n                Y = self.simulation_results[:, output_index]\n                Y_clean = Y[~np.isnan(Y)]\n                # --- Modify report generation ---\n                report_lines.append(\"### \u7edf\u8ba1\u6458\u8981\\n\\n\")\n                lhs_data = metric_results[\"latin\"]\n                report_lines.append(\n                    f\"- \u5747\u503c: {lhs_data['mean']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6807\u51c6\u5dee: {lhs_data['std']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6700\u5c0f\u503c: {lhs_data['min']/factor:.4f}{unit_str}\\n\"\n                )\n                report_lines.append(\n                    f\"- \u6700\u5927\u503c: {lhs_data['max']/factor:.4f}{unit_str}\\n\\n\"\n                )\n                # 2. Calculate more percentiles\n                if len(Y_clean) &gt; 0:\n                    percentiles_to_calc = [5, 10, 25, 50, 75, 90, 95]\n                    percentile_values = np.percentile(Y_clean, percentiles_to_calc)\n                    report_lines.append(\"### \u5206\u5e03\u5173\u952e\u70b9 (CDF)\\n\\n\")\n                    report_lines.append(\n                        f\"- 5%\u5206\u4f4d\u6570: {percentile_values[0]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 10%\u5206\u4f4d\u6570: {percentile_values[1]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 25%\u5206\u4f4d\u6570 (Q1): {percentile_values[2]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 50%\u5206\u4f4d\u6570 (\u4e2d\u4f4d\u6570): {percentile_values[3]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 75%\u5206\u4f4d\u6570 (Q3): {percentile_values[4]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 90%\u5206\u4f4d\u6570: {percentile_values[5]/factor:.4f}{unit_str}\\n\"\n                    )\n                    report_lines.append(\n                        f\"- 95%\u5206\u4f4d\u6570: {percentile_values[6]/factor:.4f}{unit_str}\\n\\n\"\n                    )\n                    # 3. Calculate histogram data\n                    hist_freq, bin_edges = np.histogram(Y_clean, bins=10)\n                    report_lines.append(\"### \u8f93\u51fa\u5206\u5e03 (\u76f4\u65b9\u56fe\u6570\u636e)\\n\\n\")\n                    report_lines.append(\"| \u6570\u503c\u8303\u56f4 | \u9891\u6570 |\\n\")\n                    report_lines.append(\"|:---|---:|\\n\")\n                    for i in range(len(hist_freq)):\n                        lower_bound = bin_edges[i] / factor\n                        upper_bound = bin_edges[i + 1] / factor\n                        freq = hist_freq[i]\n                        report_lines.append(\n                            f\"| {lower_bound:.2f} - {upper_bound:.2f} | {freq} |\\n\"\n                        )\n                    report_lines.append(\"\\n\")\n                plot_filename = f'lhs_analysis_{metric_name.replace(\" \", \"_\")}.png'\n                report_lines.append(\n                    f\"![LHS Analysis for {metric_name}]({plot_filename})\\n\\n\"\n                )\n        report_content = \"\".join(report_lines)\n        with open(report_file, \"w\", encoding=\"utf-8\") as f:\n            f.write(report_content)\n        logger.info(f\"The sensitivity analysis report has been saved.: {report_file}\")\n        return report_content\n\n    def plot_sobol_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot Sobol analysis results\"\"\"\n        if \"sobol\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results for the Sobol method were found.\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        sobol_results = self.sensitivity_results[\"sobol\"]\n\n        if not sobol_results:\n            raise ValueError(\"Sobol analysis results not found\")\n\n        # Generate charts for each metric\n        for metric_key, results in sobol_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Bar chart of first-order and total sensitivity indices\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # First-order sensitivity index\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax1.barh(y_pos, Si[\"S1\"], xerr=Si[\"S1_conf\"], alpha=0.7, color=\"skyblue\")\n            ax1.set_yticks(y_pos)\n            ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax1.set_xlabel(\"First-order sensitivity index (S1)\", fontsize=12)\n            ax1.set_title(\n                f\"First-order Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax1.grid(True, alpha=0.3)\n\n            # # Total Sensitivity Index\n            ax2.barh(y_pos, Si[\"ST\"], xerr=Si[\"ST_conf\"], alpha=0.7, color=\"orange\")\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"Total Sensitivity Index (ST)\", fontsize=12)\n            ax2.set_title(\n                f\"Total Sensitivity Indices\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = (\n                f'sobol_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n            )\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"Sobol result chart has been saved: {filename}\")\n\n    def plot_morris_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot the Morris analysis results\"\"\"\n        if \"morris\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results were found for the Morris method.\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Obtain the results of all indicators\n        morris_results = self.sensitivity_results[\"morris\"]\n\n        if not morris_results:\n            raise ValueError(\"No Morris analysis results found\")\n\n        for metric_key, results in morris_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Morris \u03bc*-\u03c3 diagram\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # \u03bc*-\u03c3 scatter plot\n            ax1.scatter(Si[\"mu_star\"], Si[\"sigma\"], s=100, alpha=0.7, color=\"red\")\n            for i, name in enumerate(self.problem[\"names\"]):\n                ax1.annotate(\n                    name,\n                    (Si[\"mu_star\"][i], Si[\"sigma\"][i]),\n                    xytext=(5, 5),\n                    textcoords=\"offset points\",\n                    fontsize=9,\n                )\n\n            ax1.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n            ax1.set_ylabel(\"\u03c3 (Standard Deviation)\", fontsize=12)\n            ax1.set_title(\n                f\"Morris \u03bc*-\u03c3 Plot\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax1.grid(True, alpha=0.3)\n\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax2.barh(\n                y_pos, Si[\"mu_star\"], xerr=Si[\"mu_star_conf\"], alpha=0.7, color=\"green\"\n            )\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n            ax2.set_title(\n                f\"Morris Elementary Effects\\n{metric_display_name}\", fontsize=14, pad=20\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = f'morris_sensitivity_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"Morris result chart has been saved: {filename}\")\n\n    def plot_fast_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot FAST analysis results\"\"\"\n        if \"fast\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results found for the FAST method\")\n\n        # No analysis results found for the FAST method\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        fast_results = self.sensitivity_results[\"fast\"]\n\n        if not fast_results:\n            raise ValueError(\"FAST analysis results not found\")\n\n        # Generate a chart for each metric\n        for metric_key, results in fast_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            # Determine the indicator name\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Bar charts of first-order and total sensitivity indices\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # first-order sensitivity index\n            y_pos = np.arange(len(self.problem[\"names\"]))\n            ax1.barh(y_pos, Si[\"S1\"], alpha=0.7, color=\"purple\")\n            ax1.set_yticks(y_pos)\n            ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax1.set_xlabel(\"\u4e00\u9636\u654f\u611f\u6027\u6307\u6570 (S1)\", fontsize=12)\n            ax1.set_title(\n                f\"FAST First-order Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax1.grid(True, alpha=0.3)\n\n            # Total Sensitivity Index\n            ax2.barh(y_pos, Si[\"ST\"], alpha=0.7, color=\"darkgreen\")\n            ax2.set_yticks(y_pos)\n            ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n            ax2.set_xlabel(\"\u603b\u654f\u611f\u6027\u6307\u6570 (ST)\", fontsize=12)\n            ax2.set_title(\n                f\"FAST Total Sensitivity Indices\\n{metric_display_name}\",\n                fontsize=14,\n                pad=20,\n            )\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = (\n                f'fast_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n            )\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"The FAST result chart has been saved: {filename}\")\n\n    def plot_lhs_results(\n        self,\n        save_dir: str = None,\n        figsize: Tuple[int, int] = (12, 8),\n        metric_names: List[str] = None,\n    ) -&gt; None:\n        \"\"\"Plot LHS (Latin Hypercube Sampling) uncertainty analysis results\"\"\"\n        if \"latin\" not in self.sensitivity_results:\n            raise ValueError(\"No analysis results found for the LHS method\")\n\n        # Ensure Chinese font settings\n        self._setup_chinese_font()\n\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        # Get the results of all indicators\n        lhs_results = self.sensitivity_results[\"latin\"]\n\n        if not lhs_results:\n            raise ValueError(\"LHS analysis results not found\")\n\n        # Generate charts for each metric\n        for metric_key, results in lhs_results.items():\n            Si = results[\"Si\"]\n            output_index = results[\"output_index\"]\n\n            # Determine the indicator name\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            # Get unit from config\n            sensitivity_analysis_config = self.base_config.get(\n                \"sensitivity_analysis\", {}\n            )\n            unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n            unit_config = self._find_unit_config(metric_display_name, unit_map)\n            unit_str = \"\"\n            if unit_config:\n                unit = unit_config.get(\"unit\")\n                if unit:\n                    unit_str = f\" ({unit})\"\n\n            xlabel = f\"{metric_display_name}{unit_str}\"\n\n            # Create a figure with two subplots\n            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n            # Plot 1: Distribution histogram\n            ax1.hist(\n                self.simulation_results[:, output_index],\n                bins=30,\n                alpha=0.7,\n                color=\"skyblue\",\n                edgecolor=\"black\",\n            )\n            ax1.set_xlabel(xlabel, fontsize=12)\n            ax1.set_ylabel(\"\u9891\u7387\", fontsize=12)\n            ax1.set_title(\"\u8f93\u51fa\u5206\u5e03\u76f4\u65b9\u56fe\", fontsize=14, pad=10)\n            ax1.grid(True, alpha=0.3)\n\n            # Add statistics text to the histogram plot\n            stats_text = f\"\u5747\u503c: {Si['mean']:.4f}\\n\u6807\u51c6\u5dee: {Si['std']:.4f}\\n\u6700\u5c0f\u503c: {Si['min']:.4f}\\n\u6700\u5927\u503c: {Si['max']:.4f}\"\n            ax1.text(\n                0.05,\n                0.95,\n                stats_text,\n                transform=ax1.transAxes,\n                fontsize=10,\n                verticalalignment=\"top\",\n                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n            )\n\n            # Plot 2: Cumulative distribution function\n            sorted_data = np.sort(self.simulation_results[:, output_index])\n            y_vals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n            ax2.plot(sorted_data, y_vals, linewidth=2, color=\"darkgreen\")\n            ax2.set_xlabel(xlabel, fontsize=12)\n            ax2.set_ylabel(\"\u7d2f\u79ef\u6982\u7387\", fontsize=12)\n            ax2.set_title(\"\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\", fontsize=14, pad=10)\n            ax2.grid(True, alpha=0.3)\n\n            plt.tight_layout()\n            filename = f'lhs_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n            plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n            logger.info(f\"LHS\u5206\u6790\u7ed3\u679c\u56fe\u8868\u5df2\u4fdd\u5b58: {filename}\")\n\n    def save_results(\n        self, save_dir: str = None, format: str = \"csv\", metric_names: List[str] = None\n    ) -&gt; None:\n        \"\"\"\n        Save sensitivity analysis results\n\n        Args:\n            save_dir: Save directory\n            format: Save format ('csv\n        \"\"\"\n        if save_dir is None:\n            save_dir = \".\"\n        os.makedirs(save_dir, exist_ok=True)\n\n        for method, method_results in self.sensitivity_results.items():\n            if not method_results:\n                continue\n\n            for metric_key, results in method_results.items():\n                output_index = results[\"output_index\"]\n\n                if metric_names and output_index &lt; len(metric_names):\n                    metric_display_name = metric_names[output_index]\n                else:\n                    metric_display_name = f\"Metric_{output_index}\"\n\n                if format == \"csv\":\n                    if method == \"sobol\":\n                        sobol_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"S1\": results[\"S1\"],\n                                \"ST\": results[\"ST\"],\n                                \"S1_conf\": results[\"S1_conf\"],\n                                \"ST_conf\": results[\"ST_conf\"],\n                            }\n                        )\n                        filename = (\n                            f'sobol_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        sobol_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"Sobol results have been saved: {filename}\")\n\n                    elif method == \"morris\":\n                        morris_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"mu\": results[\"mu\"],\n                                \"mu_star\": results[\"mu_star\"],\n                                \"sigma\": results[\"sigma\"],\n                                \"mu_star_conf\": results[\"mu_star_conf\"],\n                            }\n                        )\n                        filename = f'morris_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        morris_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"Morris results have been saved: {filename}\")\n\n                    elif method == \"fast\":\n                        fast_df = pd.DataFrame(\n                            {\n                                \"Parameter\": self.problem[\"names\"],\n                                \"S1\": results[\"S1\"],\n                                \"ST\": results[\"ST\"],\n                            }\n                        )\n                        filename = (\n                            f'fast_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        fast_df.to_csv(os.path.join(save_dir, filename), index=False)\n                        logger.info(f\"FAST results have been saved: {filename}\")\n\n                    elif method == \"latin\":\n                        # Save LHS statistics\n                        lhs_stats_df = pd.DataFrame(\n                            {\n                                \"Metric\": [metric_display_name],\n                                \"Mean\": [results[\"mean\"]],\n                                \"Std\": [results[\"std\"]],\n                                \"Min\": [results[\"min\"]],\n                                \"Max\": [results[\"max\"]],\n                                \"Percentile_5\": [results[\"percentile_5\"]],\n                                \"Percentile_95\": [results[\"percentile_95\"]],\n                            }\n                        )\n                        filename_stats = (\n                            f'lhs_stats_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        )\n                        lhs_stats_df.to_csv(\n                            os.path.join(save_dir, filename_stats), index=False\n                        )\n                        logger.info(f\"LHS\u7edf\u8ba1\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_stats}\")\n\n                        # Remove LHS sensitivity indices saving\n                        # lhs_sens_df = pd.DataFrame({\n                        #     \"Parameter\": self.problem[\"names\"],\n                        #     \"Partial_Correlation\": results[\"partial_correlations\"]\n                        # })\n                        # filename_sens = f'lhs_sensitivity_{metric_display_name.replace(\" \", \"_\")}.csv'\n                        # lhs_sens_df.to_csv(os.path.join(save_dir, filename_sens), index=False)\n                        # logger.info(f\"LHS\u654f\u611f\u6027\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_sens}\")\n\n        logger.info(f\"The result has been saved to: {save_dir}\")\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.__init__","title":"<code>__init__(base_config)</code>","text":"<p>Initialize the analyzer</p> <p>Parameters:</p> Name Type Description Default <code>base_config</code> <code>Dict[str, Any]</code> <p>Tricys base configuration dictionary</p> required Source code in <code>tricys/analysis/salib.py</code> <pre><code>def __init__(self, base_config: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Initialize the analyzer\n\n    Args:\n        base_config: Tricys base configuration dictionary\n    \"\"\"\n    self.base_config = base_config.copy()\n    self.problem = None\n    self.parameter_samples = None\n    self.simulation_results = None\n    self.sensitivity_results = {}\n\n    self._setup_chinese_font()\n    self._validate_tricys_config()\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.analyze_fast","title":"<code>analyze_fast(output_index=0, **kwargs)</code>","text":"<p>Perform FAST sensitivity analysis</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>FAST analysis parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>FAST sensitivity analysis results</p> Note <p>FAST analysis requires samples generated by the fast_sampler sampling method! Results from Morris or Sobol sampling cannot be used.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_fast(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform FAST sensitivity analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: FAST analysis parameters\n\n    Returns:\n        FAST sensitivity analysis results\n\n    Note:\n        FAST analysis requires samples generated by the fast_sampler sampling method!\n        Results from Morris or Sobol sampling cannot be used.\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"fast\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but FAST analysis requires FAST sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('fast')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"FAST\u5206\u6790\")\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n\n    try:\n        # Perform FAST analysis\n        Si = fast.analyze(self.problem, Y, **kwargs)\n\n        if \"fast\" not in self.sensitivity_results:\n            self.sensitivity_results[\"fast\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"fast\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"S1\": Si[\"S1\"],\n            \"ST\": Si[\"ST\"],\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(\n            f\"FAST sensitivity analysis completed (indicator {output_index})\"\n        )\n        return self.sensitivity_results[\"fast\"][metric_name]\n\n    except Exception as e:\n        if \"fast\" in str(e).lower() or \"sample\" in str(e).lower():\n            raise ValueError(\n                f\"FAST analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('fast')\"\n            ) from e\n        else:\n            raise\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.analyze_lhs","title":"<code>analyze_lhs(output_index=0, **kwargs)</code>","text":"<p>Perform LHS (Latin Hypercube Sampling) uncertainty analysis</p> <p>Note: This is a basic statistical analysis method for LHS samples, providing descriptive statistics and basic sensitivity indices.</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Analysis parameters (reserved for future use)</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>LHS uncertainty analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_lhs(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform LHS (Latin Hypercube Sampling) uncertainty analysis\n\n    Note: This is a basic statistical analysis method for LHS samples,\n    providing descriptive statistics and basic sensitivity indices.\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Analysis parameters (reserved for future use)\n\n    Returns:\n        LHS uncertainty analysis results\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"latin\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f The current sampling method is {self._last_sampling_method}, but LHS analysis is designed for Latin Hypercube Sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('latin')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    # Handle NaN values\n    Y = self._handle_nan_values(Y, \"LHS\u5206\u6790\")\n\n    # Basic statistical analysis\n    mean_val = np.mean(Y)\n    std_val = np.std(Y)\n    min_val = np.min(Y)\n    max_val = np.max(Y)\n    percentile_5 = np.percentile(Y, 5)\n    percentile_95 = np.percentile(Y, 95)\n\n    # Create results dictionary\n    Si = {\n        \"mean\": mean_val,\n        \"std\": std_val,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"percentile_5\": percentile_5,\n        \"percentile_95\": percentile_95,\n    }\n\n    if \"latin\" not in self.sensitivity_results:\n        self.sensitivity_results[\"latin\"] = {}\n\n    metric_name = f\"metric_{output_index}\"\n    self.sensitivity_results[\"latin\"][metric_name] = {\n        \"output_index\": output_index,\n        \"Si\": Si,\n        \"mean\": mean_val,\n        \"std\": std_val,\n        \"min\": min_val,\n        \"max\": max_val,\n        \"percentile_5\": percentile_5,\n        \"percentile_95\": percentile_95,\n        \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n    }\n\n    logger.info(f\"LHS uncertainty analysis completed (\u6307\u6807 {output_index})\")\n    return self.sensitivity_results[\"latin\"][metric_name]\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.analyze_morris","title":"<code>analyze_morris(output_index=0, **kwargs)</code>","text":"<p>Perform Morris sensitivity analysis</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Morris analysis parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Morris sensitivity analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_morris(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform Morris sensitivity analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Morris analysis parameters\n\n    Returns:\n        Morris sensitivity analysis results\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"Morris\u5206\u6790\")\n    X = self.parameter_samples\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n    #    X = self.parameter_samples[valid_indices]\n    # else:\n    #    X = self.parameter_samples\n\n    # Perform Morris analysis\n    logger.info(\n        f\"Start Morris sensitivity analysis: X.shape={X.shape}, Y.shape={Y.shape}, X.dtype={X.dtype}\"\n    )\n\n    try:\n        Si = morris_analyze.analyze(self.problem, X, Y, **kwargs)\n    except Exception as e:\n        logger.error(f\"Morris analysis execution failed: {e}\")\n        logger.error(f\"problem: {self.problem}\")\n        logger.error(f\"X shape: {X.shape}, type: {X.dtype}\")\n        logger.error(f\"Yshape: {Y.shape}, type: {Y.dtype}\")\n        if hasattr(X, \"dtype\") and X.dtype == \"object\":\n            logger.error(\n                \"X contains non-numeric data, please check the sampled data\"\n            )\n        raise\n\n    if \"morris\" not in self.sensitivity_results:\n        self.sensitivity_results[\"morris\"] = {}\n\n    metric_name = f\"metric_{output_index}\"\n    self.sensitivity_results[\"morris\"][metric_name] = {\n        \"output_index\": output_index,\n        \"Si\": Si,\n        \"mu\": Si[\"mu\"],\n        \"mu_star\": Si[\"mu_star\"],\n        \"sigma\": Si[\"sigma\"],\n        \"mu_star_conf\": Si[\"mu_star_conf\"],\n    }\n\n    logger.info(f\"Morris sensitivity analysis completed (metric {output_index})\")\n    return self.sensitivity_results[\"morris\"][metric_name]\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.analyze_sobol","title":"<code>analyze_sobol(output_index=0, **kwargs)</code>","text":"<p>Perform Sobol Sensitivity Analysis</p> <p>Parameters:</p> Name Type Description Default <code>output_index</code> <code>int</code> <p>Output variable index</p> <code>0</code> <code>**kwargs</code> <p>Sobol analysis parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Sobol sensitivity analysis results</p> Note <p>Sobol analysis requires samples generated using the Saltelli sampling method! Results from Morris or FAST sampling cannot be used.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def analyze_sobol(self, output_index: int = 0, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform Sobol Sensitivity Analysis\n\n    Args:\n        output_index: Output variable index\n        **kwargs: Sobol analysis parameters\n\n    Returns:\n        Sobol sensitivity analysis results\n\n    Note:\n        Sobol analysis requires samples generated using the Saltelli sampling method!\n        Results from Morris or FAST sampling cannot be used.\n    \"\"\"\n    if self.simulation_results is None:\n        raise ValueError(\"The simulation must be run first to obtain the results.\")\n\n    # Check sampling method compatibility\n    if (\n        hasattr(self, \"_last_sampling_method\")\n        and self._last_sampling_method != \"sobol\"\n    ):\n        logger.warning(\n            f\"\u26a0\ufe0f Currently using {self._last_sampling_method} sampling, but Sobol analysis requires Saltelli sampling!\"\n        )\n        logger.warning(\n            \"Suggestion: Regenerate samples using generate_samples('sobol')\"\n        )\n\n    Y = self.simulation_results[:, output_index]\n\n    Y = self._handle_nan_values(Y, \"Sobol\u5206\u6790\")\n\n    # Remove NaN values\n    # valid_indices = ~np.isnan(Y)\n    # if not np.all(valid_indices):\n    #    logger.warning(f\"\u53d1\u73b0{np.sum(~valid_indices)}\u4e2a\u65e0\u6548\u7ed3\u679c\uff0c\u5c06\u88ab\u6392\u9664\")\n    #    Y = Y[valid_indices]\n    #    X = self.parameter_samples[valid_indices]\n    # else:\n    #    X = self.parameter_samples\n\n    try:\n        Si = sobol.analyze(self.problem, Y, **kwargs)\n\n        if \"sobol\" not in self.sensitivity_results:\n            self.sensitivity_results[\"sobol\"] = {}\n\n        metric_name = f\"metric_{output_index}\"\n        self.sensitivity_results[\"sobol\"][metric_name] = {\n            \"output_index\": output_index,\n            \"Si\": Si,\n            \"S1\": Si[\"S1\"],\n            \"ST\": Si[\"ST\"],\n            \"S2\": Si.get(\"S2\", None),\n            \"S1_conf\": Si[\"S1_conf\"],\n            \"ST_conf\": Si[\"ST_conf\"],\n            \"sampling_method\": getattr(self, \"_last_sampling_method\", \"unknown\"),\n        }\n\n        logger.info(f\"Sobol sensitivity analysis completed (index {output_index})\")\n        return self.sensitivity_results[\"sobol\"][metric_name]\n\n    except Exception as e:\n        if \"saltelli\" in str(e).lower() or \"sample\" in str(e).lower():\n            raise ValueError(\n                f\"Sobol analysis failed, possibly due to incompatible sampling method: {e}\\nPlease regenerate samples using generate_samples('sobol')\"\n            ) from e\n        else:\n            raise\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.define_problem","title":"<code>define_problem(param_bounds, param_distributions=None)</code>","text":"<p>Define SALib problem space</p> <p>Parameters:</p> Name Type Description Default <code>param_bounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Parameter bounds dictionary {'param_name': (min_val, max_val)}</p> required <code>param_distributions</code> <code>Dict[str, str]</code> <p>Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}                 Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>SALib problem definition dictionary</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def define_problem(\n    self,\n    param_bounds: Dict[str, Tuple[float, float]],\n    param_distributions: Dict[str, str] = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Define SALib problem space\n\n    Args:\n        param_bounds: Parameter bounds dictionary {'param_name': (min_val, max_val)}\n        param_distributions: Parameter distribution type dictionary {'param_name': 'unif'/'norm'/etc}\n                            Valid distribution types: 'unif', 'triang', 'norm', 'truncnorm', 'lognorm'\n\n    Returns:\n        SALib problem definition dictionary\n    \"\"\"\n    if param_distributions is None:\n        param_distributions = {name: \"unif\" for name in param_bounds.keys()}\n\n    valid_dists = [\"unif\", \"triang\", \"norm\", \"truncnorm\", \"lognorm\"]\n    for name, dist in param_distributions.items():\n        if dist not in valid_dists:\n            logger.warning(\n                \"Invalid distribution type, using 'unif' instead\",\n                extra={\n                    \"parameter_name\": name,\n                    \"invalid_distribution\": dist,\n                },\n            )\n            param_distributions[name] = \"unif\"\n\n    self.problem = {\n        \"num_vars\": len(param_bounds),\n        \"names\": list(param_bounds.keys()),\n        \"bounds\": list(param_bounds.values()),\n        \"dists\": [\n            param_distributions.get(name, \"unif\") for name in param_bounds.keys()\n        ],\n    }\n\n    logger.info(\n        \"Defined a problem space\",\n        extra={\n            \"num_parameters\": self.problem[\"num_vars\"],\n        },\n    )\n    for i, name in enumerate(self.problem[\"names\"]):\n        logger.info(\n            \"Parameter definition\",\n            extra={\n                \"parameter_name\": name,\n                \"bounds\": self.problem[\"bounds\"][i],\n                \"distribution\": self.problem[\"dists\"][i],\n            },\n        )\n\n    return self.problem\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.generate_samples","title":"<code>generate_samples(method='sobol', N=1024, **kwargs)</code>","text":"<p>Generate parameter samples</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Sampling method ('sobol', 'morris', 'fast', 'latin')</p> <code>'sobol'</code> <code>N</code> <code>int</code> <p>Number of samples (for Sobol this is the base sample count, actual sample count is N(2D+2))</p> <code>1024</code> <code>**kwargs</code> <p>Method-specific parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Parameter sample array (n_samples, n_params)</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def generate_samples(\n    self, method: str = \"sobol\", N: int = 1024, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate parameter samples\n\n    Args:\n        method: Sampling method ('sobol', 'morris', 'fast', 'latin')\n        N: Number of samples (for Sobol this is the base sample count, actual sample count is N*(2*D+2))\n        **kwargs: Method-specific parameters\n\n    Returns:\n        Parameter sample array (n_samples, n_params)\n    \"\"\"\n    if self.problem is None:\n        raise ValueError(\n            \"You must first call define_problem() to define the problem space.\"\n        )\n\n    logger.info(\n        \"Generating samples\",\n        extra={\n            \"method\": method,\n            \"base_sample_count\": N,\n        },\n    )\n\n    if method.lower() == \"sobol\":\n        # Sobol method: generate N*(2*D+2) samples\n        self.parameter_samples = saltelli.sample(self.problem, N, **kwargs)\n        actual_samples = N * (2 * self.problem[\"num_vars\"] + 2)\n\n    elif method.lower() == \"morris\":\n        # Morris method: Generate N trajectories\n        # Note: Different versions of SALib may have different parameter names\n        morris_kwargs = {\"num_levels\": 4}\n        # Check the SALib version and use the correct parameter names\n        try:\n            morris_kwargs.update(kwargs)\n            self.parameter_samples = morris.sample(self.problem, N, **morris_kwargs)\n        except TypeError as e:\n            if \"grid_jump\" in str(e):\n                morris_kwargs = {\n                    k: v for k, v in morris_kwargs.items() if k != \"grid_jump\"\n                }\n                morris_kwargs.update(\n                    {k: v for k, v in kwargs.items() if k != \"grid_jump\"}\n                )\n                self.parameter_samples = morris.sample(\n                    self.problem, N, **morris_kwargs\n                )\n            else:\n                raise e\n\n        actual_samples = len(self.parameter_samples)\n\n    elif method.lower() == \"fast\":\n        # FAST method\n        fast_kwargs = {\"M\": 4}\n        fast_kwargs.update(kwargs)\n        self.parameter_samples = fast_sampler.sample(self.problem, N, **fast_kwargs)\n        actual_samples = len(self.parameter_samples)\n\n    elif method.lower() == \"latin\":\n        # Latin Hypercube Sampling\n        self.parameter_samples = latin.sample(self.problem, N, **kwargs)\n        actual_samples = N\n\n    else:\n        raise ValueError(f\"Unsupported sampling method: {method}\")\n\n    logger.info(\n        \"Successfully generated samples\", extra={\"actual_samples\": actual_samples}\n    )\n\n    if self.parameter_samples is not None:\n        self.parameter_samples = np.round(self.parameter_samples, decimals=5)\n        logger.info(\"Parameter sample precision adjusted to 5 decimal places\")\n\n    self._last_sampling_method = method.lower()\n\n    return self.parameter_samples\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.generate_tricys_config","title":"<code>generate_tricys_config(csv_file_path=None, output_metrics=None)</code>","text":"<p>Generate Tricys configuration file for reading CSV parameter files and executing simulations This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs</p> <p>Parameters:</p> Name Type Description Default <code>csv_file_path</code> <code>str</code> <p>Path to the CSV parameter file. If None, the last generated file is used</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be calculated</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Path of the generated configuration file</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def generate_tricys_config(\n    self, csv_file_path: str = None, output_metrics: List[str] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Generate Tricys configuration file for reading CSV parameter files and executing simulations\n    This function reuses the base configuration and specifically modifies simulation_parameters and analysis_case for file-based SALib runs\n\n    Args:\n        csv_file_path: Path to the CSV parameter file. If None, the last generated file is used\n        output_metrics: List of output metrics to be calculated\n\n    Returns:\n        Path of the generated configuration file\n    \"\"\"\n    if csv_file_path is None:\n        if hasattr(self, \"sampling_csv_path\"):\n            csv_file_path = self.sampling_csv_path\n        else:\n            raise ValueError(\n                \"CSV file path not found, please first call run_tricys_simulations() or specify csv_file_path\"\n            )\n\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    csv_abs_path = os.path.abspath(csv_file_path)\n\n    import copy\n\n    tricys_config = copy.deepcopy(self.base_config)\n    tricys_config[\"simulation_parameters\"] = {\"file\": csv_abs_path}\n\n    if \"sensitivity_analysis\" not in tricys_config:\n        tricys_config[\"sensitivity_analysis\"] = {\"enabled\": True}\n\n    tricys_config[\"sensitivity_analysis\"][\"analysis_case\"] = {\n        \"name\": \"SALib_Analysis\",\n        \"independent_variable\": \"file\",\n        \"independent_variable_sampling\": csv_abs_path,\n        \"dependent_variables\": output_metrics,\n    }\n\n    return tricys_config\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.get_compatible_analysis_methods","title":"<code>get_compatible_analysis_methods(sampling_method)</code>","text":"<p>Get analysis methods compatible with the specified sampling method.</p> <p>Parameters:</p> Name Type Description Default <code>sampling_method</code> <code>str</code> <p>Sampling method</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of compatible analysis methods</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def get_compatible_analysis_methods(self, sampling_method: str) -&gt; List[str]:\n    \"\"\"\n    Get analysis methods compatible with the specified sampling method.\n\n    Args:\n        sampling_method: Sampling method\n\n    Returns:\n        List of compatible analysis methods\n    \"\"\"\n    compatibility_map = {\n        \"sobol\": [\"sobol\"],\n        \"morris\": [\"morris\"],\n        \"fast\": [\"fast\"],\n        \"latin\": [\"latin\"],\n        \"unknown\": [],\n    }\n\n    return compatibility_map.get(sampling_method, [])\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.load_tricys_results","title":"<code>load_tricys_results(sensitivity_summary_csv, output_metrics=None)</code>","text":"<p>Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys</p> <p>Parameters:</p> Name Type Description Default <code>sensitivity_summary_csv</code> <code>str</code> <p>Path to the sensitivity analysis summary CSV file output by Tricys</p> required <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to extract</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Simulation result array (n_samples, n_metrics)</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def load_tricys_results(\n    self, sensitivity_summary_csv: str, output_metrics: List[str] = None\n) -&gt; np.ndarray:\n    \"\"\"\n    Read simulation results from the sensitivity_analysis_summary.csv file output by Tricys\n\n    Args:\n        sensitivity_summary_csv: Path to the sensitivity analysis summary CSV file output by Tricys\n        output_metrics: List of output metrics to extract\n\n    Returns:\n        Simulation result array (n_samples, n_metrics)\n    \"\"\"\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    logger.info(f\"Read data from the Tricys result file: {sensitivity_summary_csv}\")\n\n    df = pd.read_csv(sensitivity_summary_csv)\n\n    logger.info(f\"Read {len(df)} simulation results\")\n    logger.info(f\"Result file columns: {list(df.columns)}\")\n\n    param_cols = []\n    metric_cols = []\n\n    for col in df.columns:\n        if col in output_metrics:\n            metric_cols.append(col)\n        elif col in self.problem[\"names\"] if self.problem else False:\n            param_cols.append(col)\n\n    logger.info(f\"Recognized parameter columns: {param_cols}\")\n    logger.info(f\"Identified metric columns: {metric_cols}\")\n\n    ordered_metric_cols = []\n    for metric in output_metrics:\n        if metric in metric_cols:\n            ordered_metric_cols.append(metric)\n        else:\n            logger.warning(f\"Metric column not found: {metric}\")\n\n    if not ordered_metric_cols:\n        raise ValueError(f\"No valid output metrics columns found: {output_metrics}\")\n\n    results_data = df[ordered_metric_cols].values\n\n    self.simulation_results = results_data\n\n    logger.info(f\"Successfully loaded simulation results: {results_data.shape}\")\n    logger.info(\n        f\"Result Statistics:\\n{pd.DataFrame(results_data, columns=ordered_metric_cols).describe()}\"\n    )\n    logger.info(\n        f\"Result preview:\\n{pd.DataFrame(results_data, columns=metric_cols).head()}\"\n    )\n    return self.simulation_results\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.plot_fast_results","title":"<code>plot_fast_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot FAST analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_fast_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot FAST analysis results\"\"\"\n    if \"fast\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results found for the FAST method\")\n\n    # No analysis results found for the FAST method\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    fast_results = self.sensitivity_results[\"fast\"]\n\n    if not fast_results:\n        raise ValueError(\"FAST analysis results not found\")\n\n    # Generate a chart for each metric\n    for metric_key, results in fast_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        # Determine the indicator name\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Bar charts of first-order and total sensitivity indices\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # first-order sensitivity index\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax1.barh(y_pos, Si[\"S1\"], alpha=0.7, color=\"purple\")\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax1.set_xlabel(\"\u4e00\u9636\u654f\u611f\u6027\u6307\u6570 (S1)\", fontsize=12)\n        ax1.set_title(\n            f\"FAST First-order Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax1.grid(True, alpha=0.3)\n\n        # Total Sensitivity Index\n        ax2.barh(y_pos, Si[\"ST\"], alpha=0.7, color=\"darkgreen\")\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"\u603b\u654f\u611f\u6027\u6307\u6570 (ST)\", fontsize=12)\n        ax2.set_title(\n            f\"FAST Total Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = (\n            f'fast_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n        )\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"The FAST result chart has been saved: {filename}\")\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.plot_lhs_results","title":"<code>plot_lhs_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot LHS (Latin Hypercube Sampling) uncertainty analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_lhs_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot LHS (Latin Hypercube Sampling) uncertainty analysis results\"\"\"\n    if \"latin\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results found for the LHS method\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    lhs_results = self.sensitivity_results[\"latin\"]\n\n    if not lhs_results:\n        raise ValueError(\"LHS analysis results not found\")\n\n    # Generate charts for each metric\n    for metric_key, results in lhs_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        # Determine the indicator name\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Get unit from config\n        sensitivity_analysis_config = self.base_config.get(\n            \"sensitivity_analysis\", {}\n        )\n        unit_map = sensitivity_analysis_config.get(\"unit_map\", {})\n        unit_config = self._find_unit_config(metric_display_name, unit_map)\n        unit_str = \"\"\n        if unit_config:\n            unit = unit_config.get(\"unit\")\n            if unit:\n                unit_str = f\" ({unit})\"\n\n        xlabel = f\"{metric_display_name}{unit_str}\"\n\n        # Create a figure with two subplots\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # Plot 1: Distribution histogram\n        ax1.hist(\n            self.simulation_results[:, output_index],\n            bins=30,\n            alpha=0.7,\n            color=\"skyblue\",\n            edgecolor=\"black\",\n        )\n        ax1.set_xlabel(xlabel, fontsize=12)\n        ax1.set_ylabel(\"\u9891\u7387\", fontsize=12)\n        ax1.set_title(\"\u8f93\u51fa\u5206\u5e03\u76f4\u65b9\u56fe\", fontsize=14, pad=10)\n        ax1.grid(True, alpha=0.3)\n\n        # Add statistics text to the histogram plot\n        stats_text = f\"\u5747\u503c: {Si['mean']:.4f}\\n\u6807\u51c6\u5dee: {Si['std']:.4f}\\n\u6700\u5c0f\u503c: {Si['min']:.4f}\\n\u6700\u5927\u503c: {Si['max']:.4f}\"\n        ax1.text(\n            0.05,\n            0.95,\n            stats_text,\n            transform=ax1.transAxes,\n            fontsize=10,\n            verticalalignment=\"top\",\n            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n        )\n\n        # Plot 2: Cumulative distribution function\n        sorted_data = np.sort(self.simulation_results[:, output_index])\n        y_vals = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n        ax2.plot(sorted_data, y_vals, linewidth=2, color=\"darkgreen\")\n        ax2.set_xlabel(xlabel, fontsize=12)\n        ax2.set_ylabel(\"\u7d2f\u79ef\u6982\u7387\", fontsize=12)\n        ax2.set_title(\"\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\", fontsize=14, pad=10)\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = f'lhs_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"LHS\u5206\u6790\u7ed3\u679c\u56fe\u8868\u5df2\u4fdd\u5b58: {filename}\")\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.plot_morris_results","title":"<code>plot_morris_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot the Morris analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_morris_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot the Morris analysis results\"\"\"\n    if \"morris\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results were found for the Morris method.\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Obtain the results of all indicators\n    morris_results = self.sensitivity_results[\"morris\"]\n\n    if not morris_results:\n        raise ValueError(\"No Morris analysis results found\")\n\n    for metric_key, results in morris_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Morris \u03bc*-\u03c3 diagram\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # \u03bc*-\u03c3 scatter plot\n        ax1.scatter(Si[\"mu_star\"], Si[\"sigma\"], s=100, alpha=0.7, color=\"red\")\n        for i, name in enumerate(self.problem[\"names\"]):\n            ax1.annotate(\n                name,\n                (Si[\"mu_star\"][i], Si[\"sigma\"][i]),\n                xytext=(5, 5),\n                textcoords=\"offset points\",\n                fontsize=9,\n            )\n\n        ax1.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n        ax1.set_ylabel(\"\u03c3 (Standard Deviation)\", fontsize=12)\n        ax1.set_title(\n            f\"Morris \u03bc*-\u03c3 Plot\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax1.grid(True, alpha=0.3)\n\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax2.barh(\n            y_pos, Si[\"mu_star\"], xerr=Si[\"mu_star_conf\"], alpha=0.7, color=\"green\"\n        )\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"\u03bc*(Average Absolute Effect)\", fontsize=12)\n        ax2.set_title(\n            f\"Morris Elementary Effects\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = f'morris_sensitivity_analysis_{metric_display_name.replace(\" \", \"_\")}.png'\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"Morris result chart has been saved: {filename}\")\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.plot_sobol_results","title":"<code>plot_sobol_results(save_dir=None, figsize=(12, 8), metric_names=None)</code>","text":"<p>Plot Sobol analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def plot_sobol_results(\n    self,\n    save_dir: str = None,\n    figsize: Tuple[int, int] = (12, 8),\n    metric_names: List[str] = None,\n) -&gt; None:\n    \"\"\"Plot Sobol analysis results\"\"\"\n    if \"sobol\" not in self.sensitivity_results:\n        raise ValueError(\"No analysis results for the Sobol method were found.\")\n\n    # Ensure Chinese font settings\n    self._setup_chinese_font()\n\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # Get the results of all indicators\n    sobol_results = self.sensitivity_results[\"sobol\"]\n\n    if not sobol_results:\n        raise ValueError(\"Sobol analysis results not found\")\n\n    # Generate charts for each metric\n    for metric_key, results in sobol_results.items():\n        Si = results[\"Si\"]\n        output_index = results[\"output_index\"]\n\n        if metric_names and output_index &lt; len(metric_names):\n            metric_display_name = metric_names[output_index]\n        else:\n            metric_display_name = f\"Metric_{output_index}\"\n\n        # Bar chart of first-order and total sensitivity indices\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n\n        # First-order sensitivity index\n        y_pos = np.arange(len(self.problem[\"names\"]))\n        ax1.barh(y_pos, Si[\"S1\"], xerr=Si[\"S1_conf\"], alpha=0.7, color=\"skyblue\")\n        ax1.set_yticks(y_pos)\n        ax1.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax1.set_xlabel(\"First-order sensitivity index (S1)\", fontsize=12)\n        ax1.set_title(\n            f\"First-order Sensitivity Indices\\n{metric_display_name}\",\n            fontsize=14,\n            pad=20,\n        )\n        ax1.grid(True, alpha=0.3)\n\n        # # Total Sensitivity Index\n        ax2.barh(y_pos, Si[\"ST\"], xerr=Si[\"ST_conf\"], alpha=0.7, color=\"orange\")\n        ax2.set_yticks(y_pos)\n        ax2.set_yticklabels(self.problem[\"names\"], fontsize=10)\n        ax2.set_xlabel(\"Total Sensitivity Index (ST)\", fontsize=12)\n        ax2.set_title(\n            f\"Total Sensitivity Indices\\n{metric_display_name}\", fontsize=14, pad=20\n        )\n        ax2.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n        filename = (\n            f'sobol_sensitivity_indices_{metric_display_name.replace(\" \", \"_\")}.png'\n        )\n        plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches=\"tight\")\n\n        logger.info(f\"Sobol result chart has been saved: {filename}\")\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.run_salib_analysis_from_tricys_results","title":"<code>run_salib_analysis_from_tricys_results(sensitivity_summary_csv, param_bounds=None, output_metrics=None, methods=['sobol', 'morris', 'fast'], save_dir=None)</code>","text":"<p>Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys</p> <p>Parameters:</p> Name Type Description Default <code>sensitivity_summary_csv</code> <code>str</code> <p>Path to the sensitivity summary CSV file output by Tricys</p> required <code>param_bounds</code> <code>Dict[str, Tuple[float, float]]</code> <p>Dictionary of parameter bounds, inferred from the CSV file if None</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to analyze</p> <code>None</code> <code>methods</code> <code>List[str]</code> <p>List of sensitivity analysis methods to execute</p> <code>['sobol', 'morris', 'fast']</code> <code>save_dir</code> <code>str</code> <p>Directory to save the results</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing all analysis results</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_salib_analysis_from_tricys_results(\n    self,\n    sensitivity_summary_csv: str,\n    param_bounds: Dict[str, Tuple[float, float]] = None,\n    output_metrics: List[str] = None,\n    methods: List[str] = [\"sobol\", \"morris\", \"fast\"],\n    save_dir: str = None,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run a complete SALib sensitivity analysis from the sensitivity analysis results file output by Tricys\n\n    Args:\n        sensitivity_summary_csv: Path to the sensitivity summary CSV file output by Tricys\n        param_bounds: Dictionary of parameter bounds, inferred from the CSV file if None\n        output_metrics: List of output metrics to analyze\n        methods: List of sensitivity analysis methods to execute\n        save_dir: Directory to save the results\n\n    Returns:\n        Dictionary containing all analysis results\n    \"\"\"\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    if save_dir is None:\n        save_dir = os.path.join(\n            os.path.dirname(sensitivity_summary_csv), \"salib_analysis\"\n        )\n    os.makedirs(save_dir, exist_ok=True)\n\n    df = pd.read_csv(sensitivity_summary_csv)\n\n    if param_bounds is None:\n        param_bounds = {}\n        param_candidates = []\n        for col in df.columns:\n            if col not in output_metrics and \".\" in col:\n                param_candidates.append(col)\n\n        for param in param_candidates:\n            param_data = df[param].dropna()\n            if len(param_data) &gt; 0:\n                param_bounds[param] = (param_data.min(), param_data.max())\n\n    if not param_bounds:\n        raise ValueError(\n            \"Unable to determine parameter boundaries, please provide the param_bounds parameter\"\n        )\n\n    self.define_problem(param_bounds)\n\n    self.load_tricys_results(sensitivity_summary_csv, output_metrics)\n\n    detected_method = self._last_sampling_method\n\n    methods = self.get_compatible_analysis_methods(detected_method)\n\n    all_results = {}\n\n    for metric_idx, metric_name in enumerate(output_metrics):\n        if metric_idx &gt;= self.simulation_results.shape[1]:\n            logger.warning(f\"The metric {metric_name} is out of range, skipping\")\n            continue\n\n        logger.info(f\"\\n=== Analysis indicators: {metric_name} ===\")\n        metric_results = {}\n\n        # Check data validity\n        Y = self.simulation_results[:, metric_idx]\n        valid_ratio = np.sum(~np.isnan(Y)) / len(Y)\n        logger.info(f\"Valid data ratio: {valid_ratio:.2%}\")\n\n        if valid_ratio &lt; 0.5:\n            logger.warning(\n                f\"The metric {metric_name} has less than 50% valid data, which may affect the analysis quality.\"\n            )\n\n        # Sobol analysis\n        if \"sobol\" in methods:\n            try:\n                logger.info(\"Performing Sobol sensitivity analysis...\")\n                sobol_result = self.analyze_sobol(output_index=metric_idx)\n                metric_results[\"sobol\"] = sobol_result\n\n                # Display Sobol results summary\n                logger.info(\"\\nSobol sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = sobol_result[\"S1\"][i]\n                    st = sobol_result[\"ST\"][i]\n                    logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"Sobol analysis failed: {e}\")\n\n        # Morris analysis\n        if \"morris\" in methods:\n            try:\n                logger.info(\"Performing Morris sensitivity analysis...\")\n                morris_result = self.analyze_morris(output_index=metric_idx)\n                metric_results[\"morris\"] = morris_result\n\n                # Display Morris results summary\n                logger.info(\"\\nMorris sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    mu_star = morris_result[\"mu_star\"][i]\n                    sigma = morris_result[\"sigma\"][i]\n                    logger.info(f\"  {param_name}: \u03bc*={mu_star:.4f}, \u03c3={sigma:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"Morris analysis failed: {e}\")\n\n        # FAST analysis\n        if \"fast\" in methods:\n            try:\n                logger.info(\"Performing FAST sensitivity analysis...\")\n                fast_result = self.analyze_fast(output_index=metric_idx)\n                metric_results[\"fast\"] = fast_result\n\n                # Display FAST results summary\n                logger.info(\"\\nFAST sensitivity index:\")\n                for i, param_name in enumerate(self.problem[\"names\"]):\n                    s1 = fast_result[\"S1\"][i]\n                    st = fast_result[\"ST\"][i]\n                    logger.info(f\"  {param_name}: S1={s1:.4f}, ST={st:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"FAST analysis failed: {e}\")\n\n        # LHS analysis\n        if \"latin\" in methods:\n            try:\n                logger.info(\"Performing LHS uncertainty analysis...\")\n                lhs_result = self.analyze_lhs(output_index=metric_idx)\n                metric_results[\"latin\"] = lhs_result\n\n                # Display LHS results summary\n                logger.info(\"\\nLHS\u5206\u6790\u7ed3\u679c:\")\n                logger.info(f\"  \u5747\u503c: {lhs_result['mean']:.4f}\")\n                logger.info(f\"  \u6807\u51c6\u5dee: {lhs_result['std']:.4f}\")\n                logger.info(f\"  \u6700\u5c0f\u503c: {lhs_result['min']:.4f}\")\n                logger.info(f\"  \u6700\u5927\u503c: {lhs_result['max']:.4f}\")\n                logger.info(f\"  5%\u5206\u4f4d\u6570: {lhs_result['percentile_5']:.4f}\")\n                logger.info(f\"  95%\u5206\u4f4d\u6570: {lhs_result['percentile_95']:.4f}\")\n\n            except Exception as e:\n                logger.error(f\"LHS\u5206\u6790\u5931\u8d25: {e}\")\n\n        all_results[metric_name] = metric_results\n\n    try:\n        if \"sobol\" in methods and \"sobol\" in self.sensitivity_results:\n            self.plot_sobol_results(save_dir=save_dir, metric_names=output_metrics)\n\n        if \"morris\" in methods and \"morris\" in self.sensitivity_results:\n            self.plot_morris_results(save_dir=save_dir, metric_names=output_metrics)\n\n        if \"fast\" in methods and \"fast\" in self.sensitivity_results:\n            self.plot_fast_results(save_dir=save_dir, metric_names=output_metrics)\n\n        # Plot LHS results\n        if \"latin\" in methods and \"latin\" in self.sensitivity_results:\n            self.plot_lhs_results(save_dir=save_dir, metric_names=output_metrics)\n\n    except Exception as e:\n        logger.warning(f\"Drawing failed: {e}\")\n\n    try:\n        self.save_results(\n            save_dir=save_dir, format=\"csv\", metric_names=output_metrics\n        )\n\n        report_content = self._save_sensitivity_report(all_results, save_dir)\n        report_path = os.path.join(save_dir, \"analysis_report.md\")\n\n        load_dotenv()\n\n        # --- LLM Calls for analysis ---\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n        ai_model = os.environ.get(\"AI_MODEL\")\n\n        sa_config = self.base_config.get(\"sensitivity_analysis\", {})\n        case_config = sa_config.get(\"analysis_case\", {})\n        ai_config = case_config.get(\"ai\")\n\n        ai_enabled = False\n        if isinstance(ai_config, bool):\n            ai_enabled = ai_config\n        elif isinstance(ai_config, dict):\n            ai_enabled = ai_config.get(\"enabled\", False)\n\n        if api_key and base_url and ai_model and ai_enabled:\n            # First LLM call for initial analysis\n            wrapper_prompt, llm_summary = call_llm_for_salib_analysis(\n                report_content=report_content,\n                api_key=api_key,\n                base_url=base_url,\n                ai_model=ai_model,\n                method=detected_method,\n            )\n            if wrapper_prompt and llm_summary:\n                with open(report_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd\\n\\n\")\n                    f.write(\"```markdown\\n\")\n                    f.write(wrapper_prompt)\n                    f.write(\"\\n```\\n\\n\")\n                    f.write(\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u7ed3\u679c\\n\\n\")\n                    f.write(llm_summary)\n                logger.info(f\"Appended LLM prompt and summary to {report_path}\")\n\n                # Second LLM call for academic report\n                glossary_path = None\n                if isinstance(case_config, dict):\n                    glossary_path = sa_config.get(\"glossary_path\")\n\n                if glossary_path and os.path.exists(glossary_path):\n                    try:\n                        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n                            glossary_content = f.read()\n\n                        (\n                            academic_wrapper_prompt,\n                            academic_report,\n                        ) = call_llm_for_academic_report(\n                            analysis_report=llm_summary,\n                            glossary_content=glossary_content,\n                            api_key=api_key,\n                            base_url=base_url,\n                            ai_model=ai_model,\n                            problem_details=self.problem,\n                            metric_names=output_metrics,\n                            method=detected_method,\n                            save_dir=save_dir,\n                        )\n\n                        if academic_wrapper_prompt and academic_report:\n                            academic_report_path = os.path.join(\n                                save_dir, \"academic_report.md\"\n                            )\n                            with open(\n                                academic_report_path, \"w\", encoding=\"utf-8\"\n                            ) as f:\n                                f.write(academic_report)\n                            logger.info(\n                                f\"Generated academic report: {academic_report_path}\"\n                            )\n                    except Exception as e:\n                        logger.error(\n                            f\"Failed to generate or save academic report: {e}\"\n                        )\n                elif glossary_path:\n                    logger.warning(\n                        f\"Glossary file not found at {glossary_path}, skipping academic report generation.\"\n                    )\n\n        else:\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not set, or AI analysis is disabled. Skipping LLM summary generation.\"\n            )\n\n    except Exception as e:\n        logger.warning(f\"Failed to save result: {e}\")\n\n    logger.info(\"\\n\u2705 SALib sensitivity analysis completed!\")\n    logger.info(f\"\ud83d\udcc1 The result has been saved to: {save_dir}\")\n\n    return all_results\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.run_tricys_analysis","title":"<code>run_tricys_analysis(csv_file_path=None, output_metrics=None)</code>","text":"<p>Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results</p> <p>Parameters:</p> Name Type Description Default <code>csv_file_path</code> <code>str</code> <p>Path to the CSV parameter file. If None, the last generated file will be used</p> <code>None</code> <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be calculated</p> <code>None</code> <code>config_output_path</code> <p>Path for the configuration file output. If None, it will be automatically generated</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the sensitivity_analysis_summary.csv file</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_tricys_analysis(\n    self, csv_file_path: str = None, output_metrics: List[str] = None\n) -&gt; str:\n    \"\"\"\n    Run the Tricys simulation using the generated CSV parameter file and obtain the sensitivity analysis results\n\n    Args:\n        csv_file_path: Path to the CSV parameter file. If None, the last generated file will be used\n        output_metrics: List of output metrics to be calculated\n        config_output_path: Path for the configuration file output. If None, it will be automatically generated\n\n    Returns:\n        Path to the sensitivity_analysis_summary.csv file\n    \"\"\"\n    # Generate Tricys configuration file\n    tricys_config = self.generate_tricys_config(\n        csv_file_path=csv_file_path, output_metrics=output_metrics\n    )\n\n    logger.info(\"Starting Tricys simulation analysis...\")\n\n    try:\n        # Call the Tricys simulation engine\n        from datetime import datetime\n\n        from tricys.simulation.simulation_analysis import run_simulation\n\n        tricys_config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n        run_simulation(tricys_config)\n\n        results_dir = tricys_config[\"paths\"][\"results_dir\"]\n\n        return Path(results_dir) / \"sensitivity_analysis_summary.csv\"\n\n    except Exception as e:\n        logger.error(f\"Tricys simulation execution failed: {e}\")\n        raise\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.run_tricys_simulations","title":"<code>run_tricys_simulations(output_metrics=None)</code>","text":"<p>Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.</p> <p>Parameters:</p> Name Type Description Default <code>output_metrics</code> <code>List[str]</code> <p>List of output metrics to be extracted (for recording but does not affect CSV generation)</p> <code>None</code> <code>max_workers</code> <p>Number of concurrent worker processes (reserved for compatibility, currently unused)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the generated CSV file</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_tricys_simulations(self, output_metrics: List[str] = None) -&gt; str:\n    \"\"\"\n    Generate sampling parameters and output them as a CSV file, which can be subsequently read by the Tricys simulation engine.\n\n    Args:\n        output_metrics: List of output metrics to be extracted (for recording but does not affect CSV generation)\n        max_workers: Number of concurrent worker processes (reserved for compatibility, currently unused)\n\n    Returns:\n        Path to the generated CSV file\n    \"\"\"\n    if self.parameter_samples is None:\n        raise ValueError(\n            \"You must first call generate_samples() to generate samples.\"\n        )\n\n    if output_metrics is None:\n        output_metrics = [\n            \"Startup_Inventory\",\n            \"Self_Sufficiency_Time\",\n            \"Doubling_Time\",\n        ]\n\n    logger.info(\"Target output metrics\", extra={\"output_metrics\": output_metrics})\n\n    sampled_param_names = self.problem[\"names\"]\n\n    base_params = self.base_config.get(\"simulation_parameters\", {}).copy()\n    csv_output_path = (\n        Path(self.base_config.get(\"paths\", {}).get(\"temp_dir\"))\n        / \"salib_sampling.csv\"\n    )\n\n    os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n\n    param_data = []\n    for i, sample in enumerate(self.parameter_samples):\n        sampled_params = {\n            sampled_param_names[j]: sample[j]\n            for j in range(len(sampled_param_names))\n        }\n\n        job_params = base_params.copy()\n        job_params.update(sampled_params)\n\n        param_data.append(job_params)\n\n    df = pd.DataFrame(param_data)\n\n    for col in df.columns:\n        if df[col].dtype in [\"float64\", \"float32\"]:\n            df[col] = df[col].round(5)\n\n    df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n\n    logger.info(\n        \"Successfully generated parameter samples\",\n        extra={\"num_samples\": len(param_data)},\n    )\n    logger.info(\"Parameter file saved\", extra={\"file_path\": csv_output_path})\n    logger.info(\"Parameter file columns\", extra={\"columns\": list(df.columns)})\n    logger.info(\"Parameter precision set to 5 decimal places\")\n    logger.info(\"Sample statistics\", extra={\"statistics\": df.describe().to_dict()})\n\n    self.sampling_csv_path = csv_output_path\n\n    return csv_output_path\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.TricysSALibAnalyzer.save_results","title":"<code>save_results(save_dir=None, format='csv', metric_names=None)</code>","text":"<p>Save sensitivity analysis results</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>str</code> <p>Save directory</p> <code>None</code> <code>format</code> <code>str</code> <p>Save format ('csv</p> <code>'csv'</code> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def save_results(\n    self, save_dir: str = None, format: str = \"csv\", metric_names: List[str] = None\n) -&gt; None:\n    \"\"\"\n    Save sensitivity analysis results\n\n    Args:\n        save_dir: Save directory\n        format: Save format ('csv\n    \"\"\"\n    if save_dir is None:\n        save_dir = \".\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    for method, method_results in self.sensitivity_results.items():\n        if not method_results:\n            continue\n\n        for metric_key, results in method_results.items():\n            output_index = results[\"output_index\"]\n\n            if metric_names and output_index &lt; len(metric_names):\n                metric_display_name = metric_names[output_index]\n            else:\n                metric_display_name = f\"Metric_{output_index}\"\n\n            if format == \"csv\":\n                if method == \"sobol\":\n                    sobol_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"S1\": results[\"S1\"],\n                            \"ST\": results[\"ST\"],\n                            \"S1_conf\": results[\"S1_conf\"],\n                            \"ST_conf\": results[\"ST_conf\"],\n                        }\n                    )\n                    filename = (\n                        f'sobol_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    sobol_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"Sobol results have been saved: {filename}\")\n\n                elif method == \"morris\":\n                    morris_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"mu\": results[\"mu\"],\n                            \"mu_star\": results[\"mu_star\"],\n                            \"sigma\": results[\"sigma\"],\n                            \"mu_star_conf\": results[\"mu_star_conf\"],\n                        }\n                    )\n                    filename = f'morris_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    morris_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"Morris results have been saved: {filename}\")\n\n                elif method == \"fast\":\n                    fast_df = pd.DataFrame(\n                        {\n                            \"Parameter\": self.problem[\"names\"],\n                            \"S1\": results[\"S1\"],\n                            \"ST\": results[\"ST\"],\n                        }\n                    )\n                    filename = (\n                        f'fast_indices_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    fast_df.to_csv(os.path.join(save_dir, filename), index=False)\n                    logger.info(f\"FAST results have been saved: {filename}\")\n\n                elif method == \"latin\":\n                    # Save LHS statistics\n                    lhs_stats_df = pd.DataFrame(\n                        {\n                            \"Metric\": [metric_display_name],\n                            \"Mean\": [results[\"mean\"]],\n                            \"Std\": [results[\"std\"]],\n                            \"Min\": [results[\"min\"]],\n                            \"Max\": [results[\"max\"]],\n                            \"Percentile_5\": [results[\"percentile_5\"]],\n                            \"Percentile_95\": [results[\"percentile_95\"]],\n                        }\n                    )\n                    filename_stats = (\n                        f'lhs_stats_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    )\n                    lhs_stats_df.to_csv(\n                        os.path.join(save_dir, filename_stats), index=False\n                    )\n                    logger.info(f\"LHS\u7edf\u8ba1\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_stats}\")\n\n                    # Remove LHS sensitivity indices saving\n                    # lhs_sens_df = pd.DataFrame({\n                    #     \"Parameter\": self.problem[\"names\"],\n                    #     \"Partial_Correlation\": results[\"partial_correlations\"]\n                    # })\n                    # filename_sens = f'lhs_sensitivity_{metric_display_name.replace(\" \", \"_\")}.csv'\n                    # lhs_sens_df.to_csv(os.path.join(save_dir, filename_sens), index=False)\n                    # logger.info(f\"LHS\u654f\u611f\u6027\u7ed3\u679c\u5df2\u4fdd\u5b58: {filename_sens}\")\n\n    logger.info(f\"The result has been saved to: {save_dir}\")\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.call_llm_for_academic_report","title":"<code>call_llm_for_academic_report(analysis_report, glossary_content, api_key, base_url, ai_model, problem_details, metric_names, method, save_dir)</code>","text":"<p>Sends an analysis report and a glossary to an LLM to generate a professional academic report.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def call_llm_for_academic_report(\n    analysis_report: str,\n    glossary_content: str,\n    api_key: str,\n    base_url: str,\n    ai_model: str,\n    problem_details: dict,\n    metric_names: list,\n    method: str,\n    save_dir: str,\n) -&gt; Tuple[str, str]:\n    \"\"\"Sends an analysis report and a glossary to an LLM to generate a professional academic report.\"\"\"\n    try:\n        logger.info(\"Proceeding with LLM for academic report generation.\")\n\n        param_names_str = \", \".join(\n            [f\"`{name}`\" for name in problem_details.get(\"names\", [])]\n        )\n        metric_names_str = \", \".join([f\"`{name}`\" for name in metric_names])\n\n        all_plots = [f for f in os.listdir(save_dir) if f.endswith((\".svg\", \".png\"))]\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n\n        method_details = {\n            \"sobol\": {\n                \"name\": \"Sobol\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**Sobol\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u65b9\u5dee\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u6280\u672f\uff0c\u80fd\u591f\u91cf\u5316\u5355\u4e2a\u53c2\u6570\u4ee5\u53ca\u53c2\u6570\u95f4\u4ea4\u4e92\u4f5c\u7528\u5bf9\u6a21\u578b\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u548c\u603b\u4f53\u654f\u611f\u6027\uff08ST\uff09\u6700\u9ad8\uff1f\u8bf7\u7ed3\u5408\u56fe\u8868\uff08\u5982\u6761\u5f62\u56fe\uff09\u8fdb\u884c\u89e3\u8bfb\u3002\n        *   S1\u548cST\u6307\u6570\u4e4b\u95f4\u7684\u5dee\u5f02\u63ed\u793a\u4e86\u4ec0\u4e48\uff1f\uff08\u4f8b\u5982\uff0cST\u663e\u8457\u5927\u4e8eS1\u610f\u5473\u7740\u8be5\u53c2\u6570\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u663e\u8457\u7684\u4ea4\u4e92\u4f5c\u7528\u6216\u5176\u5f71\u54cd\u662f\u975e\u7ebf\u6027\u7684\uff09\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n            \"morris\": {\n                \"name\": \"Morris\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**Morris\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8f68\u8ff9\u7684\u201c\u4e00\u6b21\u6027\u201d\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5e38\u7528\u4e8e\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53c2\u6570\u7b5b\u9009\uff0c\u4ee5\u8bc6\u522b\u51fa\u5f71\u54cd\u6700\u5927\u7684\u5c11\u6570\u51e0\u4e2a\u53c2\u6570\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u53c2\u6570\u7684 `\u03bc*` (mu_star) \u503c\u6700\u9ad8\uff0c\u8868\u660e\u5176\u5bf9\u8f93\u51fa\u7684\u603b\u4f53\u5f71\u54cd\u6700\u91cd\u8981\uff1f\n        *   `\u03c3` (sigma) \u503c\u7684\u5927\u5c0f\u53c8\u8bf4\u660e\u4e86\u4ec0\u4e48\uff1f\u8f83\u9ad8\u7684 `\u03c3` \u503c\u901a\u5e38\u8868\u660e\u53c2\u6570\u5177\u6709\u975e\u7ebf\u6027\u6548\u5e94\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\n        *   \u8bf7\u7ed3\u5408 `\u03bc*-\u03c3` \u56fe\u8fdb\u884c\u5206\u6790\uff0c\u5bf9\u53c2\u6570\u8fdb\u884c\u5206\u7c7b\uff08\u4f8b\u5982\uff0c\u9ad8 `\u03bc*`/\u9ad8 `\u03c3` vs. \u9ad8 `\u03bc*`/\u4f4e `\u03c3`\uff09\uff0c\u5e76\u89e3\u91ca\u5176\u542b\u4e49\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n            \"fast\": {\n                \"name\": \"FAST\",\n                \"methodology\": \"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u4f7f\u7528\u4e86**FAST\uff08\u5085\u91cc\u53f6\u5e45\u5ea6\u654f\u611f\u6027\u68c0\u9a8c\uff09\u65b9\u6cd5**\u3002\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u9891\u7387\u7684\u5168\u5c40\u654f\u611f\u6027\u5206\u6790\u6280\u672f\uff0c\u901a\u8fc7\u5c06\u53c2\u6570\u5728\u5085\u91cc\u53f6\u7ea7\u6570\u4e2d\u5c55\u5f00\u6765\u8ba1\u7b97\u654f\u611f\u6027\u6307\u6570\u3002\",\n                \"results_discussion\": \"\"\"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u6700\u9ad8\uff1f\n        *   \uff08\u5982\u679c\u53ef\u7528\uff09\u603b\u4f53\u654f\u611f\u6027\uff08ST\uff09\u4e0e\u4e00\u9636\u654f\u611f\u6027\uff08S1\uff09\u7684\u6bd4\u8f83\u63ed\u793a\u4e86\u4ec0\u4e48\uff1f\u8f83\u5927\u7684\u5dee\u5f02\u901a\u5e38\u8868\u660e\u5b58\u5728\u53c2\u6570\u4ea4\u4e92\u3002\n        *   \u5206\u6790\u4e0d\u540c\u6307\u6807\u4e4b\u95f4\u7684**\u6743\u8861\u5173\u7cfb (Trade-offs)**\u3002\u4f8b\u5982\uff0c\u67d0\u4e2a\u53c2\u6570\u5bf9\u67d0\u4e2a\u6307\u6807 (e.g., `Startup_Inventory`) \u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u53ef\u80fd\u5bf9\u53e6\u4e00\u4e2a\u6307\u6807 (e.g., `Doubling_Time`) \u6709\u8d1f\u9762\u5f71\u54cd\u3002\"\"\",\n            },\n        }\n\n        if method == \"latin\":\n            ACADEMIC_REPORT_PROMPT_WRAPPER = f\"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\uff0c\u64c5\u957f\u8fdb\u884c**\u4e0d\u786e\u5b9a\u6027\u91cf\u5316 (UQ)** \u548c\u98ce\u9669\u8bc4\u4f30\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u57fa\u4e8e**\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837 (LHS)** \u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\n**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u4e13\u4e1a\u8bcd\u6c47\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\uff0c\u805a\u7126\u4e8e**\u4e0d\u786e\u5b9a\u6027**\u7684\u91cf\u5316\u548c\u89e3\u8bfb\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u7edf\u8ba1\u6458\u8981\u3001\u5206\u5e03\u6570\u636e\u7b49\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u4e0d\u786e\u5b9a\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u4e0d\u786e\u5b9a\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u51fa\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u662f {param_names_str}\uff0c\u603b\u7ed3\u8fd9\u4e9b\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u5173\u952e\u6027\u80fd\u6307\u6807 ({metric_names_str}) \u7684\u8f93\u51fa\u5206\u5e03\uff08\u5982\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u7f6e\u4fe1\u533a\u95f4\uff09\u6709\u4f55\u5f71\u54cd\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30\u5f53\u8f93\u5165\u53c2\u6570 {param_names_str} \u5728\u5176\u5b9a\u4e49\u57df\u5185\u53d8\u5316\u65f6\uff0c\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u5173\u952e\u6027\u80fd\u6307\u6807\u7684\u7edf\u8ba1\u5206\u5e03\u548c\u7a33\u5b9a\u6027\u3002\n    *   **\u65b9\u6cd5 (Methodology):** \u7b80\u8981\u8bf4\u660e\u5206\u6790\u65b9\u6cd5\u3002\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\uff08LHS\uff09\u65b9\u6cd5\u6765\u5bf9\u8f93\u5165\u53c2\u6570\u7a7a\u95f4\u8fdb\u884c\u62bd\u6837\u3002\u8bf4\u660e\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u662f {metric_names_str}\uff0c\u4ee5\u53ca\u8f93\u5165\u53c2\u6570\u7684\u6982\u7387\u5206\u5e03\u548c\u8303\u56f4\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u7edf\u8ba1\u6570\u636e\u548c\u60a8\u5d4c\u5165\u7684\u56fe\u8868\uff08\u5982\u76f4\u65b9\u56fe\u3001\u7d2f\u79ef\u5206\u5e03\u56fe\uff09\uff0c\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n        *   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u5176\u8f93\u51fa\u7684**\u6982\u7387\u5206\u5e03**\u662f\u600e\u6837\u7684\uff1f\uff08\u4f8b\u5982\uff0c\u662f\u6b63\u6001\u5206\u5e03\u3001\u504f\u6001\u5206\u5e03\u8fd8\u662f\u53cc\u5cf0\u5206\u5e03\uff1f\uff09\n        *   \u8f93\u51fa\u6307\u6807\u7684**\u4e0d\u786e\u5b9a\u6027\u8303\u56f4**\u6709\u591a\u5927\uff1f\uff08\u53c2\u8003\u6807\u51c6\u5dee\u548c5%-95%\u767e\u5206\u4f4d\u6570\u533a\u95f4\uff09\u3002\u8fd9\u4e2a\u8303\u56f4\u5728\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u662f\u5426\u53ef\u4ee5\u63a5\u53d7\uff1f\n        *   \u662f\u5426\u5b58\u5728\u67d0\u4e9b\u6307\u6807\u7684\u6ce2\u52a8\u8303\u56f4\u8fc7\u5927\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u6027\u80fd\u4f4e\u4e8e\u8bbe\u8ba1\u8981\u6c42\u6216\u5b58\u5728\u8fd0\u884c\u98ce\u9669\uff1f\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff08\u4f8b\u5982\uff0c\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u3001\u8f93\u51fa\u6307\u6807\u7684\u53ef\u9760\u6027\u7b49\uff09\uff0c\u5e76\u5bf9\u964d\u4f4e\u5173\u952e\u6307\u6807\u4e0d\u786e\u5b9a\u6027\u6216\u672a\u6765\u7684\u98ce\u9669\u8bc4\u4f30\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n        else:\n            selected_method = method_details.get(method)\n            if not selected_method:\n                # Fallback for unknown methods\n                selected_method = {\n                    \"name\": method.capitalize(),\n                    \"methodology\": f\"\u6307\u51fa\u672c\u6b21\u5206\u6790\u91c7\u7528\u4e86SALib\u5e93\uff0c\u5e76\u63d0\u53ca\u5177\u4f53\u7684\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\u4e3a**{method.capitalize()}**\u3002\",\n                    \"results_discussion\": \"*   \u5bf9\u4e8e\u6bcf\u4e2a\u6027\u80fd\u6307\u6807\uff0c\u8bc6\u522b\u51fa\u6700\u91cd\u8981\u7684\u8f93\u5165\u53c2\u6570\u3002\\n*   \u8ba8\u8bba\u8fd9\u4e9b\u53d1\u73b0\u7684\u610f\u4e49\u3002\",\n                }\n\n            ACADEMIC_REPORT_PROMPT_WRAPPER = f\"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e**SALib {selected_method['name']} \u65b9\u6cd5\u654f\u611f\u6027\u5206\u6790**\u7684\u7a0b\u5e8f\u751f\u6210\u7684\u521d\u6b65\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\n**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `Startup_Inventory`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u654f\u611f\u6027\u6307\u6570\u8868\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u9879**\u654f\u611f\u6027\u5206\u6790**\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21\u654f\u611f\u6027\u7814\u7a76\u7684\u76ee\u7684\uff0c\u660e\u786e\u6307\u660e\u5206\u6790\u7684\u8f93\u5165\u53c2\u6570\u662f {param_names_str}\uff0c\u603b\u7ed3\u54ea\u4e9b\u53c2\u6570\u5bf9\u5173\u952e\u6027\u80fd\u6307\u6807 ({metric_names_str}) \u5f71\u54cd\u6700\u663e\u8457\uff0c\u5e76\u9648\u8ff0\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0\u8fdb\u884c\u8fd9\u9879\u654f\u611f\u6027\u5206\u6790\u7684\u80cc\u666f\u548c\u91cd\u8981\u6027\u3002\u9610\u8ff0\u7814\u7a76\u76ee\u6807\uff0c\u5373\u91cf\u5316\u8bc4\u4f30\u8f93\u5165\u53c2\u6570\u7684\u53d8\u5316\u5bf9\u6c1a\u71c3\u6599\u5faa\u73af\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\n    *   **\u65b9\u6cd5 (Methodology):** {selected_method['methodology']} \u8bf4\u660e\u88ab\u8bc4\u4f30\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u662f {metric_names_str}\uff0c\u4ee5\u53ca\u8f93\u5165\u53c2\u6570 {param_names_str} \u7684\u53d8\u5316\u8303\u56f4\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u8bf7\u7ed3\u5408\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u548c\u60a8\u5d4c\u5165\u7684\u56fe\u8868\uff0c\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n{selected_method['results_discussion']}\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u654f\u611f\u6027\u5206\u6790\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\uff0c\u5e76\u5bf9\u53cd\u5e94\u5806\u8bbe\u8ba1\u6216\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        full_prompt = f\"{ACADEMIC_REPORT_PROMPT_WRAPPER}\\n\\n---\\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a\\n---\\n{analysis_report}\\n\\n---\\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868\\n---\\n{glossary_content}\"\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending data for academic report to LLM (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_prompt}],\n                    max_tokens=4000,\n                )\n                academic_report = response.choices[0].message.content\n\n                logger.info(\"LLM academic report generation successful.\")\n                return ACADEMIC_REPORT_PROMPT_WRAPPER, academic_report\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling LLM for academic report on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to get LLM academic report after {max_retries} attempts.\"\n                    )\n                    return None, None\n\n    except Exception as e:\n        logger.error(f\"Error in call_llm_for_academic_report: {e}\", exc_info=True)\n        return None, None\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.call_llm_for_salib_analysis","title":"<code>call_llm_for_salib_analysis(report_content, api_key, base_url, ai_model, method)</code>","text":"<p>Sends a SALib analysis report to an LLM for summarization and returns the prompt and summary.</p> Source code in <code>tricys/analysis/salib.py</code> <pre><code>def call_llm_for_salib_analysis(\n    report_content: str, api_key: str, base_url: str, ai_model: str, method: str\n) -&gt; Tuple[str, str]:\n    \"\"\"Sends a SALib analysis report to an LLM for summarization and returns the prompt and summary.\"\"\"\n    try:\n        logger.info(\"Proceeding with LLM analysis for SALib report.\")\n\n        PROMPT_TEMPLATES = {\n            \"sobol\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**Sobol\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684**\u4e00\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1\uff09**\u548c**\u603b\u654f\u611f\u6027\u6307\u6570\uff08ST\uff09**\u6700\u9ad8\u3002\n3.  **\u89e3\u8bfb\u6307\u6570\u542b\u4e49**\uff1a\u89e3\u91caS1\u548cST\u6307\u6570\u7684\u542b\u4e49\u3002\u4f8b\u5982\uff0c\u9ad8S1\u503c\u8868\u793a\u53c2\u6570\u5bf9\u8f93\u51fa\u6709\u91cd\u8981\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u800cST\u4e0eS1\u7684\u663e\u8457\u5dee\u5f02\u8868\u793a\u53c2\u6570\u5b58\u5728\u5f3a\u70c8\u7684\u4ea4\u4e92\u4f5c\u7528\u6216\u975e\u7ebf\u6027\u6548\u5e94\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"morris\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**Morris\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u6839\u636e**\u03bc* (mu_star)**\u503c\u5bf9\u53c2\u6570\u8fdb\u884c\u6392\u5e8f\uff0c\u8bc6\u522b\u51fa\u5bf9\u6a21\u578b\u8f93\u51fa\u5f71\u54cd\u6700\u5927\u7684\u53c2\u6570\u3002\n3.  **\u89e3\u8bfb\u53c2\u6570\u6548\u5e94**\uff1a\u89e3\u91ca**\u03bc***\u548c**\u03c3 (sigma)**\u7684\u542b\u4e49\u3002\u9ad8\u03bc*\u8868\u793a\u53c2\u6570\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9ad8\u03c3\u8868\u793a\u53c2\u6570\u5b58\u5728\u975e\u7ebf\u6027\u5f71\u54cd\u6216\u4e0e\u5176\u4ed6\u53c2\u6570\u6709\u4ea4\u4e92\u4f5c\u7528\u3002\u7ed3\u5408\u03bc*-\u03c3\u56fe\u8fdb\u884c\u5206\u6790\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"fast\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684**FAST\u654f\u611f\u6027\u5206\u6790**\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u603b\u7ed3\u5176\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u7684**\u4e00\u9636\u654f\u611f\u6027\u6307\u6570\uff08S1\uff09**\u548c**\u603b\u654f\u611f\u6027\u6307\u6570\uff08ST\uff09**\u6700\u9ad8\u3002\n3.  **\u89e3\u8bfb\u6307\u6570\u542b\u4e49**\uff1a\u89e3\u91caS1\u548cST\u6307\u6570\u7684\u542b\u4e49\u3002\u9ad8S1\u503c\u8868\u793a\u53c2\u6570\u5bf9\u8f93\u51fa\u6709\u91cd\u8981\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u800cST\u4e0eS1\u7684\u5dee\u5f02\u8868\u793a\u53c2\u6570\u53ef\u80fd\u5b58\u5728\u4ea4\u4e92\u4f5c\u7528\u3002\n4.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n            \"latin\": \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u7edf\u8ba1\u5b66\u548c\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\uff08LHS\uff09\u751f\u6210\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u89e3\u8bfb\u7edf\u8ba1\u6570\u636e**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u7b49\uff09\uff0c\u89e3\u8bfb\u5176\u5747\u503c\u3001\u6807\u51c6\u5dee\u3001\u6700\u5927/\u6700\u5c0f\u503c\u548c\u767e\u5206\u4f4d\u6570\u3002\n2.  **\u8bc4\u4f30\u4e0d\u786e\u5b9a\u6027**\uff1a\u57fa\u4e8e\u6807\u51c6\u5dee\u548c5%/95%\u767e\u5206\u4f4d\u6570\u7684\u8303\u56f4\uff0c\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u6ce2\u52a8\u8303\u56f4\u6709\u591a\u5927\u3002\n3.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u603b\u7ed3\u5728\u7ed9\u5b9a\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u4e0b\uff0c\u6a21\u578b\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPIs\uff09\u8868\u73b0\u5982\u4f55\uff0c\u662f\u5426\u5b58\u5728\u8f83\u5927\u7684\u98ce\u9669\uff08\u4f8b\u5982\uff0c\u8f93\u51fa\u503c\u6ce2\u52a8\u8303\u56f4\u8fc7\u5927\uff09\uff0c\u5e76\u5bf9\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u7ed9\u51fa\u8bc4\u4ef7\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u805a\u7126\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\u548c\u89e3\u8bfb\uff0c\u800c\u4e0d\u662f\u53c2\u6570\u7684\u654f\u611f\u6027\u6392\u5e8f\u3002\n\"\"\",\n        }\n\n        wrapper_prompt = PROMPT_TEMPLATES.get(\n            method,\n            \"\"\"**\u89d2\u8272\uff1a** \u4f60\u662f\u4e00\u540d\u5728\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\u5177\u6709\u6df1\u539a\u80cc\u666f\u7684\u654f\u611f\u6027\u5206\u6790\u4e13\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u8bf7\u4ed4\u7ec6\u5ba1\u67e5\u5e76\u89e3\u8bfb\u4ee5\u4e0b\u8fd9\u4efd\u7531SALib\u5e93\u751f\u6210\u7684\u654f\u611f\u6027\u5206\u6790\u62a5\u544a\u3002\u4f60\u7684\u76ee\u6807\u662f\uff1a\n1.  **\u603b\u7ed3\u6838\u5fc3\u53d1\u73b0**\uff1a\u7b80\u660e\u627c\u8981\u5730\u603b\u7ed3\u62a5\u544a\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u3002\n2.  **\u8bc6\u522b\u5173\u952e\u53c2\u6570**\uff1a\u5bf9\u4e8e\u62a5\u544a\u4e2d\u63d0\u5230\u7684\u6bcf\u4e00\u4e2a\u8f93\u51fa\u6307\u6807\uff08\u5982\u201c\u542f\u52a8\u6c1a\u91cf\u201d\u3001\u201c\u500d\u589e\u65f6\u95f4\u201d\u7b49\uff09\uff0c\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u8f93\u5165\u53c2\u6570\u5bf9\u5b83\u7684\u5f71\u54cd\u6700\u5927\uff08\u5373\u6700\u654f\u611f\uff09\u3002\n3.  **\u63d0\u4f9b\u7efc\u5408\u7ed3\u8bba**\uff1a\u57fa\u4e8e\u6240\u6709\u5206\u6790\u7ed3\u679c\uff0c\u5bf9\u6a21\u578b\u7684\u6574\u4f53\u884c\u4e3a\u3001\u53c2\u6570\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff08\u5982\u679c\u53ef\u80fd\uff09\u4ee5\u53ca\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u5de5\u7a0b\u5b9e\u8df5\u7684\u6f5c\u5728\u542f\u793a\uff0c\u7ed9\u51fa\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u7ed3\u8bba\u3002\n\n\u8bf7\u786e\u4fdd\u4f60\u7684\u5206\u6790\u6e05\u6670\u3001\u4e13\u4e1a\uff0c\u5e76\u76f4\u63a5\u5207\u5165\u8981\u70b9\u3002\n\"\"\",\n        )\n\n        full_prompt = f\"{wrapper_prompt}\\n\\n---\\n**\u5206\u6790\u62a5\u544a\u539f\u6587\uff1a**\\n\\n{report_content}\"\n\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending SALib report to LLM (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_prompt}],\n                    max_tokens=4000,\n                )\n                llm_summary = response.choices[0].message.content\n\n                logger.info(\"LLM analysis successful for SALib report.\")\n                return wrapper_prompt, llm_summary  # Return wrapper prompt and summary\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling LLM for SALib report on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to get LLM summary for SALib report after {max_retries} attempts.\"\n                    )\n                    return None, None  # Return None on failure\n\n    except Exception as e:\n        logger.error(f\"Error in call_llm_for_salib_analysis: {e}\", exc_info=True)\n        return None, None\n</code></pre>"},{"location":"reference/#tricys.analysis.salib.run_salib_analysis","title":"<code>run_salib_analysis(config)</code>","text":"<p>Orchestrates the SALib sensitivity analysis workflow.</p> <p>This function extracts the necessary configuration, defines the problem space for SALib, and then runs the analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>The main configuration dictionary.</p> required Source code in <code>tricys/analysis/salib.py</code> <pre><code>def run_salib_analysis(config: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Orchestrates the SALib sensitivity analysis workflow.\n\n    This function extracts the necessary configuration, defines the problem\n    space for SALib, and then runs the analysis.\n\n    Args:\n        config: The main configuration dictionary.\n    \"\"\"\n    # 1. Extract sensitivity analysis configuration\n    sa_config = config.get(\"sensitivity_analysis\")\n    if not sa_config or not sa_config.get(\"enabled\"):\n        logger.info(\"Sensitivity analysis is not enabled in the configuration file.\")\n        return\n\n    # 2. Create analyzer\n    analyzer = TricysSALibAnalyzer(config)\n\n    # 3. Define the problem space from configuration\n    analysis_case = sa_config.get(\"analysis_case\", {})\n    param_names = analysis_case.get(\"independent_variable\")\n    sampling_details = analysis_case.get(\"independent_variable_sampling\")\n\n    if not isinstance(param_names, list):\n        raise ValueError(\"'independent_variable' must be a list of parameter names.\")\n    if not isinstance(sampling_details, dict):\n        raise ValueError(\n            \"'independent_variable_sampling' must be an object with parameter details.\"\n        )\n\n    param_bounds = {\n        name: sampling_details[name][\"bounds\"]\n        for name in param_names\n        if name in sampling_details\n    }\n    param_dists = {\n        name: sampling_details[name].get(\"distribution\", \"unif\")\n        for name in param_names\n        if name in sampling_details\n    }\n\n    if len(param_bounds) != len(param_names):\n        raise ValueError(\n            \"The keys of 'independent_variable' and 'independent_variable_sampling' do not match\"\n        )\n\n    problem = analyzer.define_problem(param_bounds, param_dists)\n    logger.info(\n        f\"\\n\ud83d\udd0d The problem space with {problem['num_vars']} parameters was defined from the configuration file\"\n    )\n\n    # 4. Generate samples from configuration\n    analyzer_config = analysis_case.get(\"analyzer\", {})\n    enabled_method_name = analyzer_config.get(\"method\")\n    if not enabled_method_name:\n        raise ValueError(\n            \"No method found in 'sensitivity_analysis.analysis_case.analyzer'\"\n        )\n\n    N = analyzer_config.get(\"sample_N\", 1024)\n\n    sample_kwargs = {}\n\n    samples = analyzer.generate_samples(\n        method=enabled_method_name, N=N, **sample_kwargs\n    )\n    logger.info(f\"\u2713 Generated {len(samples)} parameter samples\")\n\n    # 5. Run Tricys simulation\n    output_metrics = analysis_case.get(\"dependent_variables\", [])\n\n    csv_file_path = analyzer.run_tricys_simulations(output_metrics=output_metrics)\n    logger.info(f\"\u2713 Parameter file has been generated: {csv_file_path}\")\n\n    summary_file = None\n    try:\n        logger.info(\"\\nAttempting to run Tricys analysis directly...\")\n        summary_file = analyzer.run_tricys_analysis(\n            csv_file_path=csv_file_path, output_metrics=output_metrics\n        )\n        if summary_file:\n            logger.info(f\"\u2713 Tricys analysis completed, result file: {summary_file}\")\n        else:\n            logger.info(\"\u26a0\ufe0f  Tricys analysis result file not found\")\n            return\n    except Exception as e:\n        logger.info(f\"\u26a0\ufe0f  Tricys analysis failed: {e}\")\n        logger.info(\"Please check if the model path and configuration are correct\")\n        return\n\n    # 6. Run SALib analysis from Tricys results\n    try:\n        logger.info(\"\\nRunning SALib analysis from Tricys results...\")\n        all_results = analyzer.run_salib_analysis_from_tricys_results(\n            sensitivity_summary_csv=summary_file,\n            param_bounds=param_bounds,\n            output_metrics=output_metrics,\n            methods=[enabled_method_name],\n            save_dir=os.path.dirname(summary_file),\n        )\n\n        logger.info(f\"\\n\u2705 SALib {enabled_method_name.upper()} analysis completed!\")\n        logger.info(\n            f\"\ud83d\udcc1 The results have been saved to: {os.path.join(os.path.dirname(summary_file), f'salib_analysis_{enabled_method_name}')}\"\n        )\n\n        logger.info(\"\\n\ud83d\udcc8 Brief results:\")\n        for metric_name, metric_results in all_results.items():\n            logger.info(f\"\\n--- {metric_name} ---\")\n            if enabled_method_name in metric_results:\n                result_data = metric_results[enabled_method_name]\n                if enabled_method_name == \"sobol\":\n                    logger.info(\"\ud83d\udd25 Most sensitive parameters (Sobol ST):\")\n                    st_values = list(zip(analyzer.problem[\"names\"], result_data[\"ST\"]))\n                    st_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, st in st_values[:3]:\n                        logger.info(f\"   {param}: {st:.4f}\")\n                elif enabled_method_name == \"morris\":\n                    logger.info(\"\ud83d\udcca Most Sensitive Parameter (Morris \u03bc*):\")\n                    mu_star_values = list(\n                        zip(analyzer.problem[\"names\"], result_data[\"mu_star\"])\n                    )\n                    mu_star_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, mu_star in mu_star_values[:3]:\n                        logger.info(f\"   {param}: {mu_star:.4f}\")\n                elif enabled_method_name == \"fast\":\n                    logger.info(\"\u26a1 Most Sensitive Parameter (Morris \u03bc*):\")\n                    st_values = list(zip(analyzer.problem[\"names\"], result_data[\"ST\"]))\n                    st_values.sort(key=lambda x: x[1], reverse=True)\n                    for param, st in st_values[:3]:\n                        logger.info(f\"   {param}: {st:.4f}\")\n\n        return analyzer, all_results\n\n    except Exception as e:\n        logger.error(f\"SALib analysis failed: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"reference/#post-processing","title":"\u540e\u5904\u7406\u6a21\u5757 (Post-processing)","text":""},{"location":"reference/#tricyspostprocessbaseline_analysis","title":"<code>tricys.postprocess.baseline_analysis</code>","text":"<p>This module provides functions for plotting simulation results.</p>"},{"location":"reference/#tricys.postprocess.baseline_analysis.baseline_analysis","title":"<code>baseline_analysis(results_df, output_dir, **kwargs)</code>","text":"<p>Generates two plots: 1. A time-series plot with an overall view and a detailed zoom. 2. A bar chart showing the final values of all variables, sorted. 3. An optional Markdown report with AI analysis.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>The combined DataFrame of simulation results.</p> required <code>output_dir</code> <code>str</code> <p>The directory to save the plots and report.</p> required <code>**kwargs</code> <p>Additional parameters from the config, including an 'ai' flag for analysis.</p> <code>{}</code> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def baseline_analysis(results_df: pd.DataFrame, output_dir: str, **kwargs) -&gt; None:\n    \"\"\"\n    Generates two plots:\n    1. A time-series plot with an overall view and a detailed zoom.\n    2. A bar chart showing the final values of all variables, sorted.\n    3. An optional Markdown report with AI analysis.\n\n    Args:\n        results_df (pd.DataFrame): The combined DataFrame of simulation results.\n        output_dir (str): The directory to save the plots and report.\n        **kwargs: Additional parameters from the config, including an 'ai' flag for analysis.\n    \"\"\"\n    if \"time\" not in results_df.columns:\n        logger.error(\"Plotting failed: 'time' column not found in results DataFrame.\")\n        return\n\n    if \"glossary_path\" in kwargs:\n        load_glossary(kwargs[\"glossary_path\"])\n\n    df = results_df.copy()\n    # Remove duplicate rows before processing\n    df.drop_duplicates(inplace=True)\n    df.reset_index(drop=True, inplace=True)\n\n    # Create a unified color map for all variables\n    all_plot_columns = sorted([col for col in df.columns if col != \"time\"])\n    colors = sns.color_palette(\"turbo\", len(all_plot_columns))\n    color_map = dict(zip(all_plot_columns, colors))\n\n    # Add the color map to kwargs to pass it to the helper functions\n    plot_kwargs = kwargs.copy()\n    plot_kwargs[\"color_map\"] = color_map\n\n    # Generate the time-series plot with zoom\n    _plot_time_series_with_zoom(df, output_dir, **plot_kwargs)\n\n    # Generate the bar chart of final values\n    _plot_final_values_bar_chart(df, output_dir, **plot_kwargs)\n\n    # --- Report Generation and AI Analysis ---\n    base_report_path, base_report_content = _generate_postprocess_report(\n        df, output_dir, **kwargs\n    )\n\n    if base_report_path and kwargs.get(\"ai\", False):\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        # Prioritize AI_MODELS, fallback to AI_MODEL\n        ai_models_str = os.environ.get(\"AI_MODELS\")\n        if not ai_models_str:\n            ai_models_str = os.environ.get(\"AI_MODEL\")\n\n        if not api_key or not base_url or not ai_models_str:\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODELS/AI_MODEL not found in environment variables. Skipping LLM analysis.\"\n            )\n            return\n\n        ai_models = [model.strip() for model in ai_models_str.split(\",\")]\n\n        for ai_model in ai_models:\n            logger.info(f\"Generating AI analysis for model: {ai_model}\")\n\n            sanitized_model_name = \"\".join(\n                c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n            ).rstrip()\n\n            model_report_filename = (\n                f\"baseline_condition_analysis_report_{sanitized_model_name}.md\"\n            )\n            model_report_path = os.path.join(output_dir, model_report_filename)\n\n            with open(model_report_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(base_report_content)\n\n            llm_analysis = _call_openai_for_postprocess_analysis(\n                api_key=api_key,\n                base_url=base_url,\n                ai_model=ai_model,\n                report_content=base_report_content,\n                **kwargs,\n            )\n\n            if llm_analysis:\n                with open(model_report_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(f\"\\n\\n---\\n\\n# AI\u6a21\u578b\u5206\u6790\u63d0\u793a\u8bcd ({ai_model})\\n\\n\")\n                    f.write(\"```markdown\\n\")\n                    f.write(llm_analysis)\n                    f.write(\"\\n```\\n\")\n                logger.info(\n                    f\"Appended LLM analysis for model {ai_model} to {model_report_path}\"\n                )\n\n                # --- ADDED: Second AI call for academic summary ---\n                academic_kwargs = kwargs.copy()\n                academic_kwargs[\"report_filename\"] = model_report_filename\n                generate_academic_report(\n                    output_dir, ai_model=ai_model, **academic_kwargs\n                )\n</code></pre>"},{"location":"reference/#tricys.postprocess.baseline_analysis.generate_academic_report","title":"<code>generate_academic_report(output_dir, ai_model, **kwargs)</code>","text":"<p>Generates a professional academic analysis summary by sending the existing report and a glossary of terms to an LLM.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def generate_academic_report(output_dir: str, ai_model: str, **kwargs) -&gt; None:\n    \"\"\"\n    Generates a professional academic analysis summary by sending the existing report\n    and a glossary of terms to an LLM.\n    \"\"\"\n    try:\n        logger.info(\n            f\"Starting generation of the academic analysis summary for model {ai_model}.\"\n        )\n\n        # 1. Read the existing report\n        report_filename = kwargs.get(\n            \"report_filename\", \"baseline_condition_analysis_report.md\"\n        )\n        report_path = os.path.join(output_dir, report_filename)\n        if not os.path.exists(report_path):\n            logger.error(\n                f\"Cannot generate academic summary: Original report '{report_path}' not found.\"\n            )\n            return\n        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n            original_report_content = f.read()\n\n        # 2. Read the glossary\n        glossary_path = kwargs.get(\"glossary_path\", \"sheets.csv\")\n        if not os.path.exists(glossary_path):\n            logger.error(\n                f\"Cannot generate academic summary: Glossary file '{glossary_path}' not found.\"\n            )\n            return\n        with open(glossary_path, \"r\", encoding=\"utf-8\") as f:\n            glossary_content = f.read()\n\n        # 3. Check for API credentials\n        load_dotenv()\n        api_key = os.environ.get(\"API_KEY\")\n        base_url = os.environ.get(\"BASE_URL\")\n\n        if not all([api_key, base_url, ai_model]):\n            logger.warning(\n                \"API_KEY, BASE_URL, or AI_MODEL not found. Skipping academic summary generation.\"\n            )\n            return\n\n        # 4. Construct the prompt\n        role_prompt = \"\"\"**\u89d2\u8272\uff1a** \u60a8\u662f\u4e00\u4f4d\u5728\u6838\u805a\u53d8\u5de5\u7a0b\uff0c\u7279\u522b\u662f\u6c1a\u71c3\u6599\u5faa\u73af\u9886\u57df\uff0c\u5177\u6709\u6df1\u539a\u5b66\u672f\u80cc\u666f\u7684\u8d44\u6df1\u79d1\u5b66\u5bb6\u3002\n\n**\u4efb\u52a1\uff1a** \u60a8\u6536\u5230\u4e86\u7531\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7684\u521d\u6b65\u5206\u6790\u62a5\u544a\u548c\u4e00\u4efd\u4e13\u4e1a\u672f\u8bed\u8868\u3002\u8bf7\u60a8\u57fa\u4e8e\u8fd9\u4e24\u4efd\u6587\u4ef6\uff0c\u64b0\u5199\u4e00\u4efd\u66f4\u52a0\u4e13\u4e1a\u3001\u6b63\u5f0f\u3001\u7b26\u5408\u5b66\u672f\u53d1\u8868\u6807\u51c6\u7684\u6df1\u5ea6\u5206\u6790\u603b\u7ed3\u62a5\u544a\u3002\n\"\"\"\n\n        # Find all plots to instruct the LLM to include them\n        all_plots = [f for f in os.listdir(output_dir) if f.endswith((\".svg\", \".png\"))]\n        plot_list_str = \"\\n\".join([f\"    *   `{plot}`\" for plot in all_plots])\n        instructions_prompt = f\"\"\"**\u6307\u4ee4\uff1a**\n\n1.  **\u4e13\u4e1a\u5316\u8bed\u8a00\uff1a** \u5c06\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6a21\u578b\u53c2\u6570/\u7f29\u5199\uff08\u4f8b\u5982 `sds.I[1]`, `detailed_var`\uff09\u66ff\u6362\u4e3a\u672f\u8bed\u8868\u4e2d\u5bf9\u5e94\u7684\u201c\u4e2d\u6587\u7ffb\u8bd1\u201d\u6216\u201c\u82f1\u6587\u672f\u8bed\u201d\u3002\u4f8b\u5982\uff0c\u5e94\u5c06\u201c`sds`\u7684\u5e93\u5b58\u201d\u8868\u8ff0\u4e3a\u201c\u50a8\u5b58\u4e0e\u8f93\u9001\u7cfb\u7edf (SDS) \u7684\u6c1a\u5e93\u5b58\u91cf (Tritium Inventory)\u201d\u3002\n2.  **\u5b66\u672f\u5316\u91cd\u8ff0\uff1a** \u7528\u4e25\u8c28\u3001\u5ba2\u89c2\u7684\u5b66\u672f\u8bed\u8a00\u91cd\u65b0\u7ec4\u7ec7\u548c\u9610\u8ff0\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u53d1\u73b0\u3002\u907f\u514d\u4f7f\u7528\u201c\u770b\u8d77\u6765\u201d\u3001\u201c\u597d\u50cf\u201d\u7b49\u6a21\u7cca\u8bcd\u6c47\u3002\n3.  **\u56fe\u8868\u548c\u8868\u683c\u7684\u5448\u73b0\u4e0e\u5f15\u7528\uff1a**\n    *   **\u663e\u793a\u56fe\u8868\uff1a** \u5728\u62a5\u544a\u7684\u201c\u7ed3\u679c\u4e0e\u8ba8\u8bba\u201d\u90e8\u5206\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u8bed\u6cd5 `![\u56fe\u8868\u6807\u9898](\u56fe\u8868\u6587\u4ef6\u540d)` \u6765**\u76f4\u63a5\u5d4c\u5165**\u548c\u663e\u793a\u521d\u6b65\u62a5\u544a\u4e2d\u5305\u542b\u7684\u6240\u6709\u56fe\u8868\u3002\u53ef\u7528\u7684\u56fe\u8868\u6587\u4ef6\u5982\u4e0b\uff1a\n{plot_list_str}\n    *   **\u5f15\u7528\u56fe\u8868\uff1a** \u5728\u6b63\u6587\u4e2d\u5206\u6790\u548c\u8ba8\u8bba\u56fe\u8868\u5185\u5bb9\u65f6\uff0c\u8bf7\u4f7f\u7528\u201c\u5982\u56fe1\u6240\u793a...\u201d\u7b49\u65b9\u5f0f\u5bf9\u56fe\u8868\u8fdb\u884c\u7f16\u53f7\u548c\u6587\u5b57\u5f15\u7528\u3002\n    *   **\u663e\u793a\u8868\u683c\uff1a** \u5f53\u5448\u73b0\u6570\u636e\u65f6\uff08\u4f8b\u5982\uff0c\u5173\u952e\u9636\u6bb5\u7684\u62bd\u6837\u6570\u636e\u6216\u6700\u7ec8\u503c\uff09\uff0c\u60a8**\u5fc5\u987b**\u4f7f\u7528Markdown\u7684\u7ba1\u9053\u8868\u683c\uff08pipe-table\uff09\u683c\u5f0f\u6765\u6e05\u6670\u5730\u5c55\u793a\u5b83\u4eec\u3002\u60a8\u53ef\u4ee5\u76f4\u63a5\u590d\u7528\u6216\u91cd\u65b0\u683c\u5f0f\u5316\u521d\u6b65\u62a5\u544a\u4e2d\u7684\u6570\u636e\u8868\u683c\u3002\n4.  **\u7ed3\u6784\u5316\u62a5\u544a\uff1a** \u60a8\u7684\u62a5\u544a\u662f\u5173\u4e8e\u4e00\u4e2a**\u57fa\u51c6\u5de5\u51b5\uff08Baseline Operating Condition\uff09**\u7684\u6a21\u62df\u5206\u6790\u3002\u62a5\u544a\u5e94\u5305\u542b\u4ee5\u4e0b\u90e8\u5206\uff1a\n    *   **\u6458\u8981 (Abstract):** \u7b80\u8981\u6982\u62ec\u672c\u6b21**\u57fa\u51c6\u5de5\u51b5**\u6a21\u62df\u7684\u76ee\u7684\u3001\u5173\u952e\u53d1\u73b0\u548c\u6838\u5fc3\u7ed3\u8bba\u3002\n    *   **\u5f15\u8a00 (Introduction):** \u63cf\u8ff0**\u57fa\u51c6\u5de5\u51b5**\u6a21\u62df\u7684\u80cc\u666f\u548c\u76ee\u6807\uff0c\u63d0\u53ca\u5173\u952e\u7684\u8f93\u5165\u53c2\u6570\u3002\n    *   **\u7ed3\u679c\u4e0e\u8ba8\u8bba (Results and Discussion):** \u8fd9\u662f\u62a5\u544a\u7684\u6838\u5fc3\u3002\u5206\u70b9\u8be6\u7ec6\u8bba\u8ff0\uff1a\n        *   \u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u6c1a\u81ea\u6301\u65f6\u95f4\u3001\u500d\u589e\u65f6\u95f4\u7b49\uff0c\u5982\u679c\u6570\u636e\u53ef\u7528\uff09\u7684\u603b\u4f53\u8d8b\u52bf\u3002\n        *   \u5bf9\u5173\u952e\u8f6c\u6298\u70b9\uff08\u4f8b\u5982\u6c1a\u5e93\u5b58\u7684\u6700\u4f4e\u70b9\uff09\u7684\u7269\u7406\u610f\u4e49\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002\n        *   \u8bc4\u4f30\u7cfb\u7edf\u5728\u6a21\u62df\u7ed3\u675f\u65f6\u7684\u6700\u7ec8\u72b6\u6001\uff0c\u5e76\u8ba8\u8bba\u6c1a\u5728\u5404\u5b50\u7cfb\u7edf\u4e2d\u7684\u5206\u5e03\u60c5\u51b5\u3002\n    *   **\u7ed3\u8bba (Conclusion):** \u603b\u7ed3\u672c\u6b21\u6a21\u62df\u7814\u7a76\u5f97\u51fa\u7684\u4e3b\u8981\u5b66\u672f\u7ed3\u8bba\u3002\n5.  **\u8f93\u51fa\u683c\u5f0f\uff1a** \u8bf7\u76f4\u63a5\u8f93\u51fa\u5b8c\u6574\u7684\u5b66\u672f\u5206\u6790\u62a5\u544a\u6b63\u6587\uff0c\u786e\u4fdd\u6240\u6709\u5185\u5bb9\uff08\u5305\u62ec\u56fe\u8868\u548c\u8868\u683c\uff09\u90fd\u9075\u5faa\u6b63\u786e\u7684Markdown\u8bed\u6cd5\u3002\n\n**\u8f93\u5165\u6587\u4ef6\uff1a**\n\"\"\"\n\n        analysis_prompt = f\"\"\"\n---\n### 1. \u521d\u6b65\u5206\u6790\u62a5\u544a (`baseline_condition_analysis_report.md`)\n---\n{original_report_content}\n\n---\n### 2. \u4e13\u4e1a\u672f\u8bed\u8868 (`sheets.csv`)\n---\n{glossary_content}\n\"\"\"\n\n        # 5. Call the API\n        max_retries = 3\n        for attempt in range(max_retries):\n            try:\n                client = openai.OpenAI(api_key=api_key, base_url=base_url)\n                logger.info(\n                    f\"Sending request to OpenAI API for academic summary for model {ai_model} (Attempt {attempt + 1}/{max_retries})...\"\n                )\n\n                full_text_prompt = \"\\n\\n\".join(\n                    [role_prompt, instructions_prompt, analysis_prompt]\n                )\n\n                response = client.chat.completions.create(\n                    model=ai_model,\n                    messages=[{\"role\": \"user\", \"content\": full_text_prompt}],\n                    max_tokens=4000,\n                )\n                academic_summary = response.choices[0].message.content\n\n                # 6. Save the result\n                sanitized_model_name = \"\".join(\n                    c for c in ai_model if c.isalnum() or c in (\"-\", \"_\")\n                ).rstrip()\n                summary_filename = (\n                    f\"academic_analysis_summary_{sanitized_model_name}.md\"\n                )\n                summary_path = os.path.join(output_dir, summary_filename)\n                with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n                    f.write(academic_summary)\n\n                logger.info(\n                    f\"Successfully generated academic analysis summary: {summary_path}\"\n                )\n                return  # Exit after success\n\n            except Exception as e:\n                logger.error(\n                    f\"Error calling OpenAI API for academic summary on attempt {attempt + 1}: {e}\"\n                )\n                if attempt &lt; max_retries - 1:\n                    time.sleep(5)\n                else:\n                    logger.error(\n                        f\"Failed to generate academic summary for {ai_model} after {max_retries} attempts.\"\n                    )\n                    return  # Exit after all retries failed\n\n    except Exception as e:\n        logger.error(\n            f\"Error in generate_academic_report for model {ai_model}: {e}\",\n            exc_info=True,\n        )\n</code></pre>"},{"location":"reference/#tricys.postprocess.baseline_analysis.load_glossary","title":"<code>load_glossary(glossary_path)</code>","text":"<p>Loads glossary data from the specified CSV path into global dictionaries.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def load_glossary(glossary_path: str) -&gt; None:\n    \"\"\"\n    Loads glossary data from the specified CSV path into global dictionaries.\n    \"\"\"\n    global _english_glossary_map, _chinese_glossary_map\n\n    if not glossary_path or not os.path.exists(glossary_path):\n        logger.warning(\n            f\"Glossary file not found at {glossary_path}. No labels will be loaded.\"\n        )\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n        return\n\n    try:\n        df = pd.read_csv(glossary_path)\n        if (\n            \"\u6a21\u578b\u53c2\u6570 (Model Parameter)\" in df.columns\n            and \"\u82f1\u6587\u672f\u8bed (English Term)\" in df.columns\n            and \"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\" in df.columns\n        ):\n            df.dropna(subset=[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"], inplace=True)\n            _english_glossary_map = pd.Series(\n                df[\"\u82f1\u6587\u672f\u8bed (English Term)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            _chinese_glossary_map = pd.Series(\n                df[\"\u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation)\"].values,\n                index=df[\"\u6a21\u578b\u53c2\u6570 (Model Parameter)\"],\n            ).to_dict()\n            logger.info(f\"Successfully loaded glossary from {glossary_path}.\")\n        else:\n            logger.warning(\"Glossary CSV does not contain expected columns.\")\n            _english_glossary_map = {}\n            _chinese_glossary_map = {}\n    except Exception as e:\n        logger.warning(f\"Failed to load or parse glossary file. Error: {e}\")\n        _english_glossary_map = {}\n        _chinese_glossary_map = {}\n</code></pre>"},{"location":"reference/#tricys.postprocess.baseline_analysis.set_plot_language","title":"<code>set_plot_language(lang='en')</code>","text":"<p>Sets the preferred language for plot labels. Args:     lang (str): 'en' for English (default), 'cn' for Chinese.</p> Source code in <code>tricys/postprocess/baseline_analysis.py</code> <pre><code>def set_plot_language(lang: str = \"en\") -&gt; None:\n    \"\"\"\n    Sets the preferred language for plot labels.\n    Args:\n        lang (str): 'en' for English (default), 'cn' for Chinese.\n    \"\"\"\n    global _use_chinese_labels\n    _use_chinese_labels = lang.lower() == \"cn\"\n\n    if _use_chinese_labels:\n        # To display Chinese characters correctly, specify a list of fallback fonts.\n        plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]  # \u66ff\u6362\u6210\u4f60\u7535\u8111\u4e0a\u6709\u7684\u5b57\u4f53\n        plt.rcParams[\"axes.unicode_minus\"] = False  # To display minus sign correctly.\n        plt.rcParams[\"font.family\"] = \"sans-serif\"  # \u786e\u4fdd\u5b57\u4f53\u5bb6\u65cf\u8bbe\u7f6e\u751f\u6548\n    else:\n        # Restore default settings\n        plt.rcParams[\"font.sans-serif\"] = plt.rcParamsDefault[\"font.sans-serif\"]\n        plt.rcParams[\"axes.unicode_minus\"] = plt.rcParamsDefault[\"axes.unicode_minus\"]\n</code></pre>"},{"location":"reference/#tricyspostprocessrise_analysis","title":"<code>tricys.postprocess.rise_analysis</code>","text":""},{"location":"reference/#tricys.postprocess.rise_analysis.analyze_rise_dip","title":"<code>analyze_rise_dip(results_df, output_dir, **kwargs)</code>","text":"<p>Analyzes the combined results of a parameter sweep and reports the curves that fail to exhibit the 'dip and rise' feature.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>The combined DataFrame of simulation results, including time and multiple parameter combinations.</p> required <code>output_dir</code> <code>str</code> <p>The directory to save the analysis report.</p> required <code>**kwargs</code> <p>Additional parameters from the config, e.g., 'output_filename'.</p> <code>{}</code> Source code in <code>tricys/postprocess/rise_analysis.py</code> <pre><code>def analyze_rise_dip(results_df: pd.DataFrame, output_dir: str, **kwargs) -&gt; None:\n    \"\"\"\n    Analyzes the combined results of a parameter sweep and reports the curves\n    that fail to exhibit the 'dip and rise' feature.\n\n    Args:\n        results_df (pd.DataFrame): The combined DataFrame of simulation results, including time and multiple parameter combinations.\n        output_dir (str): The directory to save the analysis report.\n        **kwargs: Additional parameters from the config, e.g., 'output_filename'.\n    \"\"\"\n    logger.info(\"Starting post-processing: Analyzing curve rise/dip features...\")\n    all_curves_info = []\n    error_count = 0\n\n    # Iterate over each column of the DataFrame (except for the 'time' column)\n    for col_name in results_df.columns:\n        if col_name == \"time\":\n            continue\n\n        # Parse parameters from the column name 'variable&amp;param1=v1&amp;param2=v2'\n        try:\n            parts = col_name.split(\"&amp;\")\n            if len(parts) &lt; 2:  # Must have at least one variable name and one parameter\n                logger.warning(\n                    f\"Column name '{col_name}' has an incorrect format, skipping.\"\n                )\n                continue\n\n            # parts[0] is the variable name, parse parameters from parts[1:]\n            param_parts = parts[1:]\n            job_params = dict(item.split(\"=\") for item in param_parts)\n            job_params[\"variable\"] = parts[\n                0\n            ]  # Also add the original variable name to the info\n\n        except (ValueError, IndexError):\n            logger.warning(\n                f\"Could not parse parameters from column name '{col_name}', skipping.\"\n            )\n            continue\n\n        series = results_df[col_name]\n        rises = False\n        if len(series) &gt; 2:\n            # This logic is inspired by `time_of_turning_point` from `tricys/analysis/metric.py`.\n            # It uses a smoothed series to determine if there is a 'dip and rise' trend.\n            window_size = max(1, int(len(series) * 0.001))  # 0.1% smoothing window\n            smoothed = series.rolling(\n                window=window_size, center=True, min_periods=1\n            ).mean()\n\n            min_pos_index = smoothed.idxmin()\n            min_val = smoothed.loc[min_pos_index]\n\n            logger.info(\n                f\"Analyzing curve '{col_name}': min at index {min_pos_index} with value {min_val}\"\n            )\n\n            # Check if the minimum is at the beginning or end of the series\n            is_min_at_boundary = (min_pos_index == smoothed.index[0]) or (\n                min_pos_index == smoothed.index[-1]\n            )\n\n            if not is_min_at_boundary:\n                # Check if it dips from the start and rises to the end.\n                # A small tolerance is used to avoid issues with noise.\n                series_range = smoothed.max() - smoothed.min()\n                # Avoid division by zero or NaN tolerance if series is flat\n                if series_range &gt; 1e-9:\n                    tolerance = series_range * 0.001  # 0.1% of range as tolerance\n                else:\n                    tolerance = 0\n\n                start_val = smoothed.iloc[0]\n                end_val = smoothed.iloc[-1]\n\n                if start_val &gt; min_val + tolerance and end_val &gt; min_val + tolerance:\n                    rises = True\n\n        # Record the analysis result for every curve\n        info = job_params.copy()\n        info[\"rises\"] = bool(rises)\n        all_curves_info.append(info)\n\n        # If the feature is not detected, log it at the ERROR level\n        if not rises:\n            error_count += 1\n            logger.error(\n                f\"Feature not detected: 'Dip and rise' feature was not found for the curve with parameters {job_params}.\"\n            )\n\n    # Generate a report file with all information unconditionally\n    output_filename = kwargs.get(\"output_filename\", \"rise_report.json\")\n    report_path = os.path.join(output_dir, output_filename)\n\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(all_curves_info, f, indent=4, ensure_ascii=False)\n\n    if error_count &gt; 0:\n        logger.info(\n            f\"{error_count} curves did not exhibit the expected feature. See report for details: {report_path}\"\n        )\n    else:\n        logger.info(\n            f\"All curves exhibit the expected 'dip and rise' feature. Report generated at: {report_path}\"\n        )\n</code></pre>"},{"location":"reference/#tricyspostprocessstatic_alarm","title":"<code>tricys.postprocess.static_alarm</code>","text":""},{"location":"reference/#tricys.postprocess.static_alarm.check_thresholds","title":"<code>check_thresholds(results_df, output_dir, rules, **kwargs)</code>","text":"<p>Analyze the simulation results to check if the specified columns fall within the defined threshold range. This function supports both single tasks (column name as 'var') and parameter sweep tasks (column name as 'var&amp;param=value').</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>Merged simulation results DataFrame.</p> required <code>output_dir</code> <code>str</code> <p>Directory for saving alert reports.</p> required <code>rules</code> <code>List[Dict[str, Any]]</code> <p>List of rules, where each rule defines a column and its min/max thresholds.</p> required <code>**kwargs</code> <p>Additional parameters from the configuration, such as 'output_filename'.</p> <code>{}</code> Source code in <code>tricys/postprocess/static_alarm.py</code> <pre><code>def check_thresholds(\n    results_df: pd.DataFrame, output_dir: str, rules: List[Dict[str, Any]], **kwargs\n) -&gt; None:\n    \"\"\"\n    Analyze the simulation results to check if the specified columns fall within the defined threshold range.\n    This function supports both single tasks (column name as 'var') and parameter sweep tasks (column name as 'var&amp;param=value').\n\n    Args:\n        results_df (pd.DataFrame): Merged simulation results DataFrame.\n        output_dir (str): Directory for saving alert reports.\n        rules (List[Dict[str, Any]]): List of rules, where each rule defines a column and its min/max thresholds.\n        **kwargs: Additional parameters from the configuration, such as 'output_filename'.\n    \"\"\"\n    logger.info(\"Starting post-processing: Checking thresholds...\")\n\n    # Use a dictionary to track the alarm status of each checked column\n    checked_columns_status = {}\n\n    for i, rule in enumerate(rules):\n        min_val = rule.get(\"min\")\n        max_val = rule.get(\"max\")\n        columns_to_check = rule.get(\"columns\", [])\n\n        if not columns_to_check:\n            logger.warning(f\"Rule {i+1} does not specify 'columns', skipping.\")\n            continue\n\n        # Iterate over each base column name specified in the rule\n        for base_col_name in columns_to_check:\n            # Iterate over all actual column names in the DataFrame to find matches\n            for df_col_name in results_df.columns:\n                if df_col_name == base_col_name or df_col_name.startswith(\n                    base_col_name + \"&amp;\"\n                ):\n\n                    # Initialize status for this column if it's the first time being checked\n                    if df_col_name not in checked_columns_status:\n                        checked_columns_status[df_col_name] = (\n                            False  # Default to no alarm\n                        )\n\n                    # Check for values exceeding the maximum threshold\n                    if max_val is not None:\n                        exceeded_max = results_df[results_df[df_col_name] &gt; max_val]\n                        if not exceeded_max.empty:\n                            peak_value = exceeded_max[df_col_name].max()\n                            logger.error(\n                                f\"ALARM: Column '{df_col_name}' exceeds maximum threshold (Threshold: {max_val}, Value: {peak_value})\"\n                            )\n                            checked_columns_status[df_col_name] = True\n\n                    # Check for values falling below the minimum threshold\n                    if min_val is not None:\n                        exceeded_min = results_df[results_df[df_col_name] &lt; min_val]\n                        if not exceeded_min.empty:\n                            dip_value = exceeded_min[df_col_name].min()\n                            logger.error(\n                                f\"ALARM: Column '{df_col_name}' is below minimum threshold (Threshold: {min_val}, Value: {dip_value})\"\n                            )\n                            checked_columns_status[df_col_name] = True\n\n    # Convert to the final report format, parsing column names to include parameters\n    final_report = []\n    for col, status in checked_columns_status.items():\n        try:\n            report_item = {}\n            parts = col.split(\"&amp;\")\n\n            # For single runs, the column name may not contain '&amp;'\n            if len(parts) == 1:\n                report_item[\"variable\"] = parts[0]\n            else:\n                variable_name = parts[0]\n                param_parts = parts[1:]\n                report_item = dict(item.split(\"=\") for item in param_parts)\n                report_item[\"variable\"] = variable_name\n\n            report_item[\"has_alarm\"] = status\n            final_report.append(report_item)\n\n        except (ValueError, IndexError):\n            logger.warning(\n                f\"Could not parse column name '{col}' for the report, using the original name as a fallback.\"\n            )\n            # Fallback to the old format if parsing fails\n            final_report.append({\"column\": col, \"has_alarm\": status})\n\n    output_filename = kwargs.get(\"output_filename\", \"alarm_report.json\")\n    report_path = os.path.join(output_dir, output_filename)\n    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(final_report, f, indent=4, ensure_ascii=False)\n\n    total_alarms = sum(1 for entry in final_report if entry[\"has_alarm\"])\n    if total_alarms &gt; 0:\n        logger.info(\n            f\"{total_alarms} columns with alarms were found. See logs for details. Report generated at: {report_path}\"\n        )\n    else:\n        logger.info(\n            f\"Threshold check complete. All checked columns are within their thresholds. Report generated at: {report_path}\"\n        )\n</code></pre>"},{"location":"reference/#co-simulation-handlers","title":"\u534f\u4eff\u771f\u5904\u7406\u5668 (Co-simulation Handlers)","text":""},{"location":"reference/#tricyshandlersdiv_handler","title":"<code>tricys.handlers.div_handler</code>","text":""},{"location":"reference/#tricys.handlers.div_handler.run_div_simulation","title":"<code>run_div_simulation(temp_input_csv, temp_output_csv, **kwargs)</code>","text":"<p>Runs a simulation based on fake divertor data.</p> <p>Reads data from a source CSV, selects specific columns, and writes them to a temporary output CSV.</p> <p>Parameters:</p> Name Type Description Default <code>temp_input_csv</code> <code>str</code> <p>Path to the temporary input CSV file (unused).</p> required <code>temp_output_csv</code> <code>str</code> <p>Path to the temporary output CSV file.</p> required <code>**kwargs</code> <p>Additional keyword arguments (unused).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A placeholder dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the source CSV file cannot be found.</p> <code>ValueError</code> <p>If the source CSV is missing required columns.</p> Source code in <code>tricys/handlers/div_handler.py</code> <pre><code>def run_div_simulation(temp_input_csv, temp_output_csv, **kwargs):\n    \"\"\"\n    Runs a simulation based on fake divertor data.\n\n    Reads data from a source CSV, selects specific columns, and writes them\n    to a temporary output CSV.\n\n    Args:\n        temp_input_csv (str): Path to the temporary input CSV file (unused).\n        temp_output_csv (str): Path to the temporary output CSV file.\n        **kwargs: Additional keyword arguments (unused).\n\n    Returns:\n        dict: A placeholder dictionary.\n\n    Raises:\n        FileNotFoundError: If the source CSV file cannot be found.\n        ValueError: If the source CSV is missing required columns.\n    \"\"\"\n    handler_dir = os.path.dirname(__file__)\n    source_csv_path = os.path.join(handler_dir, \"div_handler.csv\")\n\n    try:\n        source_df = pd.read_csv(source_csv_path)\n    except FileNotFoundError:\n        pd.DataFrame({\"time\": []}).to_csv(temp_output_csv, index=False)\n        raise\n\n    columns_to_select = [\n        \"time\",\n        \"div.to_CL[1]\",\n        \"div.to_CL[2]\",\n        \"div.to_CL[3]\",\n        \"div.to_CL[4]\",\n        \"div.to_CL[5]\",\n    ]\n\n    if not all(col in source_df.columns for col in columns_to_select):\n        missing_cols = [\n            col for col in columns_to_select if col not in source_df.columns\n        ]\n        raise ValueError(\n            f\"The source file {source_csv_path} is missing required columns: \"\n            f\"{missing_cols}\"\n        )\n\n    output_df = source_df[columns_to_select].copy()\n\n    output_df.to_csv(temp_output_csv, index=False)\n\n    output_placeholder = {\"to_CL\": \"{1,2,3,4,5,6}\"}\n\n    return output_placeholder\n</code></pre>"},{"location":"reference/#tricyshandlersi_iss_handler","title":"<code>tricys.handlers.i_iss_handler</code>","text":""},{"location":"reference/#tricys.handlers.i_iss_handler.AspenEnhanced","title":"<code>AspenEnhanced</code>","text":"<p>A helper class to encapsulate interactions with an Aspen Plus COM server.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>class AspenEnhanced:\n    \"\"\"\n    A helper class to encapsulate interactions with an Aspen Plus COM server.\n    \"\"\"\n\n    def __init__(self, bkp_path) -&gt; None:\n        \"\"\"\u521d\u59cb\u5316Aspen\u8fde\u63a5\u5e76\u5b9a\u4e49\u6469\u5c14\u8d28\u91cf\"\"\"\n        logger.info(\"Dispatching Aspen COM object...\")\n        self.aspen = win32.Dispatch(\"Apwn.Document.40.0\")  # Adjust version if necessary\n        logger.info(f\"Loading Aspen backup file: {os.path.abspath(bkp_path)}\")\n        self.aspen.InitFromArchive2(os.path.abspath(bkp_path))\n        self.aspen.Visible = 0\n        self.aspen.SuppressDialogs = 1\n        logger.info(\"Aspen initialized successfully.\")\n\n        # \u5b9a\u4e49\u6469\u5c14\u8d28\u91cf (g/mol)\n        self.M_T, self.M_D, self.M_H = 3.016, 2.014, 1.008\n\n    def set_composition(self, ratios) -&gt; None:\n        \"\"\"\u8bbe\u7f6e\u516d\u5143\u7ec4\u5206\u8f93\u5165\"\"\"\n        nodes = {\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\H2\": ratios[0],  # EH2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HD\": ratios[1],  # EHD\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\D2\": ratios[2],  # ED2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HT\": ratios[3],  # EHT\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\DT\": ratios[4],  # EDT\n            r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\T2\": ratios[5],  # ET2\n            r\"\\Data\\Streams\\FROMTEP\\Input\\TOTFLOW\\MIXED\": ratios[6] / 2,  # \u603b\u6d41\u91cf/2\n        }\n        for path, value in nodes.items():\n            self.aspen.Tree.FindNode(path).Value = value\n\n    def run_step(self) -&gt; None:\n        \"\"\"\u6267\u884c\u5355\u6b65\u6a21\u62df\u5e76\u7b49\u5f85\u5b8c\u6210\"\"\"\n        self.aspen.Engine.Run2()\n        while self.aspen.Engine.IsRunning:\n            time.sleep(0.1)\n\n    def get_stream_results(self) -&gt; dict:\n        \"\"\"\u83b7\u53d6\u5173\u952e\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf(g/h)\"\"\"\n\n        def calc_stream(stream_name):\n            \"\"\"\u8ba1\u7b97\u5355\u4e2a\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf\"\"\"\n            nodes = self.aspen.Tree.FindNode(\n                rf\"\\Data\\Streams\\{stream_name}\\Output\\MOLEFLOW\\MIXED\"\n            )\n            Q1 = 1000 * nodes.FindNode(\"H2\").Value\n            Q2 = 1000 * nodes.FindNode(\"HD\").Value\n            Q3 = 1000 * nodes.FindNode(\"D2\").Value\n            Q4 = 1000 * nodes.FindNode(\"HT\").Value\n            Q5 = 1000 * nodes.FindNode(\"DT\").Value\n            Q6 = 1000 * nodes.FindNode(\"T2\").Value\n\n            H = (2 * Q1 + 1 * Q2 + 1 * Q4) * self.M_H\n            D = (1 * Q2 + 2 * Q3 + 1 * Q5) * self.M_D\n            T = (1 * Q4 + 1 * Q5 + 2 * Q6) * self.M_T\n            return [H, D, T]\n\n        streams = {\"WDS\": \"S4\", \"SDST2\": \"S17\", \"SDSD2\": \"S16\"}\n        return {name: calc_stream(path) for name, path in streams.items()}\n\n    def close(self) -&gt; None:\n        \"\"\"Closes the Aspen connection.\"\"\"\n        if self.aspen:\n            self.aspen.Close()\n            logger.info(\"Closed Aspen session.\")\n</code></pre>"},{"location":"reference/#tricys.handlers.i_iss_handler.AspenEnhanced.__init__","title":"<code>__init__(bkp_path)</code>","text":"<p>\u521d\u59cb\u5316Aspen\u8fde\u63a5\u5e76\u5b9a\u4e49\u6469\u5c14\u8d28\u91cf</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def __init__(self, bkp_path) -&gt; None:\n    \"\"\"\u521d\u59cb\u5316Aspen\u8fde\u63a5\u5e76\u5b9a\u4e49\u6469\u5c14\u8d28\u91cf\"\"\"\n    logger.info(\"Dispatching Aspen COM object...\")\n    self.aspen = win32.Dispatch(\"Apwn.Document.40.0\")  # Adjust version if necessary\n    logger.info(f\"Loading Aspen backup file: {os.path.abspath(bkp_path)}\")\n    self.aspen.InitFromArchive2(os.path.abspath(bkp_path))\n    self.aspen.Visible = 0\n    self.aspen.SuppressDialogs = 1\n    logger.info(\"Aspen initialized successfully.\")\n\n    # \u5b9a\u4e49\u6469\u5c14\u8d28\u91cf (g/mol)\n    self.M_T, self.M_D, self.M_H = 3.016, 2.014, 1.008\n</code></pre>"},{"location":"reference/#tricys.handlers.i_iss_handler.AspenEnhanced.close","title":"<code>close()</code>","text":"<p>Closes the Aspen connection.</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Closes the Aspen connection.\"\"\"\n    if self.aspen:\n        self.aspen.Close()\n        logger.info(\"Closed Aspen session.\")\n</code></pre>"},{"location":"reference/#tricys.handlers.i_iss_handler.AspenEnhanced.get_stream_results","title":"<code>get_stream_results()</code>","text":"<p>\u83b7\u53d6\u5173\u952e\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf(g/h)</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def get_stream_results(self) -&gt; dict:\n    \"\"\"\u83b7\u53d6\u5173\u952e\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf(g/h)\"\"\"\n\n    def calc_stream(stream_name):\n        \"\"\"\u8ba1\u7b97\u5355\u4e2a\u6d41\u80a1\u7684H/D/T\u8d28\u91cf\u6d41\u91cf\"\"\"\n        nodes = self.aspen.Tree.FindNode(\n            rf\"\\Data\\Streams\\{stream_name}\\Output\\MOLEFLOW\\MIXED\"\n        )\n        Q1 = 1000 * nodes.FindNode(\"H2\").Value\n        Q2 = 1000 * nodes.FindNode(\"HD\").Value\n        Q3 = 1000 * nodes.FindNode(\"D2\").Value\n        Q4 = 1000 * nodes.FindNode(\"HT\").Value\n        Q5 = 1000 * nodes.FindNode(\"DT\").Value\n        Q6 = 1000 * nodes.FindNode(\"T2\").Value\n\n        H = (2 * Q1 + 1 * Q2 + 1 * Q4) * self.M_H\n        D = (1 * Q2 + 2 * Q3 + 1 * Q5) * self.M_D\n        T = (1 * Q4 + 1 * Q5 + 2 * Q6) * self.M_T\n        return [H, D, T]\n\n    streams = {\"WDS\": \"S4\", \"SDST2\": \"S17\", \"SDSD2\": \"S16\"}\n    return {name: calc_stream(path) for name, path in streams.items()}\n</code></pre>"},{"location":"reference/#tricys.handlers.i_iss_handler.AspenEnhanced.run_step","title":"<code>run_step()</code>","text":"<p>\u6267\u884c\u5355\u6b65\u6a21\u62df\u5e76\u7b49\u5f85\u5b8c\u6210</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_step(self) -&gt; None:\n    \"\"\"\u6267\u884c\u5355\u6b65\u6a21\u62df\u5e76\u7b49\u5f85\u5b8c\u6210\"\"\"\n    self.aspen.Engine.Run2()\n    while self.aspen.Engine.IsRunning:\n        time.sleep(0.1)\n</code></pre>"},{"location":"reference/#tricys.handlers.i_iss_handler.AspenEnhanced.set_composition","title":"<code>set_composition(ratios)</code>","text":"<p>\u8bbe\u7f6e\u516d\u5143\u7ec4\u5206\u8f93\u5165</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def set_composition(self, ratios) -&gt; None:\n    \"\"\"\u8bbe\u7f6e\u516d\u5143\u7ec4\u5206\u8f93\u5165\"\"\"\n    nodes = {\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\H2\": ratios[0],  # EH2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HD\": ratios[1],  # EHD\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\D2\": ratios[2],  # ED2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\HT\": ratios[3],  # EHT\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\DT\": ratios[4],  # EDT\n        r\"\\Data\\Streams\\FROMTEP\\Input\\FLOW\\MIXED\\T2\": ratios[5],  # ET2\n        r\"\\Data\\Streams\\FROMTEP\\Input\\TOTFLOW\\MIXED\": ratios[6] / 2,  # \u603b\u6d41\u91cf/2\n    }\n    for path, value in nodes.items():\n        self.aspen.Tree.FindNode(path).Value = value\n</code></pre>"},{"location":"reference/#tricys.handlers.i_iss_handler.run_aspen_simulation","title":"<code>run_aspen_simulation(temp_input_csv, temp_output_csv, bkp_path='example_aspenbkp/T2-Threetowers4.bkp', aspen_results_csv=None, base=20, retime=60, time_step=3, min_stable_steps=100, stable_threshold=1e-06)</code>","text":"<p>Runs an Aspen Plus simulation based on inputs from a Modelica simulation.</p> <p>Parameters:</p> Name Type Description Default <code>bkp_path</code> <code>str</code> <p>Path to the Aspen backup file (.bkp).</p> <code>'example_aspenbkp/T2-Threetowers4.bkp'</code> <code>temp_input_csv</code> <code>str</code> <p>Path to the input CSV file with time-series data.</p> required <code>temp_output_csv</code> <code>str</code> <p>Path to save the final summarized output CSV.</p> required <code>aspen_results_csv</code> <code>str</code> <p>Path to save detailed Aspen results. Defaults to None.</p> <code>None</code> <code>base</code> <code>float</code> <p>Minimum inventory (heel) to start simulation (mol). Defaults to 20.</p> <code>20</code> <code>retime</code> <code>int</code> <p>Lag time in minutes for output results. Defaults to 60.</p> <code>60</code> <code>time_step</code> <code>int</code> <p>Time step in minutes. Defaults to 3.</p> <code>3</code> <code>min_stable_steps</code> <code>int</code> <p>Consecutive stable steps to confirm stability. Defaults to 100.</p> <code>100</code> <code>stable_threshold</code> <code>float</code> <p>Relative difference threshold for stability. Defaults to 1e-6.</p> <code>1e-06</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary mapping output variable names to their final values,   formatted as Modelica vector strings.   e.g., {'to_SDS': '{v1,v2,v3}', 'to_WDS': '{v4,v5,v6}'}</p> Source code in <code>tricys/handlers/i_iss_handler.py</code> <pre><code>def run_aspen_simulation(\n    temp_input_csv: str,\n    temp_output_csv: str,\n    bkp_path: str = r\"example_aspenbkp/T2-Threetowers4.bkp\",\n    aspen_results_csv: str = None,\n    base: float = 20,\n    retime: int = 60,\n    time_step: int = 3,\n    min_stable_steps: int = 100,\n    stable_threshold: float = 1e-6,\n):\n    \"\"\"\n    Runs an Aspen Plus simulation based on inputs from a Modelica simulation.\n\n    Args:\n        bkp_path (str): Path to the Aspen backup file (.bkp).\n        temp_input_csv (str): Path to the input CSV file with time-series data.\n        temp_output_csv (str): Path to save the final summarized output CSV.\n        aspen_results_csv (str, optional): Path to save detailed Aspen results. Defaults to None.\n        base (float, optional): Minimum inventory (heel) to start simulation (mol). Defaults to 20.\n        retime (int, optional): Lag time in minutes for output results. Defaults to 60.\n        time_step (int, optional): Time step in minutes. Defaults to 3.\n        min_stable_steps (int, optional): Consecutive stable steps to confirm stability. Defaults to 100.\n        stable_threshold (float, optional): Relative difference threshold for stability. Defaults to 1e-6.\n\n    Returns:\n        dict: A dictionary mapping output variable names to their final values,\n              formatted as Modelica vector strings.\n              e.g., {'to_SDS': '{v1,v2,v3}', 'to_WDS': '{v4,v5,v6}'}\n    \"\"\"\n    aspen = None\n    all_results = []\n    output_placeholder = {}\n\n    try:\n        # 1. \u521d\u59cb\u5316Aspen\n        aspen = AspenEnhanced(bkp_path)\n\n        # 2. \u8bfb\u53d6OpenModelica\u6570\u636e\n        logger.info(f\"Reading input data from: {temp_input_csv}\")\n        df_input = pd.read_csv(temp_input_csv, encoding=\"gbk\")\n\n        time_step_h = time_step / 60\n        N = int(retime / time_step)\n\n        df_input = df_input[\n            (df_input[\"time\"] / time_step_h).apply(lambda x: round(x, 9).is_integer())\n        ].copy()\n        required_cols = [\n            \"time\",\n            \"tep_fcu.outflow[1]\",\n            \"tep_fcu.outflow[2]\",\n            \"tep_fcu.outflow[3]\",\n        ]\n        input_data = df_input[required_cols].values\n\n        prev_T_flow = None\n        stable_count = 0\n        I_stock = 0\n        count = 0\n\n        # 3. \u4e3b\u5faa\u73af\u5904\u7406\n        logger.info(\"Starting main simulation loop...\")\n        for time_val, T_flow, D_flow, H_flow in input_data:\n            time_aspen = time_val * time_step\n            M_T, M_D, M_H = 3.016, 2.014, 1.008\n            T_flow_mol, D_flow_mol, H_flow_mol = (\n                T_flow / M_T,\n                D_flow / M_D,\n                H_flow / M_H,\n            )\n            total_flow = T_flow_mol + D_flow_mol + H_flow_mol\n\n            if prev_T_flow is not None and abs(prev_T_flow) &gt; 1e-9:\n                relative_diff = abs(T_flow - prev_T_flow) / abs(prev_T_flow)\n                if relative_diff &lt; stable_threshold:\n                    stable_count += 1\n                else:\n                    stable_count = 0\n                if stable_count &gt;= min_stable_steps:\n                    logger.info(\n                        f\"System stabilized at Time={time_val:.1f}h. Stopping simulation.\"\n                    )\n                    break\n            prev_T_flow = T_flow\n\n            I_stock += total_flow * time_step_h\n            if I_stock &lt;= base:\n                # Record zeros and skip simulation until inventory builds up\n                record = {\n                    \"Time\": time_val,\n                    \"Time_Aspen\": time_aspen,\n                    \"Input_T\": T_flow,\n                    \"Input_D\": D_flow,\n                    \"Input_H\": H_flow,\n                }\n                # ... (add other zero-ed out columns for consistency)\n                all_results.append(record)\n                continue\n\n            if not count:\n                count += 1\n                I_input = (I_stock - base) / time_step_h\n                logger.info(\n                    f\"Inventory base reached. Effective input flow: {I_input:.2f} mol/h\"\n                )\n                ET, ED, EH = (\n                    T_flow_mol / total_flow,\n                    D_flow_mol / total_flow,\n                    H_flow_mol / total_flow,\n                )\n                ratios = [\n                    EH**2,\n                    2 * EH * ED,\n                    ED**2,\n                    2 * EH * ET,\n                    2 * ED * ET,\n                    ET**2,\n                    I_input,\n                ]\n            else:\n                ET, ED, EH = (\n                    T_flow_mol / total_flow,\n                    D_flow_mol / total_flow,\n                    H_flow_mol / total_flow,\n                )\n                ratios = [\n                    EH**2,\n                    2 * EH * ED,\n                    ED**2,\n                    2 * EH * ET,\n                    2 * ED * ET,\n                    ET**2,\n                    total_flow,\n                ]\n\n            aspen.set_composition(ratios)\n            aspen.run_step()\n            stream_results = aspen.get_stream_results()\n\n            record = {\n                \"Time\": time_val,\n                \"Time_Aspen\": time_aspen,\n                \"Input_T\": T_flow,\n                \"Input_D\": D_flow,\n                \"Input_H\": H_flow,\n                **{\n                    f\"Input_{comp}\": val\n                    for comp, val in zip(\n                        [\"EH2\", \"EHD\", \"ED2\", \"EHT\", \"EDT\", \"ET2\", \"TOTAL\"], ratios\n                    )\n                },\n                **{\n                    f\"{stream}_{iso}_raw\": values[i]\n                    for stream, values in stream_results.items()\n                    for i, iso in enumerate([\"H\", \"D\", \"T\"])\n                },\n            }\n            all_results.append(record)\n            logger.debug(\n                f\"Progress: {len(all_results)}/{len(input_data)} | Time={time_val:.1f}h\"\n            )\n\n        # 4. \u540e\u5904\u7406\n        logger.info(\"Simulation loop finished. Starting post-processing...\")\n        if not all_results:\n            logger.warning(\n                \"No results were generated. The simulation might have been skipped entirely.\"\n            )\n            return output_placeholder\n\n        df = pd.DataFrame(all_results).fillna(0)\n\n        raw_cols = [\n            f\"{stream}_{iso}_raw\"\n            for stream in [\"WDS\", \"SDST2\", \"SDSD2\"]\n            for iso in [\"H\", \"D\", \"T\"]\n        ]\n        for col in raw_cols:\n            stream, iso, _ = col.split(\"_\")\n            df[f\"{stream}_{iso}\"] = df[col].shift(N).fillna(0)\n\n        df[\"delta_I_H\"] = (\n            df[\"Input_H\"]\n            - df.get(\"WDS_H\", 0)\n            - df.get(\"SDST2_H\", 0)\n            - df.get(\"SDSD2_H\", 0)\n        ) * time_step_h\n        df[\"delta_I_D\"] = (\n            df[\"Input_D\"]\n            - df.get(\"WDS_D\", 0)\n            - df.get(\"SDST2_D\", 0)\n            - df.get(\"SDSD2_D\", 0)\n        ) * time_step_h\n        df[\"delta_I_T\"] = (\n            df[\"Input_T\"]\n            - df.get(\"WDS_T\", 0)\n            - df.get(\"SDST2_T\", 0)\n            - df.get(\"SDSD2_T\", 0)\n        ) * time_step_h\n        df[\"I_H\"] = df[\"delta_I_H\"].cumsum()\n        df[\"I_D\"] = df[\"delta_I_D\"].cumsum()\n        df[\"I_T\"] = df[\"delta_I_T\"].cumsum()\n\n        df[\"to_SDS[1]\"] = df.get(\"SDST2_T\", 0) + df.get(\"SDSD2_T\", 0)\n        df[\"to_SDS[2]\"] = df.get(\"SDST2_D\", 0) + df.get(\"SDSD2_D\", 0)\n        df[\"to_SDS[3]\"] = df.get(\"SDST2_H\", 0) + df.get(\"SDSD2_H\", 0)\n        df[\"to_WDS[1]\"] = df.get(\"WDS_T\", 0)\n        df[\"to_WDS[2]\"] = df.get(\"WDS_D\", 0)\n        df[\"to_WDS[3]\"] = df.get(\"WDS_H\", 0)\n\n        # 5. \u4fdd\u5b58\u8f93\u51fa\u6587\u4ef6\n        out_df = df[\n            [\n                \"Time\",\n                \"to_SDS[1]\",\n                \"to_SDS[2]\",\n                \"to_SDS[3]\",\n                \"to_WDS[1]\",\n                \"to_WDS[2]\",\n                \"to_WDS[3]\",\n            ]\n        ]\n        out_df.to_csv(temp_output_csv, index=False)\n        logger.info(f\"Summary output saved to {temp_output_csv}\")\n\n        if aspen_results_csv:\n            df.drop(columns=raw_cols, errors=\"ignore\").to_csv(\n                aspen_results_csv, index=False\n            )\n            logger.info(f\"Detailed results saved to {aspen_results_csv}\")\n\n        # 6. \u6784\u5efa\u8fd4\u56de\u5b57\u5178\n        output_placeholder = {\n            \"to_SDS\": \"{1,2,3,4,1,1}\",\n            \"to_WDS\": \"{1,5,6,7,1,1}\",\n        }\n        logger.info(f\"Returning final values: {output_placeholder}\")\n\n    except Exception as e:\n        logger.error(\n            f\"An error occurred during the Aspen simulation: {str(e)}\", exc_info=True\n        )\n    finally:\n        if aspen:\n            aspen.close()\n\n    return output_placeholder\n</code></pre>"},{"location":"reference/#utilities","title":"\u5de5\u5177\u51fd\u6570 (Utilities)","text":""},{"location":"reference/#tricysutilsconfig_utils","title":"<code>tricys.utils.config_utils</code>","text":"<p>Configuration utility functions for tricys.</p>"},{"location":"reference/#tricys.utils.config_utils.analysis_prepare_config","title":"<code>analysis_prepare_config(config_path)</code>","text":"<p>Loads, validates, and prepares the configuration from the given path.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_prepare_config(config_path: str) -&gt; tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Loads, validates, and prepares the configuration from the given path.\"\"\"\n    try:\n        config_path = os.path.abspath(config_path)\n        with open(config_path, \"r\") as f:\n            base_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        print(\n            f\"ERROR: Failed to load or parse config file {config_path}: {e}\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    original_config_dir = os.path.dirname(config_path)\n    absolute_config = convert_relative_paths_to_absolute(\n        base_config, original_config_dir\n    )\n\n    # Perform all validation on the config with absolute paths\n    analysis_validate_config(absolute_config)\n\n    config = json.loads(json.dumps(absolute_config))\n    config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    config[\"paths\"][\"log_dir\"] = run_workspace\n    if \"paths\" not in config:\n        config[\"paths\"] = {}\n\n    original_string = config[\"simulation\"][\"variableFilter\"]\n    config[\"simulation\"][\"variableFilter\"] = original_string.replace(\n        \"[\", \"\\\\[[\"\n    ).replace(\"]\", \"]\\\\]\")\n\n    return config, base_config\n</code></pre>"},{"location":"reference/#tricys.utils.config_utils.analysis_setup_analysis_cases_workspaces","title":"<code>analysis_setup_analysis_cases_workspaces(config)</code>","text":"<p>Set up independent working directories and configuration files for multiple analysis_cases</p> <p>This function will: 1. Create independent working directories for each analysis_case in the current working directory 2. Convert relative paths in the original configuration to absolute paths 3. Convert analysis_cases format to standard analysis_case format 4. Generate independent config.json files for each case</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Original configuration dictionary containing analysis_cases</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List containing information for each case, each element contains:</p> <code>List[Dict[str, Any]]</code> <ul> <li>index: Case index</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>workspace: Working directory path</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>config_path: Configuration file path</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>config: Configuration applicable to this case</li> </ul> <code>List[Dict[str, Any]]</code> <ul> <li>case_data: Original case data</li> </ul> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_setup_analysis_cases_workspaces(\n    config: Dict[str, Any],\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Set up independent working directories and configuration files for multiple analysis_cases\n\n    This function will:\n    1. Create independent working directories for each analysis_case in the current working directory\n    2. Convert relative paths in the original configuration to absolute paths\n    3. Convert analysis_cases format to standard analysis_case format\n    4. Generate independent config.json files for each case\n\n    Args:\n        config: Original configuration dictionary containing analysis_cases\n\n    Returns:\n        List containing information for each case, each element contains:\n        - index: Case index\n        - workspace: Working directory path\n        - config_path: Configuration file path\n        - config: Configuration applicable to this case\n        - case_data: Original case data\n    \"\"\"\n\n    analysis_cases_raw = config[\"sensitivity_analysis\"][\"analysis_cases\"]\n\n    # Unified processing into list format\n    if isinstance(analysis_cases_raw, dict):\n        # Single analysis_case object\n        analysis_cases = [analysis_cases_raw]\n        logger.info(\n            \"Detected single analysis_case object, converting to list format for processing\"\n        )\n    else:\n        # Already in list format\n        analysis_cases = analysis_cases_raw\n\n    # The main run workspace is the timestamped directory, already created by initialize_run.\n    # We will create the case workspaces inside it.\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    # Determine the main log file path to be shared with all cases\n    main_log_file_name = f\"simulation_{config['run_timestamp']}.log\"\n    main_log_path = os.path.join(run_workspace, main_log_file_name)\n\n    logger.info(\n        f\"Detected {len(analysis_cases)} analysis cases, creating independent workspaces inside: {run_workspace}\"\n    )\n\n    case_configs = []\n\n    for i, analysis_case in enumerate(analysis_cases):\n        try:\n            # Generate case working directory name\n            workspace_name = analysis_case.get(\"name\", f\"case_{i}\")\n            # Create the case workspace directly inside the main run workspace\n            case_workspace = os.path.join(run_workspace, workspace_name)\n            os.makedirs(case_workspace, exist_ok=True)\n\n            # Create standard configuration (inlined from _create_standard_config_for_case)\n            base_config = config\n            original_config_dir = os.path.dirname(\n                base_config.get(\"paths\", {}).get(\"package_path\", os.getcwd())\n            )\n            absolute_config = convert_relative_paths_to_absolute(\n                base_config, original_config_dir\n            )\n            standard_config = json.loads(json.dumps(absolute_config))\n\n            # if analysis_case.get(\"name\") == \"SALib_Analysis\":\n            if isinstance(\n                analysis_case.get(\"independent_variable\"), list\n            ) and isinstance(analysis_case.get(\"independent_variable_sampling\"), dict):\n                sensitivity_analysis = standard_config[\"sensitivity_analysis\"]\n                if \"analysis_cases\" in sensitivity_analysis:\n                    del sensitivity_analysis[\"analysis_cases\"]\n                sensitivity_analysis[\"analysis_case\"] = analysis_case.copy()\n            else:\n                # Get independent variable and sampling from the current analysis case\n                independent_var = analysis_case[\"independent_variable\"]\n                independent_sampling = analysis_case[\"independent_variable_sampling\"]\n                logger.debug(\n                    f\"independent_sampling configuration: {independent_sampling}\"\n                )\n\n                # Ensure simulation_parameters exists at the top level\n                if \"simulation_parameters\" not in standard_config:\n                    standard_config[\"simulation_parameters\"] = {}\n\n                # If the specific analysis_case has its own simulation_parameters, merge them into the top-level ones\n                # This allows for case-specific parameter overrides or additions\n                if \"simulation_parameters\" in analysis_case:\n                    case_sim_params = analysis_case.get(\"simulation_parameters\", {})\n\n                    # Identify and handle virtual parameters (e.g., Required_TBR) used for metric configuration\n                    virtual_params = {\n                        k: v\n                        for k, v in case_sim_params.items()\n                        if k.startswith(\"Required_\") and isinstance(v, dict)\n                    }\n\n                    if virtual_params:\n                        # Merge virtual parameter config into the case's metrics_definition\n                        metrics_def = standard_config.setdefault(\n                            \"sensitivity_analysis\", {}\n                        ).setdefault(\"metrics_definition\", {})\n                        for key, value in virtual_params.items():\n                            if key in metrics_def:\n                                metrics_def[key].update(value)\n                            else:\n                                metrics_def[key] = value\n\n                    # Get real parameters by excluding virtual ones\n                    real_params = {\n                        k: v\n                        for k, v in case_sim_params.items()\n                        if k not in virtual_params\n                    }\n\n                    # Update standard_config's simulation_parameters with only real parameters for job generation\n                    standard_config[\"simulation_parameters\"].update(real_params)\n\n                # Fetch default values for both independent and simulation parameters\n                omc = None\n                try:\n                    # Get all sim params from the case, which may include virtual parameters\n                    all_case_sim_params = analysis_case.get(\"simulation_parameters\", {})\n                    # Filter out virtual parameters before fetching default values\n                    sim_param_keys = [\n                        k\n                        for k, v in all_case_sim_params.items()\n                        if not (k.startswith(\"Required_\") and isinstance(v, dict))\n                    ]\n                    # Ensure independent_var is a list for consistent processing, as it can be a list in SALib cases\n                    ind_param_keys = (\n                        [independent_var]\n                        if isinstance(independent_var, str)\n                        else independent_var\n                    )\n\n                    param_keys_to_fetch = sim_param_keys + ind_param_keys\n\n                    if param_keys_to_fetch:\n                        logger.info(\n                            f\"Fetching default values for parameters: {param_keys_to_fetch}\"\n                        )\n                        omc = get_om_session()\n                        if load_modelica_package(\n                            omc,\n                            Path(standard_config[\"paths\"][\"package_path\"]).as_posix(),\n                        ):\n                            all_defaults = get_model_default_parameters(\n                                omc, standard_config[\"simulation\"][\"model_name\"]\n                            )\n\n                            # Helper function to handle array access like 'param[1]'\n                            def get_specific_default(key, defaults):\n                                if key in defaults:\n                                    return defaults[key]\n                                if \"[\" in key and key.endswith(\"]\"):\n                                    try:\n                                        base_name, index_str = key.rsplit(\"[\", 1)\n                                        # Modelica is 1-based, Python is 0-based\n                                        index = int(index_str[:-1]) - 1\n                                        if base_name in defaults:\n                                            default_array = defaults[base_name]\n                                            if isinstance(\n                                                default_array, list\n                                            ) and 0 &lt;= index &lt; len(default_array):\n                                                return default_array[index]\n                                    except (ValueError, IndexError):\n                                        pass  # Malformed index or out of bounds\n                                return \"N/A\"\n\n                            # Get defaults for simulation_parameters\n                            default_sim_values = {\n                                p: get_specific_default(p, all_defaults)\n                                for p in sim_param_keys\n                            }\n                            analysis_case[\"default_simulation_values\"] = (\n                                default_sim_values\n                            )\n\n                            # Get defaults for independent_variable\n                            default_ind_values = {\n                                p: get_specific_default(p, all_defaults)\n                                for p in ind_param_keys\n                            }\n                            analysis_case[\"default_independent_values\"] = (\n                                default_ind_values\n                            )\n\n                except Exception as e:\n                    logger.warning(\n                        f\"Could not fetch default parameter values. Defaults will be empty. Error: {e}\"\n                    )\n                    analysis_case[\"default_simulation_values\"] = {}\n                    analysis_case[\"default_independent_values\"] = {}\n                finally:\n                    if omc:\n                        omc.sendExpression(\"quit()\")\n\n                # Add the primary independent_variable_sampling for the current analysis case\n                standard_config[\"simulation_parameters\"][\n                    independent_var\n                ] = independent_sampling\n\n                # Update sensitivity_analysis configuration\n                sensitivity_analysis = standard_config[\"sensitivity_analysis\"]\n\n                # Remove analysis_cases and replace with single analysis_case\n                if \"analysis_cases\" in sensitivity_analysis:\n                    del sensitivity_analysis[\"analysis_cases\"]\n\n                sensitivity_analysis[\"analysis_case\"] = analysis_case.copy()\n\n            # Update paths in configuration to be relative to case working directory\n            case_config = standard_config.copy()\n            case_config[\"paths\"][\"results_dir\"] = os.path.join(\n                case_workspace, \"results\"\n            )\n            case_config[\"paths\"][\"temp_dir\"] = os.path.join(case_workspace, \"temp\")\n            case_config[\"paths\"][\"db_path\"] = os.path.join(\n                case_workspace, \"data\", \"parameters.db\"\n            )\n\n            # If there's logging configuration, also update log directory\n            if \"paths\" in case_config and \"log_dir\" in case_config[\"paths\"]:\n                case_config[\"paths\"][\"log_dir\"] = os.path.join(case_workspace, \"log\")\n                # Inject the main log path for dual logging\n                if \"logging\" in case_config:\n                    case_config[\"logging\"][\"main_log_path\"] = main_log_path\n\n            # Save standard configuration file to case working directory\n            config_file_path = os.path.join(case_workspace, \"config.json\")\n            with open(config_file_path, \"w\", encoding=\"utf-8\") as f:\n                json.dump(standard_config, f, indent=4, ensure_ascii=False)\n\n            # Record case information\n            case_info = {\n                \"index\": i,\n                \"workspace\": case_workspace,\n                \"config_path\": config_file_path,\n                \"config\": case_config,\n                \"case_data\": analysis_case,\n            }\n            case_configs.append(case_info)\n\n            logger.info(\n                f\"Workspace for case {i+1} created successfully\",\n                extra={\n                    \"case_index\": i,\n                    \"case_name\": analysis_case.get(\"name\", f\"case_{i}\"),\n                    \"workspace\": case_workspace,\n                    \"config_path\": config_file_path,\n                },\n            )\n\n        except Exception as e:\n            logger.error(f\"\u2717 Error processing case {i}: {e}\", exc_info=True)\n            continue\n\n    logger.info(\n        f\"Successfully created independent working directories for {len(case_configs)} analysis cases\"\n    )\n    return case_configs\n</code></pre>"},{"location":"reference/#tricys.utils.config_utils.analysis_validate_analysis_cases_config","title":"<code>analysis_validate_analysis_cases_config(config)</code>","text":"<p>Validate analysis_cases configuration format, supporting both list and single object formats</p> <p>This function validates: 1. Basic structure and required fields of analysis_cases 2. Simulation parameters compatibility (single job requirement) 3. Required_TBR configuration completeness if used in dependent_variables</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary to validate</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if configuration is valid, False otherwise</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_validate_analysis_cases_config(config: Dict[str, Any]) -&gt; bool:\n    \"\"\"Validate analysis_cases configuration format, supporting both list and single object formats\n\n    This function validates:\n    1. Basic structure and required fields of analysis_cases\n    2. Simulation parameters compatibility (single job requirement)\n    3. Required_TBR configuration completeness if used in dependent_variables\n\n    Args:\n        config: Configuration dictionary to validate\n\n    Returns:\n        bool: True if configuration is valid, False otherwise\n    \"\"\"\n    if \"sensitivity_analysis\" not in config:\n        logger.error(\"Missing sensitivity_analysis\")\n        return False\n\n    sensitivity_analysis = config[\"sensitivity_analysis\"]\n    if \"analysis_cases\" not in sensitivity_analysis:\n        logger.error(\"Missing analysis_cases\")\n        return False\n\n    analysis_cases = sensitivity_analysis[\"analysis_cases\"]\n\n    # Support both single object and list formats\n    if isinstance(analysis_cases, dict):\n        # Single analysis_case object\n        cases_to_check = [analysis_cases]\n    elif isinstance(analysis_cases, list) and len(analysis_cases) &gt; 0:\n        # analysis_cases list\n        cases_to_check = analysis_cases\n    else:\n        logger.error(\"analysis_cases must be a non-empty list or a single object\")\n        return False\n\n    # Check required fields for each analysis_case\n    required_fields = [\"name\", \"independent_variable\", \"independent_variable_sampling\"]\n    for i, case in enumerate(cases_to_check):\n        if not isinstance(case, dict):\n            logger.error(f\"analysis_cases[{i}] must be an object\")\n            return False\n        for field in required_fields:\n            if field not in case:\n                logger.error(f\"Missing required field '{field}' in analysis_cases[{i}]\")\n                return False\n\n    # Check if top-level simulation_parameters are used, which is disallowed in analysis_cases mode\n    if config.get(\"simulation_parameters\"):\n        logger.error(\n            \"The top-level 'simulation_parameters' field cannot be used when 'analysis_cases' is defined. \"\n            \"Please move any shared or case-specific parameters into the 'simulation_parameters' field \"\n            \"inside each object within the 'analysis_cases' list.\"\n        )\n        return False\n\n    # Check Required_TBR configuration completeness if it exists in dependent_variables\n    metrics_definition = sensitivity_analysis.get(\"metrics_definition\", {})\n    for i, case in enumerate(cases_to_check):\n        dependent_vars = case.get(\"dependent_variables\", [])\n        if \"Required_TBR\" in dependent_vars:\n            # Check if Required_TBR exists in metrics_definition\n            if \"Required_TBR\" not in metrics_definition:\n                logger.error(\n                    f\"Required_TBR is in dependent_variables of analysis_cases[{i}] but missing from metrics_definition\"\n                )\n                return False\n\n            # Check if Required_TBR configuration is complete\n            required_tbr_config = metrics_definition[\"Required_TBR\"]\n            required_fields = [\n                \"method\",\n                \"parameter_to_optimize\",\n                \"search_range\",\n                \"tolerance\",\n                \"max_iterations\",\n            ]\n            missing_fields = [\n                field for field in required_fields if field not in required_tbr_config\n            ]\n            if missing_fields:\n                logger.error(\n                    f\"Required_TBR configuration in metrics_definition is incomplete. Missing fields: {missing_fields}\"\n                )\n                return False\n\n    return True\n</code></pre>"},{"location":"reference/#tricys.utils.config_utils.analysis_validate_config","title":"<code>analysis_validate_config(config, required_keys=ANALYSIS_REQUIRED_CONFIG_KEYS, parent_key='')</code>","text":"<p>Recursively validates the configuration's structure and values.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def analysis_validate_config(\n    config: Dict[str, Any],\n    required_keys: Dict = ANALYSIS_REQUIRED_CONFIG_KEYS,\n    parent_key: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Recursively validates the configuration's structure and values.\n    \"\"\"\n    # --- Structural Validation ---\n    for key, expected in required_keys.items():\n        full_key_path = f\"{parent_key}.{key}\" if parent_key else key\n        if key not in config:\n            print(\n                f\"ERROR: Missing required configuration key: '{full_key_path}'\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if isinstance(expected, dict):\n            if not isinstance(config[key], dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' must be a dictionary.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            analysis_validate_config(config[key], expected, parent_key=full_key_path)\n        elif not isinstance(config[key], expected):\n            print(\n                f\"ERROR: Configuration key '{full_key_path}' has incorrect type. Expected {expected}, got {type(config[key])}.\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n    # 2. Validate variableFilter format\n    variable_filter = config.get(\"simulation\", {}).get(\"variableFilter\")\n    if variable_filter:\n        # Regex for a valid Modelica identifier (simplified)\n        ident = r\"[a-zA-Z_][a-zA-Z0-9_]*\"\n        # Regex for a valid substring in the filter:\n        # - time\n        # - class.name\n        # - class.name[index]\n        # - class.name[start-end]\n        valid_substring_re = re.compile(rf\"^time$|^{ident}\\.{ident}(\\[\\d+(-\\d+)?\\])?$\")\n\n        substrings = variable_filter.split(\"|\")\n        for sub in substrings:\n            if not valid_substring_re.match(sub):\n                print(\n                    f\"ERROR: Invalid format in 'simulation.variableFilter'. Substring '{sub}' does not match required format. \"\n                    f\"Valid formats are 'time', 'classname.typename', 'classname.typename[1]', or 'classname.typename[1-5]'.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    # --- Value and Conditional Validation (only on top-level call) ---\n    if not parent_key:\n        # Check for package_path existence\n        package_path = config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            print(\n                f\"ERROR: File specified in 'paths.package_path' not found: {package_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        # Analysis-specific validation\n        sa_config = config.get(\"sensitivity_analysis\", {})\n        if sa_config.get(\"enabled\", False):\n            has_sim_params = (\n                \"simulation_parameters\" in config and config[\"simulation_parameters\"]\n            )\n            has_analysis_cases = (\n                \"analysis_cases\" in sa_config and sa_config[\"analysis_cases\"]\n            )\n\n            if not has_sim_params and not has_analysis_cases:\n                print(\n                    \"ERROR: When 'sensitivity_analysis' is enabled, either 'simulation_parameters' or 'sensitivity_analysis.analysis_cases' must be defined.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n            if has_analysis_cases:\n                if not analysis_validate_analysis_cases_config(config):\n                    # The original function uses a logger which is not yet configured.\n                    # Add a print statement to ensure the user sees an error.\n                    print(\n                        \"ERROR: 'analysis_cases' configuration is invalid. See previous logs for details.\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n</code></pre>"},{"location":"reference/#tricys.utils.config_utils.basic_prepare_config","title":"<code>basic_prepare_config(config_path)</code>","text":"<p>Loads and prepares the configuration from the given path.</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def basic_prepare_config(config_path: str) -&gt; tuple[Dict[str, Any], Dict[str, Any]]:\n    \"\"\"Loads and prepares the configuration from the given path.\"\"\"\n    try:\n        config_path = os.path.abspath(config_path)\n        with open(config_path, \"r\") as f:\n            base_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError) as e:\n        # Logger is not set up yet, so print directly to stderr\n        print(\n            f\"ERROR: Failed to load or parse config file {config_path}: {e}\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n\n    original_config_dir = os.path.dirname(config_path)\n\n    absolute_config = convert_relative_paths_to_absolute(\n        base_config, original_config_dir\n    )\n\n    # Perform all validation on the config with absolute paths\n    basic_validate_config(absolute_config)\n\n    config = json.loads(json.dumps(absolute_config))\n    config[\"run_timestamp\"] = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    run_workspace = os.path.abspath(config[\"run_timestamp\"])\n\n    if \"paths\" not in config:\n        config[\"paths\"] = {}\n\n    original_string = config[\"simulation\"][\"variableFilter\"]\n    config[\"simulation\"][\"variableFilter\"] = original_string.replace(\n        \"[\", \"\\\\[[\"\n    ).replace(\"]\", \"]\\\\]\")\n\n    config[\"paths\"][\"log_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"log_dir\", \"log\")\n    )\n    config[\"paths\"][\"temp_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"temp_dir\", \"temp\")\n    )\n    config[\"paths\"][\"results_dir\"] = os.path.join(\n        run_workspace, base_config[\"paths\"].get(\"results_dir\", \"results\")\n    )\n\n    os.makedirs(config[\"paths\"][\"log_dir\"], exist_ok=True)\n    os.makedirs(config[\"paths\"][\"temp_dir\"], exist_ok=True)\n    os.makedirs(config[\"paths\"][\"results_dir\"], exist_ok=True)\n\n    return config, base_config\n</code></pre>"},{"location":"reference/#tricys.utils.config_utils.basic_validate_config","title":"<code>basic_validate_config(config, required_keys=BASIC_REQUIRED_CONFIG_KEYS, parent_key='')</code>","text":"<p>Recursively validates the configuration. - Checks for required keys and types. - Performs specific value validations (e.g., path existence, string formats).</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def basic_validate_config(\n    config: Dict[str, Any],\n    required_keys: Dict = BASIC_REQUIRED_CONFIG_KEYS,\n    parent_key: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Recursively validates the configuration.\n    - Checks for required keys and types.\n    - Performs specific value validations (e.g., path existence, string formats).\n    \"\"\"\n    # --- Structural Validation ---\n    for key, expected_type_or_dict in required_keys.items():\n        full_key_path = f\"{parent_key}.{key}\" if parent_key else key\n\n        if key not in config:\n            print(\n                f\"ERROR: Missing required configuration key: '{full_key_path}'\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        if isinstance(expected_type_or_dict, dict):\n            if not isinstance(config[key], dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' must be a dictionary.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n            # Recurse for nested dictionaries\n            basic_validate_config(\n                config[key], expected_type_or_dict, parent_key=full_key_path\n            )\n        else:\n            # Perform type checking for leaf keys\n            if not isinstance(config[key], expected_type_or_dict):\n                print(\n                    f\"ERROR: Configuration key '{full_key_path}' has incorrect type. \"\n                    f\"Expected {expected_type_or_dict}, but got {type(config[key])}.\",\n                    file=sys.stderr,\n                )\n                sys.exit(1)\n\n    # --- Value Validation (only on top-level call) ---\n    if not parent_key:\n        # 1. Check if package_path exists\n        package_path = config.get(\"paths\", {}).get(\"package_path\")\n        if package_path and not os.path.exists(package_path):\n            print(\n                f\"ERROR: File specified in 'paths.package_path' not found: {package_path}\",\n                file=sys.stderr,\n            )\n            sys.exit(1)\n\n        # 2. Validate variableFilter format\n        variable_filter = config.get(\"simulation\", {}).get(\"variableFilter\")\n        if variable_filter:\n            # Regex for a valid Modelica identifier (simplified)\n            ident = r\"[a-zA-Z_][a-zA-Z0-9_]*\"\n            # Regex for a valid substring in the filter:\n            # - time\n            # - class.name\n            # - class.name[index]\n            # - class.name[start-end]\n            valid_substring_re = re.compile(\n                rf\"^time$|^{ident}\\.{ident}(\\[\\d+(-\\d+)?\\])?$\"\n            )\n\n            substrings = variable_filter.split(\"|\")\n            for sub in substrings:\n                if not valid_substring_re.match(sub):\n                    print(\n                        f\"ERROR: Invalid format in 'simulation.variableFilter'. Substring '{sub}' does not match required format. \"\n                        f\"Valid formats are 'time', 'classname.typename', 'classname.typename[1]', or 'classname.typename[1-5]'.\",\n                        file=sys.stderr,\n                    )\n                    sys.exit(1)\n</code></pre>"},{"location":"reference/#tricys.utils.config_utils.convert_relative_paths_to_absolute","title":"<code>convert_relative_paths_to_absolute(config, base_dir)</code>","text":"<p>Recursively traverse configuration data and convert relative paths to absolute paths based on the specified base directory</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict[str, Any]</code> <p>Configuration dictionary</p> required <code>base_dir</code> <code>str</code> <p>Base directory path</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Converted configuration dictionary</p> Source code in <code>tricys/utils/config_utils.py</code> <pre><code>def convert_relative_paths_to_absolute(\n    config: Dict[str, Any], base_dir: str\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Recursively traverse configuration data and convert relative paths to absolute paths based on the specified base directory\n\n    Args:\n        config: Configuration dictionary\n        base_dir: Base directory path\n\n    Returns:\n        Converted configuration dictionary\n    \"\"\"\n\n    def _process_value(value, key_name=\"\", parent_dict=None):\n        if isinstance(value, dict):\n            return {k: _process_value(v, k, value) for k, v in value.items()}\n        elif isinstance(value, list):\n            return [_process_value(item, parent_dict=parent_dict) for item in value]\n        elif isinstance(value, str):\n            # Check if it's a path-related key name (extended support for more path fields)\n            path_keys = [\n                \"package_path\",\n                \"db_path\",\n                \"results_dir\",\n                \"temp_dir\",\n                \"log_dir\",\n                \"glossary_path\",\n            ]\n\n            if key_name.endswith(\"_path\") or key_name in path_keys:\n                # If it's a relative path, convert to absolute path\n                if not os.path.isabs(value) and value:\n                    abs_path = os.path.abspath(os.path.join(base_dir, value))\n                    logger.debug(\n                        \"Converted path\",\n                        extra={\n                            \"key_name\": key_name,\n                            \"original_value\": value,\n                            \"absolute_path\": abs_path,\n                        },\n                    )\n                    return abs_path\n            return value\n        else:\n            return value\n\n    return _process_value(config)\n</code></pre>"},{"location":"reference/#tricysutilsfile_utils","title":"<code>tricys.utils.file_utils</code>","text":"<p>Utility functions for file and directory management.</p> <p>This module provides helper functions for creating unique filenames and managing log file rotation.</p>"},{"location":"reference/#tricys.utils.file_utils.archive_run","title":"<code>archive_run(timestamp)</code>","text":"<p>Archives a run (simulation or analysis) based on its configuration.</p> Source code in <code>tricys/utils/file_utils.py</code> <pre><code>def archive_run(timestamp: str) -&gt; None:\n    \"\"\"Archives a run (simulation or analysis) based on its configuration.\"\"\"\n\n    configs = restore_configs_from_log(timestamp)\n    if not configs:\n        return\n    runtime_config, original_config = configs\n    logger.info(\"Successfully extracted both runtime and original configurations.\")\n\n    is_analysis = \"sensitivity_analysis\" in original_config and original_config.get(\n        \"sensitivity_analysis\", {}\n    ).get(\"enabled\", False)\n\n    if is_analysis:\n        _archive_run(timestamp, \"analysis\")\n    else:\n        _archive_run(timestamp, \"simulation\")\n</code></pre>"},{"location":"reference/#tricys.utils.file_utils.get_unique_filename","title":"<code>get_unique_filename(base_path, filename)</code>","text":"<p>Generates a unique filename by appending a counter if the file already exists.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>The directory path where the file will be saved.</p> required <code>filename</code> <code>str</code> <p>The desired filename, including the extension.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A unique, non-existing file path.</p> Source code in <code>tricys/utils/file_utils.py</code> <pre><code>def get_unique_filename(base_path: str, filename: str) -&gt; str:\n    \"\"\"Generates a unique filename by appending a counter if the file already exists.\n\n    Args:\n        base_path (str): The directory path where the file will be saved.\n        filename (str): The desired filename, including the extension.\n\n    Returns:\n        str: A unique, non-existing file path.\n    \"\"\"\n    base_name, ext = os.path.splitext(filename)\n    counter = 0\n    new_filename = filename\n    new_filepath = os.path.join(base_path, new_filename)\n\n    while os.path.exists(new_filepath):\n        counter += 1\n        new_filename = f\"{base_name}_{counter}{ext}\"\n        new_filepath = os.path.join(base_path, new_filename)\n\n    return new_filepath\n</code></pre>"},{"location":"reference/#tricys.utils.file_utils.unarchive_run","title":"<code>unarchive_run(zip_file)</code>","text":"<p>Unarchives a simulation run from a zip file. Extracts to a new folder if the current directory is not empty.</p> Source code in <code>tricys/utils/file_utils.py</code> <pre><code>def unarchive_run(zip_file: str) -&gt; None:\n    \"\"\"\n    Unarchives a simulation run from a zip file.\n    Extracts to a new folder if the current directory is not empty.\n    \"\"\"\n    # Basic logging setup for unarchive command\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n        stream=sys.stdout,\n    )\n    logger = logging.getLogger(__name__)\n\n    if not os.path.isfile(zip_file):\n        logger.error(f\"Archive file not found: {zip_file}\")\n        sys.exit(1)\n\n    target_dir = \".\"\n    if os.listdir(\".\"):  # If the list of CWD contents is not empty\n        dir_name = os.path.splitext(os.path.basename(zip_file))[0]\n        target_dir = dir_name\n        logger.info(\n            f\"Current directory is not empty. Extracting to new directory: {target_dir}\"\n        )\n        os.makedirs(target_dir, exist_ok=True)\n    else:\n        logger.info(\"Current directory is empty. Extracting to current directory.\")\n\n    # Unzip the file\n    try:\n        with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n            zip_ref.extractall(target_dir)\n        logger.info(\n            f\"Successfully unarchived '{zip_file}' to '{os.path.abspath(target_dir)}'\"\n        )\n    except zipfile.BadZipFile:\n        logger.error(f\"Error: '{zip_file}' is not a valid zip file.\")\n        sys.exit(1)\n    except Exception as e:\n        logger.error(f\"An error occurred during unarchiving: {e}\")\n        sys.exit(1)\n</code></pre>"},{"location":"reference/#tricysutilslog_utils","title":"<code>tricys.utils.log_utils</code>","text":""},{"location":"reference/#tricys.utils.log_utils.delete_old_logs","title":"<code>delete_old_logs(log_path, max_files)</code>","text":"<p>Deletes the oldest log files in a directory to meet a specified limit.</p> <p>Checks the number of <code>.log</code> files in the given directory and removes the oldest ones based on modification time until the file count matches the <code>max_files</code> limit.</p> <p>Parameters:</p> Name Type Description Default <code>log_path</code> <code>str</code> <p>The path to the directory containing log files.</p> required <code>max_files</code> <code>int</code> <p>The maximum number of <code>.log</code> files to retain.</p> required Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def delete_old_logs(log_path: str, max_files: int) -&gt; None:\n    \"\"\"Deletes the oldest log files in a directory to meet a specified limit.\n\n    Checks the number of `.log` files in the given directory and removes the\n    oldest ones based on modification time until the file count matches the\n    `max_files` limit.\n\n    Args:\n        log_path (str): The path to the directory containing log files.\n        max_files (int): The maximum number of `.log` files to retain.\n    \"\"\"\n    log_files = [\n        os.path.join(log_path, f) for f in os.listdir(log_path) if f.endswith(\".log\")\n    ]\n\n    if len(log_files) &gt; max_files:\n        # Sort by modification time, oldest first\n        log_files.sort(key=os.path.getmtime)\n\n        # Calculate how many files to delete\n        files_to_delete_count = len(log_files) - max_files\n\n        # Delete the oldest files\n        for i in range(files_to_delete_count):\n            os.remove(log_files[i])\n</code></pre>"},{"location":"reference/#tricys.utils.log_utils.log_execution_time","title":"<code>log_execution_time(func)</code>","text":"<p>A decorator to log the execution time of a function.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def log_execution_time(func) -&gt; Callable:\n    \"\"\"A decorator to log the execution time of a function.\"\"\"\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.perf_counter()\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        duration_ms = (end_time - start_time) * 1000\n\n        logger.info(\n            \"Function executed\",\n            extra={\n                \"function_name\": func.__name__,\n                \"function_module\": func.__module__,\n                \"duration_ms\": round(duration_ms, 2),\n            },\n        )\n        return result\n\n    return wrapper\n</code></pre>"},{"location":"reference/#tricys.utils.log_utils.restore_configs_from_log","title":"<code>restore_configs_from_log(timestamp)</code>","text":"<p>Finds the log file for a given timestamp and restores the runtime and original configurations.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def restore_configs_from_log(\n    timestamp: str,\n) -&gt; tuple[Dict[str, Any] | None, Dict[str, Any] | None]:\n    \"\"\"\n    Finds the log file for a given timestamp and restores the runtime and original configurations.\n    \"\"\"\n    log_file_path = None\n    # Define potential locations for the log file\n    search_paths = [\n        os.path.join(timestamp, f\"simulation_{timestamp}.log\"),  # analysis style\n        os.path.join(timestamp, \"log\"),  # simulation style\n    ]\n\n    for path in search_paths:\n        if os.path.isfile(path):\n            log_file_path = path\n            break\n        if os.path.isdir(path):\n            for f in os.listdir(path):\n                if f.startswith(\"simulation_\") and f.endswith(\".log\"):\n                    log_file_path = os.path.join(path, f)\n                    break\n            if log_file_path:\n                break\n\n    if not log_file_path:\n        print(\n            f\"ERROR: Main log file not found for timestamp {timestamp}\", file=sys.stderr\n        )\n        return None, None\n\n    runtime_config_str = None\n    original_config_str = None\n    try:\n        with open(log_file_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                try:\n                    log_entry = json.loads(line)\n                    if \"message\" in log_entry:\n                        if log_entry[\"message\"].startswith(\n                            \"Runtime Configuration (compact JSON):\"\n                        ):\n                            runtime_config_str = log_entry[\"message\"].replace(\n                                \"Runtime Configuration (compact JSON): \", \"\"\n                            )\n                        elif log_entry[\"message\"].startswith(\n                            \"Original Configuration (compact JSON):\"\n                        ):\n                            original_config_str = log_entry[\"message\"].replace(\n                                \"Original Configuration (compact JSON): \", \"\"\n                            )\n                    if runtime_config_str and original_config_str:\n                        break\n                except json.JSONDecodeError:\n                    continue\n    except Exception as e:\n        print(f\"ERROR: Failed to read log file {log_file_path}: {e}\", file=sys.stderr)\n        return None, None\n\n    if not runtime_config_str or not original_config_str:\n        print(\n            \"ERROR: Could not find runtime and/or original configuration in log file.\",\n            file=sys.stderr,\n        )\n        return None, None\n\n    try:\n        runtime_config = json.loads(runtime_config_str)\n        original_config = json.loads(original_config_str)\n        return runtime_config, original_config\n    except json.JSONDecodeError as e:\n        print(\n            f\"ERROR: Failed to parse configuration from log file: {e}\", file=sys.stderr\n        )\n        return None, None\n</code></pre>"},{"location":"reference/#tricys.utils.log_utils.setup_logging","title":"<code>setup_logging(config, original_config=None)</code>","text":"<p>Configures the logging module based on the application configuration.</p> Source code in <code>tricys/utils/log_utils.py</code> <pre><code>def setup_logging(\n    config: Dict[str, Any], original_config: Dict[str, Any] = None\n) -&gt; None:\n    \"\"\"Configures the logging module based on the application configuration.\"\"\"\n    log_config = config.get(\"logging\", {})\n    log_level_str = log_config.get(\"log_level\", \"INFO\").upper()\n    log_level = getattr(logging, log_level_str, logging.INFO)\n    log_to_console = log_config.get(\"log_to_console\", True)\n    run_timestamp = config.get(\"run_timestamp\")\n\n    log_dir_path = config.get(\"paths\", {}).get(\"log_dir\")\n    log_count = log_config.get(\"log_count\", 5)\n\n    root_logger = logging.getLogger()\n    root_logger.setLevel(log_level)\n\n    # Clear any existing handlers to prevent duplicate logs\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n        handler.close()\n\n    formatter = jsonlogger.JsonFormatter(\n        \"%(asctime)s %(name)s %(levelname)s %(message)s\"\n    )\n\n    if log_to_console:\n        console_handler = logging.StreamHandler(sys.stdout)\n        console_handler.setFormatter(formatter)\n        root_logger.addHandler(console_handler)\n\n    if log_dir_path:\n        abs_log_dir = os.path.abspath(log_dir_path)\n        os.makedirs(abs_log_dir, exist_ok=True)\n        delete_old_logs(abs_log_dir, log_count)\n        log_file_path = os.path.join(abs_log_dir, f\"simulation_{run_timestamp}.log\")\n\n        file_handler = logging.FileHandler(log_file_path, mode=\"a\", encoding=\"utf-8\")\n        file_handler.setFormatter(formatter)\n        root_logger.addHandler(file_handler)\n\n        # If a main log path is provided (for analysis cases), add it as an additional handler\n        main_log_path = log_config.get(\"main_log_path\")\n        if main_log_path:\n            try:\n                # Ensure the directory for the main log exists, just in case\n                os.makedirs(os.path.dirname(main_log_path), exist_ok=True)\n\n                main_log_handler = logging.FileHandler(\n                    main_log_path, mode=\"a\", encoding=\"utf-8\"\n                )\n                main_log_handler.setFormatter(formatter)\n                root_logger.addHandler(main_log_handler)\n                logger.info(f\"Also logging to main log file: {main_log_path}\")\n            except Exception as e:\n                logger.warning(\n                    f\"Failed to attach main log handler for {main_log_path}: {e}\"\n                )\n\n        logger.info(f\"Logging to file: {log_file_path}\")\n        # Log the full runtime configuration in a compact JSON format\n        logger.info(\n            f\"Runtime Configuration (compact JSON): {json.dumps(config, separators=(',', ':'), ensure_ascii=False)}\"\n        )\n        if original_config:\n            logger.info(\n                f\"Original Configuration (compact JSON): {json.dumps(original_config, separators=(',', ':'), ensure_ascii=False)}\"\n            )\n</code></pre>"},{"location":"reference/#tricysutilssqlite_utils","title":"<code>tricys.utils.sqlite_utils</code>","text":"<p>Utilities for interacting with the simulation parameter SQLite database.</p> <p>This module provides functions to create, store, update, and retrieve simulation parameter data from a SQLite database file.</p>"},{"location":"reference/#tricys.utils.sqlite_utils.create_parameters_table","title":"<code>create_parameters_table(db_path)</code>","text":"<p>Creates the parameters table in the database if it does not exist.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If a database error occurs during table creation.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def create_parameters_table(db_path: str) -&gt; None:\n    \"\"\"Creates the parameters table in the database if it does not exist.\n\n    Args:\n        db_path (str): The path to the SQLite database file.\n\n    Raises:\n        sqlite3.Error: If a database error occurs during table creation.\n    \"\"\"\n    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n    logger.debug(f\"Ensuring 'parameters' table exists in {db_path}\")\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            cursor.execute(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS parameters (\n                    name TEXT PRIMARY KEY,\n                    type TEXT,\n                    default_value TEXT,\n                    sweep_values TEXT,\n                    description TEXT,\n                    dimensions TEXT\n                )\n            \"\"\"\n            )\n            conn.commit()\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while creating table: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"reference/#tricys.utils.sqlite_utils.get_parameters_from_db","title":"<code>get_parameters_from_db(db_path)</code>","text":"<p>Retrieves parameter details from the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: A list of parameter dictionaries, each containing</p> <code>List[Dict[str, Any]]</code> <p>the name, default_value, description, and sweep_values.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def get_parameters_from_db(db_path: str) -&gt; List[Dict[str, Any]]:\n    \"\"\"Retrieves parameter details from the database.\n\n    Args:\n        db_path (str): The path to the SQLite database file.\n\n    Returns:\n        List[Dict[str, Any]]: A list of parameter dictionaries, each containing\n        the name, default_value, description, and sweep_values.\n    \"\"\"\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(\n            \"SELECT name, default_value, description, sweep_values FROM parameters\"\n        )\n        params = []\n        for name, default_value, description, sweep_values in cursor.fetchall():\n            params.append(\n                {\n                    \"name\": name,\n                    \"default_value\": json.loads(default_value),\n                    \"description\": description,\n                    \"sweep_values\": json.loads(sweep_values) if sweep_values else \"\",\n                }\n            )\n    return params\n</code></pre>"},{"location":"reference/#tricys.utils.sqlite_utils.store_parameters_in_db","title":"<code>store_parameters_in_db(db_path, params_data)</code>","text":"<p>Stores or replaces a list of parameter details in the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <code>params_data</code> <code>List[Dict[str, Any]]</code> <p>A list of dictionaries, where each dictionary contains details for a single parameter.</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If a database error occurs during insertion.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def store_parameters_in_db(db_path: str, params_data: List[Dict[str, Any]]) -&gt; None:\n    \"\"\"Stores or replaces a list of parameter details in the database.\n\n    Args:\n        db_path (str): The path to the SQLite database file.\n        params_data (List[Dict[str, Any]]): A list of dictionaries, where each\n            dictionary contains details for a single parameter.\n\n    Raises:\n        sqlite3.Error: If a database error occurs during insertion.\n    \"\"\"\n    logger.info(f\"Storing {len(params_data)} parameters into '{db_path}'\")\n    if not params_data:\n        logger.warning(\"Parameter data is empty, nothing to store.\")\n        return\n\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            for param in params_data:\n                name = param.get(\"name\")\n                if not name:\n                    continue\n\n                value_json = json.dumps(param.get(\"defaultValue\"))\n                dimensions = param.get(\n                    \"dimensions\", \"()\"\n                )  # Default to '()' if not present\n\n                cursor.execute(\n                    \"\"\"\n                    INSERT OR REPLACE INTO parameters (name, type, default_value, sweep_values, description, dimensions)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                \"\"\",\n                    (\n                        name,\n                        param.get(\"type\", \"Real\"),\n                        value_json,\n                        None,\n                        param.get(\"comment\", \"\"),\n                        dimensions,\n                    ),\n                )\n            conn.commit()\n        logger.info(\"Successfully stored/updated parameters in the database.\")\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while storing parameters: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"reference/#tricys.utils.sqlite_utils.update_sweep_values_in_db","title":"<code>update_sweep_values_in_db(db_path, param_sweep)</code>","text":"<p>Updates the 'sweep_values' for specified parameters in the database.</p> <p>Parameters:</p> Name Type Description Default <code>db_path</code> <code>str</code> <p>The path to the SQLite database file.</p> required <code>param_sweep</code> <code>Dict[str, Any]</code> <p>A dictionary where keys are parameter names and values are the corresponding sweep values (e.g., a list).</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If a database error occurs during the update.</p> Source code in <code>tricys/utils/sqlite_utils.py</code> <pre><code>def update_sweep_values_in_db(db_path: str, param_sweep: Dict[str, Any]) -&gt; None:\n    \"\"\"Updates the 'sweep_values' for specified parameters in the database.\n\n    Args:\n        db_path (str): The path to the SQLite database file.\n        param_sweep (Dict[str, Any]): A dictionary where keys are parameter names\n            and values are the corresponding sweep values (e.g., a list).\n\n    Raises:\n        sqlite3.Error: If a database error occurs during the update.\n    \"\"\"\n    logger.info(f\"Updating sweep values in '{db_path}'\")\n    if not param_sweep:\n        logger.warning(\"param_sweep dictionary is empty. No values to update.\")\n        return\n\n    try:\n        with sqlite3.connect(db_path) as conn:\n            cursor = conn.cursor()\n            for param_name, sweep_values in param_sweep.items():\n                if isinstance(sweep_values, np.ndarray):\n                    sweep_values = sweep_values.tolist()\n\n                sweep_values_json = json.dumps(sweep_values)\n\n                cursor.execute(\n                    \"\"\"\n                    UPDATE parameters SET sweep_values = ? WHERE name = ?\n                \"\"\",\n                    (sweep_values_json, param_name),\n                )\n\n                if cursor.rowcount == 0:\n                    logger.warning(\n                        f\"Parameter '{param_name}' not found in database. No sweep value updated.\"\n                    )\n            conn.commit()\n        logger.info(\"Sweep values updated successfully.\")\n    except sqlite3.Error as e:\n        logger.error(f\"Database error while updating sweep values: {e}\", exc_info=True)\n        raise\n</code></pre>"},{"location":"tutorials/","title":"\u6559\u7a0b\uff08Tutorials\uff09","text":"<p>\u672c\u7ae0\u8282\u901a\u8fc7\u4e00\u7cfb\u5217\u793a\u4f8b\uff0c\u6307\u5bfc\u60a8\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7\u4f7f\u7528 <code>tricys</code> \u7684\u5404\u9879\u529f\u80fd\u3002\u6240\u6709\u793a\u4f8b\u5747\u4f4d\u4e8e\u9879\u76ee\u6839\u76ee\u5f55\u7684 <code>example/</code> \u6587\u4ef6\u5939\u4e0b\u3002</p>"},{"location":"tutorials/#openmodelica","title":"OpenModelica\u6a21\u578b","text":"<p><code>tricys</code> \u7684\u6838\u5fc3\u662f\u57fa\u4e8e OpenModelica \u8fdb\u884c\u7269\u7406\u5efa\u6a21\u548c\u4eff\u771f\u3002\u6240\u6709\u7684\u6a21\u578b\u90fd\u7531 <code>.mo</code> \u6587\u4ef6\u5b9a\u4e49\u3002\u5728 <code>tricys</code> \u4e2d\uff0c\u901a\u5e38\u4f7f\u7528\u4e00\u4e2a <code>package.mo</code> \u6587\u4ef6\u6765\u7ec4\u7ec7\u4e00\u4e2a\u5b8c\u6574\u7684\u6a21\u578b\u5e93\u3002</p> <p>\u60a8\u53ef\u4ee5\u5728 <code>example/example_model/</code> \u76ee\u5f55\u4e2d\u627e\u5230\u4e00\u4e2a\u5b8c\u6574\u7684\u793a\u4f8b\u6a21\u578b\uff0c\u5b83\u5b9a\u4e49\u4e86\u805a\u53d8\u71c3\u6599\u5faa\u73af\u4e2d\u7684\u5404\u4e2a\u5b50\u7cfb\u7edf\uff08\u5982\u589e\u6b96\u5305\u5c42 <code>Blanket</code>\u3001\u540c\u4f4d\u7d20\u5206\u79bb\u7cfb\u7edf <code>I_ISS</code> \u7b49\uff09\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u3002</p>"},{"location":"tutorials/#_1","title":"\u4e2d\u82f1\u6587\u4e13\u4e1a\u672f\u8bed\u8868","text":"<p>\u4e0b\u8868\u6574\u7406\u4e86\u6a21\u578b\u4e2d\u7684\u5173\u952e\u53c2\u6570\u548c\u5206\u6790\u6307\u6807\uff0c\u6458\u81ea <code>example/example_glossary/example_glossary.csv</code>\u3002</p> \u6a21\u578b\u53c2\u6570 (Model Parameter) \u82f1\u6587\u672f\u8bed (English Term) \u4e2d\u6587\u7ffb\u8bd1 (Chinese Translation) \u8bf4\u660e (Explanation) pulseSource.amplitude Pulse Amplitude \u8109\u51b2\u5e45\u5ea6 \u7cfb\u7edf\u9a71\u52a8\uff1a\u8bbe\u5b9a\u6c1a\u7684\u6d88\u8017\u901f\u7387 (g/h)\u3002 pulseSource.period Pulse Period \u8fd0\u884c\u5468\u671f \u6a21\u62df\u201c\u8fd0\u884c-\u505c\u673a\u201d\u7684\u603b\u5faa\u73af\u65f6\u957f\u3002 pulseSource.width Availability Factor \u5360\u7a7a\u6bd4 \u53cd\u5e94\u5806\u8fd0\u884c\u65f6\u95f4\u5360\u603b\u5468\u671f\u7684\u767e\u5206\u6bd4\uff08%\uff09\u3002 blanket.TBR Blanket Tritium Breeding Ratio \u589e\u6b96\u5305\u5c42 \u6c1a\u589e\u6b96\u6bd4 \u71c3\u6599\u81ea\u6301\u7684\u5173\u952e (\u5fc5\u987b &gt; 1)\u3002 blanket.T Blanket Mean Residence Time \u589e\u6b96\u5305\u5c42 \u5e73\u5747\u6ede\u7559\u65f6\u95f4 \u589e\u6b96\u5305\u5c42\u4e2d\u6c1a\u7684\u5e73\u5747\u6ede\u7559\u65f6\u95f4\u3002 i_iss.T I_ISS Mean Residence Time \u540c\u4f4d\u7d20\u5206\u79bbI\u8def \u5e73\u5747\u6ede\u7559\u65f6\u95f4 \u5de5\u827a\u5ef6\u8fdf\uff0cI_ISS\uff08\u4f4e\u6e29\u7cbe\u998f\uff09\u662f\u4e3b\u8981\u7684\u5e93\u5b58\u6301\u6709\u8005\u3002 plasma.fb Plasma Burn Fraction \u7b49\u79bb\u5b50\u4f53 \u71c3\u70e7\u5206\u6570 \u6ce8\u5165\u71c3\u6599\u4e2d\u5b9e\u9645\u805a\u53d8\u7684\u6bd4\u4f8b\u3002 plasma.nf Plasma Fueling Efficiency \u7b49\u79bb\u5b50\u4f53 \u71c3\u6599\u6548\u7387 \u6ce8\u5165\u71c3\u6599\u4e2d\u5b9e\u9645\u8fdb\u5165\u82af\u90e8\u7684\u6bd4\u4f8b\u3002 \u5206\u6790\u6307\u6807 Startup_Inventory Start up Inventory \u542f\u52a8\u5e93\u5b58 \u53cd\u5e94\u5806\u9996\u6b21\u542f\u52a8\u524d\u5fc5\u987b\u63d0\u4f9b\u7684\u521d\u59cb\u6c1a\u5e93\u5b58\u91cf\u3002 Required_TBR Required Tritium Breeding Ratio \u6240\u9700\u6c1a\u589e\u6b96\u6bd4 \u4e3a\u5b9e\u73b0\u6c1a\u81ea\u6301\u6240\u5fc5\u987b\u8fbe\u5230\u7684\u6700\u4f4eTBR\u3002 Doubling_Time Doubling Time (\u5e93\u5b58)\u500d\u589e\u65f6\u95f4 \u4e00\u4e2a\u53cd\u5e94\u5806\u4ea7\u751f\u8db3\u591f\u542f\u52a8\u53e6\u4e00\u4e2a\u65b0\u53cd\u5e94\u5806\u6240\u9700\u6c1a\u5e93\u5b58\u7684\u65f6\u95f4\u3002 Self_Sufficiency_Time Self Sufficiency Time (\u6c1a)\u81ea\u6301\u65f6\u95f4 \u6c1a\u5e93\u5b58\u7531\u4e0b\u964d\u8d8b\u52bf\u8f6c\u53d8\u4e3a\u4e0a\u5347\u8d8b\u52bf\u7684\u62d0\u70b9\u65f6\u95f4\u3002"},{"location":"tutorials/#tricys-basic","title":"TRICYS BASIC","text":"<p>\u8fd9\u90e8\u5206\u4ecb\u7ecd <code>tricys</code> \u7684\u57fa\u7840\u7528\u6cd5\u3002</p>"},{"location":"tutorials/#basic-configuration","title":"\u57fa\u7840\u914d\u7f6e (Basic Configuration)","text":"<p>\u8fd9\u662f\u6700\u7b80\u5355\u7684\u7528\u6cd5\uff1a\u5bf9\u4e00\u4e2a\u7ed9\u5b9a\u7684\u6a21\u578b\u548c\u53c2\u6570\uff0c\u8fd0\u884c\u4e00\u6b21\u4eff\u771f\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/basic/1_basic_configuration/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code># \u786e\u4fdd\u60a8\u5728 tricys \u7684\u9879\u76ee\u6839\u76ee\u5f55\u4e0b\ntricys -c example/basic/1_basic_configuration/basic_configuration.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>basic_configuration.json</code> <pre><code>{\n    \"paths\": {\n        \"package_path\": \"../../example_model_single/example_model.mo\"\n    },\n    \"simulation\": {\n        \"model_name\": \"example_model.Cycle\",\n        \"variableFilter\": \"time|sds.I[1]\",\n        \"stop_time\": 2000.0,\n        \"step_size\": 0.5\n    }\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>package_path</code>: \u6307\u5411\u6a21\u578b\u6587\u4ef6\u3002</li> <li><code>model_name</code>: \u6307\u5b9a\u8981\u4eff\u771f\u7684\u9876\u5c42\u6a21\u578b\u3002</li> <li><code>variableFilter</code>: \u6307\u5b9a\u9700\u8981\u8f93\u51fa\u7684\u53d8\u91cf\uff0c\u7528<code>|</code>\u5206\u9694\u3002</li> <li><code>stop_time</code>, <code>step_size</code>: \u5b9a\u4e49\u4eff\u771f\u65f6\u957f\u548c\u6b65\u957f\u3002</li> </ul>"},{"location":"tutorials/#parameter-sweep","title":"\u53c2\u6570\u626b\u63cf (Parameter Sweep)","text":"<p>\u7814\u7a76\u5355\u4e2a\u6216\u591a\u4e2a\u53c2\u6570\u53d8\u5316\u5bf9\u4eff\u771f\u7ed3\u679c\u7684\u5f71\u54cd\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/basic/2_parameter_sweep/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys -c example/basic/2_parameter_sweep/parameter_sweep.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>parameter_sweep.json</code> <pre><code>{\n    // ... simulation\u90e8\u5206\u4e0e\u57fa\u7840\u914d\u7f6e\u76f8\u540c ...\n    \"simulation_parameters\": {\n        \"tep_fep.to_SDS_Fraction[1]\":[0.1,0.15,0.2,0.3,0.4,0.6,0.8]\n    }\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>simulation_parameters</code>: \u5728\u8fd9\u91cc\u5b9a\u4e49\u8981\u626b\u63cf\u7684\u53c2\u6570\u3002</li> <li><code>\"tep_fep.to_SDS_Fraction[1]\"</code>: \u8981\u626b\u63cf\u7684\u6a21\u578b\u53c2\u6570\u540d\u3002</li> <li><code>[0.1, 0.15, ...]</code> : \u4e00\u4e2a\u5305\u542b\u6240\u6709\u626b\u63cf\u503c\u7684\u5217\u8868\u3002<code>tricys</code>\u4f1a\u4e3a\u5217\u8868\u4e2d\u7684\u6bcf\u4e2a\u503c\u8fd0\u884c\u4e00\u6b21\u4eff\u771f\u3002</li> </ul>"},{"location":"tutorials/#concurrent-operation","title":"\u5e76\u53d1\u8fd0\u884c (Concurrent operation)","text":"<p>\u5f53\u53c2\u6570\u626b\u63cf\u4efb\u52a1\u5f88\u591a\u65f6\uff0c\u53ef\u4ee5\u5f00\u542f\u5e76\u53d1\u8fd0\u884c\u4ee5\u5229\u7528\u591a\u6838CPU\u52a0\u901f\u8ba1\u7b97\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/basic/3_concurrent_operation/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys -c example/basic/3_concurrent_operation/concurrent_operation.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>concurrent_operation.json</code> <pre><code>{\n    \"simulation\": {\n        // ...\n        \"concurrent\": true\n    },\n    \"simulation_parameters\": {\n        \"blanket.TBR\": \"linspace:1:1.5:10\"\n    }\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>\"concurrent\": true</code>: \u5f00\u542f\u5e76\u53d1\u6a21\u5f0f\u3002</li> <li><code>\"linspace:1:1.5:10\"</code>: \u4e00\u79cd\u9ad8\u7ea7\u53c2\u6570\u5b9a\u4e49\u683c\u5f0f\uff0c\u8868\u793a\u57281\u52301.5\u4e4b\u95f4\u751f\u621010\u4e2a\u7b49\u95f4\u8ddd\u7684\u6570\u503c\u8fdb\u884c\u626b\u63cf\u3002</li> </ul>"},{"location":"tutorials/#post-processing-module","title":"\u540e\u5904\u7406\u6a21\u5757 (Post-processing module)","text":"<p>\u5728\u4eff\u771f\u7ed3\u675f\u540e\uff0c\u81ea\u52a8\u8c03\u7528Python\u811a\u672c\u5bf9\u7ed3\u679c\u8fdb\u884c\u5206\u6790\u3001\u7ed8\u56fe\u6216\u751f\u6210\u62a5\u544a\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/basic/4_post_processing_module/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys -c example/basic/4_post_processing_module/post_processing_module.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>post_processing_module.json</code> <pre><code>{\n    // ... simulation_parameters \u5b9a\u4e49\u4e86\u4e8c\u7ef4\u626b\u63cf ...\n    \"post_processing\": [\n        {\n            \"module\": \"tricys.postprocess.rise_analysis\",\n            \"function\": \"analyze_rise_dip\",\n            \"params\": { \"output_filename\": \"rise_report.json\" }\n        },\n        {\n            \"module\": \"tricys.postprocess.static_alarm\",\n            \"function\": \"check_thresholds\",\n            \"params\": { /* ... */ }\n        }\n    ]\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>post_processing</code>: \u4e00\u4e2a\u5217\u8868\uff0c\u5b9a\u4e49\u4e86\u8981\u6267\u884c\u7684\u540e\u5904\u7406\u4efb\u52a1\u3002</li> <li><code>module</code>, <code>function</code>: \u6307\u5b9a\u8981\u8c03\u7528\u7684Python\u6a21\u5757\u548c\u51fd\u6570\u3002</li> <li><code>params</code>: \u4f20\u9012\u7ed9\u8be5\u51fd\u6570\u7684\u53c2\u6570\u3002</li> </ul>"},{"location":"tutorials/#co-simulation-module","title":"\u534f\u540c\u4eff\u771f\u6a21\u5757 (Co-simulation module)","text":"<p>\u5c06 Modelica \u6a21\u578b\u4e0e\u5916\u90e8\u7a0b\u5e8f\uff08\u5982Aspen Plus\u3001Python\u811a\u672c\uff09\u8fde\u63a5\u8d77\u6765\uff0c\u5b9e\u73b0\u6df7\u5408\u4eff\u771f\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/basic/5_co_simulation_module/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys -c example/basic/5_co_simulation_module/co_simulation_module.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>co_simulation_module.json</code> <pre><code>{\n    // ...\n    \"co_simulation\": [\n        {\n            \"submodel_name\": \"example_model.DIV\",\n            \"instance_name\": \"div\",\n            \"handler_module\": \"tricys.handlers.div_handler\",\n            \"handler_function\": \"run_div_simulation\",\n            \"params\": { /* ... */ }\n        },\n        {\n            \"submodel_name\": \"example_model.I_ISS\",\n            \"instance_name\": \"i_iss\",\n            \"handler_module\": \"tricys.handlers.i_iss_handler\",\n            \"handler_function\": \"run_aspen_simulation\",\n            \"params\": {\n                \"bkp_path\": \"../../example_aspenbkp/T2-Threetowers4.bkp\",\n                // ...\n            }\n        }\n    ]\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>co_simulation</code>: \u5b9a\u4e49\u534f\u540c\u4eff\u771f\u4efb\u52a1\u5217\u8868\u3002</li> <li><code>submodel_name</code>: \u8981\u88ab\u5916\u90e8\u7a0b\u5e8f\u66ff\u4ee3\u7684Modelica\u5b50\u6a21\u578b\u3002</li> <li><code>handler_module</code>, <code>handler_function</code>: \u6307\u5b9a\u7528\u4e8e\u66ff\u4ee3\u8be5\u5b50\u6a21\u578b\u7684Python\u5904\u7406\u51fd\u6570\u3002</li> <li><code>params</code>: \u4f20\u9012\u7ed9\u5904\u7406\u51fd\u6570\u7684\u53c2\u6570\uff0c\u4f8b\u5982Aspen Plus\u6a21\u578b\u6587\u4ef6\u8def\u5f84 <code>bkp_path</code>\u3002</li> </ul>"},{"location":"tutorials/#tricys-analysis","title":"TRICYS ANALYSIS","text":"<p>\u8fd9\u90e8\u5206\u4ecb\u7ecd <code>tricys</code> \u5185\u7f6e\u7684\u9ad8\u7ea7\u5206\u6790\u529f\u80fd\uff0c\u901a\u8fc7 <code>sensitivity_analysis</code> \u914d\u7f6e\u5757\u5b9e\u73b0\u3002</p>"},{"location":"tutorials/#baseline-condition-analysis","title":"\u57fa\u51c6\u5de5\u51b5\u5206\u6790 (Baseline condition analysis)","text":"<p>\u5bf9\u5355\u6b21\u4eff\u771f\u7ed3\u679c\u8fdb\u884c\u8be6\u7ec6\u7684\u540e\u5904\u7406\u5206\u6790\uff0c\u5e76\u751f\u6210\u683c\u5f0f\u5316\u7684\u62a5\u544a\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/analysis/1_baseline_condition_analysis/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys-ana -c example/analysis/1_baseline_condition_analysis/baseline_condition_analysis.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>baseline_condition_analysis.json</code> <pre><code>{\n    // ... simulation ...\n    \"post_processing\": [\n        {\n           \"module\": \"tricys.postprocess.baseline_analysis\",\n           \"function\": \"baseline_analysis\",\n           \"params\": {\n                \"detailed_var\": \"sds.I[1]\",\n                \"glossary_path\": \"../../example_glossary/example_glossary.csv\"\n            }\n        }\n    ]\n}\n</code></pre> \u8bf4\u660e: \u6b64\u529f\u80fd\u901a\u8fc7\u4e00\u4e2a\u4e13\u7528\u7684\u540e\u5904\u7406\u811a\u672c <code>baseline_analysis</code> \u5b9e\u73b0\uff0c\u5b83\u4f1a\u52a0\u8f7d\u4eff\u771f\u7ed3\u679c\u548c\u672f\u8bed\u8868\uff0c\u751f\u6210\u4e00\u4efd\u56fe\u6587\u5e76\u8302\u7684\u57fa\u51c6\u5de5\u51b5\u5206\u6790\u62a5\u544a\u3002</li> </ul>"},{"location":"tutorials/#single-parameter-sensitivity-analysis","title":"\u5355\u53c2\u6570\u654f\u611f\u6027\u5206\u6790 (Single-parameter sensitivity analysis)","text":"<p>\u7cfb\u7edf\u5730\u7814\u7a76\u5355\u4e2a\u72ec\u7acb\u53c2\u6570\u7684\u53d8\u5316\u5bf9\u591a\u4e2a\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5982\u542f\u52a8\u5e93\u5b58\u3001\u81ea\u6301\u65f6\u95f4\uff09\u7684\u5f71\u54cd\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/analysis/2_single_parameter_sensitivity_analysis/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys-ana -c example/analysis/2_single_parameter_sensitivity_analysis/single_parameter_sensitivity_analysis.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>single_parameter_sensitivity_analysis.json</code> <pre><code>{\n    \"sensitivity_analysis\": {\n        \"enabled\": true,\n        \"analysis_cases\": [\n            {\n                \"name\": \"TBR_Analysis\",\n                \"independent_variable\": \"blanket.TBR\",\n                \"independent_variable_sampling\": [1.05,1.1,1.15,1.2],\n                \"dependent_variables\": [\n                    \"Startup_Inventory\",\n                    \"Self_Sufficiency_Time\",\n                    \"Doubling_Time\"\n                ],\n                // ...\n            }\n        ],\n        \"metrics_definition\": {\n            \"Startup_Inventory\": {\n                \"source_column\": \"sds.I[1]\",\n                \"method\": \"calculate_startup_inventory\"\n            },\n            // ...\n        }\n    }\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>sensitivity_analysis</code>: \u654f\u611f\u6027\u5206\u6790\u7684\u603b\u5f00\u5173\u548c\u914d\u7f6e\u3002</li> <li><code>analysis_cases</code>: \u5b9a\u4e49\u4e00\u4e2a\u6216\u591a\u4e2a\u5206\u6790\u6848\u4f8b\u3002</li> <li><code>independent_variable</code>: \u8981\u6539\u53d8\u7684\u81ea\u53d8\u91cf\u3002</li> <li><code>dependent_variables</code>: \u8981\u89c2\u5bdf\u7684\u56e0\u53d8\u91cf\uff08\u6027\u80fd\u6307\u6807\uff09\u3002</li> <li><code>metrics_definition</code>: \u5b9a\u4e49\u5982\u4f55\u4ece\u539f\u59cb\u4eff\u771f\u7ed3\u679c\uff08\u5982<code>sds.I[1]</code>\u7684\u65f6\u95f4\u5e8f\u5217\uff09\u8ba1\u7b97\u51fa\u6027\u80fd\u6307\u6807\uff08\u5982<code>Startup_Inventory</code>\uff09\u3002</li> </ul>"},{"location":"tutorials/#multi-parameter-sensitivity-analysis","title":"\u591a\u53c2\u6570\u654f\u611f\u6027\u5206\u6790 (Multi-parameter sensitivity analysis)","text":"<p>\u540c\u65f6\u7814\u7a76\u591a\u4e2a\u53c2\u6570\u53d8\u5316\u5bf9\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\uff0c\u5e38\u7528\u4e8e\u751f\u6210\u4e8c\u7ef4\u56fe\u8c31\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/analysis/3_multi_parameter_sensitivity_analysis/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys-ana -c example/analysis/3_multi_parameter_sensitivity_analysis/multi_parameter_sensitivity_analysis.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>multi_parameter_sensitivity_analysis.json</code> <pre><code>{\n    \"sensitivity_analysis\": {\n        // ...\n        \"analysis_cases\": [\n            {\n                \"name\": \"DIR_PLASMA_Analysis\",\n                \"independent_variable\": \"tep_fep.to_SDS_Fraction[1]\",\n                \"independent_variable_sampling\": [0.1,0.3,0.6,0.8],\n                \"dependent_variables\": [\"Startup_Inventory\", \"Required_TBR\"],\n                \"simulation_parameters\": {\n                    \"plasma.fb\": [0.02,0.04,0.08,0.09,0.1]\n                }\n            }\n        ]\n    }\n}\n</code></pre> \u8bf4\u660e: \u4e0e\u5355\u53c2\u6570\u5206\u6790\u7c7b\u4f3c\uff0c\u4f46\u5728 <code>analysis_cases</code> \u4e2d\u989d\u5916\u589e\u52a0\u4e86\u4e00\u4e2a <code>simulation_parameters</code> \u5757\uff0c\u7528\u4e8e\u5b9a\u4e49\u7b2c\u4e8c\u4e2a\u626b\u63cf\u7ef4\u5ea6\u3002</li> </ul>"},{"location":"tutorials/#sobol-sobol-global-sensitivity-analysis","title":"SOBOL\u5168\u5c40\u654f\u611f\u6027\u5206\u6790 (SOBOL global sensitivity analysis)","text":"<p>\u4f7f\u7528 Sobol' \u65b9\u6cd5\uff0c\u5728\u591a\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u8fdb\u884c\u91c7\u6837\u548c\u5206\u6790\uff0c\u91cf\u5316\u6bcf\u4e2a\u53c2\u6570\u5bf9\u8f93\u51fa\u65b9\u5dee\u7684\u8d21\u732e\uff0c\u4ece\u800c\u8bc6\u522b\u51fa\u6700\u91cd\u8981\u7684\u5f71\u54cd\u53c2\u6570\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/analysis/4_sobol_global_sensitivity_analysis/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys-ana -c example/analysis/4_sobol_global_sensitivity_analysis/sobol_global_sensitivity_analysis.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>sobol_global_sensitivity_analysis.json</code> <pre><code>{\n    \"sensitivity_analysis\": {\n        \"analysis_cases\": [\n            {\n                \"name\": \"SALIB_SOBOL_Analysis\",\n                \"independent_variable\":[\"pulseSource.width\",\"plasma.nf\", ...],\n                \"independent_variable_sampling\":{\n                      \"pulseSource.width\": { \"bounds\": [50,90] },\n                      // ...\n                },\n                \"analyzer\": {\n                    \"method\": \"sobol\",\n                    \"sample_N\": 256\n                }\n            }\n        ]\n    }\n}\n</code></pre> \u8bf4\u660e:</li> <li><code>independent_variable</code>: \u53d8\u4e3a\u4e00\u4e2a\u5305\u542b\u591a\u4e2a\u53c2\u6570\u7684\u5217\u8868\u3002</li> <li><code>independent_variable_sampling</code>: \u5b9a\u4e49\u6bcf\u4e2a\u53c2\u6570\u7684\u91c7\u6837\u8fb9\u754c <code>bounds</code>\u3002</li> <li><code>analyzer</code>: \u6307\u5b9a\u4f7f\u7528 <code>sobol</code> \u65b9\u6cd5\uff0c\u5e76\u8bbe\u7f6e\u91c7\u6837\u6570 <code>sample_N</code>\u3002</li> </ul>"},{"location":"tutorials/#latin-latin-uncertainty-analysis","title":"LATIN\u4e0d\u786e\u5b9a\u6027\u5206\u6790 (LATIN Uncertainty Analysis)","text":"<p>\u4f7f\u7528\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837 (Latin Hypercube Sampling) \u65b9\u6cd5\uff0c\u5728\u591a\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u9ad8\u6548\u5730\u91c7\u6837\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u8303\u56f4\u3002</p> <ul> <li>\u793a\u4f8b\u76ee\u5f55: <code>example/analysis/5_latin_uncertainty_analysis/</code></li> <li>\u8fd0\u884c\u547d\u4ee4:   <pre><code>tricys-ana -c example/analysis/5_latin_uncertainty_analysis/latin_uncertainty_analysis.json\n</code></pre></li> <li>\u914d\u7f6e\u6587\u4ef6: <code>latin_uncertainty_analysis.json</code> <pre><code>{\n    \"sensitivity_analysis\": {\n        \"analysis_cases\": [\n            {\n                // ... \u4e0eSobol\u914d\u7f6e\u7c7b\u4f3c ...\n                \"analyzer\": {\n                    \"method\": \"latin\",\n                    \"sample_N\": 256\n                }\n            }\n        ]\n    }\n}\n</code></pre> \u8bf4\u660e: \u914d\u7f6e\u4e0eSobol\u5206\u6790\u51e0\u4e4e\u5b8c\u5168\u76f8\u540c\uff0c\u53ea\u662f\u5c06 <code>analyzer.method</code> \u66f4\u6539\u4e3a <code>latin</code>\u3002</li> </ul>"},{"location":"zh/","title":"TRICYS: Tritium Integrated Cycle Simulation","text":"<p>Welcome to the TRitium Integrated CYcle Simulation (TRICYS) project. TRICYS is an open-source, 0D system modeling tool designed for simulating the complex tritium fuel cycle in fusion power plants.</p> <p>Our goal is to provide a flexible and robust platform for researchers and engineers to explore various tritium management strategies, optimize system designs, and understand the dynamics of tritium flow and inventory within a fusion reactor environment.</p> <p>We welcome contributions from the community! Whether you're a fusion scientist, a software engineer, or just passionate about open-source, there are many ways to contribute to TRICYS.</p> <p>Get Started with TRICYS Report an Issue</p>"},{"location":"zh/#what-can-tricys-do","title":"What Can TRICYS Do?","text":"<p>TRICYS allows you to:</p> <ul> <li>Simulate Key Subsystems: Model various components of the tritium fuel cycle, including the plasma exhaust processing, isotope separation, fuel storage, and emergency detritiation systems.</li> <li>Analyze Tritium Inventory: Track tritium levels throughout the plant to ensure safety and operational efficiency.</li> <li>Rapid Prototyping: Quickly set up and run simulations for different plant configurations and operational scenarios.</li> <li>Open and Extensible: Built with Python, TRICYS is designed to be easily modified and extended by the community.</li> </ul>"},{"location":"zh/#why-tricys","title":"Why TRICYS?","text":"<ul> <li>Accuracy &amp; Flexibility: Combine detailed physics models with a highly configurable system architecture.</li> <li>Community Driven: Benefit from collaborative development and transparent decision-making.</li> <li>Educational Tool: A great resource for students and new researchers to understand fusion fuel cycle dynamics.</li> </ul>"},{"location":"zh/changelog/","title":"\u66f4\u65b0\u65e5\u5fd7","text":""},{"location":"zh/changelog/#100-2025-11-15","title":"1.0.0 - (2025-11-15)","text":"<p>Info</p> <ul> <li>1</li> <li>2</li> </ul>"},{"location":"zh/license/","title":"\u5f00\u6e90\u8bb8\u53ef","text":"<pre><code>                                                              Apache License\n                                                        Version 2.0, January 2004\n                                                     http://www.apache.org/licenses/\n\n                                TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n                                1. Definitions.\n\n                                   \"License\" shall mean the terms and conditions for use, reproduction,\n                                   and distribution as defined by Sections 1 through 9 of this document.\n\n                                   \"Licensor\" shall mean the copyright owner or entity authorized by\n                                   the copyright owner that is granting the License.\n\n                                   \"Legal Entity\" shall mean the union of the acting entity and all\n                                   other entities that control, are controlled by, or are under common\n                                   control with that entity. For the purposes of this definition,\n                                   \"control\" means (i) the power, direct or indirect, to cause the\n                                   direction or management of such entity, whether by contract or\n                                   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n                                   outstanding shares, or (iii) beneficial ownership of such entity.\n\n                                   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n                                   exercising permissions granted by this License.\n\n                                   \"Source\" form shall mean the preferred form for making modifications,\n                                   including but not limited to software source code, documentation\n                                   source, and configuration files.\n\n                                   \"Object\" form shall mean any form resulting from mechanical\n                                   transformation or translation of a Source form, including but\n                                   not limited to compiled object code, generated documentation,\n                                   and conversions to other media types.\n\n                                   \"Work\" shall mean the work of authorship, whether in Source or\n                                   Object form, made available under the License, as indicated by a\n                                   copyright notice that is included in or attached to the work\n                                   (an example is provided in the Appendix below).\n\n                                   \"Derivative Works\" shall mean any work, whether in Source or Object\n                                   form, that is based on (or derived from) the Work and for which the\n                                   editorial revisions, annotations, elaborations, or other modifications\n                                   represent, as a whole, an original work of authorship. For the purposes\n                                   of this License, Derivative Works shall not include works that remain\n                                   separable from, or merely link (or bind by name) to the interfaces of,\n                                   the Work and Derivative Works thereof.\n\n                                   \"Contribution\" shall mean any work of authorship, including\n                                   the original version of the Work and any modifications or additions\n                                   to that Work or Derivative Works thereof, that is intentionally\n                                   submitted to Licensor for inclusion in the Work by the copyright owner\n                                   or by an individual or Legal Entity authorized to submit on behalf of\n                                   the copyright owner. For the purposes of this definition, \"submitted\"\n                                   means any form of electronic, verbal, or written communication sent\n                                   to the Licensor or its representatives, including but not limited to\n                                   communication on electronic mailing lists, source code control systems,\n                                   and issue tracking systems that are managed by, or on behalf of, the\n                                   Licensor for the purpose of discussing and improving the Work, but\n                                   excluding communication that is conspicuously marked or otherwise\n                                   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n                                   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n                                   on behalf of whom a Contribution has been received by Licensor and\n                                   subsequently incorporated within the Work.\n\n                                2. Grant of Copyright License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   copyright license to reproduce, prepare Derivative Works of,\n                                   publicly display, publicly perform, sublicense, and distribute the\n                                   Work and such Derivative Works in Source or Object form.\n\n                                3. Grant of Patent License. Subject to the terms and conditions of\n                                   this License, each Contributor hereby grants to You a perpetual,\n                                   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n                                   (except as stated in this section) patent license to make, have made,\n                                   use, offer to sell, sell, import, and otherwise transfer the Work,\n                                   where such license applies only to those patent claims licensable\n                                   by such Contributor that are necessarily infringed by their\n                                   Contribution(s) alone or by combination of their Contribution(s)\n                                   with the Work to which such Contribution(s) was submitted. If You\n                                   institute patent litigation against any entity (including a\n                                   cross-claim or counterclaim in a lawsuit) alleging that the Work\n                                   or a Contribution incorporated within the Work constitutes direct\n                                   or contributory patent infringement, then any patent licenses\n                                   granted to You under this License for that Work shall terminate\n                                   as of the date such litigation is filed.\n\n                                4. Redistribution. You may reproduce and distribute copies of the\n                                   Work or Derivative Works thereof in any medium, with or without\n                                   modifications, and in Source or Object form, provided that You\n                                   meet the following conditions:\n\n                                   (a) You must give any other recipients of the Work or\n                                       Derivative Works a copy of this License; and\n\n                                   (b) You must cause any modified files to carry prominent notices\n                                       stating that You changed the files; and\n\n                                   (c) You must retain, in the Source form of any Derivative Works\n                                       that You distribute, all copyright, patent, trademark, and\n                                       attribution notices from the Source form of the Work,\n                                       excluding those notices that do not pertain to any part of\n                                       the Derivative Works; and\n\n                                   (d) If the Work includes a \"NOTICE\" text file as part of its\n                                       distribution, then any Derivative Works that You distribute must\n                                       include a readable copy of the attribution notices contained\n                                       within such NOTICE file, excluding those notices that do not\n                                       pertain to any part of the Derivative Works, in at least one\n                                       of the following places: within a NOTICE text file distributed\n                                       as part of the Derivative Works; within the Source form or\n                                       documentation, if provided along with the Derivative Works; or,\n                                       within a display generated by the Derivative Works, if and\n                                       wherever such third-party notices normally appear. The contents\n                                       of the NOTICE file are for informational purposes only and\n                                       do not modify the License. You may add Your own attribution\n                                       notices within Derivative Works that You distribute, alongside\n                                       or as an addendum to the NOTICE text from the Work, provided\n                                       that such additional attribution notices cannot be construed\n                                       as modifying the License.\n\n                                   You may add Your own copyright statement to Your modifications and\n                                   may provide additional or different license terms and conditions\n                                   for use, reproduction, or distribution of Your modifications, or\n                                   for any such Derivative Works as a whole, provided Your use,\n                                   reproduction, and distribution of the Work otherwise complies with\n                                   the conditions stated in this License.\n\n                                5. Submission of Contributions. Unless You explicitly state otherwise,\n                                   any Contribution intentionally submitted for inclusion in the Work\n                                   by You to the Licensor shall be under the terms and conditions of\n                                   this License, without any additional terms or conditions.\n                                   Notwithstanding the above, nothing herein shall supersede or modify\n                                   the terms of any separate license agreement you may have executed\n                                   with Licensor regarding such Contributions.\n\n                                6. Trademarks. This License does not grant permission to use the trade\n                                   names, trademarks, service marks, or product names of the Licensor,\n                                   except as required for reasonable and customary use in describing the\n                                   origin of the Work and reproducing the content of the NOTICE file.\n\n                                7. Disclaimer of Warranty. Unless required by applicable law or\n                                   agreed to in writing, Licensor provides the Work (and each\n                                   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n                                   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n                                   implied, including, without limitation, any warranties or conditions\n                                   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n                                   PARTICULAR PURPOSE. You are solely responsible for determining the\n                                   appropriateness of using or redistributing the Work and assume any\n                                   risks associated with Your exercise of permissions under this License.\n\n                                8. Limitation of Liability. In no event and under no legal theory,\n                                   whether in tort (including negligence), contract, or otherwise,\n                                   unless required by applicable law (such as deliberate and grossly\n                                   negligent acts) or agreed to in writing, shall any Contributor be\n                                   liable to You for damages, including any direct, indirect, special,\n                                   incidental, or consequential damages of any character arising as a\n                                   result of this License or out of the use or inability to use the\n                                   Work (including but not limited to damages for loss of goodwill,\n                                   work stoppage, computer failure or malfunction, or any and all\n                                   other commercial damages or losses), even if such Contributor\n                                   has been advised of the possibility of such damages.\n\n                                9. Accepting Warranty or Additional Liability. While redistributing\n                                   the Work or Derivative Works thereof, You may choose to offer,\n                                   and charge a fee for, acceptance of support, warranty, indemnity,\n                                   or other liability obligations and/or rights consistent with this\n                                   License. However, in accepting such obligations, You may act only\n                                   on Your own behalf and on Your sole responsibility, not on behalf\n                                   of any other Contributor, and only if You agree to indemnify,\n                                   defend, and hold each Contributor harmless for any liability\n                                   incurred by, or claims asserted against, such Contributor by reason\n                                   of your accepting any such warranty or additional liability.\n\n                                END OF TERMS AND CONDITIONS\n\n                                APPENDIX: How to apply the Apache License to your work.\n\n                                   To apply the Apache License to your work, attach the following\n                                   boilerplate notice, with the fields enclosed by brackets \"[]\"\n                                   replaced with your own identifying information. (Don't include\n                                   the brackets!)  The text should be enclosed in the appropriate\n                                   comment syntax for the file format. We also recommend that a\n                                   file or class name and description of purpose be included on the\n                                   same \"printed page\" as the copyright notice for easier\n                                   identification within third-party archives.\n\n                                Copyright [yyyy] [name of copyright owner]\n\n                                Licensed under the Apache License, Version 2.0 (the \"License\");\n                                you may not use this file except in compliance with the License.\n                                You may obtain a copy of the License at\n\n                                    http://www.apache.org/licenses/LICENSE-2.0\n\n                                Unless required by applicable law or agreed to in writing, software\n                                distributed under the License is distributed on an \"AS IS\" BASIS,\n                                WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n                                See the License for the specific language governing permissions and\n                                limitations under the License.\n</code></pre>"},{"location":"zh/questions/","title":"\u64cd\u4f5c\u6307\u5357\uff08Q&amp;A\uff09","text":""},{"location":"zh/questions/#_1","title":"\u5982\u4f55\u8fd0\u884c\u4eff\u771f\uff1f","text":"<p><code>tricys</code> \u63d0\u4f9b\u547d\u4ee4\u884c (CLI) \u548c\u56fe\u5f62\u754c\u9762 (GUI) \u4e24\u79cd\u65b9\u5f0f\u3002</p> <ul> <li>CLI (\u547d\u4ee4\u884c):</li> <li>\u57fa\u7840\u548c\u534f\u540c\u4eff\u771f: <code>tricys -c &lt;your_config.json&gt;</code></li> <li>\u9ad8\u7ea7\u654f\u611f\u6027\u5206\u6790: <code>tricys-ana -c &lt;your_analysis_config.json&gt;</code></li> </ul> <p>CLI\u6a21\u5f0f\u901a\u8fc7JSON\u914d\u7f6e\u6587\u4ef6\u9a71\u52a8\uff0c\u9002\u5408\u81ea\u52a8\u5316\u548c\u6279\u91cf\u4efb\u52a1\u3002</p> <ul> <li>GUI (\u56fe\u5f62\u754c\u9762):</li> <li>\u542f\u52a8\u547d\u4ee4: <code>tricys-gui</code></li> <li>\u6838\u5fc3\u6b65\u9aa4:<ol> <li>\u8bbe\u7f6e\u5de5\u4f5c\u533a: \u542f\u52a8\u540e\uff0c\u9996\u5148\u8bbe\u7f6e\u5de5\u4f5c\u76ee\u5f55\u3002</li> <li>\u52a0\u8f7d\u6a21\u578b: \u586b\u5199\u6a21\u578b\u8def\u5f84 (<code>package.mo</code>) \u548c\u6570\u636e\u5e93\u8def\u5f84 (<code>.db</code>)\uff0c\u7136\u540e\u70b9\u51fb <code>Load Model to DB</code>\u3002\u53c2\u6570\u8868\u683c\u5c06\u88ab\u586b\u5145\u3002</li> <li>\u5b9a\u4e49\u626b\u63cf: \u5728\u53c2\u6570\u8868\u683c\u7684 <code>Sweep Value</code> \u5217\u4e2d\u586b\u5165\u626b\u63cf\u503c\uff08\u5982 <code>[1,2,3]</code> \u6216 <code>\"linspace:1:10:5\"</code>\uff09\u3002</li> <li>\u8fd0\u884c: \u70b9\u51fb <code>Run Simulation</code>\u3002</li> <li>\u76d1\u63a7: \u70b9\u51fb <code>Open the log window</code> \u67e5\u770b\u5b9e\u65f6\u65e5\u5fd7\u3002</li> </ol> </li> </ul>"},{"location":"zh/questions/#_2","title":"\u5982\u4f55\u7406\u89e3\u8f93\u51fa\u6587\u4ef6\uff1f","text":"<p>\u6bcf\u6b21\u8fd0\u884c\u90fd\u4f1a\u5728\u7ed3\u679c\u76ee\u5f55 (<code>results_dir</code>) \u5185\u521b\u5efa\u4e00\u4e2a\u4ee5\u65f6\u95f4\u6233\u547d\u540d\u7684\u5b50\u76ee\u5f55\uff0c\u5982 <code>results/20230901_103000/</code>\u3002</p> <ul> <li><code>simulation_result.csv</code>: \u5355\u6b21\u8fd0\u884c\u7684\u7ed3\u679c\uff0c\u5305\u542b\u53d8\u91cf\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6570\u636e\u3002</li> <li><code>sweep_results.csv</code>: \u53c2\u6570\u626b\u63cf\u7684\u6c47\u603b\u7ed3\u679c\u3002\u7b2c\u4e00\u5217\u662f\u65f6\u95f4\uff0c\u5176\u4f59\u5217\u662f\u6bcf\u6b21\u4eff\u771f\u8fd0\u884c\u7684\u7ed3\u679c\uff0c\u5217\u540d\u7531\u53c2\u6570\u540d\u548c\u503c\u6784\u6210\uff08\u5982 <code>blanket.TBR=1.1_i_iss.T=6</code>\uff09\u3002</li> <li><code>*_sensitivity_analysis.png</code>/<code>.csv</code>: \u654f\u611f\u6027\u5206\u6790\u751f\u6210\u7684\u56fe\u8868\u548c\u6570\u636e\u3002</li> <li><code>*_sobol_analysis.png</code>/<code>.csv</code>: Sobol\u5206\u6790\u7684\u7ed3\u679c\u3002</li> </ul>"},{"location":"zh/questions/#_3","title":"\u5982\u4f55\u5b9a\u4e49\u590d\u6742\u7684\u53c2\u6570\u626b\u63cf\uff1f","text":"<p>\u5728JSON\u914d\u7f6e\u6587\u4ef6\u6216GUI\u7684<code>Sweep Value</code>\u8f93\u5165\u6846\u4e2d\uff0c\u652f\u6301\u591a\u79cd\u9ad8\u7ea7\u683c\u5f0f\uff1a</p> \u529f\u80fd \u683c\u5f0f \u793a\u4f8b \u8bf4\u660e \u5217\u8868 <code>[v1, v2, ...]</code> <code>[6, 12, 18]</code> \u4e00\u7ec4\u79bb\u6563\u503c\u3002 \u8303\u56f4 <code>\"start:stop:step\"</code> <code>\"1.05:1.15:0.05\"</code> \u7b49\u5dee\u5e8f\u5217\u3002 \u7ebf\u6027\u95f4\u9694 <code>\"linspace:start:stop:num\"</code> <code>\"linspace:10:20:5\"</code> <code>num</code> \u4e2a\u7b49\u95f4\u8ddd\u70b9\u3002 \u5bf9\u6570\u95f4\u9694 <code>\"log:start:stop:num\"</code> <code>\"log:1:1000:4\"</code> <code>num</code> \u4e2a\u5bf9\u6570\u5c3a\u5ea6\u7684\u70b9\u3002 \u4ece\u6587\u4ef6\u8bfb\u53d6 <code>\"file:path:column\"</code> <code>\"file:data.csv:voltage\"</code> \u4eceCSV\u6587\u4ef6\u7684\u6307\u5b9a\u5217\u8bfb\u53d6\u3002"}]}